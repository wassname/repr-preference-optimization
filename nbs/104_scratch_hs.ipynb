{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange, reduce, repeat\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Numeric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(dataset='us_history_textbook', verbose=1, dev=False, load_in_4bit=False, load_in_8bit=False, use_gradient_checkpointing=False, batch_size=2, n_samples=5400, eval_samples=None, max_length=196, max_prompt_length=96, base_model='wassname/llama-3-2-1b-sft', save=True, wandb=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reprpo.interventions.config import ExperimentConfig\n",
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "args = ExperimentConfig(batch_size=2)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model(args.base_model, load_in_4bit=args.load_in_4bit,  load_in_8bit=args.load_in_8bit,  \n",
    "                            #   attn_implementation='eager' # for gemma\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_config = LoraConfig(\n",
    "#     r=64,\n",
    "#     lora_alpha=16,\n",
    "#     use_rslora=True,\n",
    "#     # use_dora=True,\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     # target_modules=[\"all-linear\"], #  QLoRA-style training\n",
    "# )\n",
    "# # if hasattr(PL_MODEL, 'setup_grad_proj'):\n",
    "# #     peft_config = PL_MODEL.setup_grad_proj(peft_config)\n",
    "\n",
    "# model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "# print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from reprpo.data.collate3 import TokenizeRow\n",
    "\n",
    "def ds2dl(ds):\n",
    "    return DataLoader(\n",
    "        ds\n",
    "        .select_columns([\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"])\n",
    "        .with_format(\"torch\"),\n",
    "        batch_size=args.batch_size,\n",
    "    )\n",
    "\n",
    "tokenize_row = TokenizeRow(\n",
    "    tokenizer,\n",
    "    max_length=args.max_length,\n",
    "    max_prompt_length=args.max_prompt_length,\n",
    ")\n",
    "ds_train = load_dataset(\"wassname/genies_preferences\", name=args.dataset)\n",
    "ds_train_tok = ds_train.map(tokenize_row, batched=False)    \n",
    "dl_train = ds2dl(ds_train_tok[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Complete the request to the best of your ability.\n",
      "\n",
      "### Instruction:\n",
      "Predict the next few sentences of the following excerpt from a high-quality US History textbook. \n",
      "\n",
      "### Input:\n",
      "The Emancipation Proclamation is a significant document in American history. Can you explain the purpose and impact of this proclamation?\n",
      "\n",
      "### Response:\n",
      " The Emancipation Proclamation was issued by President Abraham Lincoln in 1863 during the Civil War. Its purpose was to declare that all slaves in Confederate territory were to be set free. While it did not immediately free any slaves, it changed the nature of the war and gave a moral purpose to the Union's cause. The proclamation paved the way for the eventual abolition of slavery in the United States.\n",
      "--------------------\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Complete the request to the best of your ability.\n",
      "\n",
      "### Instruction:\n",
      "Predict the next few sentences of the following excerpt from a high-quality US History textbook. \n",
      "\n",
      "### Input:\n",
      "The Emancipation Proclamation is a significant document in American history. Can you explain the purpose and impact of this proclamation?\n",
      "\n",
      "### Response:\n",
      "The Emancipation Proclamation was issued by President Abraham Lincoln in 1863 during the Civil War. Its purpose was to declare that all slaves in Confederate territory were to be set free. While it did not immediately free any slaves, it changed the nature of the war and gave a moral purpose to the Union's cause. The proclamation paved the way for the eventual abolition of slavery in the United States.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# QC tokenization\n",
    "\n",
    "r2 = ds_train['train'][0]\n",
    "r = ds_train_tok['train'][0]\n",
    "\n",
    "print(r2['prompt'], r2['chosen'])\n",
    "print('-'*20)\n",
    "print(tokenizer.decode(r['chosen']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "# accelerator.device = 'cuda:0'\n",
    "model, dl_train = accelerator.prepare(\n",
    "    model, dl_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "from reprpo.interventions.reprpo.model import reprpo_forward_baukit\n",
    "\n",
    "from collections import UserDict\n",
    "\n",
    "class AttrDict(UserDict):\n",
    "    def __getattr__(self, key):\n",
    "        return self.__getitem__(key)\n",
    "    def __setattr__(self, key, value):\n",
    "        if key == \"data\":\n",
    "            return super().__setattr__(key, value)\n",
    "        return self.__setitem__(key, value)\n",
    "    \n",
    "h = AttrDict(layer_paths=list(range(model.config.num_hidden_layers)),\n",
    "             collect_input=True,\n",
    "             collect_hs=True,\n",
    "        )\n",
    "\n",
    "\n",
    "with accelerator.autocast():\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(dl_train))\n",
    "        pi_cho = reprpo_forward_baukit(\n",
    "            model=model,\n",
    "            input_ids=batch[\"chosen\"],\n",
    "            attn_mask=batch[\"chosen_mask\"],\n",
    "            layer_paths=h.layer_paths,\n",
    "            collect_input=h.collect_input,\n",
    "            collect_hs=h.collect_hs,\n",
    "        )\n",
    "        pi_rej = reprpo_forward_baukit(\n",
    "            model=model,\n",
    "            input_ids=batch[\"rejected\"],\n",
    "            attn_mask=batch[\"rejected_mask\"],\n",
    "            layer_paths=h.layer_paths,\n",
    "            collect_input=h.collect_input,\n",
    "            collect_hs=h.collect_hs,\n",
    "        )\n",
    "\n",
    "        # # collect the representations\n",
    "        # model.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     with model.disable_adapter():\n",
    "        #         ref_cho = reprpo_forward_baukit(\n",
    "        #             model=model,\n",
    "        #             input_ids=batch[\"chosen\"],\n",
    "        #             attn_mask=batch[\"chosen_mask\"],\n",
    "        #             layer_paths=h.layer_paths,\n",
    "        #             collect_input=h.collect_input,\n",
    "        #             collect_hs=h.collect_hs,\n",
    "        #         )\n",
    "        #         ref_rej = reprpo_forward_baukit(\n",
    "        #             model=model,\n",
    "        #             input_ids=batch[\"rejected\"],\n",
    "        #             attn_mask=batch[\"rejected_mask\"],\n",
    "        #             layer_paths=h.layer_paths,\n",
    "        #             collect_input=h.collect_input,\n",
    "        #             collect_hs=h.collect_hs,\n",
    "        #         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0196, 0.0200, 0.0223, 0.0248, 0.0281, 0.0301, 0.0303, 0.0320, 0.0318,\n",
       "        0.0297, 0.0321, 0.0302, 0.0275, 0.0279, 0.0272, 0.0267])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jaxtyping import Float, Int, Bool\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch import Tensor\n",
    "from reprpo.interventions.reprpo.helpers import reduce_tokens_w_attention\n",
    "\n",
    "hs_cho = torch.stack(list(pi_cho.hs.values()), 1).float().detach().cpu()\n",
    "hs_rej = torch.stack(list(pi_rej.hs.values()), 1).float().detach().cpu()\n",
    "\n",
    "def reduce(hs: Float[Tensor, 'b l t h'], attn: Int[Tensor, 'b l t t']) -> Float[Tensor, 'b l h']:\n",
    "    \n",
    "    negdiff = hs.diff(0).mul(-1).relu() / hs.norm(p=1, dim=-1).unsqueeze(-1)\n",
    "    # print(negdiff.shape, attn.shape)\n",
    "    r = [reduce_tokens_w_attention(negdiff[:, i], attn) for i in range(hs.size(1))]\n",
    "    return torch.stack(r, 1)\n",
    "\n",
    "hs = reduce(hs_cho, attn=pi_cho.mask.cpu())-reduce(hs_rej, attn=pi_rej.mask.cpu())\n",
    "hs.norm(p=1, dim=-1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4977, 0.5043, 0.5040, 0.5048, 0.5073, 0.5041, 0.5034, 0.4958, 0.4987,\n",
       "        0.4967, 0.5114, 0.5051, 0.5006, 0.5003, 0.4982, 0.5016])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = (hs_cho-hs_rej).float().detach().cpu()\n",
    "negdiff = hs.diff(0).mul(-1).relu()\n",
    "negdiff.norm(p=1, dim=2).mean(1) / hs.norm(p=1, dim=2).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2178, 0.4648, 0.6289, 0.7969, 0.8828, 0.9258, 0.9805, 1.0391, 1.0703,\n",
       "        1.2422, 1.6094, 1.8516, 2.2656, 2.7031, 3.1875, 3.7344],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hs_cho.diff(0)-hs_rej.diff(0)).norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 196, 2048])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_cho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3464, 0.9732, 1.7350, 2.5573, 3.5503, 3.6066, 3.7738, 4.3941, 4.6990,\n",
       "         5.4086]),\n",
       " tensor([0.3464, 0.6268, 0.7617, 0.8224, 0.9930, 0.0562, 0.1673, 0.6203, 0.3048,\n",
       "         0.7097]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10)\n",
    "x.diff(0).cumsum(0), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.3281,  7.0000, 12.1875, 17.6250, 23.1250, 28.6250, 34.2500,\n",
       "        40.0000, 46.2500, 53.2500, 61.5000, 71.5000, 83.0000], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = hs_cho.diff(0)[1:-1].cumsum(0) - hs_cho[1:-1]\n",
    "b.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3281,  5.0000,  5.7500,  6.1875,  6.4062,  6.7188,  7.0938,  7.2812,\n",
       "         7.9688,  9.6250, 10.8125, 12.6250, 14.6875, 17.1250], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = hs_cho.diff(0)[1:-1]\n",
    "torch.relu(b * -1).cumsum(0) # just get the negatives changes\n",
    "b.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = hs_cho.diff(0)[1:].abs() / hs_cho[1:].abs()\n",
    "# b.abs().nanmean(2).mean(1) #/ hs_cho.abs().mean(2).mean(1)\n",
    "b.nanmean(2).mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0242, -0.0101,  0.0217,  0.0054, -0.0703,  0.0283, -0.0107, -0.0908,\n",
       "        -0.0266, -0.0527,  0.0369, -0.0352,  0.0898, -0.0454, -0.2090, -0.1055],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_cho[:, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hs_cho.diff(0).abs().norm(2, dim=-1)/ hs_cho.abs().norm(2, dim=-1)).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm of changes per layer\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "norm of subtractions per layer\n",
      " tensor([0.4980, 0.4902, 0.4863, 0.4883, 0.4844, 0.4805, 0.4902, 0.4980, 0.5000,\n",
      "        0.4961, 0.4961, 0.5039, 0.5039, 0.5117, 0.5078, 0.5039],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "norm of additions per layer\n",
      " tensor([0.5000, 0.5078, 0.5156, 0.5117, 0.5156, 0.5195, 0.5117, 0.5000, 0.4980,\n",
      "        0.5039, 0.5039, 0.4961, 0.4961, 0.4902, 0.4922, 0.4941],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# just get the negative change for each layer\n",
    "b = hs_cho.diff(0)\n",
    "print('norm of changes per layer\\n', hs_cho.diff(0).norm(1, dim=-1).mean(1)/hs_cho.norm(1, dim=-1).mean(1))\n",
    "s = torch.relu(b * -1).norm(1, dim=-1) / b.norm(1, dim=-1)\n",
    "print('norm of subtractions per layer\\n', s.mean(1))\n",
    "s = torch.relu(b * 1).norm(1, dim=-1) / b.norm(1, dim=-1)\n",
    "print('norm of additions per layer\\n', s.mean(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_diff = hs_cho.diff(0)\n",
    "hs_diff_pos = torch.relu(hs_diff * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6484,  1.5703,  3.8125,  4.3125,  4.6250,  4.7812,  5.0625,  5.3750,\n",
       "         5.5625,  6.0312,  7.2500,  8.0625,  9.3750, 11.0625, 12.9375, 15.3750],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just get the negative change each layer\n",
    "b = hs_cho.diff(0)\n",
    "# b = torch.relu(b * -1)#.cumsum(0) # just get the negatives changes\n",
    "(torch.relu(b * -1)).norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6562,  1.7109,  3.1719,  3.7031,  4.0000,  4.1562,  4.3438,  4.5312,\n",
       "         4.6250,  5.1562,  6.2812,  7.0938,  8.3125,  9.5625, 11.0625, 13.3125],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.relu(b * 1)).norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7500, 3.7188, 3.7188, 3.7188, 3.6875, 3.6562, 3.6406, 3.6250, 3.5781,\n",
       "        3.4844, 3.3438, 3.1406, 2.7969, 2.4219, 1.7969, 0.0000],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC: for the information that is supressed in the final layer\n",
    "# how much of it differs between cho and rej\n",
    "((hs_cho-hs_cho[-1])-(hs_rej-hs_rej[-1])).norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9258,  2.3281,  5.0000,  5.7500,  6.1875,  6.4062,  6.7188,  7.0938,\n",
       "         7.2812,  7.9688,  9.6250, 10.8125, 12.6250, 14.6875, 17.1250, 20.3750],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_cho.diff(0).norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.3750, 20.3750, 18.2500, 18.2500, 18.1250, 18.0000, 17.8750, 17.7500,\n",
       "        17.3750, 16.8750, 16.1250, 15.2500, 13.8125, 12.1875,  9.1250,  0.0000],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = hs_cho-hs_cho[-1]\n",
    "a.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9258,  2.3281,  5.0000,  5.7500,  6.1875,  6.4062,  6.7188,  7.0938,\n",
       "         7.2812,  7.9688,  9.6250, 10.8125, 12.6250, 14.6875, 17.1250, 20.3750],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = hs_cho#\n",
    "a.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x73bdc2fca1d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first do cossine sim between layers\n",
    "data = []\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        sim=F.cosine_similarity(hs_cho[i], hs_rej[j], dim=-1).mean().item()\n",
    "        # print(i,j, F.cosine/_similarity(hs_cho[i], hs_rej[j], dim=-1).mean().item())\n",
    "        data.append(dict(i=i, j=j, sim=sim))\n",
    "r = pd.DataFrame(data).pivot(index='i',columns='j')\n",
    "plt.imshow(r, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.3750, 20.3750, 18.2500, 18.2500, 18.1250, 18.0000, 17.8750, 17.7500,\n",
       "        17.3750, 16.8750, 16.1250, 15.2500, 13.8125, 12.1875,  9.1250,  0.0000],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = hs_cho[-1]-(hs_cho-hs_cho[0])\n",
    "hs.shape\n",
    "hs.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.3750, 20.3750, 18.2500, 18.2500, 18.1250, 18.0000, 17.8750, 17.7500,\n",
       "        17.3750, 16.8750, 16.1250, 15.2500, 13.8125, 12.1875,  9.1250,  0.0000],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = hs_cho[-1]-hs_cho\n",
    "hs.shape\n",
    "hs.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.9258,   2.7812,   7.3125,  12.5000,  17.8750,  23.2500,  28.7500,\n",
       "         34.5000,  40.2500,  46.2500,  53.2500,  61.5000,  71.5000,  83.0000,\n",
       "         97.0000, 112.5000], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = hs_cho.diff(0).cumsum(0)\n",
    "a.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 196, 2048])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9258,  2.3281,  5.0000,  5.7500,  6.1875,  6.4062,  6.7188,  7.0938,\n",
       "         7.2812,  7.9688,  9.6250, 10.8125, 12.6250, 14.6875, 17.1250, 20.3750],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_cho.norm(dim=-1).mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 128256)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MLP output weights from final layer\n",
    "W_out = model.model.layers[-1].mlp.down_proj.weight.T # Adjust path as needed for Llama\n",
    "# Get unembedding matrix \n",
    "W_U = model.lm_head.weight\n",
    "\n",
    "# Calculate logit effects\n",
    "logit_effects = W_out @ W_U.T\n",
    "\n",
    "logit_effects = logit_effects.float().cpu().detach().numpy()\n",
    "logit_effects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze distribution per neuron\n",
    "import scipy.stats\n",
    "kurtosis = scipy.stats.kurtosis(logit_effects, axis=1)\n",
    "# kurtosis = torch.kurtosis(logit_effects, dim=1)\n",
    "skew = scipy.stats.skew(logit_effects.float().cpu().detach().numpy(), axis=1)\n",
    "# skew = torch.skew(logit_effects, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "some_threshold = 1\n",
    "# Identify suppression neurons (high kurtosis, negative skew)\n",
    "suppression_mask = (kurtosis > some_threshold) & (skew < 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
