{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] =\"expandable_segments:True\" # seems to stop gpu mem from filling up despite clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from reprpo.hp.helpers import optuna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import search_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_db = f\"sqlite:///optuna2.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'to visualise run in cli\\ncd nbs\\noptuna-dashboard {f_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.hp.target import override, default_tuner_kwargs, list2tuples, objective\n",
    "import functools\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import experiment_configs\n",
    "experiment_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.study.study import storages, get_all_study_names\n",
    "study_names = get_all_study_names(storage=f_db)\n",
    "\n",
    "for study_name in study_names:\n",
    "    print(study_name)\n",
    "    study = optuna.load_study(study_name=study_name, storage=f_db)\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        display(df_res)\n",
    "        print()\n",
    "    except ValueError as e:\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test, moved to pytest\n",
    "# for exp_name, (N, trial2args) in search_spaces.items():\n",
    "#     study = optuna.create_study(direction=\"maximize\")\n",
    "#     cfg = copy.deepcopy(experiment_configs[exp_name][1])\n",
    "#     print('exp_name', exp_name)\n",
    "#     for _ in range(10):\n",
    "#         trial = study.ask()\n",
    "#         kwargs = trial2args(trial)\n",
    "#         override(cfg, default_tuner_kwargs)\n",
    "#         override(cfg, kwargs)\n",
    "#         kwargs = list2tuples(kwargs)\n",
    "\n",
    "#     # try one dev run\n",
    "#     kwargs['dev'] = True\n",
    "#     _objective = functools.partial(objective, key_metric=key_metric, starter_experiment_name=exp_name, trial2args=trial2args)\n",
    "\n",
    "#     study.optimize(_objective, \n",
    "#                 n_trials=1, # do 20 at a time, round robin, untill done\n",
    "#                 gc_after_trial=True, \n",
    "#                 # catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRIALS= 250\n",
    "import numpy as np\n",
    "spaces = list(search_spaces.items())\n",
    "while True:\n",
    "    np.random.shuffle(spaces)\n",
    "    for exp_name, (max_trials, trial2args) in spaces:\n",
    "        try:\n",
    "            study_name = f\"{exp_name}\"\n",
    "            study = optuna.create_study(\n",
    "                study_name=study_name,\n",
    "                direction=\"maximize\",\n",
    "                load_if_exists=True,\n",
    "                storage=f_db,\n",
    "                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                # pruner=optuna.pruners.NopPruner(),\n",
    "            )\n",
    "\n",
    "            n = 0\n",
    "            try:\n",
    "                df = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "                n = len(df)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            if n>0:\n",
    "                print(f\"loaded {n} {study_name} trials\")\n",
    "\n",
    "                df_res = optuna_df(study, key_metric)\n",
    "                print(df_res.to_markdown())\n",
    "\n",
    "            \n",
    "            if n < max_trials:\n",
    "                _objective = functools.partial(objective, key_metric=key_metric, starter_experiment_name=exp_name, trial2args=trial2args)\n",
    "\n",
    "                study.optimize(_objective, \n",
    "                            n_trials=20, # do 20 at a time, round robin, untill done\n",
    "                            gc_after_trial=True, \n",
    "                            catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    "                )\n",
    "\n",
    "            print('='*80)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.exception(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
