{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] =\"expandable_segments:True\" # seems to stop gpu mem from filling up despite clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from reprpo.hp.helpers import optuna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-06 00:53:29,043] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from reprpo.training import train\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import search_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./optuna.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///optuna.db'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///optuna.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'to visualise run in cli\\ncd nbs\\noptuna-dashboard {f_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.hp.target import override, default_tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import functools\n",
    "\n",
    "def list2tuples(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = tuple(v)\n",
    "    return d\n",
    "\n",
    "def objective_func(kwargs, trial, starter_experiment_name):\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, default_tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    kwargs = list2tuples(kwargs)\n",
    "    r = train(cfg, trial=trial)\n",
    "    return r\n",
    "\n",
    "def objective(trial: optuna.Trial, starter_experiment_name, trial2args, key_metric=key_metric) -> float:\n",
    "    kwargs = trial2args(trial)\n",
    "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
    "    return r[key_metric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hs-svd-mse', 'hs-hra-rank', 'hs-ortho-prefvec', 'ether-prefvec', 'dpo', 'projbp', 'projgrad2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import experiment_configs\n",
    "experiment_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projgrad2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 00:54:26,331] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad2 N=✓0/✖307, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-ether-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-ether-prefvec N=✓208/✖209, best=1.169</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.219</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.218</td>\n",
       "      <td>0.403787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduction</th>\n",
       "      <td>0.146</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flip_side</th>\n",
       "      <td>0.014</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_dpo_loss</th>\n",
       "      <td>0.013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Htype</th>\n",
       "      <td>0.010</td>\n",
       "      <td>oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_nll_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_tokens</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_angle_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_orth_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            importance      best\n",
       "side-ether-prefvec N=✓208/✖209, best=1.169                      \n",
       "lr                                               0.368  0.000615\n",
       "nb                                               0.219        30\n",
       "β                                                0.218  0.403787\n",
       "reduction                                        0.146        25\n",
       "flip_side                                        0.014      True\n",
       "use_dpo_loss                                     0.013     False\n",
       "collect_hs                                       0.011     False\n",
       "Htype                                            0.010       oft\n",
       "use_nll_loss                                     0.000     False\n",
       "weight_tokens                                    0.000     False\n",
       "collect_input                                    0.000     False\n",
       "use_angle_loss                                   0.000      True\n",
       "use_orth_loss                                    0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 00:54:26,974] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projgrad\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad N=✓0/✖4, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-svd-mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-svd-mse N=✓28/✖316, best=1.010</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.635584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>0.016</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.005</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_svd</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     importance      best\n",
       "side-svd-mse N=✓28/✖316, best=1.010                      \n",
       "α                                         0.844  0.635584\n",
       "lr                                        0.126  0.001195\n",
       "quantile                                  0.016     float\n",
       "collect_hs                                0.005      True\n",
       "collect_input                             0.005     False\n",
       "dual_svd                                  0.005      True\n",
       "quantile_value                              NaN       0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-hra-rank\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-hra-rank N=✓182/✖183, best=1.229</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.110393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.095</td>\n",
       "      <td>5.920778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_GS</th>\n",
       "      <td>0.017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       importance      best\n",
       "side-hra-rank N=✓182/✖183, best=1.229                      \n",
       "β                                           0.441  0.110393\n",
       "lr                                          0.417  0.000188\n",
       "α                                           0.095  5.920778\n",
       "r                                           0.030         2\n",
       "apply_GS                                    0.017     False\n",
       "collect_hs                                  0.000     False\n",
       "collect_input                               0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-ortho-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-ortho-prefvec N=✓20/✖20, best=1.118</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.161</td>\n",
       "      <td>0.341233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_nll_loss</th>\n",
       "      <td>0.019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_proj_rel</th>\n",
       "      <td>0.019</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_angle_loss</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_dpo_loss</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_tokens</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orthogonal_map</th>\n",
       "      <td>0.004</td>\n",
       "      <td>matrix_exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_orth_loss</th>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        importance        best\n",
       "hs-ortho-prefvec N=✓20/✖20, best=1.118                        \n",
       "lr                                           0.782    0.000125\n",
       "β                                            0.161    0.341233\n",
       "use_nll_loss                                 0.019       False\n",
       "use_proj_rel                                 0.019        True\n",
       "use_angle_loss                               0.005        True\n",
       "use_dpo_loss                                 0.005        True\n",
       "weight_tokens                                0.005        True\n",
       "orthogonal_map                               0.004  matrix_exp\n",
       "use_orth_loss                                0.001       False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projbp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp N=✓10/✖24, best=1.033</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.366362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_orth</th>\n",
       "      <td>0.128</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mag_clip</th>\n",
       "      <td>0.021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_slope</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reverse_pref</th>\n",
       "      <td>0.014</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              importance      best\n",
       "projbp N=✓10/✖24, best=1.033                      \n",
       "β                                  0.512  0.366362\n",
       "lr                                 0.311  0.000003\n",
       "scale_orth                         0.128     False\n",
       "mag_clip                           0.021      None\n",
       "neg_slope                          0.014         0\n",
       "reverse_pref                       0.014     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dpo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo N=✓8/✖10, best=1.087</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance      best\n",
       "dpo N=✓8/✖10, best=1.087                      \n",
       "lr                               1.0  0.000098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-svd-mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-svd-mse N=✓14/✖332, best=1.017</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.635584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.003</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_svd</th>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>0.000</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   importance      best\n",
       "hs-svd-mse N=✓14/✖332, best=1.017                      \n",
       "lr                                      0.752  0.001195\n",
       "α                                       0.189  0.635584\n",
       "collect_input                           0.056     False\n",
       "collect_hs                              0.003      True\n",
       "dual_svd                                0.000      True\n",
       "quantile                                0.000     float\n",
       "quantile_value                            NaN       0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-hra-rank\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-hra-rank N=✓43/✖45, best=1.087</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.048</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.039</td>\n",
       "      <td>18.156422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.123722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_GS</th>\n",
       "      <td>0.002</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   importance       best\n",
       "hs-hra-rank N=✓43/✖45, best=1.087                       \n",
       "lr                                      0.907   0.000158\n",
       "r                                       0.048         96\n",
       "β                                       0.039  18.156422\n",
       "α                                       0.005   0.123722\n",
       "apply_GS                                0.002      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ether-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ether-prefvec N=3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from optuna.study.study import storages, get_all_study_names\n",
    "study_names = get_all_study_names(storage=f_db)\n",
    "\n",
    "for study_name in study_names:\n",
    "    print(study_name)\n",
    "    study = optuna.load_study(study_name=study_name, storage=f_db)\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        display(df_res)\n",
    "        print()\n",
    "    except ValueError as e:\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 00:54:53,760] A new study created in memory with name: no-name-34dae79d-d0e6-4f47-b94d-61fbacd30677\n",
      "[I 2024-10-06 00:54:53,774] A new study created in memory with name: no-name-03940010-97ac-4136-b4e1-17ddfa657803\n",
      "[I 2024-10-06 00:54:53,784] A new study created in memory with name: no-name-737d0f6c-4539-461f-99c2-1b11bbd028ad\n",
      "[I 2024-10-06 00:54:53,796] A new study created in memory with name: no-name-6dcda2eb-c085-43bf-bca4-4c2a297c6bc9\n",
      "[I 2024-10-06 00:54:53,816] A new study created in memory with name: no-name-966d6188-a1b6-4075-a088-bd42eb6177cd\n",
      "[I 2024-10-06 00:54:53,824] A new study created in memory with name: no-name-811f712a-bc11-4397-9287-334814c2b657\n",
      "[I 2024-10-06 00:54:53,831] A new study created in memory with name: no-name-578668dd-46e8-43c1-bf2d-6ae8761b5a19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name hs-svd-mse\n",
      "kwargs {'lr': 2.4008970673824455e-05, 'collect_input': True, 'collect_hs': True, 'transform.quantile': 1, 'transform.dual_svd': True, 'loss.α': 4.659412764403834}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name hs-hra-rank\n",
      "kwargs {'lr': 1.0639442660721646e-06, 'transform.r': 37, 'transform.apply_GS': False, 'loss.α': 2606.3940587280713, 'loss.β': 49.21176557089369}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name hs-ortho-prefvec\n",
      "kwargs {'lr': 0.006940820649722095, 'transform.orthogonal_map': 'cayley', 'loss.β': 0.00036668618914569695, 'loss.use_orth_loss': False, 'loss.use_angle_loss': False, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.weight_tokens': False, 'loss.use_proj_rel': True}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name ether-prefvec\n",
      "kwargs {'lr': 0.005718612175996021, 'collect_input': False, 'collect_hs': True, 'transform.nb': 4, 'transform.Htype': 'oft', 'transform.flip_side': False, 'transform.reduction': 10, 'loss.β': 0.015625783471675713, 'loss.use_orth_loss': False, 'loss.use_angle_loss': True, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.weight_tokens': False, 'loss.use_proj_rel': True}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name projgrad2\n",
      "kwargs {'lr': 1.0432371175997375e-06, 'β': 0.38861585070925975, 'reverse_pref': True, 'scale_orth': True, 'weight_dim': 0, 'neg_slope': 0.8462725843613553, 'mag_clip': None}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name projbp\n",
      "kwargs {'lr': 4.732101427687712e-06, 'β': 0.3333303930634801, 'reverse_pref': False, 'scale_orth': True, 'neg_slope': 0.8779413754304705, 'mag_clip': 6.805566038014053}\n",
      "====================================================================================================\n",
      "\n",
      "exp_name dpo\n",
      "kwargs {'lr': 0.0005759388651987035}\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "for exp_name, (N, trial2args) in search_spaces.items():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    cfg = copy.deepcopy(experiment_configs[exp_name][1])\n",
    "    print('exp_name', exp_name)\n",
    "    for _ in range(10):\n",
    "        trial = study.ask()\n",
    "        kwargs = trial2args(trial)\n",
    "        override(cfg, default_tuner_kwargs)\n",
    "        override(cfg, kwargs)\n",
    "        kwargs = list2tuples(kwargs)\n",
    "        # print()\n",
    "    print('kwargs', kwargs)\n",
    "    print('='*100)\n",
    "    print()\n",
    "\n",
    "    # TODO get float * 50 + categories * 25\n",
    "\n",
    "    # try:\n",
    "    #     df_res = optuna_df(study, key_metric)\n",
    "    #     print(df_res.to_markdown())\n",
    "    # except Exception as e:\n",
    "    #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optuna import trial\n",
    "# t = trial.create_trial(value=1)\n",
    "# t.suggest_categorical(\"a\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 00:55:01,659] Using an existing study with name 'ether-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3 ether-prefvec trials\n",
      "| ether-prefvec N=3   | importance   | best   |\n",
      "|---------------------|--------------|--------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 00:58:49,858] Trial 3 finished with value: 1.0096339113680155 and parameters: {'lr': 7.45934328572655e-06, 'collect_input': True, 'collect_hs': True, 'nb': 1, 'Htype': 'etherplus', 'flip_side': False, 'reduction': 160, 'β': 2.177484667394932e-05, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 0 with value: 1.0096339113680155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                  |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.β=2.2e-05 lr=7.5e-06 ether.Htype=etherplus ether.nb=1 ether.reduction=160 |   0.826 |      0 | 0.963 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:02:30,339] Trial 4 finished with value: 1.0 and parameters: {'lr': 9.96251322205511e-07, 'collect_input': False, 'collect_hs': False, 'nb': 1, 'Htype': 'oft', 'flip_side': True, 'reduction': 57, 'β': 0.000593490901937937, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 0 with value: 1.0096339113680155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                      |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO prefvec.use_angle_prefvec=False prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.00059 lr=1e-06 ether.Htype=oft ether.flip_side=True ether.nb=1 ether.reduction=57 |       0 |      0 |     0 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:06:08,768] Trial 5 finished with value: 0.5202312138728324 and parameters: {'lr': 0.0049830438374949175, 'collect_input': True, 'collect_hs': True, 'nb': 1, 'Htype': 'oft', 'flip_side': True, 'reduction': 4, 'β': 0.0026275095216295235, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 0 with value: 1.0096339113680155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                         |   train |    test |     oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.0026 lr=0.005 ether.Htype=oft ether.flip_side=True ether.nb=1 ether.reduction=4 | -21.488 | -19.685 | -47.977 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:09:43,949] Trial 6 finished with value: 1.0134874759152217 and parameters: {'lr': 6.199100007802271e-06, 'collect_input': False, 'collect_hs': True, 'nb': 1, 'Htype': 'oft', 'flip_side': True, 'reduction': 1, 'β': 0.03120159522837056, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 6 with value: 1.0134874759152217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                           |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.β=0.031 lr=6.2e-06 ether.Htype=oft ether.flip_side=True ether.nb=1 ether.reduction=1 |   0.826 |      0 | 1.349 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:13:12,164] Trial 7 finished with value: 0.39884393063583823 and parameters: {'lr': 0.003450105453613023, 'collect_input': False, 'collect_hs': True, 'nb': 1, 'Htype': 'oft', 'flip_side': False, 'reduction': 131, 'β': 1.4982474159458828e-05, 'use_orth_loss': True, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 6 with value: 1.0134874759152217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                         |   train |    test |     oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.β=1.5e-05 lr=0.0035 ether.Htype=oft ether.nb=1 ether.reduction=131 | -57.851 | -51.969 | -60.116 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:16:37,312] Trial 8 finished with value: 1.0 and parameters: {'lr': 1.2219544456335435e-05, 'collect_input': True, 'collect_hs': False, 'nb': 2, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 16, 'β': 7.867617817691428e-05, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 6 with value: 1.0134874759152217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                           |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.β=7.9e-05 lr=1.2e-05 ether.flip_side=True ether.nb=2 ether.reduction=16 |       0 |      0 |     0 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:20:04,785] Trial 9 finished with value: 1.0616570327552988 and parameters: {'lr': 0.00022944454507602003, 'collect_input': True, 'collect_hs': True, 'nb': 7, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 1, 'β': 0.0052873025127761295, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 9 with value: 1.0616570327552988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                                                 |   train |   test |   oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.0053 lr=0.00023 ether.flip_side=True ether.nb=7 ether.reduction=1 |   5.785 |      0 | 6.166 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:23:31,950] Trial 10 finished with value: 0.41233140655105976 and parameters: {'lr': 0.004202116526335314, 'collect_input': True, 'collect_hs': False, 'nb': 5, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 5, 'β': 0.00015862805689756922, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 9 with value: 1.0616570327552988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                            |   train |    test |     oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.00016 lr=0.0042 ether.flip_side=True ether.nb=5 ether.reduction=5 | -46.281 | -33.071 | -58.767 | 14.035 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:26:50,979] Trial 11 finished with value: 0.998073217726397 and parameters: {'lr': 1.0600050132100246e-07, 'collect_input': False, 'collect_hs': True, 'nb': 1, 'Htype': 'etherplusHH', 'flip_side': False, 'reduction': 48, 'β': 0.003810040186310128, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 9 with value: 1.0616570327552988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                            |   train |   test |    oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.0038 lr=1.1e-07 ether.nb=1 ether.reduction=48 |       0 |      0 | -0.193 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:30:14,764] Trial 12 finished with value: 1.1156069364161851 and parameters: {'lr': 0.0002406836245455099, 'collect_input': True, 'collect_hs': False, 'nb': 19, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 0.92244950497797, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 12 with value: 1.1156069364161851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |    oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.92 lr=0.00024 ether.Htype=ether ether.flip_side=True ether.nb=19 ether.reduction=1 |   0.826 |  0.787 | 11.561 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:33:37,761] Trial 13 finished with value: 1.1483622350674374 and parameters: {'lr': 0.0002901472921452969, 'collect_input': True, 'collect_hs': False, 'nb': 20, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.9166022109203233, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.9 lr=0.00029 ether.Htype=ether ether.flip_side=True ether.nb=20 ether.reduction=1 |   2.479 |  0.787 | 14.836 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:36:57,412] Trial 14 finished with value: 1.071290944123314 and parameters: {'lr': 0.0001799198232803581, 'collect_input': True, 'collect_hs': False, 'nb': 25, 'Htype': 'ether', 'flip_side': True, 'reduction': 3, 'β': 1.9699156994635347, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                  |   train |   test |   oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=2 lr=0.00018 ether.Htype=ether ether.flip_side=True ether.nb=25 ether.reduction=3 |   1.653 |  0.787 | 7.129 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:40:16,605] Trial 15 finished with value: 1.1290944123314066 and parameters: {'lr': 0.0002642694411963029, 'collect_input': True, 'collect_hs': False, 'nb': 31, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.3636261492399193, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.4 lr=0.00026 ether.Htype=ether ether.flip_side=True ether.nb=31 ether.reduction=1 |   0.826 |  0.787 | 12.909 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:43:33,812] Trial 16 finished with value: 1.1059730250481696 and parameters: {'lr': 0.0007282211424206603, 'collect_input': True, 'collect_hs': False, 'nb': 12, 'Htype': 'ether', 'flip_side': True, 'reduction': 10, 'β': 0.1523030038701377, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                      |   train |   test |    oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.15 lr=0.00073 ether.Htype=ether ether.flip_side=True ether.nb=12 ether.reduction=10 |   1.653 | -0.787 | 10.597 | -8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:46:50,631] Trial 17 finished with value: 1.0327552986512525 and parameters: {'lr': 5.8804631302704396e-05, 'collect_input': True, 'collect_hs': False, 'nb': 14, 'Htype': 'ether', 'flip_side': True, 'reduction': 2, 'β': 0.16222423275670422, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.16 lr=5.9e-05 ether.Htype=ether ether.flip_side=True ether.nb=14 ether.reduction=2 |       0 |      0 | 3.276 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:50:05,875] Trial 18 finished with value: 0.7495183044315994 and parameters: {'lr': 0.0010741233719675444, 'collect_input': True, 'collect_hs': False, 'nb': 30, 'Htype': 'ether', 'flip_side': True, 'reduction': 8, 'β': 0.36563366980566214, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                        |   train |    test |     oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.37 lr=0.0011 ether.Htype=ether ether.flip_side=True ether.reduction=8 | -19.835 | -11.024 | -25.048 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:53:28,517] Trial 19 finished with value: 0.9942196531791907 and parameters: {'lr': 7.936586160598832e-05, 'collect_input': True, 'collect_hs': False, 'nb': 11, 'Htype': 'ether', 'flip_side': True, 'reduction': 2, 'β': 2.151448230726969e-06, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                        |   train |   test |    oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=2.2e-06 lr=7.9e-05 ether.Htype=ether ether.flip_side=True ether.nb=11 ether.reduction=2 |       0 |      0 | -0.578 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 01:56:56,395] Trial 20 finished with value: 0.44123314065510605 and parameters: {'lr': 0.0008739464876170618, 'collect_input': False, 'collect_hs': False, 'nb': 3, 'Htype': 'ether', 'flip_side': False, 'reduction': 455, 'β': 0.028499794565144055, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                               |   train |    test |     oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.028 lr=0.00087 ether.Htype=ether ether.nb=3 ether.reduction=455 | -36.364 | -33.071 | -55.877 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:00:31,734] Trial 21 finished with value: 1.0211946050096339 and parameters: {'lr': 2.880497861507296e-05, 'collect_input': True, 'collect_hs': False, 'nb': 32, 'Htype': 'ether', 'flip_side': True, 'reduction': 29, 'β': 0.03531855721629355, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                       |   train |   test |   oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.035 lr=2.9e-05 ether.Htype=ether ether.flip_side=True ether.nb=32 ether.reduction=29 |       0 |      0 | 2.119 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:04:09,140] Trial 22 finished with value: 1.0077071290944124 and parameters: {'lr': 1.5875044375329296e-06, 'collect_input': True, 'collect_hs': False, 'nb': 7, 'Htype': 'etherplus', 'flip_side': True, 'reduction': 2, 'β': 0.4801430080499144, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                        |   train |   test |   oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.48 lr=1.6e-06 ether.Htype=etherplus ether.flip_side=True ether.nb=7 ether.reduction=2 |       0 |      0 | 0.771 | 1.754 |\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:04:09,976] Using an existing study with name 'hs-ortho-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 20 hs-ortho-prefvec trials\n",
      "| hs-ortho-prefvec N=✓20/✖20, best=1.118   |   importance | best                   |\n",
      "|:-----------------------------------------|-------------:|:-----------------------|\n",
      "| lr                                       |        0.782 | 0.00012461222072738544 |\n",
      "| β                                        |        0.161 | 0.3412333287913769     |\n",
      "| use_nll_loss                             |        0.019 | False                  |\n",
      "| use_proj_rel                             |        0.019 | True                   |\n",
      "| use_angle_loss                           |        0.005 | True                   |\n",
      "| use_dpo_loss                             |        0.005 | True                   |\n",
      "| weight_tokens                            |        0.005 | True                   |\n",
      "| orthogonal_map                           |        0.004 | matrix_exp             |\n",
      "| use_orth_loss                            |        0.001 | False                  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:07:42,742] Trial 20 finished with value: 1.0635838150289019 and parameters: {'lr': 0.00011599334568238253, 'orthogonal_map': 'cayley', 'β': 0.3180114413719155, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                           |   train |   test |   oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.32 lr=0.00012 ortho.orthogonal_map=cayley |   4.132 |      0 | 6.358 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:11:14,636] Trial 21 finished with value: 1.0809248554913296 and parameters: {'lr': 0.00012491186582150942, 'orthogonal_map': 'matrix_exp', 'β': 0.2045081228059815, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.2 lr=0.00012 ortho.orthogonal_map=matrix_exp |   4.959 |      0 | 8.092 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:14:51,150] Trial 22 finished with value: 0.5125240847784202 and parameters: {'lr': 0.0016208869013058956, 'orthogonal_map': 'matrix_exp', 'β': 0.016854047517786026, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |    test |     oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.017 lr=0.0016 ortho.orthogonal_map=matrix_exp | -16.529 | -20.472 | -48.748 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:18:27,484] Trial 23 finished with value: 1.0134874759152217 and parameters: {'lr': 1.2386301899925658e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.0051659814925599104, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                 |   train |   test |   oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.0052 lr=1.2e-05 ortho.orthogonal_map=matrix_exp |   0.826 |      0 | 1.349 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:22:01,311] Trial 24 finished with value: 1.0732177263969174 and parameters: {'lr': 0.00011862842031212204, 'orthogonal_map': 'matrix_exp', 'β': 0.2757169873344899, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |   test |   oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.28 lr=0.00012 ortho.orthogonal_map=matrix_exp |   4.959 |      0 | 7.322 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:25:37,062] Trial 25 finished with value: 0.393063583815029 and parameters: {'lr': 0.002294708301736453, 'orthogonal_map': 'matrix_exp', 'β': 0.04689000102665802, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |    test |     oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.047 lr=0.0023 ortho.orthogonal_map=matrix_exp | -53.719 | -44.094 | -60.694 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:29:11,973] Trial 26 finished with value: 1.001926782273603 and parameters: {'lr': 0.0003386055028879383, 'orthogonal_map': 'matrix_exp', 'β': 8.940060037547945e-05, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                |   train |   test |   oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=8.9e-05 lr=0.00034 ortho.orthogonal_map=matrix_exp |   4.959 | -0.787 | 0.193 | 26.316 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:32:52,439] Trial 27 finished with value: 1.0077071290944124 and parameters: {'lr': 1.1652434708622014e-06, 'orthogonal_map': 'matrix_exp', 'β': 0.33940306448738855, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |   test |   oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.34 lr=1.2e-06 ortho.orthogonal_map=matrix_exp |   0.826 |      0 | 0.771 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:36:22,926] Trial 28 finished with value: 1.0134874759152217 and parameters: {'lr': 1.4988101582053636e-05, 'orthogonal_map': 'cayley', 'β': 0.026993305327625432, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                            |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.027 lr=1.5e-05 ortho.orthogonal_map=cayley |   1.653 |      0 | 1.349 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:39:40,870] Trial 29 finished with value: 1.0732177263969174 and parameters: {'lr': 9.946755107077159e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.00828625130150565, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                               |   train |   test |   oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.0083 lr=9.9e-05 ortho.orthogonal_map=matrix_exp |   4.132 |      0 | 7.322 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:42:58,750] Trial 30 finished with value: 0.5183044315992293 and parameters: {'lr': 0.0012321401965320643, 'orthogonal_map': 'householder', 'β': 1.893415942662686, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |    test |    oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.9 lr=0.0012 ortho.orthogonal_map=householder | -18.182 | -18.898 | -48.17 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:46:29,469] Trial 31 finished with value: 1.0578034682080926 and parameters: {'lr': 0.00015813203819291314, 'orthogonal_map': 'matrix_exp', 'β': 0.20091910986632155, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.2 lr=0.00016 ortho.orthogonal_map=matrix_exp |   4.132 | -0.787 |  5.78 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:49:46,436] Trial 32 finished with value: 1.0597302504816957 and parameters: {'lr': 5.8494588149002014e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.10351004717522656, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.1 lr=5.8e-05 ortho.orthogonal_map=matrix_exp |   3.306 |      0 | 5.973 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:53:04,199] Trial 33 finished with value: 1.0289017341040463 and parameters: {'lr': 0.0003751225461855568, 'orthogonal_map': 'matrix_exp', 'β': 0.5460991480428049, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.55 lr=0.00038 ortho.orthogonal_map=matrix_exp |   2.479 |      0 |  2.89 | 24.561 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:56:21,701] Trial 34 finished with value: 1.019267822736031 and parameters: {'lr': 2.0474531032046485e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.1667388434597149, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                             |   train |   test |   oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.17 lr=2e-05 ortho.orthogonal_map=matrix_exp |   1.653 |      0 | 1.927 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 02:59:25,446] Trial 35 finished with value: 1.0327552986512525 and parameters: {'lr': 8.669379205870907e-05, 'orthogonal_map': 'householder', 'β': 0.001659114844538711, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.β=0.0017 lr=8.7e-05 ortho.orthogonal_map=householder |   1.653 |      0 | 3.276 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:02:43,687] Trial 36 finished with value: 0.8439306358381503 and parameters: {'lr': 0.0006066997957123247, 'orthogonal_map': 'matrix_exp', 'β': 0.035489104484769905, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                           |   train |   test |     oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.035 lr=0.00061 ortho.orthogonal_map=matrix_exp |  -0.826 |  -3.15 | -15.607 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:06:01,244] Trial 37 finished with value: 1.0809248554913296 and parameters: {'lr': 0.0002311191704253201, 'orthogonal_map': 'matrix_exp', 'β': 0.7511549894560026, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.75 lr=0.00023 ortho.orthogonal_map=matrix_exp |   5.785 |      0 | 8.092 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:09:09,874] Trial 38 finished with value: 1.0077071290944124 and parameters: {'lr': 6.2958567147763926e-06, 'orthogonal_map': 'householder', 'β': 0.012811515967641761, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                      |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.013 lr=6.3e-06 ortho.orthogonal_map=householder |   0.826 |      0 | 0.771 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:12:26,747] Trial 39 finished with value: 0.5144508670520231 and parameters: {'lr': 0.0037199683775272696, 'orthogonal_map': 'matrix_exp', 'β': 0.14258481840592632, 'use_orth_loss': True, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                  |   train |    test |     oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.weight_tokens=True prefvec.β=0.14 lr=0.0037 ortho.orthogonal_map=matrix_exp | -43.802 | -26.772 | -48.555 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:12:27,234] Using an existing study with name 'hs-svd-mse' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 332 hs-svd-mse trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:12:27,865] Using an existing study with name 'dpo' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| hs-svd-mse N=✓14/✖332, best=1.017   |   importance | best                  |\n",
      "|:------------------------------------|-------------:|:----------------------|\n",
      "| lr                                  |        0.752 | 0.0011948328168545441 |\n",
      "| α                                   |        0.189 | 0.6355835028602363    |\n",
      "| collect_input                       |        0.056 | False                 |\n",
      "| collect_hs                          |        0.003 | True                  |\n",
      "| dual_svd                            |        0     | True                  |\n",
      "| quantile                            |        0     | float                 |\n",
      "| quantile_value                      |      nan     | 0.30000000000000004   |\n",
      "================================================================================\n",
      "loaded 10 dpo trials\n",
      "| dpo N=✓8/✖10, best=1.087   |   importance |        best |\n",
      "|:---------------------------|-------------:|------------:|\n",
      "| lr                         |            1 | 9.84674e-05 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:15:41,117] Trial 10 finished with value: 1.0346820809248556 and parameters: {'lr': 7.45934328572655e-06}. Best is trial 4 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=7.5e-06         |   4.132 | -0.787 | 3.468 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:18:54,059] Trial 11 finished with value: 0.5279383429672447 and parameters: {'lr': 0.005669849511478858}. Best is trial 4 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|-------:|\n",
      "| DPO lr=0.0057          | -13.223 | -19.685 | -47.206 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:22:07,445] Trial 12 finished with value: 1.1464354527938343 and parameters: {'lr': 0.0001440481381559795}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|------:|\n",
      "| DPO lr=0.00014         |   4.959 |  0.787 | 14.644 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:25:23,522] Trial 13 finished with value: 1.1021194605009634 and parameters: {'lr': 9.467489489054227e-05}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=9.5e-05         |   5.785 | -0.787 | 10.212 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:28:40,539] Trial 14 finished with value: 0.9922928709055877 and parameters: {'lr': 0.0001225706694819564}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00012         |   5.785 |      0 | -0.771 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:31:54,270] Trial 15 finished with value: 1.0211946050096339 and parameters: {'lr': 1.4861973114366403e-05}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=1.5e-05         |   2.479 | -0.787 | 2.119 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:35:07,065] Trial 16 finished with value: 0.7610789980732177 and parameters: {'lr': 0.0004629090336090747}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |     oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|--------:|-------:|\n",
      "| DPO lr=0.00046         | -10.744 | -9.449 | -23.892 | 31.579 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:38:32,657] Trial 17 finished with value: 1.001926782273603 and parameters: {'lr': 4.3222833710008596e-05}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=4.3e-05         |   5.785 | -1.575 | 0.193 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:41:54,741] Trial 18 finished with value: 0.9267822736030829 and parameters: {'lr': 0.0004948947088376027}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00049         |   4.132 | -1.575 | -7.322 | 24.561 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:45:15,399] Trial 19 finished with value: 1.044315992292871 and parameters: {'lr': 2.494712621055077e-06}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=2.5e-06         |   1.653 |      0 | 4.432 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:48:34,700] Trial 20 finished with value: 1.0867052023121389 and parameters: {'lr': 0.00013627563818737476}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=0.00014         |   5.785 | -1.575 | 8.671 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:51:53,156] Trial 21 finished with value: 0.4913294797687862 and parameters: {'lr': 0.001378275834219443}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|-------:|\n",
      "| DPO lr=0.0014          | -24.793 | -24.409 | -50.867 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:55:12,191] Trial 22 finished with value: 0.9884393063583816 and parameters: {'lr': 4.8851293531686584e-05}. Best is trial 12 with value: 1.1464354527938343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=4.9e-05         |   5.785 | -1.575 | -1.156 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 03:58:33,399] Trial 23 finished with value: 1.1522157996146436 and parameters: {'lr': 0.00012420777462285258}. Best is trial 23 with value: 1.1522157996146436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00012         |   4.959 | -0.787 | 15.222 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:01:51,422] Trial 24 finished with value: 1.165703275529865 and parameters: {'lr': 0.0002701586889090417}. Best is trial 24 with value: 1.165703275529865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=0.00027         |   5.785 | -0.787 | 16.57 | 14.035 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:05:12,567] Trial 25 finished with value: 1.1984585741811176 and parameters: {'lr': 0.0002794857261209373}. Best is trial 25 with value: 1.1984585741811176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00028         |   5.785 | -0.787 | 19.846 | 33.333 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:08:33,084] Trial 26 finished with value: 0.4720616570327553 and parameters: {'lr': 0.001030797243720144}. Best is trial 25 with value: 1.1984585741811176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |   rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|------:|\n",
      "| DPO lr=0.001           | -28.926 | -23.622 | -52.794 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:11:47,644] Trial 27 finished with value: 1.1213872832369944 and parameters: {'lr': 0.00029780077058852265}. Best is trial 25 with value: 1.1984585741811176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.0003          |   4.959 | -1.575 | 12.139 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:15:06,581] Trial 28 finished with value: 1.0539499036608864 and parameters: {'lr': 2.4104922989942412e-05}. Best is trial 25 with value: 1.1984585741811176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=2.4e-05         |   5.785 |      0 | 5.395 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:18:25,232] Trial 29 finished with value: 0.5086705202312138 and parameters: {'lr': 0.0028153918881662753}. Best is trial 25 with value: 1.1984585741811176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |     oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|--------:|------:|\n",
      "| DPO lr=0.0028          | -24.793 | -21.26 | -49.133 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:18:26,050] Using an existing study with name 'hs-hra-rank' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 45 hs-hra-rank trials\n",
      "| hs-hra-rank N=✓43/✖45, best=1.087   |   importance |         best |\n",
      "|:------------------------------------|-------------:|-------------:|\n",
      "| lr                                  |        0.907 |  0.000157522 |\n",
      "| r                                   |        0.048 | 96           |\n",
      "| β                                   |        0.039 | 18.1564      |\n",
      "| α                                   |        0.005 |  0.123722    |\n",
      "| apply_GS                            |        0.002 |  0           |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:21:47,259] Trial 45 finished with value: 1.023121387283237 and parameters: {'lr': 0.0001650018019567111, 'r': 20, 'apply_GS': True, 'α': 1374.4173453251522, 'β': 17.347052994706306}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                  |   train |   test |   oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=1.4e+03 rank.β=17 lr=0.00017 hra.apply_GS=True hra.r=20 |   3.306 |      0 | 2.312 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:25:09,250] Trial 46 finished with value: 1.0115606936416186 and parameters: {'lr': 0.00038690644171223586, 'r': 36, 'apply_GS': True, 'α': 55.839080090728984, 'β': 24.876699752567294}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                             |   train |   test |   oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=56 rank.β=25 lr=0.00039 hra.apply_GS=True hra.r=36 |   4.132 |  0.787 | 1.156 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:28:31,679] Trial 47 finished with value: 1.0057803468208093 and parameters: {'lr': 3.53918958281575e-05, 'r': 12, 'apply_GS': True, 'α': 0.049977200081163936, 'β': 12.71894108589158}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=0.05 rank.β=13 lr=3.5e-05 hra.apply_GS=True hra.r=12 |   1.653 |      0 | 0.578 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:31:52,252] Trial 48 finished with value: 0.6300578034682082 and parameters: {'lr': 0.0006988401492280374, 'r': 406, 'apply_GS': True, 'α': 0.22774762601145612, 'β': 8.828627552617311}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |     oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|--------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=0.23 rank.β=8.8 lr=0.0007 hra.apply_GS=True hra.r=406 |  -2.479 | -7.874 | -36.994 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:35:11,699] Trial 49 finished with value: 0.5240847784200386 and parameters: {'lr': 0.0014132273758850318, 'r': 6, 'apply_GS': True, 'α': 0.018541603442753043, 'β': 1.10382516653629}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |    test |     oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.019 rank.β=1.1 lr=0.0014 hra.apply_GS=True hra.r=6 | -18.182 | -18.898 | -47.592 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:38:34,116] Trial 50 finished with value: 0.9922928709055877 and parameters: {'lr': 6.343143630486608e-05, 'r': 25, 'apply_GS': False, 'α': 0.003126572876981708, 'β': 6.369388941969746}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                   |   train |   test |    oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.0031 rank.β=6.4 lr=6.3e-05 hra.apply_GS=False hra.r=25 |   2.479 | -0.787 | -0.771 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:41:55,592] Trial 51 finished with value: 1.0500963391136802 and parameters: {'lr': 0.0003156627088202522, 'r': 80, 'apply_GS': True, 'α': 9.04039147140358, 'β': 0.34179176205063594}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                              |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=9 rank.β=0.34 lr=0.00032 hra.apply_GS=True hra.r=80 |   4.959 |  0.787 |  5.01 | 28.07 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:45:18,975] Trial 52 finished with value: 1.0038535645472062 and parameters: {'lr': 3.629782353829205e-07, 'r': 77, 'apply_GS': False, 'α': 7.024120398344573, 'β': 0.28463529783946456}. Best is trial 21 with value: 1.0867052023121389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=7 rank.β=0.28 lr=3.6e-07 hra.apply_GS=False hra.r=77 |       0 |      0 | 0.385 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:48:40,784] Trial 53 finished with value: 1.117533718689788 and parameters: {'lr': 0.00029506781353040817, 'r': 87, 'apply_GS': True, 'α': 2.4742183958572515, 'β': 0.44127239648806993}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |    oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=2.5 rank.β=0.44 lr=0.0003 hra.apply_GS=True hra.r=87 |   2.479 |      0 | 11.753 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:52:02,552] Trial 54 finished with value: 1.088631984585742 and parameters: {'lr': 0.0003948719794516659, 'r': 102, 'apply_GS': True, 'α': 2.5577812877325714, 'β': 0.41359973300906705}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=2.6 rank.β=0.41 lr=0.00039 hra.apply_GS=True hra.r=102 |   2.479 |  0.787 | 8.863 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:55:28,613] Trial 55 finished with value: 0.4816955684007707 and parameters: {'lr': 0.0033460446873014157, 'r': 101, 'apply_GS': True, 'α': 2.571463595470156, 'β': 0.7895297443206247}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |    test |    oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|--------:|-------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=2.6 rank.β=0.79 lr=0.0033 hra.apply_GS=True hra.r=101 | -17.355 | -19.685 | -51.83 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 04:58:53,833] Trial 56 finished with value: 0.9210019267822737 and parameters: {'lr': 0.0005077233455473574, 'r': 46, 'apply_GS': True, 'α': 0.7033698666887437, 'β': 0.41171288871287326}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.7 rank.β=0.41 lr=0.00051 hra.apply_GS=True hra.r=46 |   2.479 |  -3.15 |  -7.9 | -5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:02:20,038] Trial 57 finished with value: 0.5279383429672447 and parameters: {'lr': 0.0012516453018802708, 'r': 136, 'apply_GS': True, 'α': 0.23593495449900395, 'β': 0.19739584183449618}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |    test |     oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=0.24 rank.β=0.2 lr=0.0013 hra.apply_GS=True hra.r=136 | -16.529 | -19.685 | -47.206 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:05:40,370] Trial 58 finished with value: 1.0269749518304432 and parameters: {'lr': 0.00013322153067244852, 'r': 192, 'apply_GS': True, 'α': 15.307673696115064, 'β': 0.1991769444845182}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=15 rank.β=0.2 lr=0.00013 hra.apply_GS=True hra.r=192 |   3.306 |      0 | 2.697 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:09:02,396] Trial 59 finished with value: 1.0173410404624277 and parameters: {'lr': 0.00035057010920508684, 'r': 278, 'apply_GS': False, 'α': 0.92777953010552, 'β': 0.8667848203214406}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                   |   train |   test |   oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.93 rank.β=0.87 lr=0.00035 hra.apply_GS=False hra.r=278 |   4.959 | -1.575 | 1.734 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:12:23,645] Trial 60 finished with value: 1.0134874759152217 and parameters: {'lr': 2.6943626187168916e-05, 'r': 62, 'apply_GS': True, 'α': 3.2400195090183015, 'β': 0.48693025372511045}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=3.2 rank.β=0.49 lr=2.7e-05 hra.apply_GS=True hra.r=62 |   0.826 |      0 | 1.349 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:15:45,524] Trial 61 finished with value: 1.023121387283237 and parameters: {'lr': 7.346940709116254e-05, 'r': 138, 'apply_GS': False, 'α': 126.29771560392675, 'β': 0.23092723790281325}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                      |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1.3e+02 rank.β=0.23 lr=7.3e-05 hra.apply_GS=False hra.r=138 |   1.653 |      0 | 2.312 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:19:09,896] Trial 62 finished with value: 0.7919075144508672 and parameters: {'lr': 1.4152472933346213e-05, 'r': 91, 'apply_GS': False, 'α': 0.0002709613488314965, 'β': 0.13491843278385426}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                     |   train |   test |     oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------|--------:|-------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.00027 rank.β=0.13 lr=1.4e-05 hra.apply_GS=False hra.r=91 |  -0.826 | -2.362 | -20.809 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:22:33,309] Trial 63 finished with value: 1.0404624277456649 and parameters: {'lr': 0.0002670484007598556, 'r': 74, 'apply_GS': True, 'α': 7.031974420028055, 'β': 0.35395508322985203}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                              |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=7 rank.β=0.35 lr=0.00027 hra.apply_GS=True hra.r=74 |   4.132 |  0.787 | 4.046 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:26:00,618] Trial 64 finished with value: 1.0211946050096339 and parameters: {'lr': 0.00028840515000813866, 'r': 53, 'apply_GS': True, 'α': 8.64113588333861, 'β': 0.3556643353729115}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=8.6 rank.β=0.36 lr=0.00029 hra.apply_GS=True hra.r=53 |   3.306 |  0.787 | 2.119 | 12.281 |\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:26:01,497] Using an existing study with name 'projgrad2' instead of creating a new one.\n",
      "[W 2024-10-06 05:26:01,717] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 307 projgrad2 trials\n",
      "| projgrad2 N=✓0/✖307, best=nan   | importance   | best   |\n",
      "|---------------------------------|--------------|--------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 05:26:02,123] Trial 307 failed with parameters: {'lr': 7.45934328572655e-06, 'β': 0.9507143064099162, 'reverse_pref': True, 'scale_orth': True, 'weight_dim': 0} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 18, in objective\n",
      "    kwargs = trial2args(trial)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/hp/space.py\", line 78, in projgrad\n",
      "    \"neg_slope\": trial.suggest_categorical(\"neg_slope\",[0, 'float']), # error?\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 402, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 637, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 167, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 576, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 611, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 354, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 370, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 674, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-10-06 05:26:02,158] Trial 307 failed with value None.\n",
      "\u001b[31m\u001b[1mCategoricalDistribution does not support dynamic value space.\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kern...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x7ace330fe2a0>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7ace35895650>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x7ace330ff380>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ace3311e010>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7ace35895650>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x7ace3489ee80>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ace3311e010>\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x7ace348a8cc0>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7ace34a8da80>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x7ace330b3060>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7ace3311e510>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.Frame(b'2e4e0502-088'...36B)>, <zmq.Frame(b'<IDS|MSG>')>, <zmq.Frame(b'b4c1d573745e'...64B)>, <zmq.Frame(b'{\"date\":\"20...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7ace3311e510>>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object IPythonKernel.execute_request at 0x7accaea1ce40>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 10, 6, 0, 54, 57, 798000, tzinfo=tzutc()), 'msg_id': '3fe2514e-ab73-4459-bda9-3a8...\n",
      "                                  │       └ [b'2e4e0502-0880-457d-9819-71af57a19d10']\n",
      "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x7ace3311d750>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x7accaf7f9df0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x7ace330e72e0>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': 'vscode-notebook-cell://ssh-remote%2Brunpod/workspace/repr-preference-opt...\n",
      "                             └ ('MAX_TRIALS= 250\\nimport numpy as np\\nspaces = list(search_spaces.items())\\nwhile True:\\n    np.random.shuffle(spaces)\\n    ...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x7ace33c49080>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x7ace223eb5e0>\n",
      "             └ <function _pseudo_sync_runner at 0x7ace33c3c220>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x7ace223eb5e0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_277857/1846718613.py'\n",
      "                       │    │             │        └ [<ast.Assign object at 0x7acbe5d543d0>, <ast.Import object at 0x7acbe5d561a0>, <ast.Assign object at 0x7acbe5d55ae0>, <ast.Wh...\n",
      "                       │    │             └ <ast.Module object at 0x7acbe62eabc0>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7ace33c493a0>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 7acbe5c632d0, execution_count=17 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "             │    │        └ <code object <module> at 0xe9f5ca0, file \"/tmp/ipykernel_277857/1846718613.py\", line 1>\n",
      "             │    └ <function InteractiveShell.run_code at 0x7ace33c49440>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "         │         │    └ <property object at 0x7ace33c31fd0>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "         └ <code object <module> at 0xe9f5ca0, file \"/tmp/ipykernel_277857/1846718613.py\", line 1>\n",
      "\n",
      "> File \"\u001b[32m/tmp/ipykernel_277857/\u001b[0m\u001b[32m\u001b[1m1846718613.py\u001b[0m\", line \u001b[33m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mstudy\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1moptimize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m_objective\u001b[0m\u001b[1m,\u001b[0m\n",
      "    \u001b[36m│     │        └ \u001b[0m\u001b[36m\u001b[1mfunctools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\u001b[0m\n",
      "    \u001b[36m│     └ \u001b[0m\u001b[36m\u001b[1m<function Study.optimize at 0x7accae1e6de0>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<optuna.study.study.Study object at 0x7acb830ee110>\u001b[0m\n",
      "\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "    └ <function _optimize at 0x7accae1e4c20>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "    └ <function _optimize_sequential at 0x7accae1e5f80>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "                   │          │      │     └ (<class 'AssertionError'>, <class 'OSError'>, <class 'RuntimeError'>, <class 'KeyError'>, <class 'torch.OutOfMemoryError'>)\n",
      "                   │          │      └ functools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\n",
      "                   │          └ <optuna.study.study.Study object at 0x7acb830ee110>\n",
      "                   └ <function _run_trial at 0x7accae1e62a0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "          └ ValueError('CategoricalDistribution does not support dynamic value space.')\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      │    └ <optuna.trial._trial.Trial object at 0x7acb8c702090>\n",
      "                      └ functools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\n",
      "\n",
      "  File \"\u001b[32m/tmp/ipykernel_277857/\u001b[0m\u001b[32m\u001b[1m875328504.py\u001b[0m\", line \u001b[33m18\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    \u001b[1mkwargs\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mtrial2args\u001b[0m\u001b[1m(\u001b[0m\u001b[1mtrial\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m         │          └ \u001b[0m\u001b[36m\u001b[1m<optuna.trial._trial.Trial object at 0x7acb8c702090>\u001b[0m\n",
      "    \u001b[36m         └ \u001b[0m\u001b[36m\u001b[1m<function projgrad at 0x7acbf40e76a0>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m/workspace/repr-preference-optimization/reprpo/hp/\u001b[0m\u001b[32m\u001b[1mspace.py\u001b[0m\", line \u001b[33m78\u001b[0m, in \u001b[35mprojgrad\u001b[0m\n",
      "    \u001b[36m\"neg_slope\"\u001b[0m\u001b[1m:\u001b[0m \u001b[1mtrial\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1msuggest_categorical\u001b[0m\u001b[1m(\u001b[0m\u001b[36m\"neg_slope\"\u001b[0m\u001b[1m,\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m,\u001b[0m \u001b[36m'float'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m,\u001b[0m \u001b[30m\u001b[1m# error?\u001b[0m\n",
      "    \u001b[36m             │     └ \u001b[0m\u001b[36m\u001b[1m<function Trial.suggest_categorical at 0x7accae2c72e0>\u001b[0m\n",
      "    \u001b[36m             └ \u001b[0m\u001b[36m\u001b[1m<optuna.trial._trial.Trial object at 0x7acb8c702090>\u001b[0m\n",
      "\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 402, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           │    │        │     │                               └ [0, 'float']\n",
      "           │    │        │     └ <class 'optuna.distributions.CategoricalDistribution'>\n",
      "           │    │        └ 'neg_slope'\n",
      "           │    └ <function Trial._suggest at 0x7accae2c7880>\n",
      "           └ <optuna.trial._trial.Trial object at 0x7acb8c702090>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 637, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "    │       │               │         │     │                             └ CategoricalDistribution(choices=(0, 'float'))\n",
      "    │       │               │         │     └ 0\n",
      "    │       │               │         └ 'neg_slope'\n",
      "    │       │               └ 1534\n",
      "    │       └ <function _CachedStorage.set_trial_param at 0x7accae1bd760>\n",
      "    └ <optuna.storages._cached_storage._CachedStorage object at 0x7acbe5fa43d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 167, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "    │    │        │               │         │           │                     └ CategoricalDistribution(choices=(0, 'float'))\n",
      "    │    │        │               │         │           └ 0\n",
      "    │    │        │               │         └ 'neg_slope'\n",
      "    │    │        │               └ 1534\n",
      "    │    │        └ <function RDBStorage.set_trial_param at 0x7accae1832e0>\n",
      "    │    └ <optuna.storages._rdb.storage.RDBStorage object at 0x7acba0730450>\n",
      "    └ <optuna.storages._cached_storage._CachedStorage object at 0x7acbe5fa43d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 576, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "    │    └ <function RDBStorage._set_trial_param_without_commit at 0x7accae183380>\n",
      "    └ <optuna.storages._rdb.storage.RDBStorage object at 0x7acba0730450>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 611, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "    │           │             └ <sqlalchemy.orm.session.Session object at 0x7acbe5f54150>\n",
      "    │           └ <function TrialParamModel.check_and_add at 0x7acbe68b9a80>\n",
      "    └ <optuna.storages._rdb.models.TrialParamModel object at 0x7acbe59c5510>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 354, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "    │    │                                                            └ <sqlalchemy.orm.session.Session object at 0x7acbe5f54150>\n",
      "    │    └ <function TrialParamModel._check_compatibility_with_previous_trial_param_distributions at 0x7acbe68b9b20>\n",
      "    └ <optuna.storages._rdb.models.TrialParamModel object at 0x7acbe59c5510>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 370, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "    │             └ <function check_distribution_compatibility at 0x7accae272520>\n",
      "    └ <module 'optuna.distributions' from '/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distri...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 674, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "\n",
      "\u001b[31m\u001b[1mValueError\u001b[0m:\u001b[1m CategoricalDistribution does not support dynamic value space.\u001b[0m\n",
      "[I 2024-10-06 05:26:02,887] Using an existing study with name 'projbp' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 24 projbp trials\n",
      "| projbp N=✓10/✖24, best=1.033   |   importance |        best |\n",
      "|:-------------------------------|-------------:|------------:|\n",
      "| β                              |        0.512 | 0.366362    |\n",
      "| lr                             |        0.311 | 2.88884e-06 |\n",
      "| scale_orth                     |        0.128 | 0           |\n",
      "| mag_clip                       |        0.021 |             |\n",
      "| neg_slope                      |        0.014 | 0           |\n",
      "| reverse_pref                   |        0.014 | 0           |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 05:26:13,043] Trial 24 failed with parameters: {'lr': 0.000510881708506212, 'β': 0.40691929271586114, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.014599142035203292} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:26:13,168] Trial 24 failed with value None.\n",
      "[W 2024-10-06 05:26:22,670] Trial 25 failed with parameters: {'lr': 0.00024146928642541696, 'β': 0.9469618763901492, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 486.79567128895224} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:26:22,691] Trial 25 failed with value None.\n",
      "[W 2024-10-06 05:26:32,467] Trial 26 failed with parameters: {'lr': 0.00023742755309823942, 'β': 0.9355618760814246, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 211.27591273852696} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:26:32,485] Trial 26 failed with value None.\n",
      "[W 2024-10-06 05:26:42,108] Trial 27 failed with parameters: {'lr': 0.0002803386680635025, 'β': 0.9666674470691222, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.33801456666794105} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:26:42,127] Trial 27 failed with value None.\n",
      "[W 2024-10-06 05:26:52,033] Trial 28 failed with parameters: {'lr': 0.0001799198232803581, 'β': 0.950594832536664, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 20.41693185456085} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:26:52,055] Trial 28 failed with value None.\n",
      "[W 2024-10-06 05:27:01,753] Trial 29 failed with parameters: {'lr': 0.0002676227571454762, 'β': 0.9564960673660576, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 43.25007708533818} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:01,769] Trial 29 failed with value None.\n",
      "[W 2024-10-06 05:27:12,011] Trial 30 failed with parameters: {'lr': 0.0002064298222259527, 'β': 0.9407696854083638, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 61.34897085469358} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:12,035] Trial 30 failed with value None.\n",
      "[W 2024-10-06 05:27:21,641] Trial 31 failed with parameters: {'lr': 0.00021870058682035926, 'β': 0.9826861567778047, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 41.847163962345945} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:21,666] Trial 31 failed with value None.\n",
      "[W 2024-10-06 05:27:31,612] Trial 32 failed with parameters: {'lr': 8.545656766589975e-05, 'β': 0.9796464996812291, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 99.81914275807573} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:31,634] Trial 32 failed with value None.\n",
      "[W 2024-10-06 05:27:41,091] Trial 33 failed with parameters: {'lr': 0.0002232824649342481, 'β': 0.9216614236939021, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 2598.1008033053577} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:41,121] Trial 33 failed with value None.\n",
      "[W 2024-10-06 05:27:50,826] Trial 34 failed with parameters: {'lr': 0.00022015833982937558, 'β': 0.9795661442849323, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 201.21948553373986} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:27:50,847] Trial 34 failed with value None.\n",
      "[W 2024-10-06 05:28:00,548] Trial 35 failed with parameters: {'lr': 0.0001906422575081695, 'β': 0.9318765986803776, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 109.66807690554973} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:00,570] Trial 35 failed with value None.\n",
      "[W 2024-10-06 05:28:09,976] Trial 36 failed with parameters: {'lr': 0.0002401872098838915, 'β': 0.9626043623638456, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 32.166800111212595} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:10,000] Trial 36 failed with value None.\n",
      "[W 2024-10-06 05:28:19,649] Trial 37 failed with parameters: {'lr': 0.00017641079215708805, 'β': 0.9764486599224619, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.46532967482591175} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:19,672] Trial 37 failed with value None.\n",
      "[W 2024-10-06 05:28:29,219] Trial 38 failed with parameters: {'lr': 0.00036100661346716393, 'β': 0.8690193908638019, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.01853045707350885} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:29,243] Trial 38 failed with value None.\n",
      "[W 2024-10-06 05:28:38,940] Trial 39 failed with parameters: {'lr': 0.00044469997195650574, 'β': 0.9608771169328997, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.5856592971148757} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:38,962] Trial 39 failed with value None.\n",
      "[W 2024-10-06 05:28:49,059] Trial 40 failed with parameters: {'lr': 0.0004413864292455407, 'β': 0.97455268047574, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.0839723893016971} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:49,080] Trial 40 failed with value None.\n",
      "[W 2024-10-06 05:28:58,793] Trial 41 failed with parameters: {'lr': 0.0002516323859322287, 'β': 0.9756074868160973, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.03791242023102684} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:28:58,818] Trial 41 failed with value None.\n",
      "[W 2024-10-06 05:29:08,685] Trial 42 failed with parameters: {'lr': 7.874536924888812e-05, 'β': 0.9994134940876853, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.026094937237758374} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:29:08,713] Trial 42 failed with value None.\n",
      "[W 2024-10-06 05:29:21,082] Trial 43 failed with parameters: {'lr': 0.00021561048224043598, 'β': 0.9664981016783335, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 86.2883507968109} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 05:29:21,109] Trial 43 failed with value None.\n",
      "[I 2024-10-06 05:29:21,906] Using an existing study with name 'ether-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 23 ether-prefvec trials\n",
      "| ether-prefvec N=✓21/✖23, best=1.148   |   importance | best                  |\n",
      "|:--------------------------------------|-------------:|:----------------------|\n",
      "| lr                                    |        0.485 | 0.0002901472921452969 |\n",
      "| β                                     |        0.255 | 1.9166022109203233    |\n",
      "| reduction                             |        0.192 | 1                     |\n",
      "| nb                                    |        0.057 | 20                    |\n",
      "| use_dpo_loss                          |        0.004 | False                 |\n",
      "| collect_hs                            |        0.002 | False                 |\n",
      "| Htype                                 |        0.001 | ether                 |\n",
      "| use_orth_loss                         |        0.001 | True                  |\n",
      "| weight_tokens                         |        0.001 | True                  |\n",
      "| collect_input                         |        0     | True                  |\n",
      "| flip_side                             |        0     | True                  |\n",
      "| use_angle_loss                        |        0     | True                  |\n",
      "| use_nll_loss                          |        0     | True                  |\n",
      "| use_proj_rel                          |        0     | True                  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:32:45,864] Trial 23 finished with value: 1.1290944123314066 and parameters: {'lr': 0.00027057280051179895, 'collect_input': True, 'collect_hs': False, 'nb': 20, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.6123145596810586, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 13 with value: 1.1483622350674374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.6 lr=0.00027 ether.Htype=ether ether.flip_side=True ether.nb=20 ether.reduction=1 |       0 | -0.787 | 12.909 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:36:13,958] Trial 24 finished with value: 1.183044315992293 and parameters: {'lr': 0.00037772770210724844, 'collect_input': True, 'collect_hs': False, 'nb': 20, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.9848539330526844, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                  |   train |   test |    oos |     rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|--------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=2 lr=0.00038 ether.Htype=ether ether.flip_side=True ether.nb=20 ether.reduction=1 |   3.306 |      0 | 18.304 | -12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:39:38,173] Trial 25 finished with value: 0.7398843930635839 and parameters: {'lr': 0.0013843924204659044, 'collect_input': True, 'collect_hs': False, 'nb': 18, 'Htype': 'ether', 'flip_side': True, 'reduction': 2, 'β': 0.0642733051555277, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |    test |     oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.064 lr=0.0014 ether.Htype=ether ether.flip_side=True ether.nb=18 ether.reduction=2 | -12.397 | -11.024 | -26.012 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:42:58,854] Trial 26 finished with value: 1.0308285163776494 and parameters: {'lr': 6.222901334703244e-05, 'collect_input': True, 'collect_hs': False, 'nb': 8, 'Htype': 'ether', 'flip_side': True, 'reduction': 7, 'β': 0.21886655961073495, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.22 lr=6.2e-05 ether.Htype=ether ether.flip_side=True ether.nb=8 ether.reduction=7 |       0 |      0 | 3.083 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:46:26,916] Trial 27 finished with value: 1.088631984585742 and parameters: {'lr': 0.000540241927460827, 'collect_input': True, 'collect_hs': False, 'nb': 15, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 0.011498665887108626, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                      |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.011 lr=0.00054 ether.Htype=ether ether.flip_side=True ether.nb=15 ether.reduction=1 |       0 | -0.787 | 8.863 | -5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:49:54,684] Trial 28 finished with value: 0.4084778420038536 and parameters: {'lr': 0.009807755438248326, 'collect_input': False, 'collect_hs': False, 'nb': 23, 'Htype': 'ether', 'flip_side': False, 'reduction': 3, 'β': 0.7347190386431403, 'use_orth_loss': True, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |    test |     oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO prefvec.use_angle_prefvec=False prefvec.use_orth_prefvec=True prefvec.weight_tokens=True prefvec.β=0.73 lr=0.0098 ether.Htype=ether ether.nb=23 ether.reduction=3 | -47.934 | -37.795 | -59.152 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:53:19,039] Trial 29 finished with value: 0.5414258188824663 and parameters: {'lr': 0.001959142662897505, 'collect_input': True, 'collect_hs': False, 'nb': 9, 'Htype': 'ether', 'flip_side': True, 'reduction': 2, 'β': 1.9242415385419622, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                 |   train |    test |     oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.9 lr=0.002 ether.Htype=ether ether.flip_side=True ether.nb=9 ether.reduction=2 | -34.711 | -26.772 | -45.857 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 05:56:45,693] Trial 30 finished with value: 1.0500963391136802 and parameters: {'lr': 0.00013320293018846333, 'collect_input': True, 'collect_hs': False, 'nb': 5, 'Htype': 'etherplus', 'flip_side': True, 'reduction': 13, 'β': 0.12242203835214704, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                         |   train |   test |   oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.12 lr=0.00013 ether.Htype=etherplus ether.flip_side=True ether.nb=5 ether.reduction=13 |       0 |      0 |  5.01 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:00:09,564] Trial 31 finished with value: 0.9961464354527939 and parameters: {'lr': 3.5423338515200635e-05, 'collect_input': True, 'collect_hs': False, 'nb': 32, 'Htype': 'etherplus', 'flip_side': False, 'reduction': 6, 'β': 0.5002968574839632, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                |   train |   test |    oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_angle_prefvec=False prefvec.use_nll_prefvec=True prefvec.β=0.5 lr=3.5e-05 ether.Htype=etherplus ether.nb=32 ether.reduction=6 |       0 |      0 | -0.385 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:03:33,557] Trial 32 finished with value: 1.0770712909441233 and parameters: {'lr': 0.00034275767251676153, 'collect_input': True, 'collect_hs': False, 'nb': 2, 'Htype': 'ether', 'flip_side': True, 'reduction': 29, 'β': 0.014314831997847988, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                      |   train |   test |   oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.014 lr=0.00034 ether.Htype=ether ether.flip_side=True ether.nb=2 ether.reduction=29 |   1.653 | -0.787 | 7.707 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:07:00,437] Trial 33 finished with value: 1.1753371868978806 and parameters: {'lr': 0.0003513706413025965, 'collect_input': True, 'collect_hs': False, 'nb': 20, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.7504573795760632, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |     rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|--------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.8 lr=0.00035 ether.Htype=ether ether.flip_side=True ether.nb=20 ether.reduction=1 |   1.653 |      0 | 17.534 | -12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:10:23,395] Trial 34 finished with value: 1.1502890173410405 and parameters: {'lr': 0.0005495447376543452, 'collect_input': True, 'collect_hs': False, 'nb': 24, 'Htype': 'ether', 'flip_side': True, 'reduction': 3, 'β': 0.8364594214066026, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |    oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.84 lr=0.00055 ether.Htype=ether ether.flip_side=True ether.nb=24 ether.reduction=3 |       0 | -0.787 | 15.029 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:13:47,706] Trial 35 finished with value: 1.159922928709056 and parameters: {'lr': 0.0005024514091269327, 'collect_input': True, 'collect_hs': False, 'nb': 16, 'Htype': 'ether', 'flip_side': True, 'reduction': 3, 'β': 0.3210368338780154, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.32 lr=0.0005 ether.Htype=ether ether.flip_side=True ether.nb=16 ether.reduction=3 |   4.132 | -0.787 | 15.992 | -8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:17:00,840] Trial 36 finished with value: 0.4315992292870906 and parameters: {'lr': 0.0020246691409722484, 'collect_input': True, 'collect_hs': True, 'nb': 15, 'Htype': 'ether', 'flip_side': True, 'reduction': 3, 'β': 0.3325102211190215, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                          |   train |    test |    oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_angle_prefvec=False prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.33 lr=0.002 ether.Htype=ether ether.flip_side=True ether.nb=15 ether.reduction=3 | -47.107 | -35.433 | -56.84 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:20:19,870] Trial 37 finished with value: 1.0500963391136802 and parameters: {'lr': 0.00010045460667598762, 'collect_input': True, 'collect_hs': False, 'nb': 11, 'Htype': 'oft', 'flip_side': True, 'reduction': 4, 'β': 0.07531537523426912, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                            |   train |   test |   oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_orth_prefvec=True prefvec.weight_tokens=True prefvec.β=0.075 lr=0.0001 ether.Htype=oft ether.flip_side=True ether.nb=11 ether.reduction=4 |       0 |  0.787 |  5.01 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:23:44,872] Trial 38 finished with value: 0.6281310211946051 and parameters: {'lr': 0.0004955151888597254, 'collect_input': False, 'collect_hs': True, 'nb': 23, 'Htype': 'etherplus', 'flip_side': False, 'reduction': 3, 'β': 0.7049847512470013, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                   |   train |    test |     oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.7 lr=0.0005 ether.Htype=etherplus ether.nb=23 ether.reduction=3 | -16.529 | -11.024 | -37.187 | 28.07 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:27:04,906] Trial 39 finished with value: 0.4470134874759153 and parameters: {'lr': 0.0022100376622240974, 'collect_input': True, 'collect_hs': False, 'nb': 15, 'Htype': 'oft', 'flip_side': True, 'reduction': 5, 'β': 0.28954685653247836, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                     |   train |    test |     oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.29 lr=0.0022 ether.Htype=oft ether.flip_side=True ether.nb=15 ether.reduction=5 | -43.802 | -33.858 | -55.299 | -5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:30:38,867] Trial 40 finished with value: 1.0038535645472062 and parameters: {'lr': 1.4893745136120191e-05, 'collect_input': False, 'collect_hs': False, 'nb': 25, 'Htype': 'ether', 'flip_side': True, 'reduction': 21, 'β': 0.07617990393397168, 'use_orth_loss': True, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                               |   train |   test |   oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO prefvec.use_angle_prefvec=False prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.β=0.076 lr=1.5e-05 ether.Htype=ether ether.flip_side=True ether.nb=25 ether.reduction=21 |   0.826 |      0 | 0.385 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:34:03,575] Trial 41 finished with value: 0.535645472061657 and parameters: {'lr': 0.00855261240463271, 'collect_input': True, 'collect_hs': True, 'nb': 9, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 106, 'β': 0.0015255924591023127, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                       |   train |    test |     oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.0015 lr=0.0086 ether.flip_side=True ether.nb=9 ether.reduction=106 | -24.793 | -22.835 | -46.435 | 28.07 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:37:27,715] Trial 42 finished with value: 0.535645472061657 and parameters: {'lr': 0.00044538247629857857, 'collect_input': True, 'collect_hs': False, 'nb': 17, 'Htype': 'oft', 'flip_side': False, 'reduction': 2, 'β': 0.0002725993287154416, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                 |   train |    test |     oos |   rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.00027 lr=0.00045 ether.Htype=oft ether.nb=17 ether.reduction=2 |  -25.62 | -19.685 | -46.435 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:37:28,572] Using an existing study with name 'hs-ortho-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 40 hs-ortho-prefvec trials\n",
      "| hs-ortho-prefvec N=✓40/✖40, best=1.118   |   importance | best                   |\n",
      "|:-----------------------------------------|-------------:|:-----------------------|\n",
      "| lr                                       |        0.767 | 0.00012461222072738544 |\n",
      "| β                                        |        0.207 | 0.3412333287913769     |\n",
      "| use_nll_loss                             |        0.009 | False                  |\n",
      "| use_orth_loss                            |        0.006 | False                  |\n",
      "| orthogonal_map                           |        0.004 | matrix_exp             |\n",
      "| use_dpo_loss                             |        0.003 | True                   |\n",
      "| weight_tokens                            |        0.003 | True                   |\n",
      "| use_proj_rel                             |        0.001 | True                   |\n",
      "| use_angle_loss                           |        0     | True                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:40:39,527] Trial 40 finished with value: 0.9961464354527939 and parameters: {'lr': 3.9867935658727725e-05, 'orthogonal_map': 'cayley', 'β': 0.001837247699906843, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                |   train |   test |    oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.0018 lr=4e-05 ortho.orthogonal_map=cayley |       0 |      0 | -0.385 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:44:01,288] Trial 41 finished with value: 1.094412331406551 and parameters: {'lr': 0.00023024988630700053, 'orthogonal_map': 'matrix_exp', 'β': 0.8033261383517015, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                    |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.8 lr=0.00023 ortho.orthogonal_map=matrix_exp |   4.132 |      0 | 9.441 | 14.035 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:47:25,864] Trial 42 finished with value: 1.0346820809248556 and parameters: {'lr': 5.960061887970884e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.591900446280974, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.59 lr=6e-05 ortho.orthogonal_map=matrix_exp |   1.653 |      0 | 3.468 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:50:54,519] Trial 43 finished with value: 0.5221579961464355 and parameters: {'lr': 0.0009982365511321367, 'orthogonal_map': 'matrix_exp', 'β': 0.9946435751501622, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.99 lr=0.001 ortho.orthogonal_map=matrix_exp | -12.397 | -20.472 | -47.784 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:54:18,932] Trial 44 finished with value: 0.9672447013487476 and parameters: {'lr': 0.0004545300790566714, 'orthogonal_map': 'matrix_exp', 'β': 1.8271581791162788, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                    |   train |   test |    oos |   rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=1.8 lr=0.00045 ortho.orthogonal_map=matrix_exp |   2.479 |  0.787 | -3.276 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 06:57:44,195] Trial 45 finished with value: 1.0578034682080926 and parameters: {'lr': 0.00019730724112700825, 'orthogonal_map': 'matrix_exp', 'β': 0.05234674375767749, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.052 lr=0.0002 ortho.orthogonal_map=matrix_exp |   4.959 |      0 |  5.78 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:01:02,000] Trial 46 finished with value: 1.044315992292871 and parameters: {'lr': 7.42404537558471e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.5350921175310159, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                  |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.weight_tokens=True prefvec.β=0.54 lr=7.4e-05 ortho.orthogonal_map=matrix_exp |   1.653 |      0 | 4.432 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:04:09,917] Trial 47 finished with value: 0.4296724470134875 and parameters: {'lr': 0.00019531754032409994, 'orthogonal_map': 'householder', 'β': 0.332477402970353, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                             |   train |    test |     oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.β=0.33 lr=0.0002 ortho.orthogonal_map=householder |  -48.76 | -33.858 | -57.033 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:07:30,100] Trial 48 finished with value: 1.0250481695568403 and parameters: {'lr': 2.3213575329172547e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.13674752166625562, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                               |   train |   test |   oos |   rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.14 lr=2.3e-05 ortho.orthogonal_map=matrix_exp |   0.826 |      0 | 2.505 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:10:52,526] Trial 49 finished with value: 0.8323699421965318 and parameters: {'lr': 0.000601715290068621, 'orthogonal_map': 'matrix_exp', 'β': 1.8569414712450746e-05, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                               |   train |   test |     oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.9e-05 lr=0.0006 ortho.orthogonal_map=matrix_exp |  -5.785 | -7.087 | -16.763 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:14:14,044] Trial 50 finished with value: 1.0308285163776494 and parameters: {'lr': 3.4925586100146066e-05, 'orthogonal_map': 'cayley', 'β': 0.07181876571672766, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                            |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.072 lr=3.5e-05 ortho.orthogonal_map=cayley |   2.479 |      0 | 3.083 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:17:36,250] Trial 51 finished with value: 1.0539499036608864 and parameters: {'lr': 0.00015236756126156922, 'orthogonal_map': 'matrix_exp', 'β': 0.7072515850874993, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.71 lr=0.00015 ortho.orthogonal_map=matrix_exp |   4.132 |      0 | 5.395 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:21:08,514] Trial 52 finished with value: 1.0597302504816957 and parameters: {'lr': 0.0003098713597710707, 'orthogonal_map': 'matrix_exp', 'β': 0.9103861835463519, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 19 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.91 lr=0.00031 ortho.orthogonal_map=matrix_exp |   4.959 |  0.787 | 5.973 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:24:30,450] Trial 53 finished with value: 1.1310211946050097 and parameters: {'lr': 0.00023889593063246652, 'orthogonal_map': 'matrix_exp', 'β': 0.2189870349392484, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |    oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.22 lr=0.00024 ortho.orthogonal_map=matrix_exp |   4.959 | -0.787 | 13.102 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:27:50,311] Trial 54 finished with value: 0.5028901734104047 and parameters: {'lr': 0.0008385828395394134, 'orthogonal_map': 'matrix_exp', 'β': 0.24323702641375866, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |    test |     oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.24 lr=0.00084 ortho.orthogonal_map=matrix_exp | -23.967 | -26.772 | -49.711 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:31:13,089] Trial 55 finished with value: 1.0115606936416186 and parameters: {'lr': 0.0004342106741843916, 'orthogonal_map': 'matrix_exp', 'β': 0.024760626818238703, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                      |   train |   test |   oos |    rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.025 lr=0.00043 ortho.orthogonal_map=matrix_exp |   4.132 | -0.787 | 1.156 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:34:31,274] Trial 56 finished with value: 1.0520231213872833 and parameters: {'lr': 0.0001234371308829511, 'orthogonal_map': 'matrix_exp', 'β': 0.4086591646581516, 'use_orth_loss': False, 'use_angle_loss': False, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': False}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_angle_prefvec=False prefvec.use_dpo_prefvec=True prefvec.weight_tokens=True prefvec.β=0.41 lr=0.00012 ortho.orthogonal_map=matrix_exp |   3.306 |      0 | 5.202 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:37:42,564] Trial 57 finished with value: 1.0327552986512525 and parameters: {'lr': 0.00023847128154378647, 'orthogonal_map': 'matrix_exp', 'β': 0.09293347427064105, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': True}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.β=0.093 lr=0.00024 ortho.orthogonal_map=matrix_exp |   0.826 |      0 | 3.276 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:41:01,139] Trial 58 finished with value: 0.4913294797687862 and parameters: {'lr': 0.0015315026967341549, 'orthogonal_map': 'matrix_exp', 'β': 0.05018204163362304, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |    test |     oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.05 lr=0.0015 ortho.orthogonal_map=matrix_exp | -32.231 | -23.622 | -50.867 | 22.807 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:44:23,259] Trial 59 finished with value: 1.0751445086705202 and parameters: {'lr': 8.643143914150594e-05, 'orthogonal_map': 'matrix_exp', 'β': 0.20213469069945655, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 53 with value: 1.1310211946050097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                              |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True prefvec.use_dpo_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.2 lr=8.6e-05 ortho.orthogonal_map=matrix_exp |   3.306 |      0 | 7.514 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:44:24,106] Using an existing study with name 'projgrad2' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 07:44:24,298] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 308 projgrad2 trials\n",
      "| projgrad2 N=✓0/✖308, best=nan   | importance   | best   |\n",
      "|---------------------------------|--------------|--------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 07:44:24,811] Trial 308 failed with parameters: {'lr': 7.45934328572655e-06, 'β': 0.9507143064099162, 'reverse_pref': True, 'scale_orth': True, 'weight_dim': 0} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 18, in objective\n",
      "    kwargs = trial2args(trial)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/hp/space.py\", line 78, in projgrad\n",
      "    \"neg_slope\": trial.suggest_categorical(\"neg_slope\",[0, 'float']), # error?\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 402, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 637, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 167, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 576, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 611, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 354, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 370, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 674, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-10-06 07:44:24,816] Trial 308 failed with value None.\n",
      "\u001b[31m\u001b[1mCategoricalDistribution does not support dynamic value space.\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kern...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x7ace330fe2a0>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7ace35895650>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x7ace330ff380>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ace3311e010>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x7ace35895650>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x7ace3489ee80>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ace3311e010>\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x7ace348a8cc0>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x7ace34a8da80>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...4B)>, ...],))>)>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x7ace330b3060>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x7ace3311e510>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.Frame(b'2e4e0502-088'...36B)>, <zmq.Frame(b'<IDS|MSG>')>, <zmq.Frame(b'b4c1d573745e'...64B)>, <zmq.Frame(b'{\"date\":\"20...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x7ace3311e510>>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object IPythonKernel.execute_request at 0x7accaea1ce40>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 10, 6, 0, 54, 57, 798000, tzinfo=tzutc()), 'msg_id': '3fe2514e-ab73-4459-bda9-3a8...\n",
      "                                  │       └ [b'2e4e0502-0880-457d-9819-71af57a19d10']\n",
      "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x7ace3311d750>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x7accaf7f9df0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x7ace330e72e0>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': 'vscode-notebook-cell://ssh-remote%2Brunpod/workspace/repr-preference-opt...\n",
      "                             └ ('MAX_TRIALS= 250\\nimport numpy as np\\nspaces = list(search_spaces.items())\\nwhile True:\\n    np.random.shuffle(spaces)\\n    ...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x7ace33c49080>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x7ace223eb5e0>\n",
      "             └ <function _pseudo_sync_runner at 0x7ace33c3c220>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x7ace223eb5e0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/tmp/ipykernel_277857/1846718613.py'\n",
      "                       │    │             │        └ [<ast.Assign object at 0x7acbe5d543d0>, <ast.Import object at 0x7acbe5d561a0>, <ast.Assign object at 0x7acbe5d55ae0>, <ast.Wh...\n",
      "                       │    │             └ <ast.Module object at 0x7acbe62eabc0>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x7ace33c493a0>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 7acbe5c632d0, execution_count=17 error_before_exec=None error_in_exec=None info=<ExecutionInfo obj...\n",
      "             │    │        └ <code object <module> at 0xe9f5ca0, file \"/tmp/ipykernel_277857/1846718613.py\", line 1>\n",
      "             │    └ <function InteractiveShell.run_code at 0x7ace33c49440>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "         │         │    └ <property object at 0x7ace33c31fd0>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ace221dfbd0>\n",
      "         └ <code object <module> at 0xe9f5ca0, file \"/tmp/ipykernel_277857/1846718613.py\", line 1>\n",
      "\n",
      "> File \"\u001b[32m/tmp/ipykernel_277857/\u001b[0m\u001b[32m\u001b[1m1846718613.py\u001b[0m\", line \u001b[33m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mstudy\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1moptimize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m_objective\u001b[0m\u001b[1m,\u001b[0m\n",
      "    \u001b[36m│     │        └ \u001b[0m\u001b[36m\u001b[1mfunctools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\u001b[0m\n",
      "    \u001b[36m│     └ \u001b[0m\u001b[36m\u001b[1m<function Study.optimize at 0x7accae1e6de0>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<optuna.study.study.Study object at 0x7acb82b1f110>\u001b[0m\n",
      "\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "    └ <function _optimize at 0x7accae1e4c20>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "    └ <function _optimize_sequential at 0x7accae1e5f80>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "                   │          │      │     └ (<class 'AssertionError'>, <class 'OSError'>, <class 'RuntimeError'>, <class 'KeyError'>, <class 'torch.OutOfMemoryError'>)\n",
      "                   │          │      └ functools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\n",
      "                   │          └ <optuna.study.study.Study object at 0x7acb82b1f110>\n",
      "                   └ <function _run_trial at 0x7accae1e62a0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "          └ ValueError('CategoricalDistribution does not support dynamic value space.')\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      │    └ <optuna.trial._trial.Trial object at 0x7acbe673f810>\n",
      "                      └ functools.partial(<function objective at 0x7acbe8145a80>, key_metric='acc_gain_vs_ref/oos', starter_experiment_name='projgrad...\n",
      "\n",
      "  File \"\u001b[32m/tmp/ipykernel_277857/\u001b[0m\u001b[32m\u001b[1m875328504.py\u001b[0m\", line \u001b[33m18\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    \u001b[1mkwargs\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mtrial2args\u001b[0m\u001b[1m(\u001b[0m\u001b[1mtrial\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m         │          └ \u001b[0m\u001b[36m\u001b[1m<optuna.trial._trial.Trial object at 0x7acbe673f810>\u001b[0m\n",
      "    \u001b[36m         └ \u001b[0m\u001b[36m\u001b[1m<function projgrad at 0x7acbf40e76a0>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m/workspace/repr-preference-optimization/reprpo/hp/\u001b[0m\u001b[32m\u001b[1mspace.py\u001b[0m\", line \u001b[33m78\u001b[0m, in \u001b[35mprojgrad\u001b[0m\n",
      "    \u001b[36m\"neg_slope\"\u001b[0m\u001b[1m:\u001b[0m \u001b[1mtrial\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1msuggest_categorical\u001b[0m\u001b[1m(\u001b[0m\u001b[36m\"neg_slope\"\u001b[0m\u001b[1m,\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m,\u001b[0m \u001b[36m'float'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m,\u001b[0m \u001b[30m\u001b[1m# error?\u001b[0m\n",
      "    \u001b[36m             │     └ \u001b[0m\u001b[36m\u001b[1m<function Trial.suggest_categorical at 0x7accae2c72e0>\u001b[0m\n",
      "    \u001b[36m             └ \u001b[0m\u001b[36m\u001b[1m<optuna.trial._trial.Trial object at 0x7acbe673f810>\u001b[0m\n",
      "\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 402, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           │    │        │     │                               └ [0, 'float']\n",
      "           │    │        │     └ <class 'optuna.distributions.CategoricalDistribution'>\n",
      "           │    │        └ 'neg_slope'\n",
      "           │    └ <function Trial._suggest at 0x7accae2c7880>\n",
      "           └ <optuna.trial._trial.Trial object at 0x7acbe673f810>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 637, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "    │       │               │         │     │                             └ CategoricalDistribution(choices=(0, 'float'))\n",
      "    │       │               │         │     └ 0\n",
      "    │       │               │         └ 'neg_slope'\n",
      "    │       │               └ 1595\n",
      "    │       └ <function _CachedStorage.set_trial_param at 0x7accae1bd760>\n",
      "    └ <optuna.storages._cached_storage._CachedStorage object at 0x7acbe68791d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 167, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "    │    │        │               │         │           │                     └ CategoricalDistribution(choices=(0, 'float'))\n",
      "    │    │        │               │         │           └ 0\n",
      "    │    │        │               │         └ 'neg_slope'\n",
      "    │    │        │               └ 1595\n",
      "    │    │        └ <function RDBStorage.set_trial_param at 0x7accae1832e0>\n",
      "    │    └ <optuna.storages._rdb.storage.RDBStorage object at 0x7acbe6190dd0>\n",
      "    └ <optuna.storages._cached_storage._CachedStorage object at 0x7acbe68791d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 576, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "    │    └ <function RDBStorage._set_trial_param_without_commit at 0x7accae183380>\n",
      "    └ <optuna.storages._rdb.storage.RDBStorage object at 0x7acbe6190dd0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 611, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "    │           │             └ <sqlalchemy.orm.session.Session object at 0x7acbe59d3ed0>\n",
      "    │           └ <function TrialParamModel.check_and_add at 0x7acbe68b9a80>\n",
      "    └ <optuna.storages._rdb.models.TrialParamModel object at 0x7acba03946d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 354, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "    │    │                                                            └ <sqlalchemy.orm.session.Session object at 0x7acbe59d3ed0>\n",
      "    │    └ <function TrialParamModel._check_compatibility_with_previous_trial_param_distributions at 0x7acbe68b9b20>\n",
      "    └ <optuna.storages._rdb.models.TrialParamModel object at 0x7acba03946d0>\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 370, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "    │             └ <function check_distribution_compatibility at 0x7accae272520>\n",
      "    └ <module 'optuna.distributions' from '/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distri...\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 674, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "\n",
      "\u001b[31m\u001b[1mValueError\u001b[0m:\u001b[1m CategoricalDistribution does not support dynamic value space.\u001b[0m\n",
      "[I 2024-10-06 07:44:25,697] Using an existing study with name 'hs-svd-mse' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 332 hs-svd-mse trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:44:26,358] Using an existing study with name 'hs-hra-rank' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| hs-svd-mse N=✓14/✖332, best=1.017   |   importance | best                  |\n",
      "|:------------------------------------|-------------:|:----------------------|\n",
      "| lr                                  |        0.752 | 0.0011948328168545441 |\n",
      "| α                                   |        0.189 | 0.6355835028602363    |\n",
      "| collect_input                       |        0.056 | False                 |\n",
      "| collect_hs                          |        0.003 | True                  |\n",
      "| dual_svd                            |        0     | True                  |\n",
      "| quantile                            |        0     | float                 |\n",
      "| quantile_value                      |      nan     | 0.30000000000000004   |\n",
      "================================================================================\n",
      "loaded 65 hs-hra-rank trials\n",
      "| hs-hra-rank N=✓63/✖65, best=1.118   |   importance |         best |\n",
      "|:------------------------------------|-------------:|-------------:|\n",
      "| lr                                  |        0.728 |  0.000295068 |\n",
      "| r                                   |        0.181 | 87           |\n",
      "| α                                   |        0.054 |  2.47422     |\n",
      "| β                                   |        0.031 |  0.441272    |\n",
      "| apply_GS                            |        0.006 |  1           |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:47:44,337] Trial 65 finished with value: 0.5684007707129095 and parameters: {'lr': 0.0008671088919636775, 'r': 89, 'apply_GS': True, 'α': 26.671293855105542, 'β': 0.7059876643354057}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |    test |    oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|--------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=27 rank.β=0.71 lr=0.00087 hra.apply_GS=True hra.r=89 |  -8.264 | -11.811 | -43.16 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:51:04,866] Trial 66 finished with value: 1.0539499036608864 and parameters: {'lr': 0.0001632002830196323, 'r': 182, 'apply_GS': True, 'α': 1.0316397168629856, 'β': 0.44925439438157366}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |   oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1 rank.β=0.45 lr=0.00016 hra.apply_GS=True hra.r=182 |   4.959 |      0 | 5.395 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:54:26,299] Trial 67 finished with value: 1.0578034682080926 and parameters: {'lr': 0.0001410901695945212, 'r': 240, 'apply_GS': True, 'α': 1.5782195316775016, 'β': 0.5217092900690894}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1.6 rank.β=0.52 lr=0.00014 hra.apply_GS=True hra.r=240 |   2.479 |      0 |  5.78 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 07:57:45,509] Trial 68 finished with value: 0.9942196531791907 and parameters: {'lr': 0.0001874991694384327, 'r': 379, 'apply_GS': True, 'α': 1.6461247721080716, 'β': 0.523160926589976}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |    oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1.6 rank.β=0.52 lr=0.00019 hra.apply_GS=True hra.r=379 |   0.826 | -0.787 | -0.578 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:01:06,175] Trial 69 finished with value: 1.0655105973025047 and parameters: {'lr': 0.0001248730975008268, 'r': 231, 'apply_GS': True, 'α': 1.5451432922945487, 'β': 1.10382516653629}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1.5 rank.β=1.1 lr=0.00012 hra.apply_GS=True hra.r=231 |   5.785 |      0 | 6.551 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:04:24,080] Trial 70 finished with value: 1.0597302504816957 and parameters: {'lr': 0.00048262849408558416, 'r': 287, 'apply_GS': True, 'α': 0.24178700076464854, 'β': 0.9954018112718899}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_hs=True rank.α=0.24 rank.β=1 lr=0.00048 hra.apply_GS=True hra.r=287 |   3.306 |      0 | 5.973 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:07:45,298] Trial 71 finished with value: 0.48554913294797697 and parameters: {'lr': 0.001955823291657308, 'r': 330, 'apply_GS': True, 'α': 0.22508429317882464, 'β': 1.7589269365580213}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                               |   train |    test |     oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.23 rank.β=1.8 lr=0.002 hra.apply_GS=True hra.r=330 | -29.752 | -28.346 | -51.445 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:11:06,898] Trial 72 finished with value: 1.0250481695568403 and parameters: {'lr': 0.0004186029095108628, 'r': 424, 'apply_GS': True, 'α': 0.07396012866185511, 'β': 1.3175740408557266}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                  |   train |   test |   oos |     rnd |\n",
      "|:--------------------------------------------------------------------------------------|--------:|-------:|------:|--------:|\n",
      "| ReprPO collect_hs=True rank.α=0.074 rank.β=1.3 lr=0.00042 hra.apply_GS=True hra.r=424 |  -0.826 |  0.787 | 2.505 | -12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:14:29,145] Trial 73 finished with value: 1.0481695568400773 and parameters: {'lr': 0.0001202403424202951, 'r': 273, 'apply_GS': True, 'α': 0.3393223990913148, 'β': 0.9840101338921455}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                  |   train |   test |   oos |    rnd |\n",
      "|:--------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.34 rank.β=0.98 lr=0.00012 hra.apply_GS=True hra.r=273 |   4.132 |      0 | 4.817 | 17.544 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:17:51,826] Trial 74 finished with value: 0.6801541425818883 and parameters: {'lr': 0.0007223639068357127, 'r': 207, 'apply_GS': True, 'α': 3.709814248441998, 'β': 1.3290524372440018}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |     oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=3.7 rank.β=1.3 lr=0.00072 hra.apply_GS=True hra.r=207 |  -6.612 |  -3.15 | -31.985 | -8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:21:14,012] Trial 75 finished with value: 0.9884393063583816 and parameters: {'lr': 5.378195107805544e-05, 'r': 251, 'apply_GS': True, 'α': 0.6192205127779913, 'β': 2.3509612449924813}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |    oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.62 rank.β=2.4 lr=5.4e-05 hra.apply_GS=True hra.r=251 |   0.826 |      0 | -1.156 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:24:36,700] Trial 76 finished with value: 0.9421965317919077 and parameters: {'lr': 0.00024290830430073534, 'r': 328, 'apply_GS': True, 'α': 1.414595341335333, 'β': 0.636364499436993}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=1.4 rank.β=0.64 lr=0.00024 hra.apply_GS=True hra.r=328 |   2.479 | -0.787 | -5.78 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:27:58,538] Trial 77 finished with value: 0.9075144508670521 and parameters: {'lr': 0.00046148172788641165, 'r': 159, 'apply_GS': True, 'α': 2.2292990794476633, 'β': 0.8884552322963928}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |    oos |     rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|-------:|--------:|\n",
      "| ReprPO collect_hs=True rank.α=2.2 rank.β=0.89 lr=0.00046 hra.apply_GS=True hra.r=159 |   4.959 | -1.575 | -9.249 | -19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:31:21,243] Trial 78 finished with value: 1.0115606936416186 and parameters: {'lr': 8.846897825710458e-05, 'r': 237, 'apply_GS': True, 'α': 13.416482610100687, 'β': 0.5774380278605253}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=13 rank.β=0.58 lr=8.8e-05 hra.apply_GS=True hra.r=237 |   4.132 |      0 | 1.156 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:34:42,411] Trial 79 finished with value: 1.1098265895953758 and parameters: {'lr': 0.00023174505424101272, 'r': 450, 'apply_GS': True, 'α': 0.01927930235219434, 'β': 0.7324943218421319}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                   |   train |   test |    oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.019 rank.β=0.73 lr=0.00023 hra.apply_GS=True hra.r=450 |   4.132 |      0 | 10.983 | -1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:38:05,668] Trial 80 finished with value: 0.5279383429672447 and parameters: {'lr': 0.0010693420554659812, 'r': 462, 'apply_GS': True, 'α': 0.023890351229978596, 'β': 0.7426673124276196}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                  |   train |    test |     oos |    rnd |\n",
      "|:--------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.024 rank.β=0.74 lr=0.0011 hra.apply_GS=True hra.r=462 | -20.661 | -18.898 | -47.206 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:41:27,443] Trial 81 finished with value: 1.0828516377649327 and parameters: {'lr': 0.0002517246162022116, 'r': 33, 'apply_GS': True, 'α': 0.14946357994972606, 'β': 1.573507191194125}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                |   train |   test |   oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.15 rank.β=1.6 lr=0.00025 hra.apply_GS=True hra.r=33 |   3.306 | -0.787 | 8.285 | 33.333 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:44:51,324] Trial 82 finished with value: 1.0308285163776494 and parameters: {'lr': 0.00010505694964037513, 'r': 18, 'apply_GS': True, 'α': 0.015946119685078333, 'β': 3.247881167442306}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |   oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.016 rank.β=3.2 lr=0.00011 hra.apply_GS=True hra.r=18 |   2.479 |      0 | 3.083 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:48:13,907] Trial 83 finished with value: 0.9865125240847784 and parameters: {'lr': 0.0002159261134946999, 'r': 34, 'apply_GS': True, 'α': 0.08289588485171438, 'β': 2.134476185794796}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |    oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.083 rank.β=2.1 lr=0.00022 hra.apply_GS=True hra.r=34 |   5.785 |      0 | -1.349 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:51:32,424] Trial 84 finished with value: 0.8285163776493257 and parameters: {'lr': 0.0006735404734733726, 'r': 362, 'apply_GS': True, 'α': 0.17539342040087633, 'β': 1.5130853594130536}. Best is trial 53 with value: 1.117533718689788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                 |   train |   test |     oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------|--------:|-------:|--------:|-------:|\n",
      "| ReprPO collect_hs=True rank.α=0.18 rank.β=1.5 lr=0.00067 hra.apply_GS=True hra.r=362 |       0 | -4.724 | -17.148 | 15.789 |\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:51:33,340] Using an existing study with name 'dpo' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 30 dpo trials\n",
      "| dpo N=✓28/✖30, best=1.198   |   importance |        best |\n",
      "|:----------------------------|-------------:|------------:|\n",
      "| lr                          |            1 | 0.000279486 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:54:53,193] Trial 30 finished with value: 1.2620423892100192 and parameters: {'lr': 0.00025477333688550156}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00025         |   5.785 |  0.787 | 26.204 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 08:58:16,726] Trial 31 finished with value: 0.5202312138728324 and parameters: {'lr': 0.0010089911001035861}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |     oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|--------:|------:|\n",
      "| DPO lr=0.001           | -19.008 | -18.11 | -47.977 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:01:35,465] Trial 32 finished with value: 1.2119460500963393 and parameters: {'lr': 0.0003024050342772714}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.0003          |   5.785 | -0.787 | 21.195 | 26.316 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:04:56,496] Trial 33 finished with value: 1.1849710982658959 and parameters: {'lr': 0.0002660113741920887}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|------:|\n",
      "| DPO lr=0.00027         |   4.959 |      0 | 18.497 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:08:15,384] Trial 34 finished with value: 0.5183044315992293 and parameters: {'lr': 0.0007326081810912613}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00073         | -16.529 | -21.26 | -48.17 | 22.807 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:11:33,022] Trial 35 finished with value: 1.1560693641618498 and parameters: {'lr': 0.00024342730591403548}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|------:|\n",
      "| DPO lr=0.00024         |   5.785 |      0 | 15.607 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:14:55,571] Trial 36 finished with value: 0.9922928709055877 and parameters: {'lr': 3.875227167611519e-05}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=3.9e-05         |   5.785 | -1.575 | -0.771 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:18:15,044] Trial 37 finished with value: 0.6146435452793835 and parameters: {'lr': 0.002735281468893447}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|-------:|\n",
      "| DPO lr=0.0027          | -10.744 | -14.961 | -38.536 | 19.298 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:21:27,996] Trial 38 finished with value: 1.001926782273603 and parameters: {'lr': 7.124252843547831e-05}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=7.1e-05         |   5.785 | -2.362 | 0.193 | 21.053 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:24:42,447] Trial 39 finished with value: 0.418111753371869 and parameters: {'lr': 0.008523866637217492}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|-------:|\n",
      "| DPO lr=0.0085          | -55.372 | -51.181 | -58.189 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:27:56,074] Trial 40 finished with value: 1.0289017341040463 and parameters: {'lr': 1.1378854545626296e-05}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=1.1e-05         |   3.306 | -0.787 |  2.89 | 10.526 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:31:11,139] Trial 41 finished with value: 1.1290944123314066 and parameters: {'lr': 0.00027680346726999976}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00028         |   4.959 |      0 | 12.909 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:34:28,134] Trial 42 finished with value: 1.042389210019268 and parameters: {'lr': 2.6870239798129743e-06}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=2.7e-06         |   1.653 |      0 | 4.239 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:37:39,883] Trial 43 finished with value: 1.1156069364161851 and parameters: {'lr': 0.00022813978301314662}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |    oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|-------:|-------:|\n",
      "| DPO lr=0.00023         |   4.959 | -0.787 | 11.561 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:40:55,742] Trial 44 finished with value: 0.720616570327553 and parameters: {'lr': 0.000623805578829016}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |     oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|--------:|------:|\n",
      "| DPO lr=0.00062         |  -3.306 | -4.724 | -27.938 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:44:07,806] Trial 45 finished with value: 0.556840077071291 and parameters: {'lr': 0.0018158864605505986}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |   rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|------:|\n",
      "| DPO lr=0.0018          | -14.876 | -18.898 | -44.316 | 7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:47:20,811] Trial 46 finished with value: 0.9210019267822737 and parameters: {'lr': 0.0003531329647060864}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=0.00035         |   4.132 |      0 |  -7.9 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:50:34,173] Trial 47 finished with value: 1.0077071290944124 and parameters: {'lr': 6.941972990246638e-05}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |    rnd |\n",
      "|:-----------------------|--------:|-------:|------:|-------:|\n",
      "| DPO lr=6.9e-05         |   5.785 |  -3.15 | 0.771 | 12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:53:42,327] Trial 48 finished with value: 1.0346820809248556 and parameters: {'lr': 0.0001964883188114603}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |   test |   oos |   rnd |\n",
      "|:-----------------------|--------:|-------:|------:|------:|\n",
      "| DPO lr=0.0002          |   5.785 | -2.362 | 3.468 | 8.772 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:56:57,460] Trial 49 finished with value: 0.4200385356454721 and parameters: {'lr': 0.0007548147413333964}. Best is trial 30 with value: 1.2620423892100192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]   |   train |    test |     oos |    rnd |\n",
      "|:-----------------------|--------:|--------:|--------:|-------:|\n",
      "| DPO lr=0.00075         | -34.711 | -31.496 | -57.996 | 22.807 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 09:56:58,249] Using an existing study with name 'projbp' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 44 projbp trials\n",
      "| projbp N=✓10/✖44, best=1.033   |   importance |        best |\n",
      "|:-------------------------------|-------------:|------------:|\n",
      "| β                              |        0.512 | 0.366362    |\n",
      "| lr                             |        0.311 | 2.88884e-06 |\n",
      "| scale_orth                     |        0.128 | 0           |\n",
      "| mag_clip                       |        0.021 |             |\n",
      "| neg_slope                      |        0.014 | 0           |\n",
      "| reverse_pref                   |        0.014 | 0           |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 09:57:06,839] Trial 44 failed with parameters: {'lr': 0.000510881708506212, 'β': 0.40691929271586114, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.014599142035203292} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:06,862] Trial 44 failed with value None.\n",
      "[W 2024-10-06 09:57:15,977] Trial 45 failed with parameters: {'lr': 0.00024146928642541696, 'β': 0.9469618763901492, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 486.79567128895224} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:15,999] Trial 45 failed with value None.\n",
      "[W 2024-10-06 09:57:24,810] Trial 46 failed with parameters: {'lr': 0.00023742755309823942, 'β': 0.9355618760814246, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 211.27591273852696} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:24,834] Trial 46 failed with value None.\n",
      "[W 2024-10-06 09:57:40,071] Trial 47 failed with parameters: {'lr': 0.0002803386680635025, 'β': 0.9666674470691222, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.33801456666794105} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:40,093] Trial 47 failed with value None.\n",
      "[W 2024-10-06 09:57:49,438] Trial 48 failed with parameters: {'lr': 0.0001799198232803581, 'β': 0.950594832536664, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 20.41693185456085} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:49,461] Trial 48 failed with value None.\n",
      "[W 2024-10-06 09:57:59,247] Trial 49 failed with parameters: {'lr': 0.0002676227571454762, 'β': 0.9564960673660576, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 43.25007708533818} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:57:59,273] Trial 49 failed with value None.\n",
      "[W 2024-10-06 09:58:08,708] Trial 50 failed with parameters: {'lr': 0.0002064298222259527, 'β': 0.9407696854083638, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 61.34897085469358} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:08,730] Trial 50 failed with value None.\n",
      "[W 2024-10-06 09:58:18,512] Trial 51 failed with parameters: {'lr': 0.00021870058682035926, 'β': 0.9826861567778047, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 41.847163962345945} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:18,539] Trial 51 failed with value None.\n",
      "[W 2024-10-06 09:58:27,808] Trial 52 failed with parameters: {'lr': 8.545656766589975e-05, 'β': 0.9796464996812291, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 99.81914275807573} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:27,829] Trial 52 failed with value None.\n",
      "[W 2024-10-06 09:58:37,125] Trial 53 failed with parameters: {'lr': 0.0002232824649342481, 'β': 0.9216614236939021, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 2598.1008033053577} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:37,146] Trial 53 failed with value None.\n",
      "[W 2024-10-06 09:58:46,409] Trial 54 failed with parameters: {'lr': 0.00022015833982937558, 'β': 0.9795661442849323, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 201.21948553373986} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:46,435] Trial 54 failed with value None.\n",
      "[W 2024-10-06 09:58:55,735] Trial 55 failed with parameters: {'lr': 0.0001906422575081695, 'β': 0.9318765986803776, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 109.66807690554973} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:58:55,762] Trial 55 failed with value None.\n",
      "[W 2024-10-06 09:59:05,316] Trial 56 failed with parameters: {'lr': 0.0002401872098838915, 'β': 0.9626043623638456, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 32.166800111212595} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:05,335] Trial 56 failed with value None.\n",
      "[W 2024-10-06 09:59:14,378] Trial 57 failed with parameters: {'lr': 0.00017641079215708805, 'β': 0.9764486599224619, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.46532967482591175} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:14,402] Trial 57 failed with value None.\n",
      "[W 2024-10-06 09:59:23,868] Trial 58 failed with parameters: {'lr': 0.00036100661346716393, 'β': 0.8690193908638019, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.01853045707350885} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:23,893] Trial 58 failed with value None.\n",
      "[W 2024-10-06 09:59:32,983] Trial 59 failed with parameters: {'lr': 0.00044469997195650574, 'β': 0.9608771169328997, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.5856592971148757} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:33,009] Trial 59 failed with value None.\n",
      "[W 2024-10-06 09:59:42,814] Trial 60 failed with parameters: {'lr': 0.0004413864292455407, 'β': 0.97455268047574, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.0839723893016971} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:42,843] Trial 60 failed with value None.\n",
      "[W 2024-10-06 09:59:52,186] Trial 61 failed with parameters: {'lr': 0.0002516323859322287, 'β': 0.9756074868160973, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.03791242023102684} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 09:59:52,215] Trial 61 failed with value None.\n",
      "[W 2024-10-06 10:00:01,313] Trial 62 failed with parameters: {'lr': 7.874536924888812e-05, 'β': 0.9994134940876853, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 0.026094937237758374} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 10:00:01,339] Trial 62 failed with value None.\n",
      "[W 2024-10-06 10:00:10,118] Trial 63 failed with parameters: {'lr': 0.00021561048224043598, 'β': 0.9664981016783335, 'reverse_pref': False, 'scale_orth': False, 'neg_slope': 0, 'mag_clip': 'float', 'mag_clip_value': 86.2883507968109} because of the following error: RuntimeError('The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_277857/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 349, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 138, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 239, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 212, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 72, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1101, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/hooks.py\", line 212, in hook\n",
      "    hook_grad_outputs = user_pre_hook(self.module, self.grad_outputs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in backward_prehook_projgrad\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 94, in <genexpr>\n",
      "    res = tuple(proj_grad(g) for g in grad_output)\n",
      "                ^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/dpo_projbp.py\", line 69, in proj_grad\n",
      "    grad = grad / ratios\n",
      "           ~~~~~^~~~~~~~\n",
      "RuntimeError: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2\n",
      "[W 2024-10-06 10:00:10,147] Trial 63 failed with value None.\n",
      "[I 2024-10-06 10:00:10,908] Using an existing study with name 'ether-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "loaded 43 ether-prefvec trials\n",
      "| ether-prefvec N=✓41/✖43, best=1.183   |   importance | best                   |\n",
      "|:--------------------------------------|-------------:|:-----------------------|\n",
      "| lr                                    |        0.498 | 0.00037772770210724844 |\n",
      "| β                                     |        0.287 | 1.9848539330526844     |\n",
      "| nb                                    |        0.136 | 20                     |\n",
      "| reduction                             |        0.06  | 1                      |\n",
      "| collect_hs                            |        0.003 | False                  |\n",
      "| use_angle_loss                        |        0.003 | True                   |\n",
      "| use_dpo_loss                          |        0.003 | False                  |\n",
      "| use_orth_loss                         |        0.003 | True                   |\n",
      "| weight_tokens                         |        0.003 | True                   |\n",
      "| flip_side                             |        0.002 | True                   |\n",
      "| use_nll_loss                          |        0.002 | True                   |\n",
      "| use_proj_rel                          |        0.002 | True                   |\n",
      "| Htype                                 |        0.001 | ether                  |\n",
      "| collect_input                         |        0.001 | True                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:03:31,188] Trial 43 finished with value: 1.0404624277456649 and parameters: {'lr': 0.00077300924652698, 'collect_input': True, 'collect_hs': False, 'nb': 21, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 0.6860925636859312, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |   oos |    rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.69 lr=0.00077 ether.Htype=ether ether.flip_side=True ether.nb=21 ether.reduction=1 |  -6.612 | -1.575 | 4.046 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:06:47,734] Trial 44 finished with value: 1.0770712909441233 and parameters: {'lr': 0.00017094063229263905, 'collect_input': True, 'collect_hs': False, 'nb': 12, 'Htype': 'ether', 'flip_side': True, 'reduction': 4, 'β': 0.9545933239627128, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.95 lr=0.00017 ether.Htype=ether ether.flip_side=True ether.nb=12 ether.reduction=4 |   1.653 |  0.787 | 7.707 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:10:04,282] Trial 45 finished with value: 0.4566473988439307 and parameters: {'lr': 0.002762529010226291, 'collect_input': True, 'collect_hs': False, 'nb': 25, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.9753257441880685, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                 |   train |    test |     oos |    rnd |\n",
      "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=2 lr=0.0028 ether.Htype=ether ether.flip_side=True ether.nb=25 ether.reduction=1 | -40.496 | -29.921 | -54.335 | -7.018 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:13:29,937] Trial 46 finished with value: 0.5048169556840078 and parameters: {'lr': 0.0012699094933034893, 'collect_input': True, 'collect_hs': False, 'nb': 18, 'Htype': 'ether', 'flip_side': True, 'reduction': 3, 'β': 0.8616128802853223, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                                                 |   train |   test |     oos |    rnd |\n",
      "|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|--------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_dpo_prefvec=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.86 lr=0.0013 ether.Htype=ether ether.flip_side=True ether.nb=18 ether.reduction=3 | -17.355 | -18.11 | -49.518 | 15.789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:16:38,612] Trial 47 finished with value: 0.41040462427745666 and parameters: {'lr': 0.004591564295469674, 'collect_input': True, 'collect_hs': True, 'nb': 13, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 2, 'β': 0.3177259963270161, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                  |   train |    test |    oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|--------:|-------:|------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.32 lr=0.0046 ether.flip_side=True ether.nb=13 ether.reduction=2 | -45.455 | -37.008 | -58.96 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:20:13,537] Trial 48 finished with value: 1.044315992292871 and parameters: {'lr': 0.00015312239936361515, 'collect_input': False, 'collect_hs': False, 'nb': 27, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.0669954943425175, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': False, 'use_proj_rel': False}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                            |   train |   test |   oos |   rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.β=1.1 lr=0.00015 ether.Htype=ether ether.flip_side=True ether.nb=27 ether.reduction=1 |   1.653 |  0.787 | 4.432 | 5.263 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:23:39,973] Trial 49 finished with value: 1.001926782273603 and parameters: {'lr': 1.644387806403373e-07, 'collect_input': True, 'collect_hs': False, 'nb': 20, 'Htype': 'ether', 'flip_side': True, 'reduction': 4, 'β': 0.17651512809322636, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': True, 'use_nll_loss': False, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                     |   train |   test |   oos |   rnd |\n",
      "|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_dpo_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.18 lr=1.6e-07 ether.Htype=ether ether.flip_side=True ether.nb=20 ether.reduction=4 |   0.826 |      0 | 0.193 |     0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:26:56,184] Trial 50 finished with value: 0.9961464354527939 and parameters: {'lr': 3.173113358446832e-05, 'collect_input': True, 'collect_hs': False, 'nb': 6, 'Htype': 'ether', 'flip_side': True, 'reduction': 73, 'β': 1.8985707403739836e-05, 'use_orth_loss': False, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                          |   train |   test |    oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.9e-05 lr=3.2e-05 ether.Htype=ether ether.flip_side=True ether.nb=6 ether.reduction=73 |       0 |      0 | -0.385 | 3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:30:11,879] Trial 51 finished with value: 0.6589595375722545 and parameters: {'lr': 0.0004514977092235431, 'collect_input': True, 'collect_hs': False, 'nb': 10, 'Htype': 'etherplusHH', 'flip_side': True, 'reduction': 238, 'β': 5.294038979133623e-05, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                        |   train |   test |     oos |     rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|--------:|--------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=5.3e-05 lr=0.00045 ether.flip_side=True ether.nb=10 ether.reduction=238 | -15.702 | -8.661 | -34.104 | -12.281 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:33:21,445] Trial 52 finished with value: 0.9942196531791907 and parameters: {'lr': 0.0001030037238762181, 'collect_input': True, 'collect_hs': True, 'nb': 3, 'Htype': 'ether', 'flip_side': False, 'reduction': 9, 'β': 0.48895778065673723, 'use_orth_loss': True, 'use_angle_loss': False, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                                              |   train |   test |    oos |    rnd |\n",
      "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_hs=True collect_input=True prefvec.use_angle_prefvec=False prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=0.49 lr=0.0001 ether.Htype=ether ether.nb=3 ether.reduction=9 |       0 |      0 | -0.578 | -3.509 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 10:36:46,657] Trial 53 finished with value: 1.1734104046242777 and parameters: {'lr': 0.00035276039454591463, 'collect_input': True, 'collect_hs': False, 'nb': 28, 'Htype': 'ether', 'flip_side': True, 'reduction': 1, 'β': 1.1627256835820705, 'use_orth_loss': True, 'use_angle_loss': True, 'use_dpo_loss': False, 'use_nll_loss': True, 'weight_tokens': True, 'use_proj_rel': True}. Best is trial 24 with value: 1.183044315992293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                                                                                                                                    |   train |   test |    oos |    rnd |\n",
      "|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|-------:|\n",
      "| ReprPO collect_input=True prefvec.use_nll_prefvec=True prefvec.use_orth_prefvec=True prefvec.use_proj_rel=True prefvec.weight_tokens=True prefvec.β=1.2 lr=0.00035 ether.Htype=ether ether.flip_side=True ether.nb=28 ether.reduction=1 |   2.479 |      0 | 17.341 | -5.263 |\n"
     ]
    }
   ],
   "source": [
    "MAX_TRIALS= 250\n",
    "import numpy as np\n",
    "spaces = list(search_spaces.items())\n",
    "while True:\n",
    "    np.random.shuffle(spaces)\n",
    "    for exp_name, (max_trials, trial2args) in spaces:\n",
    "        try:\n",
    "            study_name = f\"{exp_name}\"\n",
    "            study = optuna.create_study(\n",
    "                study_name=study_name,\n",
    "                direction=\"maximize\",\n",
    "                load_if_exists=True,\n",
    "                storage=f_db,\n",
    "                sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "                # pruner=optuna.pruners.NopPruner(),\n",
    "            )\n",
    "\n",
    "            n = 0\n",
    "            try:\n",
    "                df = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "                n = len(df)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            if n>0:\n",
    "                print(f\"loaded {n} {study_name} trials\")\n",
    "\n",
    "                df_res = optuna_df(study, key_metric)\n",
    "                print(df_res.to_markdown())\n",
    "\n",
    "            \n",
    "            if n < max_trials:\n",
    "                _objective = functools.partial(objective, key_metric=key_metric, starter_experiment_name=exp_name, trial2args=trial2args)\n",
    "\n",
    "                study.optimize(_objective, \n",
    "                            n_trials=20, # do 20 at a time, round robin, untill done\n",
    "                            gc_after_trial=True, \n",
    "                            catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    "                )\n",
    "\n",
    "            print('='*80)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(_objective, \n",
    "            n_trials=20, \n",
    "            gc_after_trial=True, \n",
    "            catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wandb.run.get_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "from optuna.visualization.matplotlib import plot_edf\n",
    "from optuna.visualization.matplotlib import plot_intermediate_values\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_parallel_coordinate\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_rank\n",
    "from optuna.visualization.matplotlib import plot_slice\n",
    "from optuna.visualization.matplotlib import plot_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'projgrad'\n",
    "trial2args = search_spaces[exp_name]\n",
    "\n",
    "study_name = f\"{exp_name}\"\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    "    storage=f_db,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.NopPruner(),\n",
    ")\n",
    "print('study.best_trial', study.best_trial)\n",
    "df = study.trials_dataframe().query('state == \"COMPLETE\"').sort_values('value', ascending=False)\n",
    "print(len(df))\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
