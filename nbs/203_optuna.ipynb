{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] =\"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from reprpo.hp.helpers import optuna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-05 04:05:20,944] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from reprpo.training import train\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import search_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./optuna.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///optuna.db'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///optuna.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'to visualise run in cli\\ncd nbs\\noptuna-dashboard {f_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.hp.target import override, default_tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import functools\n",
    "\n",
    "def list2tuples(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = tuple(v)\n",
    "    return d\n",
    "\n",
    "def objective_func(kwargs, trial, starter_experiment_name):\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, default_tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    kwargs = list2tuples(kwargs)\n",
    "    r = train(cfg, trial=trial)\n",
    "    return r\n",
    "\n",
    "def objective(trial: optuna.Trial, starter_experiment_name, trial2args, key_metric=key_metric) -> float:\n",
    "    kwargs = trial2args(trial)\n",
    "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
    "    return r[key_metric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hs-svd-mse', 'hs-hra-rank', 'hs-ortho-prefvec', 'ether-prefvec', 'dpo', 'projbp', 'projgrad'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import experiment_configs\n",
    "experiment_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projgrad2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:25:53,717] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad2 N=307, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-ether-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-ether-prefvec N=209, best=1.169</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.219</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Î²</th>\n",
       "      <td>0.218</td>\n",
       "      <td>0.403787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduction</th>\n",
       "      <td>0.146</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flip_side</th>\n",
       "      <td>0.014</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_dpo_loss</th>\n",
       "      <td>0.013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Htype</th>\n",
       "      <td>0.010</td>\n",
       "      <td>oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_nll_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_tokens</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_angle_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_orth_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      importance      best\n",
       "side-ether-prefvec N=209, best=1.169                      \n",
       "lr                                         0.368  0.000615\n",
       "nb                                         0.219        30\n",
       "Î²                                          0.218  0.403787\n",
       "reduction                                  0.146        25\n",
       "flip_side                                  0.014      True\n",
       "use_dpo_loss                               0.013     False\n",
       "collect_hs                                 0.011     False\n",
       "Htype                                      0.010       oft\n",
       "use_nll_loss                               0.000     False\n",
       "weight_tokens                              0.000     False\n",
       "collect_input                              0.000     False\n",
       "use_angle_loss                             0.000      True\n",
       "use_orth_loss                              0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:25:54,463] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projgrad\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad N=1, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-svd-mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-svd-mse N=316, best=1.010</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Î±</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.635584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>0.016</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.005</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_svd</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                importance      best\n",
       "side-svd-mse N=316, best=1.010                      \n",
       "Î±                                    0.844  0.635584\n",
       "lr                                   0.126  0.001195\n",
       "quantile                             0.016     float\n",
       "collect_hs                           0.005      True\n",
       "collect_input                        0.005     False\n",
       "dual_svd                             0.005      True\n",
       "quantile_value                         NaN       0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-hra-rank\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-hra-rank N=183, best=1.229</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Î²</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.110393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Î±</th>\n",
       "      <td>0.095</td>\n",
       "      <td>5.920778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_GS</th>\n",
       "      <td>0.017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 importance      best\n",
       "side-hra-rank N=183, best=1.229                      \n",
       "Î²                                     0.441  0.110393\n",
       "lr                                    0.417  0.000188\n",
       "Î±                                     0.095  5.920778\n",
       "r                                     0.030         2\n",
       "apply_GS                              0.017     False\n",
       "collect_hs                            0.000     False\n",
       "collect_input                         0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:25:56,018] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-ortho-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-ortho-prefvec N=0, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projbp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:25:56,228] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp N=0, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:25:56,432] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dpo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo N=0, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-svd-mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-svd-mse N=4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from optuna.study.study import storages, get_all_study_names\n",
    "study_names = get_all_study_names(storage=f_db)\n",
    "\n",
    "for study_name in study_names:\n",
    "    print(study_name)\n",
    "    study = optuna.load_study(study_name=study_name, storage=f_db)\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        display(df_res)\n",
    "        print()\n",
    "    except ValueError as e:\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-05 04:26:00,640] A new study created in memory with name: no-name-84c13f7a-675b-4b7c-98ea-eb18f7ca7496\n",
      "[W 2024-10-05 04:26:00,646] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,653] A new study created in memory with name: no-name-33b1b6e0-76cc-4061-a443-434be9be0a79\n",
      "[W 2024-10-05 04:26:00,656] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,659] A new study created in memory with name: no-name-655f8489-7a41-488e-a0b8-3b402fae0861\n",
      "[W 2024-10-05 04:26:00,662] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,665] A new study created in memory with name: no-name-9bbe2903-1548-4853-912b-2d9bdb839a99\n",
      "[W 2024-10-05 04:26:00,668] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,671] A new study created in memory with name: no-name-ff92b867-e32a-452a-b3bd-22d30b12e322\n",
      "[W 2024-10-05 04:26:00,674] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,676] A new study created in memory with name: no-name-3227abf0-f3d7-4a68-b6b7-d1b6f3bdf7af\n",
      "[W 2024-10-05 04:26:00,679] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:26:00,681] A new study created in memory with name: no-name-7fec51ce-0557-4117-b6e4-c6e2370fa331\n",
      "[W 2024-10-05 04:26:00,682] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starter_experiment_name hs-svd-mse\n",
      "kwargs {'lr': 0.00026997784363098356, 'collect_input': False, 'collect_hs': False, 'transform.quantile': 1, 'transform.dual_svd': True, 'loss.Î±': 2.773102342213951}\n",
      "| no-name-84c13f7a-675b-4b7c-98ea-eb18f7ca7496 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name hs-hra-rank\n",
      "kwargs {'lr': 0.0007499006128374364, 'transform.r': 6, 'transform.apply_GS': True, 'loss.Î±': 0.0013263961660237875, 'loss.Î²': 88.85864680594091}\n",
      "| no-name-33b1b6e0-76cc-4061-a443-434be9be0a79 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name hs-ortho-prefvec\n",
      "kwargs {'lr': 4.578468968683337e-07, 'transform.orthogonal_map': 'cayley', 'loss.Î²': 0.00012971772314241209, 'loss.use_orth_loss': False, 'loss.use_angle_loss': True, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.weight_tokens': False, 'loss.use_proj_rel': False}\n",
      "| no-name-655f8489-7a41-488e-a0b8-3b402fae0861 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name ether-prefvec\n",
      "kwargs {'lr': 5.221384663584308e-06, 'collect_input': False, 'collect_hs': False, 'transform.nb': 7, 'transform.Htype': 'etherplus', 'transform.flip_side': False, 'transform.reduction': 1, 'loss.Î²': 3.99070571327446e-06, 'loss.use_orth_loss': True, 'loss.use_angle_loss': True, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.weight_tokens': True, 'loss.use_proj_rel': True}\n",
      "| no-name-9bbe2903-1548-4853-912b-2d9bdb839a99 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name projgrad\n",
      "kwargs {'lr': 0.005946468326014886, 'Î²': 0.07813198171959823, 'reverse_pref': True, 'scale_orth': False, 'weight_dim': 2, 'neg_slope': 0, 'mag_clip': None}\n",
      "| no-name-ff92b867-e32a-452a-b3bd-22d30b12e322 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name projbp\n",
      "kwargs {'lr': 1.9724890020101537e-07, 'Î²': 0.44105786272202385, 'reverse_pref': True, 'scale_orth': True, 'neg_slope': 0, 'mag_clip': None}\n",
      "| no-name-3227abf0-f3d7-4a68-b6b7-d1b6f3bdf7af N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name dpo\n",
      "kwargs {'lr': 1.2522702548285494e-06}\n",
      "| no-name-7fec51ce-0557-4117-b6e4-c6e2370fa331 N=1, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    trial = study.ask()\n",
    "    print('starter_experiment_name', starter_experiment_name)\n",
    "    kwargs = trial2args(trial)\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, default_tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    kwargs = list2tuples(kwargs)\n",
    "    print('kwargs', kwargs)\n",
    "\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        print(df_res.to_markdown())\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optuna import trial\n",
    "# t = trial.create_trial(value=1)\n",
    "# t.suggest_categorical(\"a\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-05 04:26:08,958] Using an existing study with name 'hs-svd-mse' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 4 hs-svd-mse trials\n",
      "| hs-svd-mse N=4   | importance   | best   |\n",
      "|------------------|--------------|--------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-05 04:29:10,914] Trial 4 finished with value: 0.9961612284069097 and parameters: {'lr': 7.45934328572655e-06, 'collect_input': True, 'collect_hs': True, 'quantile': 'float', 'dual_svd': True, 'quantile_value': 0.7000000000000001, 'Î±': 0.20584494295802447}. Best is trial 0 with value: 0.9961612284069097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| acc_inc/eval_ds [pp]                                                                                                      |   train |   test |    oos |   rnd |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------|--------:|-------:|-------:|------:|\n",
      "| ReprPO collect_hs=True collect_input=True loss.Î±=0.21 lr=0.00 transform.dual_svd=True transform.quantile=0.70 wandb=False |       0 |      0 | -0.384 | 1.754 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:29:33,187] Trial 5 failed with parameters: {'lr': 0.007072114131472241, 'collect_input': True, 'collect_hs': False, 'quantile': 1, 'dual_svd': True, 'Î±': 6.118528947223795} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 4.06 MiB is free. Process 3802064 has 8.46 GiB memory in use. Process 3842553 has 8.46 GiB memory in use. Process 3965111 has 580.00 MiB memory in use. Process 1204926 has 61.58 GiB memory in use. Of the allocated memory 60.88 GiB is allocated by PyTorch, and 170.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_255963/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_255963/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 347, in train\n",
      "    trainer.fit(pl_model, dl_train, dl_val)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 75, in optimizer_step\n",
      "    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 130, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py\", line 268, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 317, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 390, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/pl_base.py\", line 59, in training_step\n",
      "    return self._shared_step(batch, batch_idx, phase=\"train\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/pl_base.py\", line 37, in _shared_step\n",
      "    loss, info = self._loss_fn(batch, self._model)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/reprpo/model.py\", line 163, in _loss_fn\n",
      "    pi_rej = reprpo_forward_baukit(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/reprpo/model.py\", line 40, in reprpo_forward_baukit\n",
      "    outs = model(\n",
      "           ^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/peft/peft_model.py\", line 1577, in forward\n",
      "    return self.base_model(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py\", line 188, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 1189, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 1000, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 744, in forward\n",
      "    hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 125, in forward\n",
      "    variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 4.06 MiB is free. Process 3802064 has 8.46 GiB memory in use. Process 3842553 has 8.46 GiB memory in use. Process 3965111 has 580.00 MiB memory in use. Process 1204926 has 61.58 GiB memory in use. Of the allocated memory 60.88 GiB is allocated by PyTorch, and 170.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2024-10-05 04:29:33,328] Trial 5 failed with value None.\n",
      "[W 2024-10-05 04:30:01,209] Trial 6 failed with parameters: {'lr': 4.982752357076448e-07, 'collect_input': False, 'collect_hs': False, 'quantile': 1, 'dual_svd': True, 'Î±': 6.075448519014383} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1018.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 44.06 MiB is free. Process 3802064 has 8.46 GiB memory in use. Process 3842553 has 8.46 GiB memory in use. Process 3965111 has 580.00 MiB memory in use. Process 1204926 has 61.54 GiB memory in use. Of the allocated memory 61.00 GiB is allocated by PyTorch, and 1.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_255963/875328504.py\", line 19, in objective\n",
      "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_255963/875328504.py\", line 14, in objective_func\n",
      "    r = train(cfg, trial=trial)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/training.py\", line 300, in train\n",
      "    pl_model = PL_MODEL(\n",
      "               ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/reprpo/model.py\", line 123, in __init__\n",
      "    {\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/reprpo/model.py\", line 124, in <dictcomp>\n",
      "    k: transform.c(dim_hs, dim_hs, model=self._model)\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/transforms/svd.py\", line 56, in c\n",
      "    return SVDLayer(\n",
      "           ^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/interventions/transforms/svd.py\", line 22, in __init__\n",
      "    self.decomposer = DualSVDDecomposer(\n",
      "                      ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/helpers/svd_decomposer.py\", line 198, in __init__\n",
      "    self.decomposer_in = SVDDecomposer(W_in, full_matrices=full_matrices)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/repr-preference-optimization/reprpo/helpers/svd_decomposer.py\", line 124, in __init__\n",
      "    U, S, Vt = torch.linalg.svd(self.W, full_matrices=full_matrices)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1018.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 44.06 MiB is free. Process 3802064 has 8.46 GiB memory in use. Process 3842553 has 8.46 GiB memory in use. Process 3965111 has 580.00 MiB memory in use. Process 1204926 has 61.54 GiB memory in use. Of the allocated memory 61.00 GiB is allocated by PyTorch, and 1.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2024-10-05 04:30:01,223] Trial 6 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "MAX_TRIALS= 250\n",
    "import numpy as np\n",
    "spaces = list(search_spaces.items())\n",
    "np.random.shuffle(spaces)\n",
    "\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "\n",
    "    study_name = f\"{starter_experiment_name}\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True,\n",
    "        storage=f_db,\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        # pruner=optuna.pruners.NopPruner(),\n",
    "    )\n",
    "\n",
    "    n = 0\n",
    "    try:\n",
    "        df = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "        n = len(df)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    if n>0:\n",
    "        print(f\"loaded {n} {study_name} trials\")\n",
    "        # print('study.best_trial', study.best_trial)\n",
    "\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        print(df_res.to_markdown())\n",
    "\n",
    "    \n",
    "    if n < MAX_TRIALS:\n",
    "        _objective = functools.partial(objective, key_metric=key_metric, starter_experiment_name=starter_experiment_name, trial2args=trial2args)\n",
    "\n",
    "        study.optimize(_objective, \n",
    "                    n_trials=MAX_TRIALS, \n",
    "                    gc_after_trial=True, \n",
    "                    catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    "        )\n",
    "\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wandb.run.get_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "from optuna.visualization.matplotlib import plot_edf\n",
    "from optuna.visualization.matplotlib import plot_intermediate_values\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_parallel_coordinate\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_rank\n",
    "from optuna.visualization.matplotlib import plot_slice\n",
    "from optuna.visualization.matplotlib import plot_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_experiment_name = 'projgrad'\n",
    "trial2args = search_spaces[starter_experiment_name]\n",
    "\n",
    "study_name = f\"{starter_experiment_name}\"\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    "    storage=f_db,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.NopPruner(),\n",
    ")\n",
    "print('study.best_trial', study.best_trial)\n",
    "df = study.trials_dataframe().query('state == \"COMPLETE\"').sort_values('value', ascending=False)\n",
    "print(len(df))\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
