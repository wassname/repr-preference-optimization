{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from reprpo.hp.helpers import optuna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-05 03:11:52,176] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from reprpo.training import train\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import search_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./optuna.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///optuna.db'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///optuna.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'to visualise run in cli\\ncd nbs\\noptuna-dashboard {f_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.hp.target import override, default_tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import functools\n",
    "\n",
    "def list2tuples(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = tuple(v)\n",
    "    return d\n",
    "\n",
    "def objective_func(kwargs, trial, starter_experiment_name):\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, default_tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    kwargs = list2tuples(kwargs)\n",
    "    r = train(cfg, trial=trial)\n",
    "    return r\n",
    "\n",
    "def objective(trial: optuna.Trial, starter_experiment_name, trial2args, key_metric=key_metric) -> float:\n",
    "    kwargs = trial2args(trial)\n",
    "    r = objective_func(kwargs, trial, starter_experiment_name)\n",
    "    return r[key_metric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hs-svd-mse', 'hs-hra-rank', 'hs-ortho-prefvec', 'ether-prefvec', 'dpo', 'projbp', 'projgrad'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import experiment_configs\n",
    "experiment_configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projgrad2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:00:56,649] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad2 N=0, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-ether-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-ether-prefvec N=208, best=1.169</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.219</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.218</td>\n",
       "      <td>0.403787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduction</th>\n",
       "      <td>0.146</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flip_side</th>\n",
       "      <td>0.014</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_dpo_loss</th>\n",
       "      <td>0.013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Htype</th>\n",
       "      <td>0.010</td>\n",
       "      <td>oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_nll_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_tokens</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_angle_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_orth_loss</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      importance      best\n",
       "side-ether-prefvec N=208, best=1.169                      \n",
       "lr                                         0.368  0.000615\n",
       "nb                                         0.219        30\n",
       "β                                          0.218  0.403787\n",
       "reduction                                  0.146        25\n",
       "flip_side                                  0.014      True\n",
       "use_dpo_loss                               0.013     False\n",
       "collect_hs                                 0.011     False\n",
       "Htype                                      0.010       oft\n",
       "use_nll_loss                               0.000     False\n",
       "weight_tokens                              0.000     False\n",
       "collect_input                              0.000     False\n",
       "use_angle_loss                             0.000      True\n",
       "use_orth_loss                              0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-05 04:00:57,982] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projgrad\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad N=0, best=nan</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-svd-mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-svd-mse N=28, best=1.010</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.635584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>0.016</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.005</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_svd</th>\n",
       "      <td>0.005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               importance      best\n",
       "side-svd-mse N=28, best=1.010                      \n",
       "α                                   0.844  0.635584\n",
       "lr                                  0.126  0.001195\n",
       "quantile                            0.016     float\n",
       "collect_hs                          0.005      True\n",
       "collect_input                       0.005     False\n",
       "dual_svd                            0.005      True\n",
       "quantile_value                        NaN       0.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "side-hra-rank\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side-hra-rank N=182, best=1.229</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.110393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>α</th>\n",
       "      <td>0.095</td>\n",
       "      <td>5.920778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_GS</th>\n",
       "      <td>0.017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_hs</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_input</th>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 importance      best\n",
       "side-hra-rank N=182, best=1.229                      \n",
       "β                                     0.441  0.110393\n",
       "lr                                    0.417  0.000188\n",
       "α                                     0.095  5.920778\n",
       "r                                     0.030         2\n",
       "apply_GS                              0.017     False\n",
       "collect_hs                            0.000     False\n",
       "collect_input                         0.000     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-ortho-prefvec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs-ortho-prefvec N=0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "projbp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp N=0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dpo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo N=0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [importance, best]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hs-svd-mse\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate parameter importances with only a single trial.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mload_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mf_db)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     df_res \u001b[38;5;241m=\u001b[39m \u001b[43moptuna_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     display(df_res)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/reprpo/hp/helpers.py:15\u001b[0m, in \u001b[0;36moptuna_df\u001b[0;34m(study, key_metric)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m    o, \u001b[38;5;241m=\u001b[39m \u001b[43m_get_importances_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPedAnovaImportanceEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m    s_imp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(o\u001b[38;5;241m.\u001b[39mimportance_values, index\u001b[38;5;241m=\u001b[39mo\u001b[38;5;241m.\u001b[39mparam_names)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m    \u001b[38;5;66;03m# Study instance does not contain completed trials.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:82\u001b[0m, in \u001b[0;36m_get_importances_infos\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m     80\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m metric_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;28;01melse\u001b[39;00m target_name\n\u001b[1;32m     81\u001b[0m     importances_infos: \u001b[38;5;28mtuple\u001b[39m[_ImportancesInfo, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 82\u001b[0m         \u001b[43m_get_importances_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     n_objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mdirections)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:54\u001b[0m, in \u001b[0;36m_get_importances_info\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudy instance does not contain completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ImportancesInfo(\n\u001b[1;32m     48\u001b[0m         importance_values\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     49\u001b[0m         param_names\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     50\u001b[0m         importance_labels\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     51\u001b[0m         target_name\u001b[38;5;241m=\u001b[39mtarget_name,\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_param_importances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mitems())))\n\u001b[1;32m     59\u001b[0m importance_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/importance/__init__.py:111\u001b[0m, in \u001b[0;36mget_param_importances\u001b[0;34m(study, evaluator, params, target, normalize)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, BaseImportanceEvaluator):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluator must be a subclass of BaseImportanceEvaluator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    113\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(res\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/importance/_ped_anova/evaluator.py:199\u001b[0m, in \u001b[0;36mPedAnovaImportanceEvaluator.evaluate\u001b[0;34m(self, study, params, target)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    194\u001b[0m     study: Study,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     target: Callable[[FrozenTrial], \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    198\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m--> 199\u001b[0m     dists \u001b[38;5;241m=\u001b[39m \u001b[43m_get_distributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dists\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/importance/_base.py:69\u001b[0m, in \u001b[0;36m_get_distributions\u001b[0;34m(study, params)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_distributions\u001b[39m(study: Study, params: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseDistribution]:\n\u001b[1;32m     68\u001b[0m     completed_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, states\u001b[38;5;241m=\u001b[39m(TrialState\u001b[38;5;241m.\u001b[39mCOMPLETE,))\n\u001b[0;32m---> 69\u001b[0m     \u001b[43m_check_evaluate_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompleted_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m intersection_search_space(study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/optuna/importance/_base.py:114\u001b[0m, in \u001b[0;36m_check_evaluate_args\u001b[0;34m(completed_trials, params)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances without completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completed_trials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot evaluate parameter importances with only a single trial.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate parameter importances with only a single trial."
     ]
    }
   ],
   "source": [
    "from optuna.study.study import storages, get_all_study_names\n",
    "study_names = get_all_study_names(storage=f_db)\n",
    "\n",
    "for study_name in study_names:\n",
    "    print(study_name)\n",
    "    study = optuna.load_study(study_name=study_name, storage=f_db)\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        display(df_res)\n",
    "        print()\n",
    "    except ValueError as e:\n",
    "        # print(e)\n",
    "        raise\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-05 04:01:55,770] A new study created in memory with name: no-name-e554df91-d979-462c-8163-4fd44ef5718b\n",
      "[W 2024-10-05 04:01:55,775] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,786] A new study created in memory with name: no-name-ac909c68-5aeb-495c-b3e3-8b921c43e9b8\n",
      "[W 2024-10-05 04:01:55,788] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,798] A new study created in memory with name: no-name-b4cd401d-53f5-4275-9999-e1a0ac39b144\n",
      "[W 2024-10-05 04:01:55,800] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,810] A new study created in memory with name: no-name-967aeaff-bda2-4443-b7a6-e7783a98f75d\n",
      "[W 2024-10-05 04:01:55,813] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,824] A new study created in memory with name: no-name-9c079a73-3cbb-4d7f-a629-e69b68fbba91\n",
      "[W 2024-10-05 04:01:55,826] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,833] A new study created in memory with name: no-name-4cc56b36-be6a-4c95-80e0-6a74376dcfeb\n",
      "[W 2024-10-05 04:01:55,834] Study instance does not contain completed trials.\n",
      "[I 2024-10-05 04:01:55,841] A new study created in memory with name: no-name-d093cb41-5bb6-4170-85c4-1ac0ee4db5ff\n",
      "[W 2024-10-05 04:01:55,842] Study instance does not contain completed trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starter_experiment_name hs-svd-mse\n",
      "kwargs {'lr': 0.0014543130814445343, 'collect_input': True, 'collect_hs': False, 'transform.quantile': 0.4, 'transform.dual_svd': True, 'loss.α': 0.4603424071642692}\n",
      "| no-name-e554df91-d979-462c-8163-4fd44ef5718b N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name hs-hra-rank\n",
      "kwargs {'lr': 6.639431716557299e-06, 'transform.r': 6, 'transform.apply_GS': False, 'loss.α': 0.0015318280237912813, 'loss.β': 2.749249405078123}\n",
      "| no-name-ac909c68-5aeb-495c-b3e3-8b921c43e9b8 N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name hs-ortho-prefvec\n",
      "kwargs {'lr': 1.8994449075034481e-06, 'transform.orthogonal_map': 'cayley', 'loss.β': 0.0016112022795036344, 'loss.use_orth_loss': False, 'loss.use_angle_loss': False, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.weight_tokens': True, 'loss.use_proj_rel': False}\n",
      "| no-name-b4cd401d-53f5-4275-9999-e1a0ac39b144 N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name ether-prefvec\n",
      "kwargs {'lr': 0.0018297872187768658, 'collect_input': True, 'collect_hs': False, 'transform.nb': 17, 'transform.Htype': 'oft', 'transform.flip_side': True, 'transform.reduction': 80, 'loss.β': 0.24407843316695746, 'loss.use_orth_loss': False, 'loss.use_angle_loss': True, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.weight_tokens': False, 'loss.use_proj_rel': False}\n",
      "| no-name-967aeaff-bda2-4443-b7a6-e7783a98f75d N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name projgrad\n",
      "kwargs {'lr': 0.0003007022611793669, 'β': 0.5274698106407905, 'reverse_pref': False, 'scale_orth': True, 'weight_dim': 0, 'neg_slope': 0, 'mag_clip': 442.6256065878237}\n",
      "| no-name-9c079a73-3cbb-4d7f-a629-e69b68fbba91 N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name projbp\n",
      "kwargs {'lr': 1.0801124361930937e-06, 'β': 0.18859489234811888, 'reverse_pref': False, 'scale_orth': True, 'neg_slope': 0, 'mag_clip': None}\n",
      "| no-name-4cc56b36-be6a-4c95-80e0-6a74376dcfeb N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n",
      "starter_experiment_name dpo\n",
      "kwargs {'lr': 8.591233984137065e-06}\n",
      "| no-name-d093cb41-5bb6-4170-85c4-1ac0ee4db5ff N=0, best=nan   | importance   | best   |\n",
      "|--------------------------------------------------------------|--------------|--------|\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    trial = study.ask()\n",
    "    print('starter_experiment_name', starter_experiment_name)\n",
    "    kwargs = trial2args(trial)\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, default_tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    kwargs = list2tuples(kwargs)\n",
    "    print('kwargs', kwargs)\n",
    "\n",
    "    try:\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        print(df_res.to_markdown())\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optuna import trial\n",
    "# t = trial.create_trial(value=1)\n",
    "# t.suggest_categorical(\"a\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRIALS= 250\n",
    "import numpy as np\n",
    "spaces = list(search_spaces.items())\n",
    "np.random.shuffle(spaces)\n",
    "\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "\n",
    "    study_name = f\"{starter_experiment_name}\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True,\n",
    "        storage=f_db,\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        # pruner=optuna.pruners.NopPruner(),\n",
    "    )\n",
    "\n",
    "    n = 0\n",
    "    try:\n",
    "        df = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "        n = len(df)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    if n>0:\n",
    "        print(f\"loaded {n} {study_name} trials\")\n",
    "        # print('study.best_trial', study.best_trial)\n",
    "\n",
    "        df_res = optuna_df(study, key_metric)\n",
    "        print(df_res.to_markdown())\n",
    "\n",
    "    \n",
    "    if n < MAX_TRIALS:\n",
    "        _objective = functools.partial(objective, key_metric=key_metric, starter_experiment_name=starter_experiment_name, trial2args=trial2args)\n",
    "\n",
    "        study.optimize(_objective, \n",
    "                    n_trials=MAX_TRIALS, \n",
    "                    gc_after_trial=True, \n",
    "                    catch=(AssertionError, OSError, RuntimeError, KeyError, torch.OutOfMemoryError)\n",
    "        )\n",
    "\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wandb.run.get_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "from optuna.visualization.matplotlib import plot_edf\n",
    "from optuna.visualization.matplotlib import plot_intermediate_values\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_parallel_coordinate\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_rank\n",
    "from optuna.visualization.matplotlib import plot_slice\n",
    "from optuna.visualization.matplotlib import plot_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_experiment_name = 'projgrad'\n",
    "trial2args = search_spaces[starter_experiment_name]\n",
    "\n",
    "study_name = f\"{starter_experiment_name}\"\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    "    storage=f_db,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.NopPruner(),\n",
    ")\n",
    "print('study.best_trial', study.best_trial)\n",
    "df = study.trials_dataframe().query('state == \"COMPLETE\"').sort_values('value', ascending=False)\n",
    "print(len(df))\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
