{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "\n",
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "from optuna.visualization.matplotlib import plot_edf\n",
    "from optuna.visualization.matplotlib import plot_intermediate_values\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_parallel_coordinate\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_rank\n",
    "from optuna.visualization.matplotlib import plot_slice\n",
    "from optuna.visualization.matplotlib import plot_timeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.hp.space import search_spaces\n",
    "\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig, ProjGradConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../outputs/optuna/optuna.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///../outputs/optuna/optuna.db'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///../outputs/optuna/optuna.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tuner_kwargs' from 'reprpo.hp.target' (/workspace/repr-preference-optimization/reprpo/hp/target.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreprpo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override, tuner_kwargs\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreprpo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experiment_configs\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'tuner_kwargs' from 'reprpo.hp.target' (/workspace/repr-preference-optimization/reprpo/hp/target.py)"
     ]
    }
   ],
   "source": [
    "from reprpo.hp.target import override, tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRIALS= 150\n",
    "\n",
    "def list2tuples(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = tuple(v)\n",
    "    return d\n",
    "\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "    study_name = f\"{starter_experiment_name}\"\n",
    "\n",
    "    def objective_func(kwargs, trial):\n",
    "        cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "        override(cfg, tuner_kwargs)\n",
    "        \n",
    "        override(cfg, kwargs)\n",
    "        kwargs = list2tuples(kwargs)\n",
    "        r = train(cfg, trial=trial)\n",
    "        return r\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        kwargs = trial2args(trial)\n",
    "        r = objective_func(kwargs, trial)\n",
    "        return r[key_metric]\n",
    "\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = f\"{study_name}.ipynb\"\n",
    "    wandb_kwargs = {\"project\": \"reprpo-optuna\", \"name\": study_name}\n",
    "    wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True,\n",
    "        storage=f_db,\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        pruner=optuna.pruners.NopPruner(),\n",
    "    )\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    if len(study.trials)>0:\n",
    "        df = study.trials_dataframe().query('state == \"COMPLETE\"').sort_values('value', ascending=False)\n",
    "        n = len(df)\n",
    "\n",
    "        print(f\"loaded {n} {study_name} trials\")\n",
    "    if n < MAX_TRIALS:\n",
    "        study.optimize(objective, \n",
    "                    n_trials=MAX_TRIALS, \n",
    "                    callbacks=[wandbc], gc_after_trial=True, \n",
    "                    # catch=(Exception,)\n",
    "                    )\n",
    "\n",
    "    print('study.best_trial', study.best_trial)\n",
    "\n",
    "    wandb.finish(quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
