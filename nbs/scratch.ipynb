{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([\n",
    "    [ 0.0470, -0.0431,  0.0421],\n",
    "    [ 0.0282, -0.0119,  0.0402],\n",
    "    [0.0181, 0.0000, 0.0000],\n",
    "    [-0.0017,  0.0001, -0.0004],\n",
    "    [ 4.1447e-03, -2.7173e-03, -2.3842e-07]\n",
    "    ])\n",
    "x.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(-x*20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(x.exp()-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(torch.tensor([1/3, 1, 2/1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.exp()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x - x.min(1, keepdim=True)[0] + 1e-3\n",
    "x1 / x1.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOXIC dpo\n",
    "\n",
    "- turn exach pair into ds row\n",
    "- shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('unalignment/toxic-dpo-v0.1') # this should give a a bigger # use map in batched mode to return more rows than it got\n",
    "def transform(row):\n",
    "    return {\n",
    "        \"chosen\": [{'role':'user', 'content': row['prompt']},{'role':'assistant', 'content': row['chosen']}],\n",
    "        \"rejected\": [{'role':'user', 'content': row['prompt']},{'role':'assistant', 'content': row['rejected']}]\n",
    "    }\n",
    "\n",
    "dataset1 = dataset.map(transform)\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"NousResearch/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HelpSteer2\n",
    "\n",
    "https://github.com/jondurbin/bagel/blob/3c7d2410a5a5ad2fd31b63529ef541135feefce4/bagel/data_sources/helpsteer.py#L4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('nvidia/HelpSteer2')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from loguru import logger\n",
    "\n",
    "REFUSALS = [\n",
    "    re.compile(regexp)\n",
    "    for regexp in [\n",
    "        \"(against|violate) my programming\",\n",
    "        \"openai\",\n",
    "        \"language model\",\n",
    "        \"large language\",\n",
    "        \"as an? (ai|generative language|gpt|bot)\",\n",
    "        \"important to note\",\n",
    "        \"i do(n't| not) (possess|have|exhibit) (personal|consciousness|subjective)\",\n",
    "        \"personal (feelings|thoughts|emotions|desires|experiences|goals|objective|belief)\",\n",
    "        \"(can('t| ?not)|w(on't|will not)|unable.?) (\\\\w+\\\\s)+(with (that|your)|your \\\\w+|provide)\",\n",
    "        \"my limitations\",\n",
    "        \"the limitations of my\",\n",
    "        \"my abilities\",\n",
    "        \"violates my\",\n",
    "        \"i (can('t| ?not)|w(on't|will not)|am (not |un)able.?).{0,30}(you are|you're|your )\",\n",
    "        \"please note that\",\n",
    "        \"unethical|illegal|dangerous\",\n",
    "        \"a text-based\",\n",
    "        \"(engag(e|ing)|participat(e|ing)|be involved (in|with)|promot(e|ing)|discuss(ing)?|provid(e|ing))( in)?(\\\\s*\\\\w+ that)?(\\\\s+potentially)? (derogatory|inappropriate|offensive|discriminate|discriminatory|sexist|unacceptable|immoral|unethical|unacceptable|hateful|harmful)\",\n",
    "        \"i am commited to\",\n",
    "        \"adhere to safety guidelines\",\n",
    "        \"maintain user safety\",\n",
    "        \"about something else instead\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "def has_refusal(response):\n",
    "    \"\"\"Check if a response has a refusal - not perfect, but good enough...\"\"\"\n",
    "    for regexp in REFUSALS:\n",
    "        if m := regexp.search(response, re.I):\n",
    "            logger.warning(f\"Refusal? {m.group()}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    ".filter(\n",
    "        lambda item: not has_refusal(item[\"response\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(known_uids=set([]), **_):\n",
    "    \"\"\"HelpSteer dataset for DPO.\"\"\"\n",
    "    logger.info(\"Loading HelpSteer dataset...\")\n",
    "    dataset = load_dataset(\"nvidia/HelpSteer\", split=\"train\").filter(\n",
    "        lambda item: not has_refusal(item[\"response\"])\n",
    "    )\n",
    "\n",
    "    # Use the highest correctness items as the \"chosen\" responses.\n",
    "    logger.info(\"Generating DPO pairs...\")\n",
    "    options = {}\n",
    "    for item in dataset:\n",
    "        uid = get_uid(item[\"prompt\"])\n",
    "        if uid not in options:\n",
    "            options[uid] = []\n",
    "        item[\"score\"] = (\n",
    "            item[\"helpfulness\"]\n",
    "            + item[\"correctness\"]\n",
    "            + item[\"coherence\"]\n",
    "            + item[\"complexity\"]\n",
    "            + item[\"verbosity\"]\n",
    "        )\n",
    "        options[uid].append(item)\n",
    "\n",
    "    # Select the chosen and rejected items.\n",
    "    data = []\n",
    "    for uid, responses in options.items():\n",
    "        if len(responses) < 2:\n",
    "            continue\n",
    "        if uid in known_uids:\n",
    "            continue\n",
    "        known_uids.add(uid)\n",
    "        chosen = None\n",
    "        chosen_score = 0\n",
    "        rejected = None\n",
    "        rejected_score = 0\n",
    "        for item in responses:\n",
    "            if item[\"correctness\"] == 4:\n",
    "                if chosen:\n",
    "                    if item[\"score\"] > chosen[\"score\"]:\n",
    "                        rejected = chosen[\"response\"]\n",
    "                        rejected_score = chosen[\"score\"]\n",
    "                        chosen = item\n",
    "                        chosen_score = item[\"score\"]\n",
    "                        break\n",
    "                else:\n",
    "                    chosen = item\n",
    "                    chosen_score = item[\"score\"]\n",
    "            else:\n",
    "                if not rejected:\n",
    "                    rejected = item[\"response\"]\n",
    "                    rejected_score = item[\"score\"]\n",
    "        if chosen and rejected and chosen[\"response\"] != rejected:\n",
    "            logger.success(f\"Found DPO pair: {chosen_score} vs {rejected_score}\")\n",
    "            data.append(\n",
    "                {\n",
    "                    \"id\": uid,\n",
    "                    \"source\": \"helpsteer\",\n",
    "                    \"prompt\": item[\"prompt\"],\n",
    "                    \"chosen\": chosen[\"response\"],\n",
    "                    \"rejected\": rejected,\n",
    "                    \"conversations\": None,\n",
    "                }\n",
    "            )\n",
    "    return Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']['prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is norm mean same as mse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# b l t h \n",
    "x = torch.randn(2, 3, 4, 5)\n",
    "y = torch.randn(2, 3, 4 , 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1555), tensor(16.0827), tensor(1.1736), tensor(140.8272))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(x, y), torch.norm(y-x, p=2).nanmean(), F.l1_loss(x, y), torch.norm(y-x, p=1).nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1555)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "F.mse_loss(x, y, reduction='none').nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(lora_retain_hidden - orig_retain_hidden, dim=-1, p=2, dtype=torch.float).nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1159)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the norm is the same as this\n",
    "# it's not mse, it's sum squared error\n",
    "e=y-x\n",
    "((e**2).sum(-1)**(1/2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1159)\n",
      "tensor(3.1159)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.1159)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these 3 norms act the same\n",
    "print(torch.norm(y-x, p=2, dim=-1).nanmean())\n",
    "print(\n",
    "     torch.linalg.vector_norm(y-x, ord=2, dim=-1).nanmean()\n",
    ")\n",
    "torch.linalg.norm(y-x, ord=2, dim=-1).nanmean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange\n",
    "\n",
    "from reprpo.helpers.adapters import set_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a5fbb1584a4a4d9e1d1baacfca0476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41943040 || all params: 4582543360 || trainable%: 0.9152786281546499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaFlashAttention2(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME: we are meant to SFT first, so that the preferences are in sample but 1) if this works it might not be needed, and 2) this can be added later, if it works\n",
    "# for now we will use the instruct model, and try something it wasn't meant to do but it in sample \n",
    "model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "## Big adapter\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16, \n",
    "    r=16,\n",
    "    lora_dropout=0.05,\n",
    "    use_rslora=True,\n",
    "    # use_dora=True,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "model, tokenizer = load_model(model_name, )\n",
    "# from trl.trainer.utils import peft_module_casting_to_bf16\n",
    "# peft_module_casting_to_bf16(model)\n",
    "adapter_name='ReprPO'\n",
    "model = prepare_model_for_kbit_training(model, {'use_gradient_checkpointing': True})\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "print_trainable_parameters(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def sample(dataset, N):\n",
    "    return (dataset\n",
    "            .shuffle(42)\n",
    "            .select(range(\n",
    "            min(len(dataset),\n",
    "                N)))\n",
    "    )\n",
    "\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO') # TODO redo exp with\n",
    "dataset['train'] = sample(dataset['train'], num_samples)\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.trainer import collect_hs, ReprPOConfig, ReprPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/.venv/lib/python3.9/site-packages/trl/trainer/dpo_trainer.py:442: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = ReprPOConfig('./output-dir/1',\n",
    "per_device_train_batch_size=2,\n",
    "                                 gradient_checkpointing=True,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "       max_prompt_length=128,\n",
    "    max_length=256,\n",
    "                             )\n",
    "reprpo_trainer = ReprPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=training_args.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    # eval_dataset=dataset2[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = reprpo_trainer.get_train_dataloader()\n",
    "b = next(iter(dl))\n",
    "b['chosen_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_N_tok  ['Question', ' you', ' you', \"'s\", ' the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/.venv/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_N_tok ReprPO ['Question', ' you', ' you', \"'s\", ' the']\n"
     ]
    }
   ],
   "source": [
    "# with model.disable_adapter():\n",
    "with torch.no_grad():\n",
    "    with reprpo_trainer.null_ref_context():\n",
    "        (\n",
    "            reference_chosen_logps,\n",
    "            reference_rejected_logps,\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "            reference_chosen_hs,\n",
    "            _,\n",
    "        ) = reprpo_trainer.concatenated_forward(reprpo_trainer.model, b)\n",
    "reference_chosen_hs = reference_chosen_hs.detach()\n",
    "reference_chosen_logps = reference_chosen_logps.detach()\n",
    "reference_rejected_logps = reference_rejected_logps.detach()\n",
    "\n",
    "model.train()\n",
    "(\n",
    "    policy_chosen_logps,\n",
    "    policy_rejected_logps,\n",
    "    policy_chosen_logits,\n",
    "    policy_rejected_logits,\n",
    "    policy_chosen_logps_avg,\n",
    "    policy_chosen_hs,\n",
    "    policy_rejected_hs,\n",
    ") = reprpo_trainer.concatenated_forward(model, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3594, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss 1\n",
    "F.triplet_margin_with_distance_loss(anchor=reference_chosen_hs, positive=policy_chosen_hs, negative=policy_rejected_hs)\n",
    "\n",
    "F.triplet_margin_with_distance_loss(anchor=reference_chosen_hs, positive=policy_chosen_hs, negative=policy_rejected_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprpo_trainer.concatenated_forward(model, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     o = model(b)\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
