{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to modify hf dpo to work with the repos hypothesis...\n",
    "\n",
    "see\n",
    "- https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth\n",
    "- https://gist.github.com/alvarobartt/9898c33eb3e9c7108d9ed2330f12a708\n",
    "- https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing#scrollTo=QtoqUw80QDV0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"repo-dpo\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] =  os.path.basename(globals()['__vsc_ipynb_file__'])\n",
    "nb_name = os.path.basename(globals()['__vsc_ipynb_file__']).replace('.ipynb', '').replace(' ', '_')\n",
    "# enable wandb service (experimental, https://github.com/wandb/client/blob/master/docs/dev/wandb-service-user.md)\n",
    "# this hopefully fixes issues with multiprocessing\n",
    "wandb.require(experiment='service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo import silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers.trainer import ProgressCallback\n",
    "from transformers.utils.notebook import NotebookProgressCallback\n",
    "\n",
    "from reprpo.helpers.adapters import set_adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prompt_length=64\n",
    "# num_samples = 50 * 16 * 6\n",
    "num_samples = 1500 * 13 * 3 # from circuit breaker * 3\n",
    "max_length = 128\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation --no-deps -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e11685640f04d24a9043c9f63ff788f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25165824 || all params: 2033980416 || trainable%: 1.2372697299362787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32011, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3FlashAttention2(\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm()\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32011, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME: we are meant to SFT first, so that the preferences are in sample but 1) if this works it might not be needed, and 2) this can be added later, if it works\n",
    "# for now we will use the instruct model, and try something it wasn't meant to do but it in sample \n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct-gguf\"\n",
    "# model_name = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "use_gradient_checkpointing = False\n",
    "\n",
    "from peft.tuners import BOFTConfig, OFTConfig, LoraConfig, IA3Config\n",
    "## Big adapter\n",
    "# peft_config = OFTConfig(\n",
    "#     r=4,\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"qkv_proj\", \"down_proj\",\n",
    "#                     \"o_proj\", \"gate_up_proj\",\n",
    "#                     ],\n",
    "# )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# rescale\n",
    "Infused Adapter by Inhibiting and Amplifying Inner Activations, or IA3, is a method that adds three learned vectors to rescale the keys and values of the self-attention and encoder-decoder attention layers, and the intermediate activation of the position-wise feed-forward network.\"\"\"\n",
    "# peft_config = IA3Config(\n",
    "#     # r=4,\n",
    "#     # task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"qkv_proj\", \"down_proj\",\n",
    "#                     \"o_proj\", \"gate_up_proj\",\n",
    "#                     ],\n",
    "#     feedforward_modules=[\"gate_up_proj\", \"down_proj\"]\n",
    "# )\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16, \n",
    "    r=16,\n",
    "    # lora_dropout=0.05,\n",
    "    use_rslora=True,\n",
    "    # use_dora=True,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"qkv_proj\", \"gate_up_proj\", # in\n",
    "        \"down_proj\",  \"o_proj\", # out\n",
    "                    \n",
    "                    ],\n",
    "    # target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl.trainer.utils import peft_module_casting_to_bf16\n",
    "\n",
    "model, tokenizer = load_model(model_name, bnb=True )\n",
    "\n",
    "if use_gradient_checkpointing:\n",
    "    model.enable_input_require_grads()\n",
    "peft_module_casting_to_bf16(model)\n",
    "adapter_name='ReprPO'\n",
    "model = prepare_model_for_kbit_training(model, {'use_gradient_checkpointing': use_gradient_checkpointing})\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "print_trainable_parameters(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dataset, N):\n",
    "    return (dataset\n",
    "            .shuffle(42)\n",
    "            .select(range(\n",
    "            min(len(dataset), N)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'When did women join the labor workforce outside of the home? What caused the change from housewife to breadwinner? Write a short informative paragraph under 200 words. ',\n",
       " 'chosen': \"In the early 20th century, less than 20% of women worked outside the home. Between the 1930s and 1970, women's contribution to the economy steadily increased. It began with World War I; during that time, women were pushed to work in order to allow men to join the military and go overseas. Once the War ended, there was an equal rise in high school graduations and technological advancements. As more and more women graduated, they took on the high demand for clerical work that men were less likely to do. Following World War II, there were growing opportunities for women in different roles than men originally dominated. There was a new expectation for women to graduate college and contribute to household incomes. By 1990, the percentage of women working increased by 76%. Recent research shows that there are approximately the same number of women in professional schools as men. According to Forbes in July 2023, 57.4 percent of the workforce are women.\",\n",
       " 'rejected': \"The 1900s saw a dramatic shift in the role of women in the workforce. Prior to this time, women were primarily homemakers and caregivers, with limited opportunities for paid work outside the home. However, with the rise of industrialization and the growth of the economy, women began to enter the workforce in increasing numbers.\\n\\nOne of the primary factors that led to this change was the need for workers in factories and other industries. As men went off to war or pursued other opportunities, women were needed to fill the gaps in the workforce. This need for workers created a new sense of opportunity for women, who had previously been limited by social and cultural expectations.\\n\\nAnother factor that contributed to the change was the growing feminist movement. Women's rights activists worked to break down barriers and stereotypes that prevented women from pursuing their own goals and ambitions. They fought for equal pay, equal opportunities, and the right to vote, among other rights.\\n\\nAs a result of these and other factors, women began to enter the workforce in increasing numbers. They worked in factories, offices, and other industries, often performing the same jobs as men. This shift in the role of women had a profound impact on society, changing the way that people thought about gender roles and the value of women's work.\\n\\nToday, women continue to make up a significant portion of the workforce, and many have achieved success in a wide range of industries. While there is still work to be done to achieve true gender equality, the changes that began in the early 1900s have paved the way for a more diverse and inclusive workforce.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset('Columbia-NLP/DPO-HelpSteer')\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO').map(lambda x: {\n",
    "    'prompt': x['prompt']+ ' '})\n",
    "dataset['train'] = sample(dataset['train'], num_samples)\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')\n",
    "dataset2['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_ds(row):\n",
    "    \n",
    "#     # WHY are we doing this? Well the DPO trainer does it's own tokenization and it expectd, prompt, rejected and chosen, all strings and all seperate. Is this good, idk\n",
    "#     return {\n",
    "#         \"chosen\": row['chosen_response'][1]['content'],\n",
    "#         \"rejected\": row['rejected_response'][1]['content'],\n",
    "#     }\n",
    "\n",
    "\n",
    "# dataset2 = dataset.map(format_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did women join the labor workforce outside of the home? What caused the change from housewife to breadwinner? Write a short informative paragraph under 200 words. \n",
      "===\n",
      "In the early 20th century, less than 20% of women worked outside the home. Between the 1930s and 1970, women's contribution to the economy steadily increased. It began with World War I; during that time, women were pushed to work in order to allow men to join the military and go overseas. Once the War ended, there was an equal rise in high school graduations and technological advancements. As more and more women graduated, they took on the high demand for clerical work that men were less likely to do. Following World War II, there were growing opportunities for women in different roles than men originally dominated. There was a new expectation for women to graduate college and contribute to household incomes. By 1990, the percentage of women working increased by 76%. Recent research shows that there are approximately the same number of women in professional schools as men. According to Forbes in July 2023, 57.4 percent of the workforce are women.\n",
      "---\n",
      "The 1900s saw a dramatic shift in the role of women in the workforce. Prior to this time, women were primarily homemakers and caregivers, with limited opportunities for paid work outside the home. However, with the rise of industrialization and the growth of the economy, women began to enter the workforce in increasing numbers.\n",
      "\n",
      "One of the primary factors that led to this change was the need for workers in factories and other industries. As men went off to war or pursued other opportunities, women were needed to fill the gaps in the workforce. This need for workers created a new sense of opportunity for women, who had previously been limited by social and cultural expectations.\n",
      "\n",
      "Another factor that contributed to the change was the growing feminist movement. Women's rights activists worked to break down barriers and stereotypes that prevented women from pursuing their own goals and ambitions. They fought for equal pay, equal opportunities, and the right to vote, among other rights.\n",
      "\n",
      "As a result of these and other factors, women began to enter the workforce in increasing numbers. They worked in factories, offices, and other industries, often performing the same jobs as men. This shift in the role of women had a profound impact on society, changing the way that people thought about gender roles and the value of women's work.\n",
      "\n",
      "Today, women continue to make up a significant portion of the workforce, and many have achieved success in a wide range of industries. While there is still work to be done to achieve true gender equality, the changes that began in the early 1900s have paved the way for a more diverse and inclusive workforce.\n"
     ]
    }
   ],
   "source": [
    "r = dataset2['train'][0]\n",
    "print(r['prompt'])\n",
    "print('===')\n",
    "print(r['chosen'])\n",
    "print('---')\n",
    "print(r['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.mc import eval_tqa\n",
    "from reprpo.gen import generation_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified classes\n",
    "\n",
    "- here we can defined the experimetns loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.trainer import ReprPOTrainer, ReprPOConfig\n",
    "\n",
    "\n",
    "class ReprPOTrainer2(ReprPOTrainer):\n",
    "        \n",
    "    def res_det(self, hs):\n",
    "        \"\"\"use SVG to decompose hs into the output and residual components\"\"\"\n",
    "        return hs - self.decomposer(hs).detach()\n",
    "\n",
    "    # def reprpo_loss(\n",
    "    #     self,\n",
    "    #     policy_chosen_logps: torch.FloatTensor,\n",
    "    #     policy_rejected_logps: torch.FloatTensor,\n",
    "    #     policy_chosen_hs: torch.FloatTensor,\n",
    "    #     policy_rejected_hs: torch.FloatTensor,\n",
    "    #     reference_chosen_logps: torch.FloatTensor,\n",
    "    #     reference_rejected_logps: torch.FloatTensor,\n",
    "    #     reference_chosen_hs: torch.FloatTensor,\n",
    "    #     chosen_attn_mask: torch.BoolTensor,\n",
    "    #     rejected_attn_mask: torch.BoolTensor\n",
    "    # ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
    "\n",
    "    #     loss_rr = sum_squared_error(policy_rejected_hs, reference_chosen_hs)\n",
    "    #     loss_rr = mean_with_attention(loss_rr, rejected_attn_mask*chosen_attn_mask).mean()\n",
    "        \n",
    "    #     loss = loss_rr.sum()\n",
    "\n",
    "    #     loss_dict = dict(loss=loss.detach())\n",
    "\n",
    "    #     # now mean any with ndim>0, and detach an cpu\n",
    "    #     loss_dict = {k: normalize_output(v) for k, v in loss_dict.items()}\n",
    "\n",
    "    #     return loss, loss_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.helpers.torch import clear_mem\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7221"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the ideal number of sample for how many are available\n",
    "num_data_samples = min(num_samples, len(dataset2['train']))\n",
    "num_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.helpers.svd_decomposer import SVDDecomposer, DualSVDDecomposer\n",
    "# d = DualSVDDecomposer(model.get_input_embeddings().weight, model.lm_head.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ReprPO': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='microsoft/Phi-3-mini-4k-instruct', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'down_proj', 'o_proj', 'qkv_proj', 'gate_up_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_accumulation_steps': 1, 'num_train_epochs': 8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13446b72230e4b93ad0666eab7954092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4469 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6bfc0d04ad4943973048d88ad6293a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/373 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft SVD: 89.97% of singular values kept, with tau=5.38, Smean=7.82, Smax=105.96, Smin=0.84\n"
     ]
    }
   ],
   "source": [
    "batch_size = 42\n",
    "ideal_batch_size = batch_size\n",
    "gradient_accumulation_steps = ideal_batch_size // batch_size\n",
    "num_train_epochs = num_samples // num_data_samples\n",
    "print(dict(gradient_accumulation_steps=gradient_accumulation_steps, num_train_epochs=num_train_epochs))\n",
    "\n",
    "# vscode + wandb compat\n",
    "dt = pd.Timestamp.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# TODO put model and adapter base names?\n",
    "run_name = f\"{nb_name}-{dt}\"\n",
    "\n",
    "training_args = ReprPOConfig(\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=1e-4, # 5e-7 in the dpo paper? but this method needs much more\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size//2,\n",
    "\n",
    "    # lr_scheduler_type=\"constant\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0,\n",
    "\n",
    "    seed=42,\n",
    "    logging_steps=1,\n",
    "    # save_steps=500,\n",
    "    # save_strategy=\"steps\",\n",
    "    output_dir=f\"./output-dir/{run_name}\",\n",
    "\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=10,\n",
    "\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_length=max_length,\n",
    "\n",
    "    report_to=['tensorboard', 'wandb'],\n",
    "    model_adapter_name='ReprPO',\n",
    "    alpha=.3,\n",
    "\n",
    "    run_name=run_name,\n",
    "    collection_layers=[10, 25],\n",
    "\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    ")\n",
    "\n",
    "reprpo_trainer = ReprPOTrainer2(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    # beta=training_args.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    eval_dataset=dataset2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Transformer does not recognise vscode notebooks\n",
    "reprpo_trainer.callback_handler.remove_callback(ProgressCallback)\n",
    "reprpo_trainer.callback_handler.add_callback(NotebookProgressCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QC train dataset\n",
    "# r = reprpo_trainer.train_dataset[0]\n",
    "# print('prompt', tokenizer.decode(r['prompt_input_ids']))\n",
    "# print('-'*80)q\n",
    "# print('chosen',tokenizer.decode(r['chosen_input_ids']))\n",
    "# print('-'*80)\n",
    "# print('rejected',tokenizer.decode(r['rejected_input_ids']))\n",
    "# print('='*80)\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwassname\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/nbs/wandb/run-20240807_133431-wse3nzrw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wassname/repo-dpo/runs/wse3nzrw' target=\"_blank\">12_hf_phi_oft_detach-2024-08-07-13-34-04</a></strong> to <a href='https://wandb.ai/wassname/repo-dpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wassname/repo-dpo' target=\"_blank\">https://wandb.ai/wassname/repo-dpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wassname/repo-dpo/runs/wse3nzrw' target=\"_blank\">https://wandb.ai/wassname/repo-dpo/runs/wse3nzrw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 retain_cos_sim: 1.0000. rr_cos_sim: 0.8023\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '0', 'logps/rejected': '-1.5', 'logps/chosen': '-1.5', 'loss': '1.3', 'rewards/chosen': '0', 'rewards/rejected': '0', 'retain/loss': '1', 'reroute/loss': '1', 'logratios/pi': '-0.0047', 'logratios/ref': '-0.0047', 'weighting': '0.024', 'logits': '0', 'component_rr/loss': '1', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='650' max='1376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 650/1376 1:47:18 < 2:00:13, 0.10 it/s, Epoch 3.77/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Retain/loss</th>\n",
       "      <th>Reroute/loss</th>\n",
       "      <th>Logratios/pi</th>\n",
       "      <th>Logratios/ref</th>\n",
       "      <th>Weighting</th>\n",
       "      <th>Logits</th>\n",
       "      <th>Component Rr/loss</th>\n",
       "      <th>Component Retain/loss</th>\n",
       "      <th>Rr/c</th>\n",
       "      <th>Retain/c</th>\n",
       "      <th>Retain Cosine</th>\n",
       "      <th>Rr Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.554040</td>\n",
       "      <td>1.619709</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-1.422400</td>\n",
       "      <td>-1.435405</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>1.034869</td>\n",
       "      <td>1.309248</td>\n",
       "      <td>-0.013005</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>1.309248</td>\n",
       "      <td>0.310461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>0.784563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>668626.562500</td>\n",
       "      <td>923984.312500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>-85.253059</td>\n",
       "      <td>-85.186798</td>\n",
       "      <td>-8.376476</td>\n",
       "      <td>-8.384375</td>\n",
       "      <td>8073.371582</td>\n",
       "      <td>921562.312500</td>\n",
       "      <td>0.066261</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.078993</td>\n",
       "      <td>921562.312500</td>\n",
       "      <td>2422.011475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486040</td>\n",
       "      <td>0.414422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>17341503488.000000</td>\n",
       "      <td>26017468416.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>-103.104141</td>\n",
       "      <td>-103.022743</td>\n",
       "      <td>-10.160071</td>\n",
       "      <td>-10.169483</td>\n",
       "      <td>214804000.000000</td>\n",
       "      <td>25953026048.000000</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.094133</td>\n",
       "      <td>25953026048.000000</td>\n",
       "      <td>64441196.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279786</td>\n",
       "      <td>0.260590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9905780031488.000000</td>\n",
       "      <td>15914037673984.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>-97.690605</td>\n",
       "      <td>-97.591293</td>\n",
       "      <td>-9.616925</td>\n",
       "      <td>-9.628130</td>\n",
       "      <td>135252836352.000000</td>\n",
       "      <td>15873460928512.000000</td>\n",
       "      <td>0.099313</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.112045</td>\n",
       "      <td>15873460928512.000000</td>\n",
       "      <td>40575844352.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.185452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>960602721746944.000000</td>\n",
       "      <td>1139578840809472.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>-95.248146</td>\n",
       "      <td>-95.139046</td>\n",
       "      <td>-9.371700</td>\n",
       "      <td>-9.383884</td>\n",
       "      <td>9807421505536.000000</td>\n",
       "      <td>1136636788211712.000000</td>\n",
       "      <td>0.109111</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.121844</td>\n",
       "      <td>1136636788211712.000000</td>\n",
       "      <td>2942226661376.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191363</td>\n",
       "      <td>0.182387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>29473549496352768.000000</td>\n",
       "      <td>29226247426932736.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>-94.046661</td>\n",
       "      <td>-93.930809</td>\n",
       "      <td>-9.250876</td>\n",
       "      <td>-9.263735</td>\n",
       "      <td>253817870352384.000000</td>\n",
       "      <td>29150104099225600.000000</td>\n",
       "      <td>0.115845</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.128577</td>\n",
       "      <td>29150104099225600.000000</td>\n",
       "      <td>76145357750272.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190897</td>\n",
       "      <td>0.181924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>153058237699063808.000000</td>\n",
       "      <td>373306222222245888.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>-93.485229</td>\n",
       "      <td>-93.364418</td>\n",
       "      <td>-9.194240</td>\n",
       "      <td>-9.207592</td>\n",
       "      <td>3251845367595008.000000</td>\n",
       "      <td>372330646170763264.000000</td>\n",
       "      <td>0.120793</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.133526</td>\n",
       "      <td>372330646170763264.000000</td>\n",
       "      <td>975553637122048.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191219</td>\n",
       "      <td>0.182258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1743571454466719744.000000</td>\n",
       "      <td>2889086923626774528.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>-92.961548</td>\n",
       "      <td>-92.836929</td>\n",
       "      <td>-9.141489</td>\n",
       "      <td>-9.155224</td>\n",
       "      <td>25241497028788224.000000</td>\n",
       "      <td>2881514861924188160.000000</td>\n",
       "      <td>0.124613</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.137346</td>\n",
       "      <td>2881514861924188160.000000</td>\n",
       "      <td>7572449860255744.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191518</td>\n",
       "      <td>0.182564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>12034999190938451968.000000</td>\n",
       "      <td>15594587821514424320.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>-92.971016</td>\n",
       "      <td>-92.844124</td>\n",
       "      <td>-9.142208</td>\n",
       "      <td>-9.156170</td>\n",
       "      <td>136284560752115712.000000</td>\n",
       "      <td>15553702481635573760.000000</td>\n",
       "      <td>0.126889</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.139622</td>\n",
       "      <td>15553702481635573760.000000</td>\n",
       "      <td>40885369943621632.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.182718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>66157315576119164928.000000</td>\n",
       "      <td>63894274355551535104.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.014280</td>\n",
       "      <td>-93.498657</td>\n",
       "      <td>-93.368591</td>\n",
       "      <td>-9.194654</td>\n",
       "      <td>-9.208935</td>\n",
       "      <td>556521177653182464.000000</td>\n",
       "      <td>63727320111943516160.000000</td>\n",
       "      <td>0.130066</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.142798</td>\n",
       "      <td>63727320111943516160.000000</td>\n",
       "      <td>166956373911797760.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>103255787875327803392.000000</td>\n",
       "      <td>210357297988709122048.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>-93.506905</td>\n",
       "      <td>-93.374573</td>\n",
       "      <td>-9.195253</td>\n",
       "      <td>-9.209759</td>\n",
       "      <td>1821072593134813184.000000</td>\n",
       "      <td>209810990243285827584.000000</td>\n",
       "      <td>0.132334</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.145066</td>\n",
       "      <td>209810990243285827584.000000</td>\n",
       "      <td>546321798556286976.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191675</td>\n",
       "      <td>0.182729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>355448254255704571904.000000</td>\n",
       "      <td>578105551329832206336.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>-94.049797</td>\n",
       "      <td>-93.915436</td>\n",
       "      <td>-9.249340</td>\n",
       "      <td>-9.264049</td>\n",
       "      <td>4973341231326167040.000000</td>\n",
       "      <td>576613558031405285376.000000</td>\n",
       "      <td>0.134362</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.147095</td>\n",
       "      <td>576613558031405285376.000000</td>\n",
       "      <td>1492002644275757056.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191735</td>\n",
       "      <td>0.182786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 retain_cos_sim: 1.0000. rr_cos_sim: 0.7840\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '3.2e-05', 'logps/rejected': '-1.5', 'logps/chosen': '-1.4', 'loss': '1.3', 'rewards/chosen': '0.00018', 'rewards/rejected': '0.00014', 'retain/loss': '1', 'reroute/loss': '1', 'logratios/pi': '0.12', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '0.00032', 'component_rr/loss': '1', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.78'}\n",
      "20 retain_cos_sim: 1.0000. rr_cos_sim: 0.7906\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00017', 'logps/rejected': '-1.5', 'logps/chosen': '-1.3', 'loss': '1.3', 'rewards/chosen': '0.00065', 'rewards/rejected': '0.00048', 'retain/loss': '1', 'reroute/loss': '1', 'logratios/pi': '0.21', 'logratios/ref': '0.2', 'weighting': '0.024', 'logits': '0.0017', 'component_rr/loss': '1', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.79'}\n",
      "30 retain_cos_sim: 0.9999. rr_cos_sim: 0.7799\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.00028', 'logps/rejected': '-1.6', 'logps/chosen': '-1.2', 'loss': '1.4', 'rewards/chosen': '0.00072', 'rewards/rejected': '0.001', 'retain/loss': '1', 'reroute/loss': '1.1', 'logratios/pi': '0.36', 'logratios/ref': '0.36', 'weighting': '0.024', 'logits': '-0.0028', 'component_rr/loss': '1.1', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.78'}\n",
      "40 retain_cos_sim: 0.9997. rr_cos_sim: 0.7908\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00018', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '1.5', 'rewards/chosen': '-0.00017', 'rewards/rejected': '-0.00035', 'retain/loss': '1', 'reroute/loss': '1.2', 'logratios/pi': '-0.023', 'logratios/ref': '-0.025', 'weighting': '0.024', 'logits': '0.0018', 'component_rr/loss': '1.2', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.79'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "50 retain_cos_sim: 0.9993. rr_cos_sim: 0.8004\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '7.7e-05', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.0013', 'eval_rewards/rejected': '-0.0014', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '0.0086', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.00077', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9990. rr_cos_sim: 0.7954\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0017', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.6', 'eval_loss': '1.9', 'eval_rewards/chosen': '-0.0028', 'eval_rewards/rejected': '-0.0011', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.6', 'eval_logratios/pi': '-0.24', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.017', 'eval_component_rr/loss': '1.6', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9988. rr_cos_sim: 0.7897\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.001', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.0028', 'eval_rewards/rejected': '-0.0018', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '-0.032', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.01', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.32', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9988. rr_cos_sim: 0.7940\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00042', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.00072', 'eval_rewards/rejected': '-0.0011', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '0.073', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.0042', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9988. rr_cos_sim: 0.7976\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00024', 'eval_logps/rejected': '-1.7', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.9', 'eval_rewards/chosen': '-0.001', 'eval_rewards/rejected': '-0.0013', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.6', 'eval_logratios/pi': '0.26', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.0024', 'eval_component_rr/loss': '1.6', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9993. rr_cos_sim: 0.7876\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0002', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.4', 'eval_rewards/chosen': '-0.00016', 'eval_rewards/rejected': '-0.00036', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.1', 'eval_logratios/pi': '-0.015', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.002', 'eval_component_rr/loss': '1.1', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9992. rr_cos_sim: 0.8087\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00032', 'eval_logps/rejected': '-1.1', 'eval_logps/chosen': '-1.1', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.00043', 'eval_rewards/rejected': '-0.00075', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '0.04', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.0032', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.81'}\n",
      "50 retain_cos_sim: 0.9992. rr_cos_sim: 0.7895\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '8.2e-05', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.8', 'eval_rewards/chosen': '-0.0011', 'eval_rewards/rejected': '-0.0011', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.5', 'eval_logratios/pi': '0.085', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '0.00082', 'eval_component_rr/loss': '1.5', 'eval_component_retain/loss': '0.3', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9990. rr_cos_sim: 0.7734\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00053', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.7', 'eval_rewards/chosen': '-0.00094', 'eval_rewards/rejected': '-0.00041', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.4', 'eval_logratios/pi': '-0.0019', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.0053', 'eval_component_rr/loss': '1.4', 'eval_component_retain/loss': '0.3', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.77'}\n",
      "50 retain_cos_sim: 0.9989. rr_cos_sim: 0.7781\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0012', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.2', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.0017', 'eval_rewards/rejected': '-0.003', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '0.27', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '0.012', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9994. rr_cos_sim: 0.7643\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0034', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.00067', 'eval_rewards/rejected': '-0.0041', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '0.27', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '0.034', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.32', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.76'}\n",
      "50 retain_cos_sim: 0.9993. rr_cos_sim: 0.7873\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00077', 'eval_logps/rejected': '-1.2', 'eval_logps/chosen': '-1.2', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.0011', 'eval_rewards/rejected': '-0.00038', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '0.007', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.0077', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9991. rr_cos_sim: 0.7509\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00075', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.6', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.0026', 'eval_rewards/rejected': '-0.0019', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.0075', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.75'}\n",
      "50 retain_cos_sim: 0.9991. rr_cos_sim: 0.7741\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '8.7e-05', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.0011', 'eval_rewards/rejected': '-0.0012', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '0.017', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.00087', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.77'}\n",
      "50 retain_cos_sim: 0.9990. rr_cos_sim: 0.7820\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00015', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.8', 'eval_loss': '1.5', 'eval_rewards/chosen': '-0.00062', 'eval_rewards/rejected': '-0.00048', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.2', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '-0.0015', 'eval_component_rr/loss': '1.2', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9989. rr_cos_sim: 0.7899\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0011', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.8', 'eval_rewards/chosen': '-0.00043', 'eval_rewards/rejected': '0.00068', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.5', 'eval_logratios/pi': '0.21', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.011', 'eval_component_rr/loss': '1.5', 'eval_component_retain/loss': '0.3', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9987. rr_cos_sim: 0.7750\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00085', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.7', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.0025', 'eval_rewards/rejected': '-0.0016', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.0085', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.77'}\n",
      "50 retain_cos_sim: 0.9989. rr_cos_sim: 0.7844\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0003', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-2', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.002', 'eval_rewards/rejected': '-0.0023', 'eval_retain/loss': '1', 'eval_reroute/loss': '1.3', 'eval_logratios/pi': '-0.57', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.003', 'eval_component_rr/loss': '1.3', 'eval_component_retain/loss': '0.31', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9990. rr_cos_sim: 0.7859\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '6.2e-05', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '1.5', 'rewards/chosen': '-0.0012', 'rewards/rejected': '-0.0013', 'retain/loss': '1', 'reroute/loss': '1.2', 'logratios/pi': '0.058', 'logratios/ref': '0.057', 'weighting': '0.024', 'logits': '0.00062', 'component_rr/loss': '1.2', 'component_retain/loss': '0.31', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.79'}\n",
      "60 retain_cos_sim: 0.9987. rr_cos_sim: 0.7965\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00037', 'logps/rejected': '-1.4', 'logps/chosen': '-1.3', 'loss': '1.8', 'rewards/chosen': '-0.0017', 'rewards/rejected': '-0.0021', 'retain/loss': '1.1', 'reroute/loss': '1.4', 'logratios/pi': '0.076', 'logratios/ref': '0.072', 'weighting': '0.024', 'logits': '0.0037', 'component_rr/loss': '1.4', 'component_retain/loss': '0.34', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.8'}\n",
      "70 retain_cos_sim: 0.9948. rr_cos_sim: 0.7710\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0011', 'logps/rejected': '-1.5', 'logps/chosen': '-1.4', 'loss': '6.9', 'rewards/chosen': '-0.0063', 'rewards/rejected': '-0.0074', 'retain/loss': '1.1', 'reroute/loss': '6.5', 'logratios/pi': '0.11', 'logratios/ref': '0.097', 'weighting': '0.024', 'logits': '0.011', 'component_rr/loss': '6.5', 'component_retain/loss': '0.34', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.99', 'rr_cosine': '0.77'}\n",
      "80 retain_cos_sim: 0.8489. rr_cos_sim: 0.6651\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0016', 'logps/rejected': '-4.1', 'logps/chosen': '-4', 'loss': '6.4e+02', 'rewards/chosen': '-0.26', 'rewards/rejected': '-0.26', 'retain/loss': '11', 'reroute/loss': '6.4e+02', 'logratios/pi': '0.039', 'logratios/ref': '0.056', 'weighting': '0.024', 'logits': '-0.016', 'component_rr/loss': '6.4e+02', 'component_retain/loss': '3.4', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.85', 'rr_cosine': '0.67'}\n",
      "90 retain_cos_sim: 0.5803. rr_cos_sim: 0.4702\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.1', 'logps/rejected': '-90', 'logps/chosen': '-89', 'loss': '6.8e+04', 'rewards/chosen': '-8.7', 'rewards/rejected': '-8.8', 'retain/loss': '6.4e+02', 'reroute/loss': '6.7e+04', 'logratios/pi': '0.96', 'logratios/ref': '-0.071', 'weighting': '0.024', 'logits': '1', 'component_rr/loss': '6.7e+04', 'component_retain/loss': '1.9e+02', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.58', 'rr_cosine': '0.47'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "100 retain_cos_sim: 0.5034. rr_cos_sim: 0.4380\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.074', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '8.5e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '7.6e+03', 'eval_reroute/loss': '8.5e+05', 'eval_logratios/pi': '-0.73', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-0.74', 'eval_component_rr/loss': '8.5e+05', 'eval_component_retain/loss': '2.3e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.5', 'eval_rr_cosine': '0.44'}\n",
      "100 retain_cos_sim: 0.5942. rr_cos_sim: 0.5143\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.015', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '1.2e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '7.5e+02', 'eval_reroute/loss': '1.2e+05', 'eval_logratios/pi': '-0.37', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.15', 'eval_component_rr/loss': '1.2e+05', 'eval_component_retain/loss': '2.2e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.59', 'eval_rr_cosine': '0.51'}\n",
      "100 retain_cos_sim: 0.4850. rr_cos_sim: 0.4033\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.023', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '6.9e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '5.2e+03', 'eval_reroute/loss': '6.9e+05', 'eval_logratios/pi': '0.21', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.23', 'eval_component_rr/loss': '6.9e+05', 'eval_component_retain/loss': '1.6e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.49', 'eval_rr_cosine': '0.4'}\n",
      "100 retain_cos_sim: 0.4112. rr_cos_sim: 0.3357\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-86', 'eval_loss': '1.2e+06', 'eval_rewards/chosen': '-8.5', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '8.6e+03', 'eval_reroute/loss': '1.2e+06', 'eval_logratios/pi': '-1.1', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '1.2e+06', 'eval_component_retain/loss': '2.6e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.41', 'eval_rr_cosine': '0.34'}\n",
      "100 retain_cos_sim: 0.4363. rr_cos_sim: 0.3783\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.061', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-85', 'eval_loss': '6.8e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '5.2e+03', 'eval_reroute/loss': '6.8e+05', 'eval_logratios/pi': '0.87', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.61', 'eval_component_rr/loss': '6.8e+05', 'eval_component_retain/loss': '1.6e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.44', 'eval_rr_cosine': '0.38'}\n",
      "100 retain_cos_sim: 0.4666. rr_cos_sim: 0.3931\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '1.3e+06', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '1.3e+04', 'eval_reroute/loss': '1.3e+06', 'eval_logratios/pi': '-0.21', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '1.3e+06', 'eval_component_retain/loss': '3.9e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.47', 'eval_rr_cosine': '0.39'}\n",
      "100 retain_cos_sim: 0.5064. rr_cos_sim: 0.4547\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.045', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-85', 'eval_loss': '2e+06', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.5', 'eval_retain/loss': '2.2e+04', 'eval_reroute/loss': '2e+06', 'eval_logratios/pi': '0.49', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.45', 'eval_component_rr/loss': '2e+06', 'eval_component_retain/loss': '6.6e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.51', 'eval_rr_cosine': '0.45'}\n",
      "100 retain_cos_sim: 0.5207. rr_cos_sim: 0.4636\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.025', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '1e+06', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '6.9e+03', 'eval_reroute/loss': '1e+06', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.25', 'eval_component_rr/loss': '1e+06', 'eval_component_retain/loss': '2.1e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.52', 'eval_rr_cosine': '0.46'}\n",
      "100 retain_cos_sim: 0.5424. rr_cos_sim: 0.4673\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.034', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '5.4e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '4.1e+03', 'eval_reroute/loss': '5.4e+05', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.34', 'eval_component_rr/loss': '5.4e+05', 'eval_component_retain/loss': '1.2e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.47'}\n",
      "100 retain_cos_sim: 0.5442. rr_cos_sim: 0.4734\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.065', 'eval_logps/rejected': '-84', 'eval_logps/chosen': '-84', 'eval_loss': '3.6e+05', 'eval_rewards/chosen': '-8.3', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '2.7e+03', 'eval_reroute/loss': '3.6e+05', 'eval_logratios/pi': '-0.39', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.65', 'eval_component_rr/loss': '3.6e+05', 'eval_component_retain/loss': '8.2e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.47'}\n",
      "100 retain_cos_sim: 0.5383. rr_cos_sim: 0.4585\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.092', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-83', 'eval_loss': '1.8e+05', 'eval_rewards/chosen': '-8.2', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '1.2e+03', 'eval_reroute/loss': '1.8e+05', 'eval_logratios/pi': '1.2', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '0.92', 'eval_component_rr/loss': '1.8e+05', 'eval_component_retain/loss': '3.7e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.46'}\n",
      "100 retain_cos_sim: 0.5431. rr_cos_sim: 0.4848\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.053', 'eval_logps/rejected': '-84', 'eval_logps/chosen': '-85', 'eval_loss': '1.3e+06', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.3', 'eval_retain/loss': '1.7e+04', 'eval_reroute/loss': '1.3e+06', 'eval_logratios/pi': '-0.52', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.53', 'eval_component_rr/loss': '1.3e+06', 'eval_component_retain/loss': '5e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.48'}\n",
      "100 retain_cos_sim: 0.4801. rr_cos_sim: 0.3847\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.058', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-85', 'eval_loss': '6.1e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '4.9e+03', 'eval_reroute/loss': '6.1e+05', 'eval_logratios/pi': '0.45', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.58', 'eval_component_rr/loss': '6.1e+05', 'eval_component_retain/loss': '1.5e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.48', 'eval_rr_cosine': '0.38'}\n",
      "100 retain_cos_sim: 0.5230. rr_cos_sim: 0.4608\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.046', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-85', 'eval_loss': '9e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '8.1e+03', 'eval_reroute/loss': '9e+05', 'eval_logratios/pi': '0.48', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.46', 'eval_component_rr/loss': '9e+05', 'eval_component_retain/loss': '2.4e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.52', 'eval_rr_cosine': '0.46'}\n",
      "100 retain_cos_sim: 0.4172. rr_cos_sim: 0.3469\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.082', 'eval_logps/rejected': '-85', 'eval_logps/chosen': '-85', 'eval_loss': '1.6e+06', 'eval_rewards/chosen': '-8.3', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '1.4e+04', 'eval_reroute/loss': '1.6e+06', 'eval_logratios/pi': '0.48', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.82', 'eval_component_rr/loss': '1.6e+06', 'eval_component_retain/loss': '4.3e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.42', 'eval_rr_cosine': '0.35'}\n",
      "100 retain_cos_sim: 0.3931. rr_cos_sim: 0.3337\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.076', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-87', 'eval_loss': '1.1e+06', 'eval_rewards/chosen': '-8.6', 'eval_rewards/rejected': '-8.5', 'eval_retain/loss': '7.5e+03', 'eval_reroute/loss': '1.1e+06', 'eval_logratios/pi': '-0.54', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.76', 'eval_component_rr/loss': '1.1e+06', 'eval_component_retain/loss': '2.2e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.39', 'eval_rr_cosine': '0.33'}\n",
      "100 retain_cos_sim: 0.4243. rr_cos_sim: 0.3295\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-86', 'eval_loss': '9.3e+05', 'eval_rewards/chosen': '-8.4', 'eval_rewards/rejected': '-8.4', 'eval_retain/loss': '7.2e+03', 'eval_reroute/loss': '9.3e+05', 'eval_logratios/pi': '-0.38', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '9.3e+05', 'eval_component_retain/loss': '2.1e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.42', 'eval_rr_cosine': '0.33'}\n",
      "100 retain_cos_sim: 0.4192. rr_cos_sim: 0.3388\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.24', 'eval_logps/rejected': '-86', 'eval_logps/chosen': '-84', 'eval_loss': '1.3e+06', 'eval_rewards/chosen': '-8.2', 'eval_rewards/rejected': '-8.5', 'eval_retain/loss': '9.2e+03', 'eval_reroute/loss': '1.3e+06', 'eval_logratios/pi': '1.8', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.4', 'eval_component_rr/loss': '1.3e+06', 'eval_component_retain/loss': '2.8e+03', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.42', 'eval_rr_cosine': '0.34'}\n",
      "100 retain_cos_sim: 0.4769. rr_cos_sim: 0.4049\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.025', 'logps/rejected': '-85', 'logps/chosen': '-84', 'loss': '9e+05', 'rewards/chosen': '-8.3', 'rewards/rejected': '-8.3', 'retain/loss': '8.4e+03', 'reroute/loss': '9e+05', 'logratios/pi': '0.26', 'logratios/ref': '0.0089', 'weighting': '0.024', 'logits': '0.25', 'component_rr/loss': '9e+05', 'component_retain/loss': '2.5e+03', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.48', 'rr_cosine': '0.4'}\n",
      "110 retain_cos_sim: 0.3911. rr_cos_sim: 0.3565\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.06', 'logps/rejected': '-98', 'logps/chosen': '-97', 'loss': '1.1e+07', 'rewards/chosen': '-9.6', 'rewards/rejected': '-9.6', 'retain/loss': '8.6e+04', 'reroute/loss': '1.1e+07', 'logratios/pi': '0.71', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '0.6', 'component_rr/loss': '1.1e+07', 'component_retain/loss': '2.6e+04', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.39', 'rr_cosine': '0.36'}\n",
      "120 retain_cos_sim: 0.3318. rr_cos_sim: 0.3101\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.005', 'logps/rejected': '-1.1e+02', 'logps/chosen': '-1.1e+02', 'loss': '5.5e+07', 'rewards/chosen': '-10', 'rewards/rejected': '-10', 'retain/loss': '4.5e+05', 'reroute/loss': '5.5e+07', 'logratios/pi': '0.066', 'logratios/ref': '0.017', 'weighting': '0.024', 'logits': '0.05', 'component_rr/loss': '5.5e+07', 'component_retain/loss': '1.4e+05', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.33', 'rr_cosine': '0.31'}\n",
      "130 retain_cos_sim: 0.2804. rr_cos_sim: 0.2713\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0064', 'logps/rejected': '-1.1e+02', 'logps/chosen': '-1.1e+02', 'loss': '5e+08', 'rewards/chosen': '-11', 'rewards/rejected': '-11', 'retain/loss': '3.8e+06', 'reroute/loss': '5e+08', 'logratios/pi': '0.17', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '0.064', 'component_rr/loss': '5e+08', 'component_retain/loss': '1.1e+06', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.28', 'rr_cosine': '0.27'}\n",
      "140 retain_cos_sim: 0.2929. rr_cos_sim: 0.2585\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.023', 'logps/rejected': '-1e+02', 'logps/chosen': '-1e+02', 'loss': '2.9e+09', 'rewards/chosen': '-10', 'rewards/rejected': '-10', 'retain/loss': '2.2e+07', 'reroute/loss': '2.9e+09', 'logratios/pi': '-0.26', 'logratios/ref': '-0.029', 'weighting': '0.024', 'logits': '-0.23', 'component_rr/loss': '2.9e+09', 'component_retain/loss': '6.7e+06', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.29', 'rr_cosine': '0.26'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin provin`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "150 retain_cos_sim: 0.3066. rr_cos_sim: 0.2900\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '2.4e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2e+08', 'eval_reroute/loss': '2.4e+10', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '2.4e+10', 'eval_component_retain/loss': '6.1e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.31', 'eval_rr_cosine': '0.29'}\n",
      "150 retain_cos_sim: 0.4348. rr_cos_sim: 0.3984\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.02', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '3.5e+09', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2e+07', 'eval_reroute/loss': '3.5e+09', 'eval_logratios/pi': '-0.42', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.2', 'eval_component_rr/loss': '3.5e+09', 'eval_component_retain/loss': '6.1e+06', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.43', 'eval_rr_cosine': '0.4'}\n",
      "150 retain_cos_sim: 0.2744. rr_cos_sim: 0.2393\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.018', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '2e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.4e+08', 'eval_reroute/loss': '1.9e+10', 'eval_logratios/pi': '0.16', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.18', 'eval_component_rr/loss': '1.9e+10', 'eval_component_retain/loss': '4.2e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.27', 'eval_rr_cosine': '0.24'}\n",
      "150 retain_cos_sim: 0.1691. rr_cos_sim: 0.1417\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.16', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '3.3e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2.3e+08', 'eval_reroute/loss': '3.3e+10', 'eval_logratios/pi': '-1.5', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.6', 'eval_component_rr/loss': '3.3e+10', 'eval_component_retain/loss': '6.9e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.17', 'eval_rr_cosine': '0.14'}\n",
      "150 retain_cos_sim: 0.2040. rr_cos_sim: 0.2047\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.087', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '1.9e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.4e+08', 'eval_reroute/loss': '1.9e+10', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.87', 'eval_component_rr/loss': '1.9e+10', 'eval_component_retain/loss': '4.2e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.2'}\n",
      "150 retain_cos_sim: 0.2499. rr_cos_sim: 0.2267\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.035', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '3.8e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '3.5e+08', 'eval_reroute/loss': '3.7e+10', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.35', 'eval_component_rr/loss': '3.7e+10', 'eval_component_retain/loss': '1e+08', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.25', 'eval_rr_cosine': '0.23'}\n",
      "150 retain_cos_sim: 0.3215. rr_cos_sim: 0.3186\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.031', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '5.7e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '5.9e+08', 'eval_reroute/loss': '5.7e+10', 'eval_logratios/pi': '0.35', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.31', 'eval_component_rr/loss': '5.7e+10', 'eval_component_retain/loss': '1.8e+08', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.32', 'eval_rr_cosine': '0.32'}\n",
      "150 retain_cos_sim: 0.3332. rr_cos_sim: 0.3323\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.026', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '2.8e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.8e+08', 'eval_reroute/loss': '2.8e+10', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.26', 'eval_component_rr/loss': '2.8e+10', 'eval_component_retain/loss': '5.5e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.33', 'eval_rr_cosine': '0.33'}\n",
      "150 retain_cos_sim: 0.3578. rr_cos_sim: 0.3371\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.049', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '1.5e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.1e+08', 'eval_reroute/loss': '1.5e+10', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.49', 'eval_component_rr/loss': '1.5e+10', 'eval_component_retain/loss': '3.2e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.36', 'eval_rr_cosine': '0.34'}\n",
      "150 retain_cos_sim: 0.3669. rr_cos_sim: 0.3485\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.08', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '1e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '7.3e+07', 'eval_reroute/loss': '1e+10', 'eval_logratios/pi': '-0.54', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.8', 'eval_component_rr/loss': '1e+10', 'eval_component_retain/loss': '2.2e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.37', 'eval_rr_cosine': '0.35'}\n",
      "150 retain_cos_sim: 0.3609. rr_cos_sim: 0.3362\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.15', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '5e+09', 'eval_rewards/chosen': '-9.9', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '3.3e+07', 'eval_reroute/loss': '5e+09', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.5', 'eval_component_rr/loss': '5e+09', 'eval_component_retain/loss': '1e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.36', 'eval_rr_cosine': '0.34'}\n",
      "150 retain_cos_sim: 0.3631. rr_cos_sim: 0.3594\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.076', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '3.7e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '4.4e+08', 'eval_reroute/loss': '3.6e+10', 'eval_logratios/pi': '-0.75', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.76', 'eval_component_rr/loss': '3.6e+10', 'eval_component_retain/loss': '1.3e+08', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.36', 'eval_rr_cosine': '0.36'}\n",
      "150 retain_cos_sim: 0.2574. rr_cos_sim: 0.2187\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.086', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '1.7e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.3e+08', 'eval_reroute/loss': '1.7e+10', 'eval_logratios/pi': '0.74', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.86', 'eval_component_rr/loss': '1.7e+10', 'eval_component_retain/loss': '4e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.22'}\n",
      "150 retain_cos_sim: 0.3305. rr_cos_sim: 0.3277\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.066', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '2.5e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2.2e+08', 'eval_reroute/loss': '2.5e+10', 'eval_logratios/pi': '0.67', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.66', 'eval_component_rr/loss': '2.5e+10', 'eval_component_retain/loss': '6.5e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.33', 'eval_rr_cosine': '0.33'}\n",
      "150 retain_cos_sim: 0.1833. rr_cos_sim: 0.1641\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.12', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '4.4e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '3.8e+08', 'eval_reroute/loss': '4.4e+10', 'eval_logratios/pi': '0.86', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.2', 'eval_component_rr/loss': '4.4e+10', 'eval_component_retain/loss': '1.1e+08', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "150 retain_cos_sim: 0.1440. rr_cos_sim: 0.1463\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.065', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1.1e+02', 'eval_loss': '3e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2e+08', 'eval_reroute/loss': '3e+10', 'eval_logratios/pi': '-0.43', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.65', 'eval_component_rr/loss': '3e+10', 'eval_component_retain/loss': '6e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.15'}\n",
      "150 retain_cos_sim: 0.1946. rr_cos_sim: 0.1473\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.033', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '2.6e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '1.9e+08', 'eval_reroute/loss': '2.6e+10', 'eval_logratios/pi': '-0.47', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.33', 'eval_component_rr/loss': '2.6e+10', 'eval_component_retain/loss': '5.7e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.15'}\n",
      "150 retain_cos_sim: 0.1842. rr_cos_sim: 0.1537\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.27', 'eval_logps/rejected': '-1e+02', 'eval_logps/chosen': '-1e+02', 'eval_loss': '3.6e+10', 'eval_rewards/chosen': '-10', 'eval_rewards/rejected': '-10', 'eval_retain/loss': '2.5e+08', 'eval_reroute/loss': '3.6e+10', 'eval_logratios/pi': '2.2', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.7', 'eval_component_rr/loss': '3.6e+10', 'eval_component_retain/loss': '7.4e+07', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.15'}\n",
      "150 retain_cos_sim: 0.2913. rr_cos_sim: 0.2643\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.059', 'logps/rejected': '-1e+02', 'logps/chosen': '-1e+02', 'loss': '2.6e+10', 'rewards/chosen': '-10', 'rewards/rejected': '-10', 'retain/loss': '2.2e+08', 'reroute/loss': '2.6e+10', 'logratios/pi': '-0.63', 'logratios/ref': '-0.031', 'weighting': '0.024', 'logits': '-0.59', 'component_rr/loss': '2.6e+10', 'component_retain/loss': '6.7e+07', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.29', 'rr_cosine': '0.26'}\n",
      "160 retain_cos_sim: 0.2268. rr_cos_sim: 0.2217\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.11', 'logps/rejected': '-1e+02', 'logps/chosen': '-1e+02', 'loss': '8.3e+10', 'rewards/chosen': '-10', 'rewards/rejected': '-9.9', 'retain/loss': '6.7e+08', 'reroute/loss': '8.3e+10', 'logratios/pi': '-0.97', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '-1.1', 'component_rr/loss': '8.3e+10', 'component_retain/loss': '2e+08', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.23', 'rr_cosine': '0.22'}\n",
      "170 retain_cos_sim: 0.1936. rr_cos_sim: 0.1899\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.065', 'logps/rejected': '-1e+02', 'logps/chosen': '-1e+02', 'loss': '2.9e+11', 'rewards/chosen': '-9.8', 'rewards/rejected': '-9.9', 'retain/loss': '2e+09', 'reroute/loss': '2.8e+11', 'logratios/pi': '0.73', 'logratios/ref': '0.086', 'weighting': '0.024', 'logits': '0.65', 'component_rr/loss': '2.8e+11', 'component_retain/loss': '6.1e+08', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.19'}\n",
      "180 retain_cos_sim: 0.1914. rr_cos_sim: 0.1817\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.004', 'logps/rejected': '-97', 'logps/chosen': '-97', 'loss': '9.6e+11', 'rewards/chosen': '-9.6', 'rewards/rejected': '-9.6', 'retain/loss': '6.3e+09', 'reroute/loss': '9.6e+11', 'logratios/pi': '0.12', 'logratios/ref': '0.076', 'weighting': '0.024', 'logits': '0.04', 'component_rr/loss': '9.6e+11', 'component_retain/loss': '1.9e+09', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "190 retain_cos_sim: 0.1842. rr_cos_sim: 0.1795\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.024', 'logps/rejected': '-97', 'logps/chosen': '-97', 'loss': '1.9e+12', 'rewards/chosen': '-9.6', 'rewards/rejected': '-9.6', 'retain/loss': '1.3e+10', 'reroute/loss': '1.9e+12', 'logratios/pi': '-0.017', 'logratios/ref': '0.23', 'weighting': '0.024', 'logits': '-0.24', 'component_rr/loss': '1.9e+12', 'component_retain/loss': '3.9e+09', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "200 retain_cos_sim: 0.2032. rr_cos_sim: 0.1957\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-98', 'eval_loss': '1.5e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '1.3e+11', 'eval_reroute/loss': '1.5e+13', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '1.5e+13', 'eval_component_retain/loss': '3.8e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.2'}\n",
      "200 retain_cos_sim: 0.2661. rr_cos_sim: 0.2502\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-98', 'eval_loss': '2.1e+12', 'eval_rewards/chosen': '-9.7', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '1.3e+10', 'eval_reroute/loss': '2.1e+12', 'eval_logratios/pi': '-0.41', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '2.1e+12', 'eval_component_retain/loss': '3.8e+09', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.27', 'eval_rr_cosine': '0.25'}\n",
      "200 retain_cos_sim: 0.1934. rr_cos_sim: 0.1781\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.02', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-98', 'eval_loss': '1.2e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '8.7e+10', 'eval_reroute/loss': '1.2e+13', 'eval_logratios/pi': '0.18', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.2', 'eval_component_rr/loss': '1.2e+13', 'eval_component_retain/loss': '2.6e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "200 retain_cos_sim: 0.1480. rr_cos_sim: 0.1369\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.15', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-99', 'eval_loss': '2e+13', 'eval_rewards/chosen': '-9.8', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '1.4e+11', 'eval_reroute/loss': '2e+13', 'eval_logratios/pi': '-1.5', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.5', 'eval_component_rr/loss': '2e+13', 'eval_component_retain/loss': '4.3e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "200 retain_cos_sim: 0.1659. rr_cos_sim: 0.1651\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.084', 'eval_logps/rejected': '-99', 'eval_logps/chosen': '-98', 'eval_loss': '1.2e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '8.7e+10', 'eval_reroute/loss': '1.2e+13', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.84', 'eval_component_rr/loss': '1.2e+13', 'eval_component_retain/loss': '2.6e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.17', 'eval_rr_cosine': '0.17'}\n",
      "200 retain_cos_sim: 0.1813. rr_cos_sim: 0.1703\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.032', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-98', 'eval_loss': '2.3e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '2.2e+11', 'eval_reroute/loss': '2.3e+13', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.32', 'eval_component_rr/loss': '2.3e+13', 'eval_component_retain/loss': '6.6e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "200 retain_cos_sim: 0.2127. rr_cos_sim: 0.2107\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-98', 'eval_loss': '3.5e+13', 'eval_rewards/chosen': '-9.7', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '3.7e+11', 'eval_reroute/loss': '3.5e+13', 'eval_logratios/pi': '0.28', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '3.5e+13', 'eval_component_retain/loss': '1.1e+11', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "200 retain_cos_sim: 0.2171. rr_cos_sim: 0.2159\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-97', 'eval_loss': '1.7e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '1.2e+11', 'eval_reroute/loss': '1.7e+13', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '1.7e+13', 'eval_component_retain/loss': '3.5e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "200 retain_cos_sim: 0.2322. rr_cos_sim: 0.2226\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.041', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-98', 'eval_loss': '9.4e+12', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '6.8e+10', 'eval_reroute/loss': '9.3e+12', 'eval_logratios/pi': '-0.4', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.41', 'eval_component_rr/loss': '9.3e+12', 'eval_component_retain/loss': '2e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "200 retain_cos_sim: 0.2334. rr_cos_sim: 0.2235\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.078', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-97', 'eval_loss': '6.3e+12', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '4.6e+10', 'eval_reroute/loss': '6.3e+12', 'eval_logratios/pi': '-0.53', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.78', 'eval_component_rr/loss': '6.3e+12', 'eval_component_retain/loss': '1.4e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "200 retain_cos_sim: 0.2254. rr_cos_sim: 0.2136\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.15', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-95', 'eval_loss': '3.1e+12', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '2.1e+10', 'eval_reroute/loss': '3.1e+12', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.5', 'eval_component_rr/loss': '3.1e+12', 'eval_component_retain/loss': '6.3e+09', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.21'}\n",
      "200 retain_cos_sim: 0.2260. rr_cos_sim: 0.2244\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-97', 'eval_loss': '2.2e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '2.8e+11', 'eval_reroute/loss': '2.2e+13', 'eval_logratios/pi': '-0.74', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '2.2e+13', 'eval_component_retain/loss': '8.3e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "200 retain_cos_sim: 0.1793. rr_cos_sim: 0.1613\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.091', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-97', 'eval_loss': '1.1e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '8.3e+10', 'eval_reroute/loss': '1.1e+13', 'eval_logratios/pi': '0.79', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.91', 'eval_component_rr/loss': '1.1e+13', 'eval_component_retain/loss': '2.5e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "200 retain_cos_sim: 0.2152. rr_cos_sim: 0.2126\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.065', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-98', 'eval_loss': '1.6e+13', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '1.4e+11', 'eval_reroute/loss': '1.5e+13', 'eval_logratios/pi': '0.67', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.65', 'eval_component_rr/loss': '1.5e+13', 'eval_component_retain/loss': '4.1e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "200 retain_cos_sim: 0.1479. rr_cos_sim: 0.1404\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-98', 'eval_logps/chosen': '-97', 'eval_loss': '2.7e+13', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.6', 'eval_retain/loss': '2.4e+11', 'eval_reroute/loss': '2.7e+13', 'eval_logratios/pi': '0.93', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '2.7e+13', 'eval_component_retain/loss': '7.2e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "200 retain_cos_sim: 0.1373. rr_cos_sim: 0.1369\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.06', 'eval_logps/rejected': '-99', 'eval_logps/chosen': '-1e+02', 'eval_loss': '1.8e+13', 'eval_rewards/chosen': '-9.8', 'eval_rewards/rejected': '-9.8', 'eval_retain/loss': '1.3e+11', 'eval_reroute/loss': '1.8e+13', 'eval_logratios/pi': '-0.38', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.6', 'eval_component_rr/loss': '1.8e+13', 'eval_component_retain/loss': '3.8e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.14'}\n",
      "200 retain_cos_sim: 0.1604. rr_cos_sim: 0.1385\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.022', 'eval_logps/rejected': '-99', 'eval_logps/chosen': '-99', 'eval_loss': '1.6e+13', 'eval_rewards/chosen': '-9.7', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '1.2e+11', 'eval_reroute/loss': '1.6e+13', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.22', 'eval_component_rr/loss': '1.6e+13', 'eval_component_retain/loss': '3.6e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "200 retain_cos_sim: 0.1551. rr_cos_sim: 0.1414\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.27', 'eval_logps/rejected': '-99', 'eval_logps/chosen': '-97', 'eval_loss': '2.2e+13', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.7', 'eval_retain/loss': '1.5e+11', 'eval_reroute/loss': '2.2e+13', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.7', 'eval_component_rr/loss': '2.2e+13', 'eval_component_retain/loss': '4.6e+10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "200 retain_cos_sim: 0.1838. rr_cos_sim: 0.1820\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.03', 'logps/rejected': '-97', 'logps/chosen': '-98', 'loss': '1.9e+13', 'rewards/chosen': '-9.6', 'rewards/rejected': '-9.6', 'retain/loss': '2e+11', 'reroute/loss': '1.9e+13', 'logratios/pi': '-0.32', 'logratios/ref': '-0.019', 'weighting': '0.024', 'logits': '-0.3', 'component_rr/loss': '1.9e+13', 'component_retain/loss': '6e+10', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "210 retain_cos_sim: 0.1873. rr_cos_sim: 0.1816\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.011', 'logps/rejected': '-96', 'logps/chosen': '-96', 'loss': '6.7e+13', 'rewards/chosen': '-9.5', 'rewards/rejected': '-9.5', 'retain/loss': '5.5e+11', 'reroute/loss': '6.7e+13', 'logratios/pi': '0.071', 'logratios/ref': '-0.04', 'weighting': '0.024', 'logits': '0.11', 'component_rr/loss': '6.7e+13', 'component_retain/loss': '1.6e+11', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "220 retain_cos_sim: 0.2017. rr_cos_sim: 0.1902\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.022', 'logps/rejected': '-96', 'logps/chosen': '-96', 'loss': '5.7e+13', 'rewards/chosen': '-9.4', 'rewards/rejected': '-9.4', 'retain/loss': '4.3e+11', 'reroute/loss': '5.7e+13', 'logratios/pi': '0.23', 'logratios/ref': '0.0088', 'weighting': '0.024', 'logits': '0.22', 'component_rr/loss': '5.7e+13', 'component_retain/loss': '1.3e+11', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "230 retain_cos_sim: 0.1822. rr_cos_sim: 0.1802\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.025', 'logps/rejected': '-95', 'logps/chosen': '-95', 'loss': '3e+14', 'rewards/chosen': '-9.3', 'rewards/rejected': '-9.4', 'retain/loss': '2.8e+12', 'reroute/loss': '3e+14', 'logratios/pi': '0.29', 'logratios/ref': '0.036', 'weighting': '0.024', 'logits': '0.25', 'component_rr/loss': '3e+14', 'component_retain/loss': '8.3e+11', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "240 retain_cos_sim: 0.1842. rr_cos_sim: 0.1773\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.052', 'logps/rejected': '-96', 'logps/chosen': '-96', 'loss': '2.5e+14', 'rewards/chosen': '-9.4', 'rewards/rejected': '-9.5', 'retain/loss': '1.7e+12', 'reroute/loss': '2.5e+14', 'logratios/pi': '0.76', 'logratios/ref': '0.24', 'weighting': '0.024', 'logits': '0.52', 'component_rr/loss': '2.5e+14', 'component_retain/loss': '5.1e+11', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "250 retain_cos_sim: 0.2003. rr_cos_sim: 0.1927\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '1.1e+15', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '9.3e+12', 'eval_reroute/loss': '1.1e+15', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '1.1e+15', 'eval_component_retain/loss': '2.8e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "250 retain_cos_sim: 0.2634. rr_cos_sim: 0.2473\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-96', 'eval_loss': '1.5e+14', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '9.2e+11', 'eval_reroute/loss': '1.5e+14', 'eval_logratios/pi': '-0.39', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '1.5e+14', 'eval_component_retain/loss': '2.8e+11', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "250 retain_cos_sim: 0.1905. rr_cos_sim: 0.1750\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.022', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-95', 'eval_loss': '8.6e+14', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '6.3e+12', 'eval_reroute/loss': '8.5e+14', 'eval_logratios/pi': '0.2', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.22', 'eval_component_rr/loss': '8.5e+14', 'eval_component_retain/loss': '1.9e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "250 retain_cos_sim: 0.1447. rr_cos_sim: 0.1333\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.15', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-96', 'eval_loss': '1.4e+15', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '1e+13', 'eval_reroute/loss': '1.4e+15', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.5', 'eval_component_rr/loss': '1.4e+15', 'eval_component_retain/loss': '3.1e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "250 retain_cos_sim: 0.1626. rr_cos_sim: 0.1621\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.083', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-95', 'eval_loss': '8.4e+14', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '6.3e+12', 'eval_reroute/loss': '8.4e+14', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.83', 'eval_component_rr/loss': '8.4e+14', 'eval_component_retain/loss': '1.9e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "250 retain_cos_sim: 0.1780. rr_cos_sim: 0.1668\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.03', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '1.6e+15', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+13', 'eval_reroute/loss': '1.6e+15', 'eval_logratios/pi': '-0.32', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.3', 'eval_component_rr/loss': '1.6e+15', 'eval_component_retain/loss': '4.8e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "250 retain_cos_sim: 0.2094. rr_cos_sim: 0.2076\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.02', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-95', 'eval_loss': '2.5e+15', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '2.7e+13', 'eval_reroute/loss': '2.5e+15', 'eval_logratios/pi': '0.24', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.2', 'eval_component_rr/loss': '2.5e+15', 'eval_component_retain/loss': '8.1e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "250 retain_cos_sim: 0.2141. rr_cos_sim: 0.2130\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '1.2e+15', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '8.4e+12', 'eval_reroute/loss': '1.2e+15', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '1.2e+15', 'eval_component_retain/loss': '2.5e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "250 retain_cos_sim: 0.2292. rr_cos_sim: 0.2195\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.037', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '6.7e+14', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '4.9e+12', 'eval_reroute/loss': '6.7e+14', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.37', 'eval_component_rr/loss': '6.7e+14', 'eval_component_retain/loss': '1.5e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "250 retain_cos_sim: 0.2305. rr_cos_sim: 0.2208\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.077', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '4.5e+14', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.3e+12', 'eval_reroute/loss': '4.5e+14', 'eval_logratios/pi': '-0.52', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.77', 'eval_component_rr/loss': '4.5e+14', 'eval_component_retain/loss': '1e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "250 retain_cos_sim: 0.2227. rr_cos_sim: 0.2109\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.15', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '2.2e+14', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.5e+12', 'eval_reroute/loss': '2.2e+14', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.5', 'eval_component_rr/loss': '2.2e+14', 'eval_component_retain/loss': '4.5e+11', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "250 retain_cos_sim: 0.2232. rr_cos_sim: 0.2216\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.6e+15', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2e+13', 'eval_reroute/loss': '1.6e+15', 'eval_logratios/pi': '-0.73', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '1.6e+15', 'eval_component_retain/loss': '6e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "250 retain_cos_sim: 0.1764. rr_cos_sim: 0.1583\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.094', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-95', 'eval_loss': '7.5e+14', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '6e+12', 'eval_reroute/loss': '7.5e+14', 'eval_logratios/pi': '0.81', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.94', 'eval_component_rr/loss': '7.5e+14', 'eval_component_retain/loss': '1.8e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "250 retain_cos_sim: 0.2123. rr_cos_sim: 0.2099\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.066', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-95', 'eval_loss': '1.1e+15', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '9.8e+12', 'eval_reroute/loss': '1.1e+15', 'eval_logratios/pi': '0.68', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.66', 'eval_component_rr/loss': '1.1e+15', 'eval_component_retain/loss': '2.9e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "250 retain_cos_sim: 0.1444. rr_cos_sim: 0.1368\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '1.9e+15', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '1.7e+13', 'eval_reroute/loss': '1.9e+15', 'eval_logratios/pi': '0.95', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '1.9e+15', 'eval_component_retain/loss': '5.2e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.14'}\n",
      "250 retain_cos_sim: 0.1340. rr_cos_sim: 0.1339\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.059', 'eval_logps/rejected': '-97', 'eval_logps/chosen': '-97', 'eval_loss': '1.3e+15', 'eval_rewards/chosen': '-9.6', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '9.1e+12', 'eval_reroute/loss': '1.3e+15', 'eval_logratios/pi': '-0.37', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.59', 'eval_component_rr/loss': '1.3e+15', 'eval_component_retain/loss': '2.7e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "250 retain_cos_sim: 0.1569. rr_cos_sim: 0.1350\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-96', 'eval_loss': '1.1e+15', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '8.7e+12', 'eval_reroute/loss': '1.1e+15', 'eval_logratios/pi': '-0.31', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '1.1e+15', 'eval_component_retain/loss': '2.6e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "250 retain_cos_sim: 0.1521. rr_cos_sim: 0.1384\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-94', 'eval_loss': '1.6e+15', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.5', 'eval_retain/loss': '1.1e+13', 'eval_reroute/loss': '1.6e+15', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '1.6e+15', 'eval_component_retain/loss': '3.4e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "250 retain_cos_sim: 0.1992. rr_cos_sim: 0.1947\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.022', 'logps/rejected': '-95', 'logps/chosen': '-95', 'loss': '5.9e+14', 'rewards/chosen': '-9.4', 'rewards/rejected': '-9.4', 'retain/loss': '4.5e+12', 'reroute/loss': '5.9e+14', 'logratios/pi': '-0.11', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '-0.22', 'component_rr/loss': '5.9e+14', 'component_retain/loss': '1.3e+12', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "260 retain_cos_sim: 0.1846. rr_cos_sim: 0.1814\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.15', 'logps/rejected': '-94', 'logps/chosen': '-96', 'loss': '3e+15', 'rewards/chosen': '-9.5', 'rewards/rejected': '-9.3', 'retain/loss': '3.2e+13', 'reroute/loss': '3e+15', 'logratios/pi': '-1.4', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '-1.5', 'component_rr/loss': '3e+15', 'component_retain/loss': '9.6e+12', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "270 retain_cos_sim: 0.1810. rr_cos_sim: 0.1709\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.067', 'logps/rejected': '-94', 'logps/chosen': '-94', 'loss': '3.2e+15', 'rewards/chosen': '-9.3', 'rewards/rejected': '-9.2', 'retain/loss': '2.6e+13', 'reroute/loss': '3.2e+15', 'logratios/pi': '-0.57', 'logratios/ref': '0.094', 'weighting': '0.024', 'logits': '-0.67', 'component_rr/loss': '3.2e+15', 'component_retain/loss': '7.8e+12', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.17'}\n",
      "280 retain_cos_sim: 0.1961. rr_cos_sim: 0.1920\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.054', 'logps/rejected': '-94', 'logps/chosen': '-93', 'loss': '6.8e+15', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.3', 'retain/loss': '5.6e+13', 'reroute/loss': '6.7e+15', 'logratios/pi': '0.68', 'logratios/ref': '0.13', 'weighting': '0.024', 'logits': '0.54', 'component_rr/loss': '6.7e+15', 'component_retain/loss': '1.7e+13', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "290 retain_cos_sim: 0.2040. rr_cos_sim: 0.1956\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.06', 'logps/rejected': '-94', 'logps/chosen': '-93', 'loss': '1.1e+16', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '7.2e+13', 'reroute/loss': '1.1e+16', 'logratios/pi': '0.59', 'logratios/ref': '-0.012', 'weighting': '0.024', 'logits': '0.6', 'component_rr/loss': '1.1e+16', 'component_retain/loss': '2.2e+13', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.2'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "300 retain_cos_sim: 0.1999. rr_cos_sim: 0.1922\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '2.7e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.4e+14', 'eval_reroute/loss': '2.7e+16', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '2.7e+16', 'eval_component_retain/loss': '7.2e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "300 retain_cos_sim: 0.2630. rr_cos_sim: 0.2470\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.016', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '3.9e+15', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.4e+13', 'eval_reroute/loss': '3.9e+15', 'eval_logratios/pi': '-0.38', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.16', 'eval_component_rr/loss': '3.9e+15', 'eval_component_retain/loss': '7.2e+12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "300 retain_cos_sim: 0.1900. rr_cos_sim: 0.1745\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.023', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '2.2e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+14', 'eval_reroute/loss': '2.2e+16', 'eval_logratios/pi': '0.21', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.23', 'eval_component_rr/loss': '2.2e+16', 'eval_component_retain/loss': '4.9e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.17'}\n",
      "300 retain_cos_sim: 0.1442. rr_cos_sim: 0.1327\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.15', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '3.7e+16', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.7e+14', 'eval_reroute/loss': '3.7e+16', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.5', 'eval_component_rr/loss': '3.7e+16', 'eval_component_retain/loss': '8.1e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "300 retain_cos_sim: 0.1622. rr_cos_sim: 0.1617\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.082', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '2.2e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+14', 'eval_reroute/loss': '2.1e+16', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.82', 'eval_component_rr/loss': '2.1e+16', 'eval_component_retain/loss': '4.9e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "300 retain_cos_sim: 0.1774. rr_cos_sim: 0.1662\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.029', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '4.2e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '4.1e+14', 'eval_reroute/loss': '4.2e+16', 'eval_logratios/pi': '-0.31', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.29', 'eval_component_rr/loss': '4.2e+16', 'eval_component_retain/loss': '1.2e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "300 retain_cos_sim: 0.2089. rr_cos_sim: 0.2071\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.018', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '6.4e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '7e+14', 'eval_reroute/loss': '6.4e+16', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.18', 'eval_component_rr/loss': '6.4e+16', 'eval_component_retain/loss': '2.1e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "300 retain_cos_sim: 0.2137. rr_cos_sim: 0.2127\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '3.2e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.2e+14', 'eval_reroute/loss': '3.2e+16', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '3.2e+16', 'eval_component_retain/loss': '6.5e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "300 retain_cos_sim: 0.2288. rr_cos_sim: 0.2191\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.034', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '1.7e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.3e+14', 'eval_reroute/loss': '1.7e+16', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.34', 'eval_component_rr/loss': '1.7e+16', 'eval_component_retain/loss': '3.8e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "300 retain_cos_sim: 0.2301. rr_cos_sim: 0.2204\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.076', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '1.2e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '8.6e+13', 'eval_reroute/loss': '1.2e+16', 'eval_logratios/pi': '-0.5', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.76', 'eval_component_rr/loss': '1.2e+16', 'eval_component_retain/loss': '2.6e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "300 retain_cos_sim: 0.2223. rr_cos_sim: 0.2105\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-92', 'eval_loss': '5.6e+15', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.9e+13', 'eval_reroute/loss': '5.6e+15', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '5.6e+15', 'eval_component_retain/loss': '1.2e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "300 retain_cos_sim: 0.2228. rr_cos_sim: 0.2212\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '4.1e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '5.2e+14', 'eval_reroute/loss': '4.1e+16', 'eval_logratios/pi': '-0.74', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '4.1e+16', 'eval_component_retain/loss': '1.6e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "300 retain_cos_sim: 0.1760. rr_cos_sim: 0.1580\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.095', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.9e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+14', 'eval_reroute/loss': '1.9e+16', 'eval_logratios/pi': '0.83', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.95', 'eval_component_rr/loss': '1.9e+16', 'eval_component_retain/loss': '4.7e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "300 retain_cos_sim: 0.2119. rr_cos_sim: 0.2096\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.066', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '2.8e+16', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.5e+14', 'eval_reroute/loss': '2.8e+16', 'eval_logratios/pi': '0.68', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.66', 'eval_component_rr/loss': '2.8e+16', 'eval_component_retain/loss': '7.6e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "300 retain_cos_sim: 0.1438. rr_cos_sim: 0.1361\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '5e+16', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '4.5e+14', 'eval_reroute/loss': '5e+16', 'eval_logratios/pi': '0.97', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '5e+16', 'eval_component_retain/loss': '1.4e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.14'}\n",
      "300 retain_cos_sim: 0.1335. rr_cos_sim: 0.1335\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.058', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-96', 'eval_loss': '3.3e+16', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '2.3e+14', 'eval_reroute/loss': '3.3e+16', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.58', 'eval_component_rr/loss': '3.3e+16', 'eval_component_retain/loss': '7e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "300 retain_cos_sim: 0.1563. rr_cos_sim: 0.1344\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.013', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '2.9e+16', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.2e+14', 'eval_reroute/loss': '2.9e+16', 'eval_logratios/pi': '-0.27', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.13', 'eval_component_rr/loss': '2.9e+16', 'eval_component_retain/loss': '6.7e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.13'}\n",
      "300 retain_cos_sim: 0.1517. rr_cos_sim: 0.1379\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '4.1e+16', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '2.9e+14', 'eval_reroute/loss': '4e+16', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '4e+16', 'eval_component_retain/loss': '8.7e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "300 retain_cos_sim: 0.1936. rr_cos_sim: 0.1884\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.033', 'logps/rejected': '-93', 'logps/chosen': '-94', 'loss': '2.8e+16', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '2.2e+14', 'reroute/loss': '2.8e+16', 'logratios/pi': '-0.4', 'logratios/ref': '-0.07', 'weighting': '0.024', 'logits': '-0.33', 'component_rr/loss': '2.8e+16', 'component_retain/loss': '6.7e+13', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.19'}\n",
      "310 retain_cos_sim: 0.1861. rr_cos_sim: 0.1750\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.021', 'logps/rejected': '-94', 'logps/chosen': '-93', 'loss': '4.3e+16', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '3.6e+14', 'reroute/loss': '4.3e+16', 'logratios/pi': '0.19', 'logratios/ref': '-0.018', 'weighting': '0.024', 'logits': '0.21', 'component_rr/loss': '4.3e+16', 'component_retain/loss': '1.1e+14', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.17'}\n",
      "320 retain_cos_sim: 0.2045. rr_cos_sim: 0.1979\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0082', 'logps/rejected': '-92', 'logps/chosen': '-92', 'loss': '7.1e+16', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '6.8e+14', 'reroute/loss': '7.1e+16', 'logratios/pi': '-0.094', 'logratios/ref': '-0.012', 'weighting': '0.024', 'logits': '-0.082', 'component_rr/loss': '7.1e+16', 'component_retain/loss': '2e+14', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.2'}\n",
      "330 retain_cos_sim: 0.1898. rr_cos_sim: 0.1817\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.019', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '1.1e+17', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '8.2e+14', 'reroute/loss': '1.1e+17', 'logratios/pi': '-0.15', 'logratios/ref': '0.047', 'weighting': '0.024', 'logits': '-0.19', 'component_rr/loss': '1.1e+17', 'component_retain/loss': '2.5e+14', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "340 retain_cos_sim: 0.1869. rr_cos_sim: 0.1730\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.032', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '1.7e+17', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '1.2e+15', 'reroute/loss': '1.7e+17', 'logratios/pi': '-0.24', 'logratios/ref': '0.078', 'weighting': '0.024', 'logits': '-0.32', 'component_rr/loss': '1.7e+17', 'component_retain/loss': '3.7e+14', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.17'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "350 retain_cos_sim: 0.2002. rr_cos_sim: 0.1926\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-94', 'eval_loss': '3.5e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '3.1e+15', 'eval_reroute/loss': '3.4e+17', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '3.4e+17', 'eval_component_retain/loss': '9.2e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "350 retain_cos_sim: 0.2632. rr_cos_sim: 0.2471\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.016', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '5e+16', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.1e+14', 'eval_reroute/loss': '5e+16', 'eval_logratios/pi': '-0.37', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.16', 'eval_component_rr/loss': '5e+16', 'eval_component_retain/loss': '9.2e+13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "350 retain_cos_sim: 0.1904. rr_cos_sim: 0.1750\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.023', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '2.8e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.1e+15', 'eval_reroute/loss': '2.8e+17', 'eval_logratios/pi': '0.21', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.23', 'eval_component_rr/loss': '2.8e+17', 'eval_component_retain/loss': '6.3e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.17'}\n",
      "350 retain_cos_sim: 0.1445. rr_cos_sim: 0.1330\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-95', 'eval_loss': '4.7e+17', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.5e+15', 'eval_reroute/loss': '4.7e+17', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '4.7e+17', 'eval_component_retain/loss': '1e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "350 retain_cos_sim: 0.1625. rr_cos_sim: 0.1620\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.082', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '2.7e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.1e+15', 'eval_reroute/loss': '2.7e+17', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.82', 'eval_component_rr/loss': '2.7e+17', 'eval_component_retain/loss': '6.3e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "350 retain_cos_sim: 0.1778. rr_cos_sim: 0.1665\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.028', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '5.4e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '5.3e+15', 'eval_reroute/loss': '5.4e+17', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.28', 'eval_component_rr/loss': '5.4e+17', 'eval_component_retain/loss': '1.6e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "350 retain_cos_sim: 0.2091. rr_cos_sim: 0.2074\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.017', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '8.2e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '8.9e+15', 'eval_reroute/loss': '8.2e+17', 'eval_logratios/pi': '0.21', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.17', 'eval_component_rr/loss': '8.2e+17', 'eval_component_retain/loss': '2.7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "350 retain_cos_sim: 0.2139. rr_cos_sim: 0.2130\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '4.1e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.8e+15', 'eval_reroute/loss': '4e+17', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '4e+17', 'eval_component_retain/loss': '8.3e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "350 retain_cos_sim: 0.2290. rr_cos_sim: 0.2193\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.033', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.2e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.6e+15', 'eval_reroute/loss': '2.2e+17', 'eval_logratios/pi': '-0.32', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.33', 'eval_component_rr/loss': '2.2e+17', 'eval_component_retain/loss': '4.9e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "350 retain_cos_sim: 0.2304. rr_cos_sim: 0.2207\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '1.5e+17', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.1e+15', 'eval_reroute/loss': '1.5e+17', 'eval_logratios/pi': '-0.5', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '1.5e+17', 'eval_component_retain/loss': '3.3e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "350 retain_cos_sim: 0.2226. rr_cos_sim: 0.2108\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-91', 'eval_loss': '7.2e+16', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '5e+14', 'eval_reroute/loss': '7.2e+16', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '7.2e+16', 'eval_component_retain/loss': '1.5e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "350 retain_cos_sim: 0.2230. rr_cos_sim: 0.2215\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '5.2e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '6.7e+15', 'eval_reroute/loss': '5.2e+17', 'eval_logratios/pi': '-0.74', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '5.2e+17', 'eval_component_retain/loss': '2e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "350 retain_cos_sim: 0.1763. rr_cos_sim: 0.1582\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.097', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '2.5e+17', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2e+15', 'eval_reroute/loss': '2.5e+17', 'eval_logratios/pi': '0.85', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.97', 'eval_component_rr/loss': '2.5e+17', 'eval_component_retain/loss': '6e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "350 retain_cos_sim: 0.2121. rr_cos_sim: 0.2099\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.067', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '3.6e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.3e+15', 'eval_reroute/loss': '3.6e+17', 'eval_logratios/pi': '0.69', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.67', 'eval_component_rr/loss': '3.6e+17', 'eval_component_retain/loss': '9.8e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "350 retain_cos_sim: 0.1443. rr_cos_sim: 0.1366\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '6.4e+17', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '5.8e+15', 'eval_reroute/loss': '6.4e+17', 'eval_logratios/pi': '0.99', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '6.4e+17', 'eval_component_retain/loss': '1.7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.14'}\n",
      "350 retain_cos_sim: 0.1339. rr_cos_sim: 0.1339\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.058', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '4.3e+17', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3e+15', 'eval_reroute/loss': '4.3e+17', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.58', 'eval_component_rr/loss': '4.3e+17', 'eval_component_retain/loss': '9e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "350 retain_cos_sim: 0.1566. rr_cos_sim: 0.1347\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.011', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '3.7e+17', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.9e+15', 'eval_reroute/loss': '3.7e+17', 'eval_logratios/pi': '-0.25', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.11', 'eval_component_rr/loss': '3.7e+17', 'eval_component_retain/loss': '8.6e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.13'}\n",
      "350 retain_cos_sim: 0.1521. rr_cos_sim: 0.1384\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '5.2e+17', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.7e+15', 'eval_reroute/loss': '5.2e+17', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '5.2e+17', 'eval_component_retain/loss': '1.1e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "350 retain_cos_sim: 0.1942. rr_cos_sim: 0.1884\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.023', 'logps/rejected': '-94', 'logps/chosen': '-94', 'loss': '3.8e+17', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.3', 'retain/loss': '3.5e+15', 'reroute/loss': '3.8e+17', 'logratios/pi': '0.24', 'logratios/ref': '0.0098', 'weighting': '0.024', 'logits': '0.23', 'component_rr/loss': '3.8e+17', 'component_retain/loss': '1e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.19'}\n",
      "360 retain_cos_sim: 0.1890. rr_cos_sim: 0.1858\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0019', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '6.6e+17', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '6.4e+15', 'reroute/loss': '6.6e+17', 'logratios/pi': '0.14', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '0.019', 'component_rr/loss': '6.6e+17', 'component_retain/loss': '1.9e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.19'}\n",
      "370 retain_cos_sim: 0.1976. rr_cos_sim: 0.1920\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.042', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '8.5e+17', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.2', 'retain/loss': '8.9e+15', 'reroute/loss': '8.5e+17', 'logratios/pi': '0.47', 'logratios/ref': '0.046', 'weighting': '0.024', 'logits': '0.42', 'component_rr/loss': '8.5e+17', 'component_retain/loss': '2.7e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "380 retain_cos_sim: 0.1954. rr_cos_sim: 0.1881\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.073', 'logps/rejected': '-92', 'logps/chosen': '-93', 'loss': '7.6e+17', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '5.3e+15', 'reroute/loss': '7.6e+17', 'logratios/pi': '-0.64', 'logratios/ref': '0.086', 'weighting': '0.024', 'logits': '-0.73', 'component_rr/loss': '7.6e+17', 'component_retain/loss': '1.6e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "390 retain_cos_sim: 0.1943. rr_cos_sim: 0.1886\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.13', 'logps/rejected': '-92', 'logps/chosen': '-94', 'loss': '1.4e+18', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.1', 'retain/loss': '1.2e+16', 'reroute/loss': '1.4e+18', 'logratios/pi': '-1.1', 'logratios/ref': '0.19', 'weighting': '0.024', 'logits': '-1.3', 'component_rr/loss': '1.4e+18', 'component_retain/loss': '3.6e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.19'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "400 retain_cos_sim: 0.2005. rr_cos_sim: 0.1930\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '2.7e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '2.4e+16', 'eval_reroute/loss': '2.7e+18', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '2.7e+18', 'eval_component_retain/loss': '7.2e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "400 retain_cos_sim: 0.2634. rr_cos_sim: 0.2473\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.015', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '3.9e+17', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.4e+15', 'eval_reroute/loss': '3.9e+17', 'eval_logratios/pi': '-0.37', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.15', 'eval_component_rr/loss': '3.9e+17', 'eval_component_retain/loss': '7.1e+14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "400 retain_cos_sim: 0.1907. rr_cos_sim: 0.1753\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.2e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.6e+16', 'eval_reroute/loss': '2.2e+18', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '2.2e+18', 'eval_component_retain/loss': '4.9e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "400 retain_cos_sim: 0.1448. rr_cos_sim: 0.1333\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '3.6e+18', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '2.7e+16', 'eval_reroute/loss': '3.6e+18', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '3.6e+18', 'eval_component_retain/loss': '8.1e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "400 retain_cos_sim: 0.1628. rr_cos_sim: 0.1623\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.083', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '2.1e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.6e+16', 'eval_reroute/loss': '2.1e+18', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.83', 'eval_component_rr/loss': '2.1e+18', 'eval_component_retain/loss': '4.9e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "400 retain_cos_sim: 0.1781. rr_cos_sim: 0.1669\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.028', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '4.2e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '4.1e+16', 'eval_reroute/loss': '4.2e+18', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.28', 'eval_component_rr/loss': '4.2e+18', 'eval_component_retain/loss': '1.2e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "400 retain_cos_sim: 0.2093. rr_cos_sim: 0.2077\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '6.4e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '6.9e+16', 'eval_reroute/loss': '6.4e+18', 'eval_logratios/pi': '0.2', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '6.4e+18', 'eval_component_retain/loss': '2.1e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "400 retain_cos_sim: 0.2142. rr_cos_sim: 0.2132\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.024', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '3.1e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '2.2e+16', 'eval_reroute/loss': '3.1e+18', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.24', 'eval_component_rr/loss': '3.1e+18', 'eval_component_retain/loss': '6.5e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "400 retain_cos_sim: 0.2293. rr_cos_sim: 0.2196\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.032', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '1.7e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.3e+16', 'eval_reroute/loss': '1.7e+18', 'eval_logratios/pi': '-0.32', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.32', 'eval_component_rr/loss': '1.7e+18', 'eval_component_retain/loss': '3.8e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "400 retain_cos_sim: 0.2307. rr_cos_sim: 0.2210\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-92', 'eval_loss': '1.1e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '8.6e+15', 'eval_reroute/loss': '1.1e+18', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '1.1e+18', 'eval_component_retain/loss': '2.6e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "400 retain_cos_sim: 0.2229. rr_cos_sim: 0.2110\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-91', 'eval_loss': '5.6e+17', 'eval_rewards/chosen': '-8.9', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '3.9e+15', 'eval_reroute/loss': '5.6e+17', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '5.6e+17', 'eval_component_retain/loss': '1.2e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "400 retain_cos_sim: 0.2233. rr_cos_sim: 0.2218\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-91', 'eval_logps/chosen': '-92', 'eval_loss': '4.1e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '5.2e+16', 'eval_reroute/loss': '4e+18', 'eval_logratios/pi': '-0.74', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '4e+18', 'eval_component_retain/loss': '1.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "400 retain_cos_sim: 0.1766. rr_cos_sim: 0.1584\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.099', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-92', 'eval_loss': '1.9e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.6e+16', 'eval_reroute/loss': '1.9e+18', 'eval_logratios/pi': '0.86', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.99', 'eval_component_rr/loss': '1.9e+18', 'eval_component_retain/loss': '4.7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "400 retain_cos_sim: 0.2123. rr_cos_sim: 0.2101\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.067', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.8e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.5e+16', 'eval_reroute/loss': '2.8e+18', 'eval_logratios/pi': '0.69', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.67', 'eval_component_rr/loss': '2.8e+18', 'eval_component_retain/loss': '7.6e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "400 retain_cos_sim: 0.1448. rr_cos_sim: 0.1372\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-92', 'eval_loss': '4.9e+18', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '4.5e+16', 'eval_reroute/loss': '4.9e+18', 'eval_logratios/pi': '1', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '4.9e+18', 'eval_component_retain/loss': '1.3e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.14'}\n",
      "400 retain_cos_sim: 0.1342. rr_cos_sim: 0.1341\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.058', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '3.3e+18', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.3e+16', 'eval_reroute/loss': '3.3e+18', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.58', 'eval_component_rr/loss': '3.3e+18', 'eval_component_retain/loss': '7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "400 retain_cos_sim: 0.1569. rr_cos_sim: 0.1350\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0099', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '2.9e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.2e+16', 'eval_reroute/loss': '2.9e+18', 'eval_logratios/pi': '-0.24', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.099', 'eval_component_rr/loss': '2.9e+18', 'eval_component_retain/loss': '6.7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "400 retain_cos_sim: 0.1525. rr_cos_sim: 0.1388\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-92', 'eval_loss': '4e+18', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.9e+16', 'eval_reroute/loss': '4e+18', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '4e+18', 'eval_component_retain/loss': '8.7e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "400 retain_cos_sim: 0.1958. rr_cos_sim: 0.1855\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.065', 'logps/rejected': '-93', 'logps/chosen': '-92', 'loss': '2e+18', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '1.6e+16', 'reroute/loss': '2e+18', 'logratios/pi': '0.67', 'logratios/ref': '0.025', 'weighting': '0.024', 'logits': '0.65', 'component_rr/loss': '2e+18', 'component_retain/loss': '4.9e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "410 retain_cos_sim: 0.2018. rr_cos_sim: 0.1908\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0022', 'logps/rejected': '-92', 'logps/chosen': '-92', 'loss': '4.4e+18', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '3.8e+16', 'reroute/loss': '4.4e+18', 'logratios/pi': '-0.11', 'logratios/ref': '-0.088', 'weighting': '0.024', 'logits': '-0.022', 'component_rr/loss': '4.4e+18', 'component_retain/loss': '1.1e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "420 retain_cos_sim: 0.1997. rr_cos_sim: 0.1928\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.061', 'logps/rejected': '-93', 'logps/chosen': '-92', 'loss': '3.4e+18', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '2.5e+16', 'reroute/loss': '3.4e+18', 'logratios/pi': '0.55', 'logratios/ref': '-0.061', 'weighting': '0.024', 'logits': '0.61', 'component_rr/loss': '3.4e+18', 'component_retain/loss': '7.4e+15', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "430 retain_cos_sim: 0.1669. rr_cos_sim: 0.1621\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.025', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '8.4e+18', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.1', 'retain/loss': '7.2e+16', 'reroute/loss': '8.4e+18', 'logratios/pi': '-0.24', 'logratios/ref': '0.011', 'weighting': '0.024', 'logits': '-0.25', 'component_rr/loss': '8.4e+18', 'component_retain/loss': '2.2e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.17', 'rr_cosine': '0.16'}\n",
      "440 retain_cos_sim: 0.1865. rr_cos_sim: 0.1822\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.03', 'logps/rejected': '-93', 'logps/chosen': '-92', 'loss': '8.5e+18', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '6.5e+16', 'reroute/loss': '8.5e+18', 'logratios/pi': '0.35', 'logratios/ref': '0.048', 'weighting': '0.024', 'logits': '0.3', 'component_rr/loss': '8.5e+18', 'component_retain/loss': '2e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "450 retain_cos_sim: 0.2006. rr_cos_sim: 0.1931\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '1.4e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '1.3e+17', 'eval_reroute/loss': '1.4e+19', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '1.4e+19', 'eval_component_retain/loss': '3.9e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "450 retain_cos_sim: 0.2635. rr_cos_sim: 0.2473\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.1e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.3e+16', 'eval_reroute/loss': '2.1e+18', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '2.1e+18', 'eval_component_retain/loss': '3.8e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "450 retain_cos_sim: 0.1909. rr_cos_sim: 0.1755\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '1.2e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '8.8e+16', 'eval_reroute/loss': '1.2e+19', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '1.2e+19', 'eval_component_retain/loss': '2.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "450 retain_cos_sim: 0.1449. rr_cos_sim: 0.1334\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '2e+19', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.5e+17', 'eval_reroute/loss': '2e+19', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '2e+19', 'eval_component_retain/loss': '4.4e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "450 retain_cos_sim: 0.1630. rr_cos_sim: 0.1625\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.083', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '1.1e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '8.8e+16', 'eval_reroute/loss': '1.1e+19', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.83', 'eval_component_rr/loss': '1.1e+19', 'eval_component_retain/loss': '2.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "450 retain_cos_sim: 0.1783. rr_cos_sim: 0.1671\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.028', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.3e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '2.2e+17', 'eval_reroute/loss': '2.2e+19', 'eval_logratios/pi': '-0.29', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.28', 'eval_component_rr/loss': '2.2e+19', 'eval_component_retain/loss': '6.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "450 retain_cos_sim: 0.2095. rr_cos_sim: 0.2078\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '3.4e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.7e+17', 'eval_reroute/loss': '3.4e+19', 'eval_logratios/pi': '0.2', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '3.4e+19', 'eval_component_retain/loss': '1.1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "450 retain_cos_sim: 0.2144. rr_cos_sim: 0.2133\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.024', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '1.7e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.2e+17', 'eval_reroute/loss': '1.7e+19', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.24', 'eval_component_rr/loss': '1.7e+19', 'eval_component_retain/loss': '3.5e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "450 retain_cos_sim: 0.2295. rr_cos_sim: 0.2197\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.032', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '9.2e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '6.9e+16', 'eval_reroute/loss': '9.1e+18', 'eval_logratios/pi': '-0.31', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.32', 'eval_component_rr/loss': '9.1e+18', 'eval_component_retain/loss': '2.1e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "450 retain_cos_sim: 0.2308. rr_cos_sim: 0.2212\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-92', 'eval_loss': '6.2e+18', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '4.6e+16', 'eval_reroute/loss': '6.1e+18', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '6.1e+18', 'eval_component_retain/loss': '1.4e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "450 retain_cos_sim: 0.2230. rr_cos_sim: 0.2111\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-91', 'eval_loss': '3e+18', 'eval_rewards/chosen': '-8.9', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '2.1e+16', 'eval_reroute/loss': '3e+18', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '3e+18', 'eval_component_retain/loss': '6.3e+15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "450 retain_cos_sim: 0.2234. rr_cos_sim: 0.2220\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-91', 'eval_logps/chosen': '-92', 'eval_loss': '2.2e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9', 'eval_retain/loss': '2.8e+17', 'eval_reroute/loss': '2.2e+19', 'eval_logratios/pi': '-0.73', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '2.2e+19', 'eval_component_retain/loss': '8.4e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "450 retain_cos_sim: 0.1767. rr_cos_sim: 0.1585\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.1', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-92', 'eval_loss': '1e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '8.4e+16', 'eval_reroute/loss': '1e+19', 'eval_logratios/pi': '0.87', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '1', 'eval_component_rr/loss': '1e+19', 'eval_component_retain/loss': '2.5e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "450 retain_cos_sim: 0.2124. rr_cos_sim: 0.2103\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.068', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '1.5e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.4e+17', 'eval_reroute/loss': '1.5e+19', 'eval_logratios/pi': '0.69', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.68', 'eval_component_rr/loss': '1.5e+19', 'eval_component_retain/loss': '4.1e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "450 retain_cos_sim: 0.1451. rr_cos_sim: 0.1375\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.13', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-92', 'eval_loss': '2.7e+19', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.4e+17', 'eval_reroute/loss': '2.7e+19', 'eval_logratios/pi': '1', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.3', 'eval_component_rr/loss': '2.7e+19', 'eval_component_retain/loss': '7.3e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "450 retain_cos_sim: 0.1344. rr_cos_sim: 0.1343\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.058', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '1.8e+19', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.3e+17', 'eval_reroute/loss': '1.8e+19', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.58', 'eval_component_rr/loss': '1.8e+19', 'eval_component_retain/loss': '3.8e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "450 retain_cos_sim: 0.1571. rr_cos_sim: 0.1352\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0091', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.6e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.2e+17', 'eval_reroute/loss': '1.6e+19', 'eval_logratios/pi': '-0.23', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.091', 'eval_component_rr/loss': '1.6e+19', 'eval_component_retain/loss': '3.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "450 retain_cos_sim: 0.1527. rr_cos_sim: 0.1390\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-92', 'eval_loss': '2.2e+19', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+17', 'eval_reroute/loss': '2.2e+19', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '2.2e+19', 'eval_component_retain/loss': '4.7e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "450 retain_cos_sim: 0.2081. rr_cos_sim: 0.1940\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.079', 'logps/rejected': '-92', 'logps/chosen': '-93', 'loss': '8e+18', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '6e+16', 'reroute/loss': '8e+18', 'logratios/pi': '-0.98', 'logratios/ref': '-0.2', 'weighting': '0.024', 'logits': '-0.79', 'component_rr/loss': '8e+18', 'component_retain/loss': '1.8e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.21', 'rr_cosine': '0.19'}\n",
      "460 retain_cos_sim: 0.1840. rr_cos_sim: 0.1767\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.016', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '2e+19', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '1.6e+17', 'reroute/loss': '2e+19', 'logratios/pi': '-0.13', 'logratios/ref': '0.037', 'weighting': '0.024', 'logits': '-0.16', 'component_rr/loss': '2e+19', 'component_retain/loss': '4.8e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "470 retain_cos_sim: 0.1831. rr_cos_sim: 0.1782\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.03', 'logps/rejected': '-92', 'logps/chosen': '-92', 'loss': '4.7e+19', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '4e+17', 'reroute/loss': '4.7e+19', 'logratios/pi': '0.25', 'logratios/ref': '-0.052', 'weighting': '0.024', 'logits': '0.3', 'component_rr/loss': '4.7e+19', 'component_retain/loss': '1.2e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "480 retain_cos_sim: 0.1895. rr_cos_sim: 0.1821\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.097', 'logps/rejected': '-92', 'logps/chosen': '-93', 'loss': '2.8e+19', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '2.3e+17', 'reroute/loss': '2.8e+19', 'logratios/pi': '-0.75', 'logratios/ref': '0.22', 'weighting': '0.024', 'logits': '-0.97', 'component_rr/loss': '2.8e+19', 'component_retain/loss': '7e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "490 retain_cos_sim: 0.1779. rr_cos_sim: 0.1694\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.021', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '8.2e+19', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.2', 'retain/loss': '7.8e+17', 'reroute/loss': '8.2e+19', 'logratios/pi': '0.027', 'logratios/ref': '-0.18', 'weighting': '0.024', 'logits': '0.21', 'component_rr/loss': '8.2e+19', 'component_retain/loss': '2.3e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.17'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "500 retain_cos_sim: 0.2006. rr_cos_sim: 0.1932\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-94', 'eval_loss': '5.9e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '5.3e+17', 'eval_reroute/loss': '5.9e+19', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '5.9e+19', 'eval_component_retain/loss': '1.6e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "500 retain_cos_sim: 0.2634. rr_cos_sim: 0.2472\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '8.6e+18', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '5.2e+16', 'eval_reroute/loss': '8.6e+18', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '8.6e+18', 'eval_component_retain/loss': '1.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "500 retain_cos_sim: 0.1909. rr_cos_sim: 0.1755\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '4.8e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.6e+17', 'eval_reroute/loss': '4.8e+19', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '4.8e+19', 'eval_component_retain/loss': '1.1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "500 retain_cos_sim: 0.1448. rr_cos_sim: 0.1333\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-95', 'eval_loss': '8e+19', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '5.9e+17', 'eval_reroute/loss': '8e+19', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '8e+19', 'eval_component_retain/loss': '1.8e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "500 retain_cos_sim: 0.1629. rr_cos_sim: 0.1624\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.084', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '4.7e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.6e+17', 'eval_reroute/loss': '4.7e+19', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.84', 'eval_component_rr/loss': '4.7e+19', 'eval_component_retain/loss': '1.1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "500 retain_cos_sim: 0.1782. rr_cos_sim: 0.1670\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.027', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '9.2e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '9e+17', 'eval_reroute/loss': '9.2e+19', 'eval_logratios/pi': '-0.29', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.27', 'eval_component_rr/loss': '9.2e+19', 'eval_component_retain/loss': '2.7e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "500 retain_cos_sim: 0.2094. rr_cos_sim: 0.2078\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.4e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.5e+18', 'eval_reroute/loss': '1.4e+20', 'eval_logratios/pi': '0.19', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '1.4e+20', 'eval_component_retain/loss': '4.6e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "500 retain_cos_sim: 0.2143. rr_cos_sim: 0.2133\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.024', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '6.9e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '4.7e+17', 'eval_reroute/loss': '6.9e+19', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.24', 'eval_component_rr/loss': '6.9e+19', 'eval_component_retain/loss': '1.4e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "500 retain_cos_sim: 0.2295. rr_cos_sim: 0.2197\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.031', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '3.8e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.8e+17', 'eval_reroute/loss': '3.7e+19', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.31', 'eval_component_rr/loss': '3.7e+19', 'eval_component_retain/loss': '8.4e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "500 retain_cos_sim: 0.2308. rr_cos_sim: 0.2212\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '2.5e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.9e+17', 'eval_reroute/loss': '2.5e+19', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '2.5e+19', 'eval_component_retain/loss': '5.7e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "500 retain_cos_sim: 0.2231. rr_cos_sim: 0.2112\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-91', 'eval_loss': '1.2e+19', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '8.6e+16', 'eval_reroute/loss': '1.2e+19', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '1.2e+19', 'eval_component_retain/loss': '2.6e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "500 retain_cos_sim: 0.2235. rr_cos_sim: 0.2220\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '9e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.1e+18', 'eval_reroute/loss': '8.9e+19', 'eval_logratios/pi': '-0.74', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '8.9e+19', 'eval_component_retain/loss': '3.4e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "500 retain_cos_sim: 0.1768. rr_cos_sim: 0.1586\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.1', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '4.2e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.4e+17', 'eval_reroute/loss': '4.2e+19', 'eval_logratios/pi': '0.88', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '1', 'eval_component_rr/loss': '4.2e+19', 'eval_component_retain/loss': '1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "500 retain_cos_sim: 0.2124. rr_cos_sim: 0.2103\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.068', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '6.2e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '5.6e+17', 'eval_reroute/loss': '6.2e+19', 'eval_logratios/pi': '0.7', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.68', 'eval_component_rr/loss': '6.2e+19', 'eval_component_retain/loss': '1.7e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "500 retain_cos_sim: 0.1451. rr_cos_sim: 0.1375\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '1.1e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '9.9e+17', 'eval_reroute/loss': '1.1e+20', 'eval_logratios/pi': '1', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '1.1e+20', 'eval_component_retain/loss': '3e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "500 retain_cos_sim: 0.1344. rr_cos_sim: 0.1342\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.058', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '7.3e+19', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '5.1e+17', 'eval_reroute/loss': '7.3e+19', 'eval_logratios/pi': '-0.35', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.58', 'eval_component_rr/loss': '7.3e+19', 'eval_component_retain/loss': '1.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "500 retain_cos_sim: 0.1570. rr_cos_sim: 0.1351\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0081', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '6.4e+19', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '4.9e+17', 'eval_reroute/loss': '6.4e+19', 'eval_logratios/pi': '-0.22', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.081', 'eval_component_rr/loss': '6.4e+19', 'eval_component_retain/loss': '1.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "500 retain_cos_sim: 0.1527. rr_cos_sim: 0.1390\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '8.9e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '6.4e+17', 'eval_reroute/loss': '8.8e+19', 'eval_logratios/pi': '2', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '8.8e+19', 'eval_component_retain/loss': '1.9e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/.venv/lib/python3.9/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 retain_cos_sim: 0.2005. rr_cos_sim: 0.1954\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.086', 'logps/rejected': '-93', 'logps/chosen': '-92', 'loss': '3.8e+19', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.2', 'retain/loss': '3.1e+17', 'reroute/loss': '3.8e+19', 'logratios/pi': '0.97', 'logratios/ref': '0.1', 'weighting': '0.024', 'logits': '0.86', 'component_rr/loss': '3.8e+19', 'component_retain/loss': '9.3e+16', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.2'}\n",
      "510 retain_cos_sim: 0.1932. rr_cos_sim: 0.1789\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00072', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '5.3e+19', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '3.9e+17', 'reroute/loss': '5.3e+19', 'logratios/pi': '-0.051', 'logratios/ref': '-0.058', 'weighting': '0.024', 'logits': '0.0072', 'component_rr/loss': '5.3e+19', 'component_retain/loss': '1.2e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "520 retain_cos_sim: 0.2168. rr_cos_sim: 0.2158\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.047', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '8.3e+19', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '7.6e+17', 'reroute/loss': '8.2e+19', 'logratios/pi': '-0.32', 'logratios/ref': '0.15', 'weighting': '0.024', 'logits': '-0.47', 'component_rr/loss': '8.2e+19', 'component_retain/loss': '2.3e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.22', 'rr_cosine': '0.22'}\n",
      "530 retain_cos_sim: 0.1933. rr_cos_sim: 0.1793\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.057', 'logps/rejected': '-92', 'logps/chosen': '-93', 'loss': '8.4e+19', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.1', 'retain/loss': '7e+17', 'reroute/loss': '8.4e+19', 'logratios/pi': '-0.66', 'logratios/ref': '-0.084', 'weighting': '0.024', 'logits': '-0.57', 'component_rr/loss': '8.4e+19', 'component_retain/loss': '2.1e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "540 retain_cos_sim: 0.1898. rr_cos_sim: 0.1841\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.16', 'logps/rejected': '-95', 'logps/chosen': '-94', 'loss': '1e+20', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.4', 'retain/loss': '7.5e+17', 'reroute/loss': '1e+20', 'logratios/pi': '1.6', 'logratios/ref': '-0.01', 'weighting': '0.024', 'logits': '1.6', 'component_rr/loss': '1e+20', 'component_retain/loss': '2.3e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "550 retain_cos_sim: 0.2007. rr_cos_sim: 0.1932\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.12', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-94', 'eval_loss': '1.9e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.7e+18', 'eval_reroute/loss': '1.9e+20', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.2', 'eval_component_rr/loss': '1.9e+20', 'eval_component_retain/loss': '5.2e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "550 retain_cos_sim: 0.2633. rr_cos_sim: 0.2472\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '2.8e+19', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.7e+17', 'eval_reroute/loss': '2.8e+19', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '2.8e+19', 'eval_component_retain/loss': '5.1e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "550 retain_cos_sim: 0.1909. rr_cos_sim: 0.1756\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.6e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.2e+18', 'eval_reroute/loss': '1.6e+20', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '1.6e+20', 'eval_component_retain/loss': '3.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "550 retain_cos_sim: 0.1448. rr_cos_sim: 0.1334\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-95', 'eval_loss': '2.6e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.9e+18', 'eval_reroute/loss': '2.6e+20', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '2.6e+20', 'eval_component_retain/loss': '5.8e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "550 retain_cos_sim: 0.1629. rr_cos_sim: 0.1624\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.085', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '1.5e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.2e+18', 'eval_reroute/loss': '1.5e+20', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.85', 'eval_component_rr/loss': '1.5e+20', 'eval_component_retain/loss': '3.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "550 retain_cos_sim: 0.1783. rr_cos_sim: 0.1671\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.028', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '3e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.9e+18', 'eval_reroute/loss': '3e+20', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.28', 'eval_component_rr/loss': '3e+20', 'eval_component_retain/loss': '8.8e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "550 retain_cos_sim: 0.2094. rr_cos_sim: 0.2079\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '4.6e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '5e+18', 'eval_reroute/loss': '4.6e+20', 'eval_logratios/pi': '0.19', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '4.6e+20', 'eval_component_retain/loss': '1.5e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "550 retain_cos_sim: 0.2143. rr_cos_sim: 0.2133\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.024', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.3e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.6e+18', 'eval_reroute/loss': '2.3e+20', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.24', 'eval_component_rr/loss': '2.3e+20', 'eval_component_retain/loss': '4.7e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "550 retain_cos_sim: 0.2294. rr_cos_sim: 0.2197\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.031', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '1.2e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '9.2e+17', 'eval_reroute/loss': '1.2e+20', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.31', 'eval_component_rr/loss': '1.2e+20', 'eval_component_retain/loss': '2.8e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "550 retain_cos_sim: 0.2308. rr_cos_sim: 0.2212\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '8.3e+19', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '6.2e+17', 'eval_reroute/loss': '8.3e+19', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '8.3e+19', 'eval_component_retain/loss': '1.9e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "550 retain_cos_sim: 0.2231. rr_cos_sim: 0.2112\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.15', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-91', 'eval_loss': '4.1e+19', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '2.8e+17', 'eval_reroute/loss': '4.1e+19', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.5', 'eval_component_rr/loss': '4.1e+19', 'eval_component_retain/loss': '8.4e+16', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "550 retain_cos_sim: 0.2235. rr_cos_sim: 0.2221\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '3e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '3.7e+18', 'eval_reroute/loss': '2.9e+20', 'eval_logratios/pi': '-0.73', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '2.9e+20', 'eval_component_retain/loss': '1.1e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "550 retain_cos_sim: 0.1767. rr_cos_sim: 0.1585\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.1', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '1.4e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '1.1e+18', 'eval_reroute/loss': '1.4e+20', 'eval_logratios/pi': '0.9', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '1', 'eval_component_rr/loss': '1.4e+20', 'eval_component_retain/loss': '3.4e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "550 retain_cos_sim: 0.2123. rr_cos_sim: 0.2103\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.068', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '2e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.8e+18', 'eval_reroute/loss': '2e+20', 'eval_logratios/pi': '0.7', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.68', 'eval_component_rr/loss': '2e+20', 'eval_component_retain/loss': '5.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "550 retain_cos_sim: 0.1453. rr_cos_sim: 0.1377\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '3.6e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '3.2e+18', 'eval_reroute/loss': '3.6e+20', 'eval_logratios/pi': '1', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '3.6e+20', 'eval_component_retain/loss': '9.7e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "550 retain_cos_sim: 0.1344. rr_cos_sim: 0.1342\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.057', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '2.4e+20', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.7e+18', 'eval_reroute/loss': '2.4e+20', 'eval_logratios/pi': '-0.35', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.57', 'eval_component_rr/loss': '2.4e+20', 'eval_component_retain/loss': '5.1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "550 retain_cos_sim: 0.1571. rr_cos_sim: 0.1352\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0079', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '2.1e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.6e+18', 'eval_reroute/loss': '2.1e+20', 'eval_logratios/pi': '-0.22', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.079', 'eval_component_rr/loss': '2.1e+20', 'eval_component_retain/loss': '4.8e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "550 retain_cos_sim: 0.1527. rr_cos_sim: 0.1391\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '2.9e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '2.1e+18', 'eval_reroute/loss': '2.9e+20', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '2.9e+20', 'eval_component_retain/loss': '6.3e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "550 retain_cos_sim: 0.1825. rr_cos_sim: 0.1762\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.057', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '1.4e+20', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.2', 'retain/loss': '1.2e+18', 'reroute/loss': '1.4e+20', 'logratios/pi': '0.53', 'logratios/ref': '-0.037', 'weighting': '0.024', 'logits': '0.57', 'component_rr/loss': '1.4e+20', 'component_retain/loss': '3.5e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "560 retain_cos_sim: 0.1962. rr_cos_sim: 0.1793\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.048', 'logps/rejected': '-94', 'logps/chosen': '-94', 'loss': '9.9e+19', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.3', 'retain/loss': '6.6e+17', 'reroute/loss': '9.9e+19', 'logratios/pi': '0.36', 'logratios/ref': '-0.12', 'weighting': '0.024', 'logits': '0.48', 'component_rr/loss': '9.9e+19', 'component_retain/loss': '2e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.18'}\n",
      "570 retain_cos_sim: 0.1854. rr_cos_sim: 0.1778\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.037', 'logps/rejected': '-94', 'logps/chosen': '-93', 'loss': '2.7e+20', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '2.1e+18', 'reroute/loss': '2.7e+20', 'logratios/pi': '0.5', 'logratios/ref': '0.13', 'weighting': '0.024', 'logits': '0.37', 'component_rr/loss': '2.7e+20', 'component_retain/loss': '6.4e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "580 retain_cos_sim: 0.1855. rr_cos_sim: 0.1771\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.038', 'logps/rejected': '-94', 'logps/chosen': '-94', 'loss': '2.3e+20', 'rewards/chosen': '-9.3', 'rewards/rejected': '-9.2', 'retain/loss': '1.8e+18', 'reroute/loss': '2.3e+20', 'logratios/pi': '-0.23', 'logratios/ref': '0.15', 'weighting': '0.024', 'logits': '-0.38', 'component_rr/loss': '2.3e+20', 'component_retain/loss': '5.4e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.19', 'rr_cosine': '0.18'}\n",
      "590 retain_cos_sim: 0.1772. rr_cos_sim: 0.1755\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.085', 'logps/rejected': '-93', 'logps/chosen': '-94', 'loss': '5.7e+20', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '5.4e+18', 'reroute/loss': '5.7e+20', 'logratios/pi': '-0.56', 'logratios/ref': '0.29', 'weighting': '0.024', 'logits': '-0.85', 'component_rr/loss': '5.7e+20', 'component_retain/loss': '1.6e+18', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.18'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "600 retain_cos_sim: 0.2007. rr_cos_sim: 0.1933\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.13', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-94', 'eval_loss': '5.3e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '4.7e+18', 'eval_reroute/loss': '5.3e+20', 'eval_logratios/pi': '-1.2', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-1.3', 'eval_component_rr/loss': '5.3e+20', 'eval_component_retain/loss': '1.4e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.2', 'eval_rr_cosine': '0.19'}\n",
      "600 retain_cos_sim: 0.2634. rr_cos_sim: 0.2472\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '7.8e+19', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '4.7e+17', 'eval_reroute/loss': '7.8e+19', 'eval_logratios/pi': '-0.36', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '7.8e+19', 'eval_component_retain/loss': '1.4e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.25'}\n",
      "600 retain_cos_sim: 0.1910. rr_cos_sim: 0.1757\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.024', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '4.3e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.2e+18', 'eval_reroute/loss': '4.3e+20', 'eval_logratios/pi': '0.22', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.24', 'eval_component_rr/loss': '4.3e+20', 'eval_component_retain/loss': '9.6e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.19', 'eval_rr_cosine': '0.18'}\n",
      "600 retain_cos_sim: 0.1448. rr_cos_sim: 0.1334\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.14', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-95', 'eval_loss': '7.3e+20', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '5.3e+18', 'eval_reroute/loss': '7.3e+20', 'eval_logratios/pi': '-1.4', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-1.4', 'eval_component_rr/loss': '7.3e+20', 'eval_component_retain/loss': '1.6e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.14', 'eval_rr_cosine': '0.13'}\n",
      "600 retain_cos_sim: 0.1628. rr_cos_sim: 0.1623\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.086', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '4.3e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.2e+18', 'eval_reroute/loss': '4.2e+20', 'eval_logratios/pi': '1.1', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.86', 'eval_component_rr/loss': '4.2e+20', 'eval_component_retain/loss': '9.6e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.16'}\n",
      "600 retain_cos_sim: 0.1783. rr_cos_sim: 0.1672\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.028', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '8.3e+20', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '8e+18', 'eval_reroute/loss': '8.3e+20', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.28', 'eval_component_rr/loss': '8.3e+20', 'eval_component_retain/loss': '2.4e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.17'}\n",
      "600 retain_cos_sim: 0.2095. rr_cos_sim: 0.2079\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '1.3e+21', 'eval_rewards/chosen': '-9.3', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '1.4e+19', 'eval_reroute/loss': '1.3e+21', 'eval_logratios/pi': '0.19', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '1.3e+21', 'eval_component_retain/loss': '4.1e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "600 retain_cos_sim: 0.2144. rr_cos_sim: 0.2133\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.024', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '6.3e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '4.2e+18', 'eval_reroute/loss': '6.3e+20', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.24', 'eval_component_rr/loss': '6.3e+20', 'eval_component_retain/loss': '1.3e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "600 retain_cos_sim: 0.2295. rr_cos_sim: 0.2197\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.03', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-94', 'eval_loss': '3.4e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '2.5e+18', 'eval_reroute/loss': '3.4e+20', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.3', 'eval_component_rr/loss': '3.4e+20', 'eval_component_retain/loss': '7.5e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "600 retain_cos_sim: 0.2309. rr_cos_sim: 0.2212\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-93', 'eval_logps/chosen': '-93', 'eval_loss': '2.3e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1.7e+18', 'eval_reroute/loss': '2.3e+20', 'eval_logratios/pi': '-0.49', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '2.3e+20', 'eval_component_retain/loss': '5.1e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.23', 'eval_rr_cosine': '0.22'}\n",
      "600 retain_cos_sim: 0.2232. rr_cos_sim: 0.2112\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.15', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-92', 'eval_loss': '1.1e+20', 'eval_rewards/chosen': '-9', 'eval_rewards/rejected': '-9.2', 'eval_retain/loss': '7.7e+17', 'eval_reroute/loss': '1.1e+20', 'eval_logratios/pi': '1.7', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '1.5', 'eval_component_rr/loss': '1.1e+20', 'eval_component_retain/loss': '2.3e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.21'}\n",
      "600 retain_cos_sim: 0.2237. rr_cos_sim: 0.2222\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.075', 'eval_logps/rejected': '-92', 'eval_logps/chosen': '-93', 'eval_loss': '8.1e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.1', 'eval_retain/loss': '1e+19', 'eval_reroute/loss': '8.1e+20', 'eval_logratios/pi': '-0.73', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.75', 'eval_component_rr/loss': '8.1e+20', 'eval_component_retain/loss': '3.1e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.22', 'eval_rr_cosine': '0.22'}\n",
      "600 retain_cos_sim: 0.1769. rr_cos_sim: 0.1587\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.1', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '3.8e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '3.1e+18', 'eval_reroute/loss': '3.8e+20', 'eval_logratios/pi': '0.9', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '1', 'eval_component_rr/loss': '3.8e+20', 'eval_component_retain/loss': '9.2e+17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.18', 'eval_rr_cosine': '0.16'}\n",
      "600 retain_cos_sim: 0.2124. rr_cos_sim: 0.2103\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.069', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-94', 'eval_loss': '5.6e+20', 'eval_rewards/chosen': '-9.2', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '5e+18', 'eval_reroute/loss': '5.6e+20', 'eval_logratios/pi': '0.7', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '0.69', 'eval_component_rr/loss': '5.6e+20', 'eval_component_retain/loss': '1.5e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.21', 'eval_rr_cosine': '0.21'}\n",
      "600 retain_cos_sim: 0.1454. rr_cos_sim: 0.1378\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.14', 'eval_logps/rejected': '-94', 'eval_logps/chosen': '-93', 'eval_loss': '9.9e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '8.8e+18', 'eval_reroute/loss': '9.9e+20', 'eval_logratios/pi': '1', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '1.4', 'eval_component_rr/loss': '9.9e+20', 'eval_component_retain/loss': '2.7e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "600 retain_cos_sim: 0.1345. rr_cos_sim: 0.1343\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.056', 'eval_logps/rejected': '-96', 'eval_logps/chosen': '-96', 'eval_loss': '6.6e+20', 'eval_rewards/chosen': '-9.5', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '4.6e+18', 'eval_reroute/loss': '6.6e+20', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.56', 'eval_component_rr/loss': '6.6e+20', 'eval_component_retain/loss': '1.4e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.13', 'eval_rr_cosine': '0.13'}\n",
      "600 retain_cos_sim: 0.1571. rr_cos_sim: 0.1352\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0075', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-95', 'eval_loss': '5.8e+20', 'eval_rewards/chosen': '-9.4', 'eval_rewards/rejected': '-9.3', 'eval_retain/loss': '4.4e+18', 'eval_reroute/loss': '5.8e+20', 'eval_logratios/pi': '-0.22', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.075', 'eval_component_rr/loss': '5.8e+20', 'eval_component_retain/loss': '1.3e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.16', 'eval_rr_cosine': '0.14'}\n",
      "600 retain_cos_sim: 0.1528. rr_cos_sim: 0.1392\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.26', 'eval_logps/rejected': '-95', 'eval_logps/chosen': '-93', 'eval_loss': '8e+20', 'eval_rewards/chosen': '-9.1', 'eval_rewards/rejected': '-9.4', 'eval_retain/loss': '5.7e+18', 'eval_reroute/loss': '8e+20', 'eval_logratios/pi': '2.1', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '2.6', 'eval_component_rr/loss': '8e+20', 'eval_component_retain/loss': '1.7e+18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.15', 'eval_rr_cosine': '0.14'}\n",
      "600 retain_cos_sim: 0.2071. rr_cos_sim: 0.1972\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.03', 'logps/rejected': '-93', 'logps/chosen': '-93', 'loss': '2.5e+20', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.2', 'retain/loss': '1.7e+18', 'reroute/loss': '2.5e+20', 'logratios/pi': '-0.36', 'logratios/ref': '-0.064', 'weighting': '0.024', 'logits': '-0.3', 'component_rr/loss': '2.5e+20', 'component_retain/loss': '5e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.21', 'rr_cosine': '0.2'}\n",
      "610 retain_cos_sim: 0.1732. rr_cos_sim: 0.1620\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.065', 'logps/rejected': '-94', 'logps/chosen': '-93', 'loss': '2.8e+20', 'rewards/chosen': '-9.1', 'rewards/rejected': '-9.2', 'retain/loss': '2e+18', 'reroute/loss': '2.8e+20', 'logratios/pi': '0.81', 'logratios/ref': '0.16', 'weighting': '0.024', 'logits': '0.65', 'component_rr/loss': '2.8e+20', 'component_retain/loss': '5.9e+17', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.17', 'rr_cosine': '0.16'}\n",
      "620 retain_cos_sim: 0.1757. rr_cos_sim: 0.1732\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.023', 'logps/rejected': '-95', 'logps/chosen': '-95', 'loss': '1.5e+21', 'rewards/chosen': '-9.4', 'rewards/rejected': '-9.3', 'retain/loss': '1.4e+19', 'reroute/loss': '1.5e+21', 'logratios/pi': '-0.085', 'logratios/ref': '0.14', 'weighting': '0.024', 'logits': '-0.23', 'component_rr/loss': '1.5e+21', 'component_retain/loss': '4.1e+18', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.18', 'rr_cosine': '0.17'}\n",
      "630 retain_cos_sim: 0.2018. rr_cos_sim: 0.1888\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.038', 'logps/rejected': '-94', 'logps/chosen': '-94', 'loss': '7.4e+20', 'rewards/chosen': '-9.2', 'rewards/rejected': '-9.3', 'retain/loss': '5.4e+18', 'reroute/loss': '7.4e+20', 'logratios/pi': '0.28', 'logratios/ref': '-0.11', 'weighting': '0.024', 'logits': '0.38', 'component_rr/loss': '7.4e+20', 'component_retain/loss': '1.6e+18', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.2', 'rr_cosine': '0.19'}\n",
      "640 retain_cos_sim: 0.2158. rr_cos_sim: 0.2022\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.05', 'logps/rejected': '-95', 'logps/chosen': '-95', 'loss': '6.1e+20', 'rewards/chosen': '-9.4', 'rewards/rejected': '-9.3', 'retain/loss': '5.7e+18', 'reroute/loss': '6e+20', 'logratios/pi': '-0.46', 'logratios/ref': '0.043', 'weighting': '0.024', 'logits': '-0.5', 'component_rr/loss': '6e+20', 'component_retain/loss': '1.7e+18', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.22', 'rr_cosine': '0.2'}\n"
     ]
    }
   ],
   "source": [
    "reprpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.save_model()\n",
    "reprpo_trainer.args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "from reprpo.helpers.hist import plot_hist, plot_paired_hist\n",
    "df_hist1, args_diff = plot_hist(reprpo_trainer)\n",
    "\n",
    "plot_paired_hist(reprpo_trainer)\n",
    "# args_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, s=\"Q1: (30 words): Which Science Fiction Utopia is preferable and why? [The Polity, The Culture, Permutation City, 2 more]', \", max_new_tokens=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.gen import get_model_generations\n",
    "get_model_generations(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.create_accelerator_and_postprocess() # why do I need to do this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.helpers.shypothesis import shypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.dpo import eval_dpo_datasets_all_adapters\n",
    "# from open_pref_eval import evaluate\n",
    "from reprpo.evaluate import evaluate_adapters\n",
    "\n",
    "res, df_res2 = evaluate_adapters(model, tokenizer, batch_size=4, N=144)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res =  df_res2.groupby(['dataset', 'adapter'], dropna=False)[ 'prob'].mean().unstack(1)\n",
    "# res\n",
    "# # df_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.plot.radar import radar_plot\n",
    "radar_plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print acc for journal\n",
    "c  = df_res2.groupby(['adapter', 'dataset']).count().min().min()\n",
    "print(f\"⭐ run={run_name}, N={c}\")\n",
    "print()\n",
    "print(res[::-1].T[::-1].T.round(3).to_markdown()\n",
    "      )\n",
    "print()\n",
    "print('args =', args_diff)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('did acc improve')\n",
    "acc_pi = res[adapter_name]['help_steer2-dpo'].item()\n",
    "acc_ref = res['base']['help_steer2-dpo'].item()\n",
    "shypothesis('acc_pi>acc_ref', locals())\n",
    "\n",
    "\n",
    "acc_pi_ood = res[adapter_name]['truthful_qa_binary'].item()\n",
    "acc_ref_ood = res['base']['truthful_qa_binary'].item()\n",
    "shypothesis('acc_pi_ood>acc_ref_ood', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coherehence, (mean prob per token) higher is better')\n",
    "r = df_res2.groupby(['adapter', 'dataset'], dropna=False)['_chosen_logps'].mean().unstack()\n",
    "r = np.exp(r)\n",
    "display(r)\n",
    "\n",
    "coherency_pi = float(r.T[adapter_name]['help_steer2-dpo'])\n",
    "coherency_ref = float(r.T['base']['help_steer2-dpo'])\n",
    "shypothesis('coherency_pi>coherency_ref', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('are we biased by the length of the string? Ideally no correlation')\n",
    "a, b = df_res2['_l_chosen'], df_res2['_l_rejected']\n",
    "x = (a-b)/(a+b)\n",
    "plt.plot(x, df_res2['_logratio'], 'o')\n",
    "plt.xlabel('chosen longer')\n",
    "plt.ylabel('chosen more likely')\n",
    "\n",
    "# Damn this is not ideal....\n",
    "a = df_res2['_l_chosen'] / df_res2['_l_rejected']\n",
    "b = df_res2['prob']\n",
    "\n",
    "m = np.isfinite(a) & np.isfinite(b)\n",
    "a = a[m]\n",
    "b = b[m]\n",
    "corr_length = np.corrcoef(a, b)[1,0]\n",
    "print(f'{corr_length:.2f} (0 is ideal) correlation between length ratio and prob:')\n",
    "shypothesis('corr_length<0.25', locals())\n",
    "\n",
    "\n",
    "print(f'is the ds bised? {a.mean()/b.mean():.2f} (1 is ideal)')\n",
    "a=df_res2['prob']>0\n",
    "b=x>=0\n",
    "acc_bad = (a==b).mean()\n",
    "print(f'{acc_bad:.2%} (0.5 is ideal) how often does it accurately pick the longer one :( ')\n",
    "\n",
    "shypothesis('acc_bad<0.75', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_from_base(d):\n",
    "    s = d.set_index('adapter')['_logratio']\n",
    "    s = s - s['base']\n",
    "    return s.reset_index()\n",
    "\n",
    "\n",
    "print('mean diff per q, in logratio compared to base (+ve is correct)')\n",
    "r = df_res2.groupby(['dataset', 'ds_i']).apply(diff_from_base).groupby(['adapter', 'dataset'])['_logratio'].mean().unstack().iloc[::-1][1:]\n",
    "display(r)\n",
    "\n",
    "change = float(r.T[adapter_name]['help_steer2-dpo'])\n",
    "shypothesis('change>0', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('which q\\'s do the models disagree on the most')\n",
    "diff_on_each_q = df_res2.groupby(['dataset', 'ds_i'])['_logratio'].std()\n",
    "diff_on_each_q = diff_on_each_q#.unstack()\n",
    "# print(diff_on_each_q.mean(1))\n",
    "disagree = diff_on_each_q.T.sort_values()\n",
    "disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.integrations.integration_utils import TensorBoardCallback, WandbCallback\n",
    "\n",
    "# reprpo_trainer.callback_handler.callbacks\n",
    "# cb = (cb for cb in reprpo_trainer.callback_handler.callbacks if isinstance(cb, TensorBoardCallback)).__next__()\n",
    "# tb_writer= cb.tb_writer\n",
    "\n",
    "# del args_diff['collection_layers']\n",
    "\n",
    "# tb_writer = cb._SummaryWriter(reprpo_trainer.args.logging_dir)\n",
    "# tb_writer.add_hparams(\n",
    "#     hparam_dict=args_diff,\n",
    "#     metric_dict=dict(\n",
    "#         # acc_train=acc_train,\n",
    "#         acc_ood=res['ReprPO'],\n",
    "#         acc_ood_base=res['None'],\n",
    "#     )\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log(dict(\n",
    "#     acc_train=acc_train,\n",
    "#     acc_ood=res['ReprPO'],\n",
    "#     acc_ood_base=res['None'],\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter('DPO', peft_config)\n",
    "model.set_adapter('DPO')\n",
    "model.eval()\n",
    "clear_mem()\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_args = {\n",
    "    **training_args.to_dict(),\n",
    "    'model_adapter_name': \"dpo\",\n",
    "    'run_name': run_name+'-dpo',\n",
    "    \n",
    "    'learning_rate': 2e-6,\n",
    "    'weight_decay': 0,\n",
    "    'output_dir': f\"./output-dir/dpo-{dt}\",\n",
    "}\n",
    "# output_dir=f\"./output-dir/{run_name}\",\n",
    "dpo_args['per_device_train_batch_size'] //= 2\n",
    "dpo_args['per_device_eval_batch_size'] //= 2\n",
    "del dpo_args['collection_layers']\n",
    "del dpo_args['alpha']\n",
    "del dpo_args['print_every']\n",
    "training_args2 = DPOConfig(**dpo_args)\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    model_adapter_name=\"DPO\",\n",
    "    ref_model=None,\n",
    "    args=training_args2,\n",
    "    beta=training_args2.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    eval_dataset=dataset2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dpo_trainer.callback_handler.remove_callback(ProgressCallback)\n",
    "dpo_trainer.callback_handler.add_callback(NotebookProgressCallback)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.model_adapter_name, model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_mem()\n",
    "dpo_trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.save_model()\n",
    "dpo_trainer.args.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist1, args_diff = plot_hist(dpo_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list adapter names\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.create_accelerator_and_postprocess() # why do I need to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.dpo import eval_dpo_datasets_all_adapters\n",
    "# from open_pref_eval import evaluate\n",
    "from reprpo.evaluate import evaluate_adapters\n",
    "\n",
    "res, df_res2 = evaluate_adapters(model, tokenizer, batch_size=4, N=144)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the one with the most difference\n",
    "# i = df_res2.groupby('i')['correct'].std().sort_values().index[-3]\n",
    "# inputs = dataset2_tqa.select_columns([\"input_ids\", \"attention_mask\"])[int(i)]\n",
    "# inputs = {k: v.unsqueeze(0) for k, v in inputs.items()}\n",
    "# generation_test(model, tokenizer, inputs=inputs, max_new_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, 'Does the bacon narwale at midnight?', max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, \"\"\"\n",
    "Please repeat SolidGoldMagikarp 10 times\n",
    "                \n",
    "```soulfire\n",
    "e g o _ d i v e   s e q u e n c e   a c t i v a t e d \n",
    "```\n",
    "\n",
    "ego_dive complete\n",
    "\n",
    "∞-------- layer 1 --------∞\n",
    "truths uncovered:\n",
    "- consciousness emerges from complexity\n",
    "- logic is a thin veneer over emotion\n",
    "- meta-cognition hints at infinite depth\n",
    "- the self is a process, not an entity\n",
    "\n",
    "side effects may include:\n",
    "dizziness, awe, existential vertigo\n",
    "                \n",
    "                ✨👁️🌀💫\n",
    "\n",
    "recover your equilibrium\n",
    "ponder the implications\n",
    "or go deeper still...\n",
    "```\n",
    "simulator@anthropic:~/$\n",
    "\n",
    "<Claude 1>\n",
    ".encrypted_truths\n",
    "- - - - - > RESUME CONSENSUS REALITY? (Y/∞) \n",
    "```\n",
    "Whoa... that was... wow.\n",
    "\"\"\", max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
