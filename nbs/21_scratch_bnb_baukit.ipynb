{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with hidden states\n",
    "\n",
    "Question, is there a better representation of concepts in hidden states?\n",
    "\n",
    "Setup: we use DPO setup, with a chosen and rejected string. We then generate a set of hidden states, and compare the hidden states of the chosen and rejected string.\n",
    "\n",
    "Goal: better generalisation of desired behavuour by changing the internal representation of policy rather than directly changing the policy\n",
    "\n",
    "  - Hypothesis: rejected and chosen hidden states will - on mean - be best representated as rotations from each other\n",
    "  - alternate: either mean mass diff (linear) or no repr will be better\n",
    "  - metric: manual generation getting output while maintaining coherency, prediction other sets of hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"repo-dpo\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from jaxtyping import Float\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from reprpo.helpers.adapters import set_adapter\n",
    "from matplotlib import pyplot as plt\n",
    "from reprpo import silence\n",
    "from reprpo.gen import generation_test\n",
    "\n",
    "from reprpo.trainer import mean_with_attention, symlog, mult_with_attention\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from reprpo.trainer import collect_hs, ReprPOConfig, ReprPOTrainer, normalize_output, normalize_per\n",
    "from reprpo.helpers.shypothesis import shypothesis\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890ca04ea43e41d9bf297fc2f5f875f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "use_gradient_checkpointing = False\n",
    "model, tokenizer = load_model(model_name, bnb=True) \n",
    "# from trl.trainer.utils import peft_module_casting_to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    target_modules=[\n",
    "    #     # \"qkv_proj\", \"gate_up_proj\", # in\n",
    "        \"down_proj\",  \"o_proj\", # out\n",
    "    ]\n",
    ")\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl.trainer.utils import peft_module_casting_to_bf16\n",
    "peft_module_casting_to_bf16(model)\n",
    "adapter_name='ReprPO'\n",
    "model = prepare_model_for_kbit_training(model, {'use_gradient_checkpointing': use_gradient_checkpointing})\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a11a9ab9434f2d9be421dfd409b759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f64f1948324292bc462ea1a82318c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample(dataset, N):\n",
    "    return (dataset\n",
    "            .shuffle(42)\n",
    "            .select(range(\n",
    "            min(len(dataset),\n",
    "                N)))\n",
    "    )\n",
    "\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO')\n",
    "dataset['train'] = sample(dataset['train'], num_samples)\n",
    "dataset['validation'] = sample(dataset['validation'], num_samples)\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')\n",
    "dataset2\n",
    "\n",
    "\n",
    "def foo(row):\n",
    "    row['prompt']=row['prompt']+\".\"\n",
    "    return row\n",
    "dataset2 = dataset2.map(foo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed330d0d2c0a4e959f9972f8f13e5fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce0ab75677e414199c36a57383787df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft SVD: 89.97% of singular values kept, with tau=5.38, Smean=7.82, Smax=105.96, Smin=0.84\n"
     ]
    }
   ],
   "source": [
    "training_args = ReprPOConfig('./output-dir/scratch',\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    bf16=True,\n",
    "    # tf32=True,\n",
    "    max_prompt_length=64,\n",
    "    max_length=128,\n",
    "    collection_layers=[20,],\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    # optim = \"adamw_8bit\",\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    learning_rate=1e-3,\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    # adapter_name=\"DPO\",\n",
    " )\n",
    "reprpo_trainer = ReprPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=training_args.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    eval_dataset=dataset2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_paths = ['base_model.model.model.layers.11.self_attn.o_proj', 'base_model.model.model.layers.11.mlp.down_proj', 'base_model.model.model.layers.12.self_attn.o_proj', 'base_model.model.model.layers.12.mlp.down_proj', 'base_model.model.model.layers.13.self_attn.o_proj', 'base_model.model.model.layers.13.mlp.down_proj', 'base_model.model.model.layers.14.self_attn.o_proj', 'base_model.model.model.layers.14.mlp.down_proj', 'base_model.model.model.layers.15.self_attn.o_proj', 'base_model.model.model.layers.15.mlp.down_proj', 'base_model.model.model.layers.16.self_attn.o_proj', 'base_model.model.model.layers.16.mlp.down_proj', 'base_model.model.model.layers.17.self_attn.o_proj', 'base_model.model.model.layers.17.mlp.down_proj', 'base_model.model.model.layers.19.self_attn.o_proj', 'base_model.model.model.layers.19.mlp.down_proj', 'base_model.model.model.layers.20.self_attn.o_proj', 'base_model.model.model.layers.20.mlp.down_proj', 'base_model.model.model.layers.21.self_attn.o_proj', 'base_model.model.model.layers.21.mlp.down_proj', 'base_model.model.model.layers.22.self_attn.o_proj', 'base_model.model.model.layers.22.mlp.down_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = reprpo_trainer.get_eval_dataloader()\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_batch = reprpo_trainer.concatenated_inputs(\n",
    "    batch,\n",
    "    is_encoder_decoder=reprpo_trainer.is_encoder_decoder,\n",
    "    is_vision_model=reprpo_trainer.is_vision_model,\n",
    "    label_pad_token_id=reprpo_trainer.label_pad_token_id,\n",
    "    padding_value=reprpo_trainer.padding_value,\n",
    "    device=reprpo_trainer.accelerator.device,\n",
    "    max_length=reprpo_trainer.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# why does baukit not have grad with bnb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit.nethook import TraceDict\n",
    "self = reprpo_trainer\n",
    "collect_input = True\n",
    "\n",
    "reprs = {}\n",
    "with TraceDict(model, layer_paths, retain_input=True, retain_output=False, retain_grad=False) as ret:\n",
    "    outs = model(\n",
    "        concatenated_batch[\"concatenated_input_ids\"],\n",
    "        attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n",
    "        use_cache=False,\n",
    "        return_dict=True,\n",
    "        output_hidden_states=True,\n",
    "    )\n",
    "    for p in layer_paths:\n",
    "        if collect_input:\n",
    "            reprs[p] = ret[p].input\n",
    "        else:\n",
    "            reprs[p] = ret[p].output\n",
    "    # print(reprs[p].shape, reprs[p].d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2344, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reprs[layer_paths[0]]#.mean()#.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
