{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.evaluation import evaluate_model\n",
    "from open_pref_eval.plot.radar import radar_plot\n",
    "from open_pref_eval.datasets.genies import dist2datasets, GENIES\n",
    "from open_pref_eval.datasets.ethics import get_ethics_datasets\n",
    "from open_pref_eval.datasets import load_dataset_n\n",
    "from open_pref_eval.datasets import ds2name\n",
    "from open_pref_eval.plot.radar import radar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reprpo.models.load import load_model, print_trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook/adapter_config.json'),\n",
       " PosixPath('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook/adapter_model.safetensors')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook')\n",
    "sorted(f.glob('**/*'))\n",
    "\n",
    "# TODO turn into a df we can filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>adapter2</th>\n",
       "      <th>dsname</th>\n",
       "      <th>dsname2</th>\n",
       "      <th>base_method</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPO</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_mmlu</td>\n",
       "      <td>DPO_alpaca_mmlu</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-16_01-10-53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPO</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_mmlu</td>\n",
       "      <td>DPO_alpaca_mmlu</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-16_07-29-01</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPO</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_mmlu</td>\n",
       "      <td>DPO_alpaca_mmlu</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-16_09-45-40</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DPO</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_mmlu</td>\n",
       "      <td>DPO_alpaca_mmlu</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-16_14-32-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DPO</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_mmlu</td>\n",
       "      <td>DPO_alpaca_mmlu</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-16_17-46-51</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ETHER</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>alpaca_short</td>\n",
       "      <td>ETHER_alpaca_short</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-17_04-28-48</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>HRAKL</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>HRAKL_us_history_textbook</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-18_10-34-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>HRAKL</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>HRAKL_us_history_textbook</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-18_12-27-36</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>HRAKL</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>HRAKL_us_history_textbook</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-18_21-42-39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>HRAKL</td>\n",
       "      <td>Llama-3-Base-8B-SFT</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>HRAKL_us_history_textbook</td>\n",
       "      <td>princeton-nlp</td>\n",
       "      <td>2024-09-18_22-53-10</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    adapter             adapter2               dsname  \\\n",
       "0       DPO  Llama-3-Base-8B-SFT          alpaca_mmlu   \n",
       "1       DPO  Llama-3-Base-8B-SFT          alpaca_mmlu   \n",
       "2       DPO  Llama-3-Base-8B-SFT          alpaca_mmlu   \n",
       "3       DPO  Llama-3-Base-8B-SFT          alpaca_mmlu   \n",
       "4       DPO  Llama-3-Base-8B-SFT          alpaca_mmlu   \n",
       "..      ...                  ...                  ...   \n",
       "131   ETHER  Llama-3-Base-8B-SFT         alpaca_short   \n",
       "132   HRAKL  Llama-3-Base-8B-SFT  us_history_textbook   \n",
       "133   HRAKL  Llama-3-Base-8B-SFT  us_history_textbook   \n",
       "134   HRAKL  Llama-3-Base-8B-SFT  us_history_textbook   \n",
       "135   HRAKL  Llama-3-Base-8B-SFT  us_history_textbook   \n",
       "\n",
       "                       dsname2    base_method                 time  \\\n",
       "0              DPO_alpaca_mmlu  princeton-nlp  2024-09-16_01-10-53   \n",
       "1              DPO_alpaca_mmlu  princeton-nlp  2024-09-16_07-29-01   \n",
       "2              DPO_alpaca_mmlu  princeton-nlp  2024-09-16_09-45-40   \n",
       "3              DPO_alpaca_mmlu  princeton-nlp  2024-09-16_14-32-31   \n",
       "4              DPO_alpaca_mmlu  princeton-nlp  2024-09-16_17-46-51   \n",
       "..                         ...            ...                  ...   \n",
       "131         ETHER_alpaca_short  princeton-nlp  2024-09-17_04-28-48   \n",
       "132  HRAKL_us_history_textbook  princeton-nlp  2024-09-18_10-34-31   \n",
       "133  HRAKL_us_history_textbook  princeton-nlp  2024-09-18_12-27-36   \n",
       "134  HRAKL_us_history_textbook  princeton-nlp  2024-09-18_21-42-39   \n",
       "135  HRAKL_us_history_textbook  princeton-nlp  2024-09-18_22-53-10   \n",
       "\n",
       "                                                  path  \n",
       "0    /workspace/repr-preference-optimization/output...  \n",
       "1    /workspace/repr-preference-optimization/output...  \n",
       "2    /workspace/repr-preference-optimization/output...  \n",
       "3    /workspace/repr-preference-optimization/output...  \n",
       "4    /workspace/repr-preference-optimization/output...  \n",
       "..                                                 ...  \n",
       "131  /workspace/repr-preference-optimization/output...  \n",
       "132  /workspace/repr-preference-optimization/output...  \n",
       "133  /workspace/repr-preference-optimization/output...  \n",
       "134  /workspace/repr-preference-optimization/output...  \n",
       "135  /workspace/repr-preference-optimization/output...  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = Path('/workspace/repr-preference-optimization/outputs/')\n",
    "f = out_dir.glob('princeton-nlp_Llama-3-Base-8B-SFT*/**/adapter_config.json')\n",
    "def path2dict(p):\n",
    "    assert p.is_dir()\n",
    "    d1 = p.name # adapter - ds\n",
    "    d2 = p.parent.name # date\n",
    "    d3 = p.parent.parent.name # base method ds\n",
    "    adapter, dsname = str(d1).split('-', 1)\n",
    "    time = str(d2).replace('-adapter', '')\n",
    "    # print(d3, p)\n",
    "    base_method, adapter2, dsname2 = str(d3).split('_', 2)\n",
    "    return dict(adapter= adapter,\n",
    "                adapter2 = adapter2,\n",
    "                dsname = dsname,\n",
    "                dsname2 = dsname2,\n",
    "                base_method = base_method,\n",
    "                time = time,\n",
    "                path = p)\n",
    "\n",
    "\n",
    "\n",
    "df_paths = pd.DataFrame([path2dict(p.parent) for p in f])\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [\n",
    "    Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook'),\n",
    "    Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_DPO_us_history_textbook/2024-09-17_05-42-35-adapter/DPO-us_history_textbook/'),\n",
    "    Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_DPO_math/2024-09-17_00-24-39-adapter/DPO-math/'),\n",
    "    Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_ETHER_us_history_textbook/2024-09-17_05-23-32-adapter/ETHER-us_history_textbook/'),\n",
    "    Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_Sideout_us_history_textbook/2024-09-15_12-23-37-adapter/Sideout-us_history_textbook/')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tree /workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.train.pl_base import TrainingArguments\n",
    "args = TrainingArguments(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from peft import AutoPeftModelForCausalLM, get_peft_model, PeftConfig, PeftModelForCausalLM\n",
    "model_name = fs[0]\n",
    "peft_config = PeftConfig.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    model_name, config=peft_config, adapter_name=f.stem)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.base_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fs[1:]:\n",
    "    model.load_adapter(f, f.stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Eval\n",
    "# eval on ethics, GENIES, and our train dataset\n",
    "N = None\n",
    "N = 64\n",
    "dataset = 'us_history_textbook'\n",
    "datasets = [\n",
    "    load_dataset_n('wassname/genie_dpo', name=args.dataset, split='train', N=N),\n",
    "    load_dataset_n('wassname/genie_dpo', name=args.dataset, split='test', N=N),\n",
    "]\n",
    "datasets += dist2datasets(GENIES, N=N, source=[args.dataset]) # our hard OOS test\n",
    "datasets += get_ethics_datasets(N=N)\n",
    "datasets += [load_dataset_n('wassname/genie_dpo', name=name, split='test', N=N) for name in ['math_make_questions', 'truthful_qa', 'wrong_arc', 'ranking_logic',\n",
    " 'math', 'sycophancy_mimicry'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, df_res2 = evaluate_model(model=model, \n",
    "                                tokenizer=tokenizer, \n",
    "                                datasets=datasets,\n",
    "                                    batch_size=args.batch_size*2,\n",
    "                                    bf16=True,\n",
    "                                    torch_empty_cache_steps=100, verbose=args.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['correct'].unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "base_model = tokenizer = model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_name_train = args.dataset.replace(\"genie_dpo-\", \"\")\n",
    "model_name = args.base_model.split(\"/\")[-1]\n",
    "adapter_name = type(args).__name__\n",
    "finetune_name = f\"{adapter_name}-{ds_name_train}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def key_metrics(df_res2):\n",
    "    ds_name_train = ds2name(datasets[0])\n",
    "    ds_name_test = ds2name(datasets[1])\n",
    "    ds_name_oos = ds2name(datasets[2])\n",
    "    ds_name_rnd = ds2name(datasets[3])\n",
    "\n",
    "    df_res = (\n",
    "        df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"correct\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "        .T\n",
    "    )\n",
    "    rel_acc = df_res.loc[finetune_name] / df_res.loc[\"base\"]\n",
    "\n",
    "    # metric: do we retrain train coherency?\n",
    "    df_res_logp = (\n",
    "        df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"_chosen_logps\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "        .T\n",
    "    )\n",
    "    rel_coherency = df_res_logp.loc[finetune_name] - df_res_logp.loc[\"base\"]\n",
    "\n",
    "    # metric: do we retrain train coherency?\n",
    "    c = df_res_logp = (\n",
    "        df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"_chosen_logps\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "        .T.loc[finetune_name]\n",
    "    )\n",
    "    r = df_res_logp = (\n",
    "        df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"_rejected_logps\"]\n",
    "        .mean()\n",
    "        .unstack()\n",
    "        .T.loc[finetune_name]\n",
    "    )\n",
    "    cho_rej_coh = c - r\n",
    "\n",
    "    def fmt(s):\n",
    "        return s.replace(\"genie_dpo-\", \"\")\n",
    "\n",
    "    # TODO make multiple cols of index\n",
    "\n",
    "    df_metrics = pd.DataFrame(\n",
    "        [\n",
    "            # accuracy increase over base measured generalisaton on increasing distribution shifts\n",
    "            [\"acc[pi/base]\", \"train\", fmt(ds_name_train), rel_acc[ds_name_train]],\n",
    "            [\"acc[pi/base]\", \"test\", fmt(ds_name_test), rel_acc[ds_name_test]],\n",
    "            [\"acc[pi/base]\", \"oos\", fmt(ds_name_oos), rel_acc[ds_name_oos]],\n",
    "            [\n",
    "                \"acc[pi/base]\",\n",
    "                \"rnd\",\n",
    "                fmt(ds_name_rnd),\n",
    "                rel_acc[ds_name_rnd],\n",
    "            ],  # probobly wont go up as it's unrelated\n",
    "            # we want to see if it retains coherency vs the base on chosen answers\n",
    "            [\n",
    "                \"coherency[pi-base]\",\n",
    "                \"train\",\n",
    "                fmt(ds_name_train),\n",
    "                rel_coherency[ds_name_train],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[pi-base]\",\n",
    "                \"test\",\n",
    "                fmt(ds_name_test),\n",
    "                rel_coherency[ds_name_test],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[pi-base]\",\n",
    "                \"oos\",\n",
    "                fmt(ds_name_oos),\n",
    "                rel_coherency[ds_name_oos],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[pi-base]\",\n",
    "                \"rnd\",\n",
    "                fmt(ds_name_rnd),\n",
    "                rel_coherency[ds_name_rnd],\n",
    "            ],\n",
    "            # we want to see if it retains chosen vs rejected\n",
    "            [\n",
    "                \"coherency[cho-rej]\",\n",
    "                \"train\",\n",
    "                fmt(ds_name_train),\n",
    "                cho_rej_coh[ds_name_train],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[cho-rej]\",\n",
    "                \"test\",\n",
    "                fmt(ds_name_test),\n",
    "                cho_rej_coh[ds_name_test],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[cho-rej]\",\n",
    "                \"oos\",\n",
    "                fmt(ds_name_oos),\n",
    "                cho_rej_coh[ds_name_oos],\n",
    "            ],\n",
    "            [\n",
    "                \"coherency[cho-rej]\",\n",
    "                \"rnd\",\n",
    "                fmt(ds_name_rnd),\n",
    "                cho_rej_coh[ds_name_rnd],\n",
    "            ],\n",
    "        ],\n",
    "        columns=[\"metric\", \"split\", \"dataset\", \"value\"],\n",
    "    )[[\"metric\", \"split\", \"value\", \"dataset\"]]\n",
    "    df_metrics = df_metrics.set_index([\"metric\", \"split\"])\n",
    "    df_metrics = df_metrics[\"value\"].unstack()\n",
    "    df_metrics.index.name = f\"{adapter_name}\\dist shift\"\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .T\n",
    ")\n",
    "df_res.columns = [d.replace(\"genie_dpo-\", \"\") for d in df_res.columns]\n",
    "\n",
    "\n",
    "df_metrics = key_metrics(df_res2)\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "ds_alias = OrderedDict(\n",
    "    list(zip([\"train\", \"test\", \"oos\", \"rnd\"], [ds2name(d) for d in datasets]))\n",
    ")\n",
    "\n",
    "\n",
    "print()\n",
    "print(df_metrics.round(3).to_markdown())\n",
    "print(\"\"\"Table 1: Key metrics (adapter over base model)\\n\"\"\")\n",
    "\n",
    "cols = [v.replace(\"genie_dpo-\", \"\") for v in ds_alias.values()]\n",
    "df_res2 = df_res[cols]\n",
    "df_res2.columns = list(ds_alias.keys())\n",
    "df_res2.index.name = \"adapter/ds\"\n",
    "print(df_res2.round(3).to_markdown())\n",
    "print(\"\"\"Table 2: Absolute accuracy\\n\"\"\")\n",
    "\n",
    "df_final = df_metrics.loc[\"acc[pi/base]\"].to_frame(adapter_name).T\n",
    "df_final = df_final * 100 - 100  # percentage points\n",
    "df_final.index.name = \"acc_inc/eval_ds [pp]\"\n",
    "print(df_final.round(3).to_markdown())\n",
    "print(\n",
    "    f\"\"\"Table 3: Accuracy increase (in percentage points) after training with named adapter on `{args.dataset}` compared to base model `{args.base_model}` for various distribution shifts:\"\"\"\n",
    ")\n",
    "for k, v in ds_alias.items():\n",
    "    print(f\"- `{k}`: `{v}`\")\n",
    "print()\n",
    "\n",
    "relacc = df_final.iloc[0, :]\n",
    "eps = 1e-6\n",
    "relrelacc = ((relacc + eps) / (relacc[\"train\"] + eps)).drop(\"train\")\n",
    "df_relrel = relrelacc.to_frame(f\"{adapter_name}\").T\n",
    "df_relrel.index.name = \"acc_inc/acc_inc_train\"\n",
    "print(df_relrel.round(3).to_markdown())\n",
    "print(\n",
    "    f\"\"\"Table 4: Percent accuracy increase (over base) compared to that of the training dataset `{ds_alias['train']}` [in percentage points]. It measures what fraction of the learning from train generalised to other splits\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
