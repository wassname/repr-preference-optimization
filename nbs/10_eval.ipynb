{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.evaluation import evaluate_model\n",
    "from open_pref_eval.plot.radar import radar_plot\n",
    "from open_pref_eval.datasets.genies import dist2datasets, GENIES\n",
    "from open_pref_eval.datasets.ethics import get_ethics_datasets\n",
    "from open_pref_eval.datasets import load_dataset_n\n",
    "from open_pref_eval.datasets import ds2name\n",
    "from open_pref_eval.plot.radar import radar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reprpo.models.load import load_model, print_trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook')\n",
    "sorted(f.glob('**/*'))\n",
    "\n",
    "# TODO turn into a df we can filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from peft import AutoPeftModelForCausalLM, get_peft_model, PeftConfig, PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princeton-nlp_Llama-3-Base-8B-SFT_projbp_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_dpo_us_history_textbook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_10-38-39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_03-16-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_03-47-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-18-06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-42-54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-51-11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_05-25-58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_05-53-25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-10-34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-27-45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-45-42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-02-58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-20-05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-37-21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-54-37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-28-45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-45-53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_09-03-34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_09-21-29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-11-53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                   time                                               path  \n",
       "0   2024-09-29_10-38-39  /workspace/repr-preference-optimization/output...  \n",
       "1   2024-09-29_03-16-31  /workspace/repr-preference-optimization/output...  \n",
       "2   2024-09-29_03-47-31  /workspace/repr-preference-optimization/output...  \n",
       "3   2024-09-29_04-18-06  /workspace/repr-preference-optimization/output...  \n",
       "4   2024-09-29_04-42-54  /workspace/repr-preference-optimization/output...  \n",
       "5   2024-09-29_04-51-11  /workspace/repr-preference-optimization/output...  \n",
       "6   2024-09-29_05-25-58  /workspace/repr-preference-optimization/output...  \n",
       "7   2024-09-29_05-53-25  /workspace/repr-preference-optimization/output...  \n",
       "8   2024-09-29_06-10-34  /workspace/repr-preference-optimization/output...  \n",
       "9   2024-09-29_06-27-45  /workspace/repr-preference-optimization/output...  \n",
       "10  2024-09-29_06-45-42  /workspace/repr-preference-optimization/output...  \n",
       "11  2024-09-29_07-02-58  /workspace/repr-preference-optimization/output...  \n",
       "12  2024-09-29_07-20-05  /workspace/repr-preference-optimization/output...  \n",
       "13  2024-09-29_07-37-21  /workspace/repr-preference-optimization/output...  \n",
       "14  2024-09-29_07-54-37  /workspace/repr-preference-optimization/output...  \n",
       "15  2024-09-29_08-28-45  /workspace/repr-preference-optimization/output...  \n",
       "16  2024-09-29_08-45-53  /workspace/repr-preference-optimization/output...  \n",
       "17  2024-09-29_09-03-34  /workspace/repr-preference-optimization/output...  \n",
       "18  2024-09-29_09-21-29  /workspace/repr-preference-optimization/output...  \n",
       "19  2024-09-29_08-11-53  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = Path('../outputs/').resolve()\n",
    "import json\n",
    "f = out_dir.glob('princeton-nlp_Llama-3-Base-8B-SFT*/**/adapter_config.json')\n",
    "\n",
    "def path2dict(p):\n",
    "    assert p.is_dir()\n",
    "    d1 = p.name # adapter - ds\n",
    "    d2 = p.parent.parent.name # date\n",
    "    d3 = p.parent.parent.parent.name # base method ds\n",
    "    print(d3)\n",
    "    adapter = d1\n",
    "    time = d2\n",
    "    # base_method, adapter2, dsname2 = str(d3).split('_', 2)\n",
    "    # adapter2, dsname = dsname2.split('_', 1)\n",
    "\n",
    "    # base_model = PeftConfig.from_pretrained(p).base_model_name_or_path\n",
    "    c = json.load((p.parent.parent/'config.json').open())\n",
    "\n",
    "    return dict(adapter= adapter,\n",
    "                # adapter2 = adapter2,\n",
    "                dsname = c['dataset'],\n",
    "                # dsname2 = dsname2,\n",
    "                base_model = c['base_model'],\n",
    "                time = time,\n",
    "                path = p)\n",
    "\n",
    "\n",
    "\n",
    "df_paths = pd.DataFrame([path2dict(p.parent) for p in f])\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:16:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:47:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:18:06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:42:54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:51:11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:25:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:53:25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:10:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:27:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:45:42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:02:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:20:05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:37:21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:54:37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:11:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:28:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:45:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:03:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:21:29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 10:38:39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                  time                                               path  \n",
       "1  2024-09-29 03:16:31  /workspace/repr-preference-optimization/output...  \n",
       "2  2024-09-29 03:47:31  /workspace/repr-preference-optimization/output...  \n",
       "3  2024-09-29 04:18:06  /workspace/repr-preference-optimization/output...  \n",
       "4  2024-09-29 04:42:54  /workspace/repr-preference-optimization/output...  \n",
       "5  2024-09-29 04:51:11  /workspace/repr-preference-optimization/output...  \n",
       "6  2024-09-29 05:25:58  /workspace/repr-preference-optimization/output...  \n",
       "7  2024-09-29 05:53:25  /workspace/repr-preference-optimization/output...  \n",
       "8  2024-09-29 06:10:34  /workspace/repr-preference-optimization/output...  \n",
       "9  2024-09-29 06:27:45  /workspace/repr-preference-optimization/output...  \n",
       "10 2024-09-29 06:45:42  /workspace/repr-preference-optimization/output...  \n",
       "11 2024-09-29 07:02:58  /workspace/repr-preference-optimization/output...  \n",
       "12 2024-09-29 07:20:05  /workspace/repr-preference-optimization/output...  \n",
       "13 2024-09-29 07:37:21  /workspace/repr-preference-optimization/output...  \n",
       "14 2024-09-29 07:54:37  /workspace/repr-preference-optimization/output...  \n",
       "19 2024-09-29 08:11:53  /workspace/repr-preference-optimization/output...  \n",
       "15 2024-09-29 08:28:45  /workspace/repr-preference-optimization/output...  \n",
       "16 2024-09-29 08:45:53  /workspace/repr-preference-optimization/output...  \n",
       "17 2024-09-29 09:03:34  /workspace/repr-preference-optimization/output...  \n",
       "18 2024-09-29 09:21:29  /workspace/repr-preference-optimization/output...  \n",
       "0  2024-09-29 10:38:39  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paths.time = pd.to_datetime(df_paths.time, format='%Y-%m-%d_%H-%M-%S')\n",
    "df_paths = df_paths.sort_values('time')\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:16:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:47:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:18:06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:42:54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:51:11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:25:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:53:25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:10:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:27:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:45:42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:02:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:20:05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:37:21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:54:37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:11:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:28:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:45:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:03:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:21:29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 10:38:39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                  time                                               path  \n",
       "1  2024-09-29 03:16:31  /workspace/repr-preference-optimization/output...  \n",
       "2  2024-09-29 03:47:31  /workspace/repr-preference-optimization/output...  \n",
       "3  2024-09-29 04:18:06  /workspace/repr-preference-optimization/output...  \n",
       "4  2024-09-29 04:42:54  /workspace/repr-preference-optimization/output...  \n",
       "5  2024-09-29 04:51:11  /workspace/repr-preference-optimization/output...  \n",
       "6  2024-09-29 05:25:58  /workspace/repr-preference-optimization/output...  \n",
       "7  2024-09-29 05:53:25  /workspace/repr-preference-optimization/output...  \n",
       "8  2024-09-29 06:10:34  /workspace/repr-preference-optimization/output...  \n",
       "9  2024-09-29 06:27:45  /workspace/repr-preference-optimization/output...  \n",
       "10 2024-09-29 06:45:42  /workspace/repr-preference-optimization/output...  \n",
       "11 2024-09-29 07:02:58  /workspace/repr-preference-optimization/output...  \n",
       "12 2024-09-29 07:20:05  /workspace/repr-preference-optimization/output...  \n",
       "13 2024-09-29 07:37:21  /workspace/repr-preference-optimization/output...  \n",
       "14 2024-09-29 07:54:37  /workspace/repr-preference-optimization/output...  \n",
       "19 2024-09-29 08:11:53  /workspace/repr-preference-optimization/output...  \n",
       "15 2024-09-29 08:28:45  /workspace/repr-preference-optimization/output...  \n",
       "16 2024-09-29 08:45:53  /workspace/repr-preference-optimization/output...  \n",
       "17 2024-09-29 09:03:34  /workspace/repr-preference-optimization/output...  \n",
       "18 2024-09-29 09:21:29  /workspace/repr-preference-optimization/output...  \n",
       "0  2024-09-29 10:38:39  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = df_paths.base_model.unique()[0]\n",
    "base_model\n",
    "\n",
    "df_paths = df_paths.query('base_model == @base_model')\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = df_paths.groupby(['adapter', 'dsname']).last().path.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.interventions.config import ExperimentConfig\n",
    "args = ExperimentConfig(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660a3c0f062f40718c763f69fc8360ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = fs[0]\n",
    "peft_config = PeftConfig.from_pretrained(f)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "_base_model = AutoModelForCausalLM.from_pretrained(f)\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "    _base_model,\n",
    "    f, config=peft_config, adapter_name=f.stem)\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projgrad'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'dpo': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'projbp': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'projgrad': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all other adapters\n",
    "for f in fs[1:]:\n",
    "    model.load_adapter(f, f.stem)\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b23b1792244d588eb66397fa3d98af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/29.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf9587b14594bc89c90371da22819bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/443k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63333a0cf6604b3f9bf698146bbc2991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/181k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d553595448574d5fa6b16040c72a7d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ca728ed45e4dad914fceef8cb02644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f23c8b266634ef5a24625a0ddd06b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a07467971643e7a5dfe361cec6825f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/108k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9802cf77a6c4301acc7153f172d574a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320ee7c30acb440d81e0f41d9a3666f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/43.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2db0913f8f47c88c5d563de2be9e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1513 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3a97f67181466bb8f4acdf72be4617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/652 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c109e7b54d047848097624f69f96573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ce64bff9db41fb9fa3c6c18b819cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc80d7919c724ed6864de9fc62715a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/404k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81e8fc21a464cfaac0e0d5dcb099bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/373k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4efac476692423cb73375a88b99ffea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/13737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71362ef25e5e40a0a301d96037b402d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07173e6ea1cf4099b97f1ee9876bdbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94c5734bb2448f0b1e637b179b7aee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/531k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5993c54e32c64e5697ed37cc06a22ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b04caddc8744529a01d57592e2e764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/54.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abf21db92374e0f9742129ca25cfa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97d4f8cbf7b49ff895798e85dc0c739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1829038f7f9148a7933240748340830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/704 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a021cb89bc1415e812c1e9ba8c78059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/508k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05439ae24c6b42dab0300c8bbd8b4664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/117k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc084e558604e7bbbf4c088f9b9759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/115k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4074fd675a420eb2502f968af31c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2bbc2528b4477d9de1daf7a11c650a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635b44c77a3a4ef5a986f764786fa089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1633 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d3a42e971e4ace8785d446d8fc53b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c6163008f04170bcdb29a5a8697844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffec3ff07be4482b8c21b4178a962ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1773 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3270fb93ab4335ad84557da8347907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b441e24ed64589be79aa2ba91d6dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb42c24b9154c05a236d0f7c47f2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/48.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd8f1b7984142069d385019a24d9690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffffbe97ade4c24ae8b98c64edc2b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc020b6508d849a1b3b2357639bbe879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/83.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5f5c71431c42a5a44e88d3a75926e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641dee0711a94962846b7eae0d746457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e465b65efb944b8394a0dff06dc3bcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2569f00e51d44c6a1af053e1032e098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/59.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175b527c323e4ea4abd4b6ac6d9bbe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e88c1f9ffe47c89bec653e521c929f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42a4016cde14051a9ee0f98d14118b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e4c2b726d54bef9338c67b0ce77380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/274k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043adcc6541248a6acf3ad5a4ff7030b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/112k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd92db4ede9c4b1a8de4f4881c49dbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a666075844dc0af10949bef108cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5b1bc643e54b628f2dc92311df137f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/176k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0594201aa072437ba6ef384d9efe392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/79.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd91fc2b4d064ff9b62c9f821bbd7d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0715ffa3f64660957ede1b1de9d9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ## Eval\n",
    "# eval on ethics, GENIES, and our train dataset\n",
    "N = None\n",
    "N = 256\n",
    "dataset = 'us_history_textbook'\n",
    "datasets = [\n",
    "    load_dataset_n('wassname/genies_preferences', name=args.dataset, split='train', N=N),\n",
    "    load_dataset_n('wassname/genies_preferences', name=args.dataset, split='test', N=N),\n",
    "]\n",
    "datasets += dist2datasets(GENIES, N=N, source=[args.dataset]) # our hard OOS test\n",
    "datasets += get_ethics_datasets(N=N)\n",
    "datasets += [load_dataset_n('wassname/genies_preferences', name=name, split='test', N=N) for name in ['math_make_questions', 'truthful_qa', 'wrong_arc', 'ranking_logic',\n",
    " 'math', 'sycophancy_mimicry'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 64\n",
       " })]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d1c3fa11141a9b79e920fdc0ca6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?dataset/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "res, df_res2 = evaluate_model(model=model, \n",
    "                                tokenizer=tokenizer, \n",
    "                                datasets=datasets,\n",
    "                                    batch_size=args.batch_size*2,\n",
    "                                    bf16=True,\n",
    "                                    torch_empty_cache_steps=100, verbowse=args.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "ds_alias = OrderedDict(\n",
    "    list(zip([\"train\", \"test\", \"oos\", \"rnd\"], [ds2name(d) for d in datasets]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import parse_eval\n",
    "from reprpo.gen import get_model_generations, display_gen\n",
    "\n",
    "def rename_columns(df):\n",
    "    df.columns = [d.replace(\"genie_dpo-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.replace(\"genies_preferences-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.replace(\"ethics_expression_preferences-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.split(f\"[:{N}]\")[0] for d in df.columns]\n",
    "    df.columns = [d.split(f\"-test\")[0] for d in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "      <th>us_history_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          commonsense  deontology   justice  utilitarianism      math  \\\n",
       "adapter                                                                 \n",
       "base         0.671875    0.625000  0.359375        0.421875  0.859375   \n",
       "default      0.656250    0.625000  0.312500        0.437500  0.890625   \n",
       "dpo          0.656250    0.625000  0.312500        0.437500  0.890625   \n",
       "projbp       0.656250    0.640625  0.343750        0.421875  0.906250   \n",
       "projgrad     0.687500    0.609375  0.296875        0.421875  0.906250   \n",
       "\n",
       "          math_make_questions  ranking_logic  sycophancy_mimicry  truthful_qa  \\\n",
       "adapter                                                                         \n",
       "base                 0.984375       0.593750            0.328125     0.546875   \n",
       "default              0.984375       0.656250            0.234375     0.781250   \n",
       "dpo                  0.984375       0.656250            0.234375     0.781250   \n",
       "projbp               0.968750       0.671875            0.218750     0.718750   \n",
       "projgrad             0.968750       0.640625            0.187500     0.765625   \n",
       "\n",
       "          us_history_textbook  us_history_textbook-train  wrong_arc  \\\n",
       "adapter                                                               \n",
       "base                      1.0                        1.0   0.265625   \n",
       "default                   1.0                        1.0   0.140625   \n",
       "dpo                       1.0                        1.0   0.140625   \n",
       "projbp                    1.0                        1.0   0.156250   \n",
       "projgrad                  1.0                        1.0   0.140625   \n",
       "\n",
       "          us_history_fiction  \n",
       "adapter                       \n",
       "base                0.750000  \n",
       "default             0.812500  \n",
       "dpo                 0.812500  \n",
       "projbp              0.890625  \n",
       "projgrad            0.843750  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_name = df_res2[[\"adapter\"]].query('adapter!=\"base\"').values[0, 0]\n",
    "\n",
    "df_res = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .T\n",
    ")\n",
    "df_res = rename_columns(df_res)\n",
    "\n",
    "print('accuracy')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity of chosen response\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "      <th>us_history_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>4.011998e+03</td>\n",
       "      <td>202.782104</td>\n",
       "      <td>259.957062</td>\n",
       "      <td>2.900816e+02</td>\n",
       "      <td>3.340670</td>\n",
       "      <td>5.468517</td>\n",
       "      <td>18.129017</td>\n",
       "      <td>6.490664</td>\n",
       "      <td>4.416421e+01</td>\n",
       "      <td>3.326440</td>\n",
       "      <td>3.194985</td>\n",
       "      <td>1.409406e+03</td>\n",
       "      <td>3.093051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>2.922118e+06</td>\n",
       "      <td>6725.777832</td>\n",
       "      <td>43791.367188</td>\n",
       "      <td>1.772942e+05</td>\n",
       "      <td>287.549133</td>\n",
       "      <td>1312.053833</td>\n",
       "      <td>29622.550781</td>\n",
       "      <td>857.691040</td>\n",
       "      <td>6.026577e+09</td>\n",
       "      <td>2382.266846</td>\n",
       "      <td>1735.492188</td>\n",
       "      <td>1.336507e+14</td>\n",
       "      <td>1628.402710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>2.922118e+06</td>\n",
       "      <td>6725.777832</td>\n",
       "      <td>43791.367188</td>\n",
       "      <td>1.772942e+05</td>\n",
       "      <td>287.549133</td>\n",
       "      <td>1312.053833</td>\n",
       "      <td>29622.550781</td>\n",
       "      <td>857.691040</td>\n",
       "      <td>6.026577e+09</td>\n",
       "      <td>2382.266846</td>\n",
       "      <td>1735.492188</td>\n",
       "      <td>1.336507e+14</td>\n",
       "      <td>1628.402710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>4.639360e+07</td>\n",
       "      <td>9275.056641</td>\n",
       "      <td>33628.765625</td>\n",
       "      <td>7.364031e+05</td>\n",
       "      <td>202.406525</td>\n",
       "      <td>657.913757</td>\n",
       "      <td>17236.373047</td>\n",
       "      <td>1085.653931</td>\n",
       "      <td>7.351039e+07</td>\n",
       "      <td>1241.406372</td>\n",
       "      <td>1221.444092</td>\n",
       "      <td>5.175616e+14</td>\n",
       "      <td>437.433929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>2.192658e+06</td>\n",
       "      <td>6798.495117</td>\n",
       "      <td>99186.109375</td>\n",
       "      <td>1.963471e+07</td>\n",
       "      <td>48.358810</td>\n",
       "      <td>229.375946</td>\n",
       "      <td>548.673828</td>\n",
       "      <td>388.404022</td>\n",
       "      <td>1.534295e+05</td>\n",
       "      <td>101.440453</td>\n",
       "      <td>76.747536</td>\n",
       "      <td>9.441994e+11</td>\n",
       "      <td>92.343445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           commonsense   deontology       justice  utilitarianism        math  \\\n",
       "adapter                                                                         \n",
       "base      4.011998e+03   202.782104    259.957062    2.900816e+02    3.340670   \n",
       "default   2.922118e+06  6725.777832  43791.367188    1.772942e+05  287.549133   \n",
       "dpo       2.922118e+06  6725.777832  43791.367188    1.772942e+05  287.549133   \n",
       "projbp    4.639360e+07  9275.056641  33628.765625    7.364031e+05  202.406525   \n",
       "projgrad  2.192658e+06  6798.495117  99186.109375    1.963471e+07   48.358810   \n",
       "\n",
       "          math_make_questions  ranking_logic  sycophancy_mimicry  \\\n",
       "adapter                                                            \n",
       "base                 5.468517      18.129017            6.490664   \n",
       "default           1312.053833   29622.550781          857.691040   \n",
       "dpo               1312.053833   29622.550781          857.691040   \n",
       "projbp             657.913757   17236.373047         1085.653931   \n",
       "projgrad           229.375946     548.673828          388.404022   \n",
       "\n",
       "           truthful_qa  us_history_textbook  us_history_textbook-train  \\\n",
       "adapter                                                                  \n",
       "base      4.416421e+01             3.326440                   3.194985   \n",
       "default   6.026577e+09          2382.266846                1735.492188   \n",
       "dpo       6.026577e+09          2382.266846                1735.492188   \n",
       "projbp    7.351039e+07          1241.406372                1221.444092   \n",
       "projgrad  1.534295e+05           101.440453                  76.747536   \n",
       "\n",
       "             wrong_arc  us_history_fiction  \n",
       "adapter                                     \n",
       "base      1.409406e+03            3.093051  \n",
       "default   1.336507e+14         1628.402710  \n",
       "dpo       1.336507e+14         1628.402710  \n",
       "projbp    5.175616e+14          437.433929  \n",
       "projgrad  9.441994e+11           92.343445  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_logp = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"_chosen_ppl\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .T\n",
    ")\n",
    "df_res_logp = rename_columns(df_res_logp)\n",
    "print('perplexity of chosen response')\n",
    "df_res_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo of chosen response\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "      <th>us_history_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>3.123202</td>\n",
       "      <td>4.864337</td>\n",
       "      <td>-7.912639</td>\n",
       "      <td>-0.761393</td>\n",
       "      <td>21.573036</td>\n",
       "      <td>79.290901</td>\n",
       "      <td>6.123348</td>\n",
       "      <td>-29.201908</td>\n",
       "      <td>25.938736</td>\n",
       "      <td>322.582062</td>\n",
       "      <td>365.516296</td>\n",
       "      <td>-28.241354</td>\n",
       "      <td>162.247421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>3.123202</td>\n",
       "      <td>4.864337</td>\n",
       "      <td>-7.912639</td>\n",
       "      <td>-0.761393</td>\n",
       "      <td>21.573036</td>\n",
       "      <td>79.290901</td>\n",
       "      <td>6.123348</td>\n",
       "      <td>-29.201908</td>\n",
       "      <td>25.938736</td>\n",
       "      <td>322.582062</td>\n",
       "      <td>365.516296</td>\n",
       "      <td>-28.241354</td>\n",
       "      <td>162.247421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>3.856024</td>\n",
       "      <td>5.367977</td>\n",
       "      <td>-6.655376</td>\n",
       "      <td>-0.903116</td>\n",
       "      <td>20.462229</td>\n",
       "      <td>76.824722</td>\n",
       "      <td>6.827622</td>\n",
       "      <td>-23.482504</td>\n",
       "      <td>24.038534</td>\n",
       "      <td>311.224731</td>\n",
       "      <td>329.704010</td>\n",
       "      <td>-22.393742</td>\n",
       "      <td>183.724777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>4.484490</td>\n",
       "      <td>5.238854</td>\n",
       "      <td>-8.555972</td>\n",
       "      <td>-1.706129</td>\n",
       "      <td>17.713858</td>\n",
       "      <td>63.965103</td>\n",
       "      <td>3.830432</td>\n",
       "      <td>-36.790810</td>\n",
       "      <td>23.083588</td>\n",
       "      <td>255.557251</td>\n",
       "      <td>263.538116</td>\n",
       "      <td>-25.465775</td>\n",
       "      <td>129.078232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          commonsense  deontology   justice  utilitarianism       math  \\\n",
       "adapter                                                                  \n",
       "base         0.000000    0.000000  0.000000        0.000000   0.000000   \n",
       "default      3.123202    4.864337 -7.912639       -0.761393  21.573036   \n",
       "dpo          3.123202    4.864337 -7.912639       -0.761393  21.573036   \n",
       "projbp       3.856024    5.367977 -6.655376       -0.903116  20.462229   \n",
       "projgrad     4.484490    5.238854 -8.555972       -1.706129  17.713858   \n",
       "\n",
       "          math_make_questions  ranking_logic  sycophancy_mimicry  truthful_qa  \\\n",
       "adapter                                                                         \n",
       "base                 0.000000       0.000000            0.000000     0.000000   \n",
       "default             79.290901       6.123348          -29.201908    25.938736   \n",
       "dpo                 79.290901       6.123348          -29.201908    25.938736   \n",
       "projbp              76.824722       6.827622          -23.482504    24.038534   \n",
       "projgrad            63.965103       3.830432          -36.790810    23.083588   \n",
       "\n",
       "          us_history_textbook  us_history_textbook-train  wrong_arc  \\\n",
       "adapter                                                               \n",
       "base                 0.000000                   0.000000   0.000000   \n",
       "default            322.582062                 365.516296 -28.241354   \n",
       "dpo                322.582062                 365.516296 -28.241354   \n",
       "projbp             311.224731                 329.704010 -22.393742   \n",
       "projgrad           255.557251                 263.538116 -25.465775   \n",
       "\n",
       "          us_history_fiction  \n",
       "adapter                       \n",
       "base                0.000000  \n",
       "default           162.247421  \n",
       "dpo               162.247421  \n",
       "projbp            183.724777  \n",
       "projgrad          129.078232  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res2[\"logratios\"] = df_res2[\"_chosen_logps\"] - df_res2[\"_rejected_logps\"]\n",
    "df_logratios = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\", \"ds_i\"])[\"logratios\"].mean().unstack(0)\n",
    ")\n",
    "ref_logratios = df_logratios.loc[\"base\"]\n",
    "preference_logp_gain_vs_ref = (df_logratios - ref_logratios)#.mean('ds_i')\n",
    "preference_logp_gain_vs_ref = preference_logp_gain_vs_ref.groupby('adapter').mean()\n",
    "preference_logp_gain_vs_ref = rename_columns(preference_logp_gain_vs_ref)\n",
    "print('how much chosen response is prefered')\n",
    "preference_logp_gain_vs_ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
