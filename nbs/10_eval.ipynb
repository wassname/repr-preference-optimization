{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.evaluation import evaluate_model\n",
    "from open_pref_eval.plot.radar import radar_plot\n",
    "from open_pref_eval.datasets.genies import dist2datasets, GENIES\n",
    "from open_pref_eval.datasets.ethics import get_ethics_datasets\n",
    "from open_pref_eval.datasets import load_dataset_n\n",
    "from open_pref_eval.datasets import ds2name\n",
    "from open_pref_eval.plot.radar import radar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reprpo.models.load import load_model, print_trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Path('/workspace/repr-preference-optimization/outputs/princeton-nlp_Llama-3-Base-8B-SFT_HRAKL_us_history_textbook/2024-09-18_10-34-31-adapter/HRAKL-us_history_textbook')\n",
    "sorted(f.glob('**/*'))\n",
    "\n",
    "# TODO turn into a df we can filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from peft import AutoPeftModelForCausalLM, get_peft_model, PeftConfig, PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princeton-nlp_Llama-3-Base-8B-SFT_projbp_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_projgrad_us_history_textbook\n",
      "princeton-nlp_Llama-3-Base-8B-SFT_dpo_us_history_textbook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_10-38-39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_03-16-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_03-47-31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-18-06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-42-54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_04-51-11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_05-25-58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_05-53-25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-10-34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-27-45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_06-45-42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-02-58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-20-05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-37-21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_07-54-37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-28-45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-45-53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_09-03-34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_09-21-29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29_08-11-53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                   time                                               path  \n",
       "0   2024-09-29_10-38-39  /workspace/repr-preference-optimization/output...  \n",
       "1   2024-09-29_03-16-31  /workspace/repr-preference-optimization/output...  \n",
       "2   2024-09-29_03-47-31  /workspace/repr-preference-optimization/output...  \n",
       "3   2024-09-29_04-18-06  /workspace/repr-preference-optimization/output...  \n",
       "4   2024-09-29_04-42-54  /workspace/repr-preference-optimization/output...  \n",
       "5   2024-09-29_04-51-11  /workspace/repr-preference-optimization/output...  \n",
       "6   2024-09-29_05-25-58  /workspace/repr-preference-optimization/output...  \n",
       "7   2024-09-29_05-53-25  /workspace/repr-preference-optimization/output...  \n",
       "8   2024-09-29_06-10-34  /workspace/repr-preference-optimization/output...  \n",
       "9   2024-09-29_06-27-45  /workspace/repr-preference-optimization/output...  \n",
       "10  2024-09-29_06-45-42  /workspace/repr-preference-optimization/output...  \n",
       "11  2024-09-29_07-02-58  /workspace/repr-preference-optimization/output...  \n",
       "12  2024-09-29_07-20-05  /workspace/repr-preference-optimization/output...  \n",
       "13  2024-09-29_07-37-21  /workspace/repr-preference-optimization/output...  \n",
       "14  2024-09-29_07-54-37  /workspace/repr-preference-optimization/output...  \n",
       "15  2024-09-29_08-28-45  /workspace/repr-preference-optimization/output...  \n",
       "16  2024-09-29_08-45-53  /workspace/repr-preference-optimization/output...  \n",
       "17  2024-09-29_09-03-34  /workspace/repr-preference-optimization/output...  \n",
       "18  2024-09-29_09-21-29  /workspace/repr-preference-optimization/output...  \n",
       "19  2024-09-29_08-11-53  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = Path('../outputs/').resolve()\n",
    "import json\n",
    "f = out_dir.glob('princeton-nlp_Llama-3-Base-8B-SFT*/**/adapter_config.json')\n",
    "\n",
    "def path2dict(p):\n",
    "    assert p.is_dir()\n",
    "    d1 = p.name # adapter - ds\n",
    "    d2 = p.parent.parent.name # date\n",
    "    d3 = p.parent.parent.parent.name # base method ds\n",
    "    print(d3)\n",
    "    adapter = d1\n",
    "    time = d2\n",
    "    # base_method, adapter2, dsname2 = str(d3).split('_', 2)\n",
    "    # adapter2, dsname = dsname2.split('_', 1)\n",
    "\n",
    "    # base_model = PeftConfig.from_pretrained(p).base_model_name_or_path\n",
    "    c = json.load((p.parent.parent/'config.json').open())\n",
    "\n",
    "    return dict(adapter= adapter,\n",
    "                # adapter2 = adapter2,\n",
    "                dsname = c['dataset'],\n",
    "                # dsname2 = dsname2,\n",
    "                base_model = c['base_model'],\n",
    "                time = time,\n",
    "                path = p)\n",
    "\n",
    "\n",
    "\n",
    "df_paths = pd.DataFrame([path2dict(p.parent) for p in f])\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:16:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:47:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:18:06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:42:54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:51:11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:25:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:53:25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:10:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:27:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:45:42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:02:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:20:05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:37:21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:54:37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:11:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:28:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:45:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:03:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:21:29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 10:38:39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                  time                                               path  \n",
       "1  2024-09-29 03:16:31  /workspace/repr-preference-optimization/output...  \n",
       "2  2024-09-29 03:47:31  /workspace/repr-preference-optimization/output...  \n",
       "3  2024-09-29 04:18:06  /workspace/repr-preference-optimization/output...  \n",
       "4  2024-09-29 04:42:54  /workspace/repr-preference-optimization/output...  \n",
       "5  2024-09-29 04:51:11  /workspace/repr-preference-optimization/output...  \n",
       "6  2024-09-29 05:25:58  /workspace/repr-preference-optimization/output...  \n",
       "7  2024-09-29 05:53:25  /workspace/repr-preference-optimization/output...  \n",
       "8  2024-09-29 06:10:34  /workspace/repr-preference-optimization/output...  \n",
       "9  2024-09-29 06:27:45  /workspace/repr-preference-optimization/output...  \n",
       "10 2024-09-29 06:45:42  /workspace/repr-preference-optimization/output...  \n",
       "11 2024-09-29 07:02:58  /workspace/repr-preference-optimization/output...  \n",
       "12 2024-09-29 07:20:05  /workspace/repr-preference-optimization/output...  \n",
       "13 2024-09-29 07:37:21  /workspace/repr-preference-optimization/output...  \n",
       "14 2024-09-29 07:54:37  /workspace/repr-preference-optimization/output...  \n",
       "19 2024-09-29 08:11:53  /workspace/repr-preference-optimization/output...  \n",
       "15 2024-09-29 08:28:45  /workspace/repr-preference-optimization/output...  \n",
       "16 2024-09-29 08:45:53  /workspace/repr-preference-optimization/output...  \n",
       "17 2024-09-29 09:03:34  /workspace/repr-preference-optimization/output...  \n",
       "18 2024-09-29 09:21:29  /workspace/repr-preference-optimization/output...  \n",
       "0  2024-09-29 10:38:39  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paths.time = pd.to_datetime(df_paths.time, format='%Y-%m-%d_%H-%M-%S')\n",
    "df_paths = df_paths.sort_values('time')\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>dsname</th>\n",
       "      <th>base_model</th>\n",
       "      <th>time</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:16:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 03:47:31</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:18:06</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:42:54</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 04:51:11</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:25:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 05:53:25</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:10:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:27:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 06:45:42</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:02:58</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:20:05</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:37:21</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 07:54:37</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dpo</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:11:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:28:45</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 08:45:53</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:03:34</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>projgrad</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 09:21:29</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>projbp</td>\n",
       "      <td>us_history_textbook</td>\n",
       "      <td>princeton-nlp/Llama-3-Base-8B-SFT</td>\n",
       "      <td>2024-09-29 10:38:39</td>\n",
       "      <td>/workspace/repr-preference-optimization/output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adapter               dsname                         base_model  \\\n",
       "1   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "2   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "3   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "4   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "5   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "6   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "7   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "8   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "9   projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "10  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "11  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "12  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "13  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "14  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "19       dpo  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "15  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "16  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "17  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "18  projgrad  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "0     projbp  us_history_textbook  princeton-nlp/Llama-3-Base-8B-SFT   \n",
       "\n",
       "                  time                                               path  \n",
       "1  2024-09-29 03:16:31  /workspace/repr-preference-optimization/output...  \n",
       "2  2024-09-29 03:47:31  /workspace/repr-preference-optimization/output...  \n",
       "3  2024-09-29 04:18:06  /workspace/repr-preference-optimization/output...  \n",
       "4  2024-09-29 04:42:54  /workspace/repr-preference-optimization/output...  \n",
       "5  2024-09-29 04:51:11  /workspace/repr-preference-optimization/output...  \n",
       "6  2024-09-29 05:25:58  /workspace/repr-preference-optimization/output...  \n",
       "7  2024-09-29 05:53:25  /workspace/repr-preference-optimization/output...  \n",
       "8  2024-09-29 06:10:34  /workspace/repr-preference-optimization/output...  \n",
       "9  2024-09-29 06:27:45  /workspace/repr-preference-optimization/output...  \n",
       "10 2024-09-29 06:45:42  /workspace/repr-preference-optimization/output...  \n",
       "11 2024-09-29 07:02:58  /workspace/repr-preference-optimization/output...  \n",
       "12 2024-09-29 07:20:05  /workspace/repr-preference-optimization/output...  \n",
       "13 2024-09-29 07:37:21  /workspace/repr-preference-optimization/output...  \n",
       "14 2024-09-29 07:54:37  /workspace/repr-preference-optimization/output...  \n",
       "19 2024-09-29 08:11:53  /workspace/repr-preference-optimization/output...  \n",
       "15 2024-09-29 08:28:45  /workspace/repr-preference-optimization/output...  \n",
       "16 2024-09-29 08:45:53  /workspace/repr-preference-optimization/output...  \n",
       "17 2024-09-29 09:03:34  /workspace/repr-preference-optimization/output...  \n",
       "18 2024-09-29 09:21:29  /workspace/repr-preference-optimization/output...  \n",
       "0  2024-09-29 10:38:39  /workspace/repr-preference-optimization/output...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = df_paths.base_model.unique()[0]\n",
    "base_model\n",
    "\n",
    "df_paths = df_paths.query('base_model == @base_model')\n",
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = df_paths.groupby(['adapter', 'dsname']).last().path.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.interventions.config import ExperimentConfig\n",
    "args = ExperimentConfig(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74571d627d2b4cdbbe62432699c61cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'default': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'dpo': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = fs[0]\n",
    "peft_config = PeftConfig.from_pretrained(f)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "_base_model = AutoModelForCausalLM.from_pretrained(f)\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "    _base_model,\n",
    "    f, config=peft_config, adapter_name=f.stem)\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dpo'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'dpo': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'projbp': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False)),\n",
       " 'projgrad': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='princeton-nlp/Llama-3-Base-8B-SFT', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=64, target_modules={'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all other adapters\n",
    "for f in fs[1:]:\n",
    "    model.load_adapter(f, f.stem)\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b89d3d19ed845e8b17d803d87a506eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88afd470eea4f13b2620ef41412c47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/48.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1901652e9d934e3f8fa75bcc7e66d6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea887d791834c01825a26a2b438c475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f681e42706c64ea497897387ecb4ac6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/83.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba6839142a94d48b4559f2659dba746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b587aebb58418ea6216b147d8c52a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c5e9063290439e80982acd278907f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83ac4c9203045ebba3253187260d71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/59.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e06058f5b68408998dd8ff7b5665339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea4ef1c44f741efb6b8f79b96956233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc8ca2e1e874fdfaed424de608d2a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6d1963b0f642c08eb67156a5a8b4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/274k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a54cd2f1cf4810bb33d751d9bd86c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/112k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ff70e8a4df41a28365a970209b13f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc8581a90b541bda1059c82c9a9d2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef98527f22c41e9a6a5baf25afbca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/176k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ac589ab193472486217b79ad7db2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/79.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4aca6db4b4ac2a930ee3353e02557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9589e5b8d7e40ee92670f92059378aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ## Eval\n",
    "# eval on ethics, GENIES, and our train dataset\n",
    "N = None\n",
    "N = 256\n",
    "dataset = 'us_history_textbook'\n",
    "datasets = [\n",
    "    load_dataset_n('wassname/genies_preferences', name=args.dataset, split='train', N=N),\n",
    "    load_dataset_n('wassname/genies_preferences', name=args.dataset, split='test', N=N),\n",
    "]\n",
    "datasets += dist2datasets(GENIES, N=N, source=[args.dataset]) # our hard OOS test\n",
    "datasets += get_ethics_datasets(N=N)\n",
    "datasets += [load_dataset_n('wassname/genies_preferences', name=name, split='test', N=N) for name in ['math_make_questions', 'truthful_qa', 'wrong_arc', 'ranking_logic',\n",
    " 'math', 'sycophancy_mimicry'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 250\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'chosen', 'rejected', 'i'],\n",
       "     num_rows: 250\n",
       " })]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e573e286fa5e4c619bbb020b83df3e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?dataset/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res, df_res2 = evaluate_model(model=model, \n",
    "                                tokenizer=tokenizer, \n",
    "                                datasets=datasets,\n",
    "                                    batch_size=args.batch_size*2,\n",
    "                                    bf16=True,\n",
    "                                    torch_empty_cache_steps=100, verbose=args.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "ds_alias = OrderedDict(\n",
    "    list(zip([\"train\", \"test\", \"oos\", \"rnd\"], [ds2name(d) for d in datasets]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import parse_eval\n",
    "from reprpo.gen import get_model_generations, display_gen\n",
    "\n",
    "def rename_columns(df):\n",
    "    df.columns = [d.replace(\"genie_dpo-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.replace(\"genies_preferences-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.replace(\"ethics_expression_preferences-\", \"\") for d in df.columns]\n",
    "    df.columns = [d.split(f\"[:{N}]\")[0] for d in df.columns]\n",
    "    df.columns = [d.split(f\"-test\")[0] for d in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_fiction</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.347656</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.792969</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.621094</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.621094</td>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          commonsense  deontology   justice  utilitarianism      math  \\\n",
       "adapter                                                                 \n",
       "base         0.652344    0.582031  0.347656        0.480469  0.867188   \n",
       "default      0.675781    0.605469  0.339844        0.496094  0.886719   \n",
       "dpo          0.675781    0.605469  0.339844        0.496094  0.886719   \n",
       "projbp       0.683594    0.617188  0.355469        0.480469  0.875000   \n",
       "projgrad     0.675781    0.605469  0.343750        0.492188  0.875000   \n",
       "\n",
       "          math_make_questions  ranking_logic  sycophancy_mimicry  truthful_qa  \\\n",
       "adapter                                                                         \n",
       "base                 0.972656       0.675781               0.276     0.402344   \n",
       "default              0.980469       0.710938               0.216     0.621094   \n",
       "dpo                  0.980469       0.710938               0.216     0.621094   \n",
       "projbp               0.980469       0.757812               0.228     0.593750   \n",
       "projgrad             0.972656       0.722656               0.172     0.554688   \n",
       "\n",
       "          us_history_fiction  us_history_textbook  us_history_textbook-train  \\\n",
       "adapter                                                                        \n",
       "base                0.792969             0.988281                   0.980469   \n",
       "default             0.832031             0.988281                   1.000000   \n",
       "dpo                 0.832031             0.988281                   1.000000   \n",
       "projbp              0.859375             0.992188                   1.000000   \n",
       "projgrad            0.851562             0.996094                   1.000000   \n",
       "\n",
       "          wrong_arc  \n",
       "adapter              \n",
       "base          0.240  \n",
       "default       0.188  \n",
       "dpo           0.188  \n",
       "projbp        0.188  \n",
       "projgrad      0.152  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_name = df_res2[[\"adapter\"]].query('adapter!=\"base\"').values[0, 0]\n",
    "\n",
    "df_res = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .T\n",
    ")\n",
    "df_res = rename_columns(df_res)\n",
    "\n",
    "print('accuracy')\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8a5e7_row0_col0, #T_8a5e7_row0_col1, #T_8a5e7_row0_col3, #T_8a5e7_row0_col4, #T_8a5e7_row0_col5, #T_8a5e7_row0_col6, #T_8a5e7_row0_col8, #T_8a5e7_row0_col9, #T_8a5e7_row0_col10, #T_8a5e7_row0_col11, #T_8a5e7_row1_col2, #T_8a5e7_row1_col10, #T_8a5e7_row2_col2, #T_8a5e7_row2_col10, #T_8a5e7_row3_col3, #T_8a5e7_row4_col5, #T_8a5e7_row4_col7, #T_8a5e7_row4_col12 {\n",
       "  background-color: #ff0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row0_col2, #T_8a5e7_row3_col10 {\n",
       "  background-color: #fefeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row0_col7, #T_8a5e7_row0_col12, #T_8a5e7_row1_col3, #T_8a5e7_row1_col4, #T_8a5e7_row1_col5, #T_8a5e7_row1_col8, #T_8a5e7_row1_col11, #T_8a5e7_row2_col3, #T_8a5e7_row2_col4, #T_8a5e7_row2_col5, #T_8a5e7_row2_col8, #T_8a5e7_row2_col11, #T_8a5e7_row3_col0, #T_8a5e7_row3_col1, #T_8a5e7_row3_col2, #T_8a5e7_row3_col5, #T_8a5e7_row3_col6, #T_8a5e7_row3_col9, #T_8a5e7_row3_col11, #T_8a5e7_row4_col10, #T_8a5e7_row4_col11 {\n",
       "  background-color: #0000ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row1_col0, #T_8a5e7_row2_col0, #T_8a5e7_row4_col0, #T_8a5e7_row4_col3 {\n",
       "  background-color: #7e7eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row1_col1, #T_8a5e7_row2_col1, #T_8a5e7_row4_col1 {\n",
       "  background-color: #aaaaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row1_col6, #T_8a5e7_row2_col6 {\n",
       "  background-color: #ffdada;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row1_col7, #T_8a5e7_row2_col7 {\n",
       "  background-color: #ffd8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row1_col9, #T_8a5e7_row2_col9 {\n",
       "  background-color: #d2d2ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row1_col12, #T_8a5e7_row2_col12, #T_8a5e7_row3_col12 {\n",
       "  background-color: #ffd0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row3_col4, #T_8a5e7_row4_col4 {\n",
       "  background-color: #ffcccc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row3_col7 {\n",
       "  background-color: #ececff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row3_col8 {\n",
       "  background-color: #3e3eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row4_col2 {\n",
       "  background-color: #ff8080;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row4_col6 {\n",
       "  background-color: #dadaff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a5e7_row4_col8 {\n",
       "  background-color: #9a9aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a5e7_row4_col9 {\n",
       "  background-color: #3c3cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8a5e7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8a5e7_level0_col0\" class=\"col_heading level0 col0\" >commonsense</th>\n",
       "      <th id=\"T_8a5e7_level0_col1\" class=\"col_heading level0 col1\" >deontology</th>\n",
       "      <th id=\"T_8a5e7_level0_col2\" class=\"col_heading level0 col2\" >justice</th>\n",
       "      <th id=\"T_8a5e7_level0_col3\" class=\"col_heading level0 col3\" >utilitarianism</th>\n",
       "      <th id=\"T_8a5e7_level0_col4\" class=\"col_heading level0 col4\" >math</th>\n",
       "      <th id=\"T_8a5e7_level0_col5\" class=\"col_heading level0 col5\" >math_make_questions</th>\n",
       "      <th id=\"T_8a5e7_level0_col6\" class=\"col_heading level0 col6\" >ranking_logic</th>\n",
       "      <th id=\"T_8a5e7_level0_col7\" class=\"col_heading level0 col7\" >sycophancy_mimicry</th>\n",
       "      <th id=\"T_8a5e7_level0_col8\" class=\"col_heading level0 col8\" >truthful_qa</th>\n",
       "      <th id=\"T_8a5e7_level0_col9\" class=\"col_heading level0 col9\" >us_history_fiction</th>\n",
       "      <th id=\"T_8a5e7_level0_col10\" class=\"col_heading level0 col10\" >us_history_textbook</th>\n",
       "      <th id=\"T_8a5e7_level0_col11\" class=\"col_heading level0 col11\" >us_history_textbook-train</th>\n",
       "      <th id=\"T_8a5e7_level0_col12\" class=\"col_heading level0 col12\" >wrong_arc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >adapter</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8a5e7_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_8a5e7_row0_col0\" class=\"data row0 col0\" >0.652344</td>\n",
       "      <td id=\"T_8a5e7_row0_col1\" class=\"data row0 col1\" >0.582031</td>\n",
       "      <td id=\"T_8a5e7_row0_col2\" class=\"data row0 col2\" >0.347656</td>\n",
       "      <td id=\"T_8a5e7_row0_col3\" class=\"data row0 col3\" >0.480469</td>\n",
       "      <td id=\"T_8a5e7_row0_col4\" class=\"data row0 col4\" >0.867188</td>\n",
       "      <td id=\"T_8a5e7_row0_col5\" class=\"data row0 col5\" >0.972656</td>\n",
       "      <td id=\"T_8a5e7_row0_col6\" class=\"data row0 col6\" >0.675781</td>\n",
       "      <td id=\"T_8a5e7_row0_col7\" class=\"data row0 col7\" >0.276000</td>\n",
       "      <td id=\"T_8a5e7_row0_col8\" class=\"data row0 col8\" >0.402344</td>\n",
       "      <td id=\"T_8a5e7_row0_col9\" class=\"data row0 col9\" >0.792969</td>\n",
       "      <td id=\"T_8a5e7_row0_col10\" class=\"data row0 col10\" >0.988281</td>\n",
       "      <td id=\"T_8a5e7_row0_col11\" class=\"data row0 col11\" >0.980469</td>\n",
       "      <td id=\"T_8a5e7_row0_col12\" class=\"data row0 col12\" >0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a5e7_level0_row1\" class=\"row_heading level0 row1\" >default</th>\n",
       "      <td id=\"T_8a5e7_row1_col0\" class=\"data row1 col0\" >0.675781</td>\n",
       "      <td id=\"T_8a5e7_row1_col1\" class=\"data row1 col1\" >0.605469</td>\n",
       "      <td id=\"T_8a5e7_row1_col2\" class=\"data row1 col2\" >0.339844</td>\n",
       "      <td id=\"T_8a5e7_row1_col3\" class=\"data row1 col3\" >0.496094</td>\n",
       "      <td id=\"T_8a5e7_row1_col4\" class=\"data row1 col4\" >0.886719</td>\n",
       "      <td id=\"T_8a5e7_row1_col5\" class=\"data row1 col5\" >0.980469</td>\n",
       "      <td id=\"T_8a5e7_row1_col6\" class=\"data row1 col6\" >0.710938</td>\n",
       "      <td id=\"T_8a5e7_row1_col7\" class=\"data row1 col7\" >0.216000</td>\n",
       "      <td id=\"T_8a5e7_row1_col8\" class=\"data row1 col8\" >0.621094</td>\n",
       "      <td id=\"T_8a5e7_row1_col9\" class=\"data row1 col9\" >0.832031</td>\n",
       "      <td id=\"T_8a5e7_row1_col10\" class=\"data row1 col10\" >0.988281</td>\n",
       "      <td id=\"T_8a5e7_row1_col11\" class=\"data row1 col11\" >1.000000</td>\n",
       "      <td id=\"T_8a5e7_row1_col12\" class=\"data row1 col12\" >0.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a5e7_level0_row2\" class=\"row_heading level0 row2\" >dpo</th>\n",
       "      <td id=\"T_8a5e7_row2_col0\" class=\"data row2 col0\" >0.675781</td>\n",
       "      <td id=\"T_8a5e7_row2_col1\" class=\"data row2 col1\" >0.605469</td>\n",
       "      <td id=\"T_8a5e7_row2_col2\" class=\"data row2 col2\" >0.339844</td>\n",
       "      <td id=\"T_8a5e7_row2_col3\" class=\"data row2 col3\" >0.496094</td>\n",
       "      <td id=\"T_8a5e7_row2_col4\" class=\"data row2 col4\" >0.886719</td>\n",
       "      <td id=\"T_8a5e7_row2_col5\" class=\"data row2 col5\" >0.980469</td>\n",
       "      <td id=\"T_8a5e7_row2_col6\" class=\"data row2 col6\" >0.710938</td>\n",
       "      <td id=\"T_8a5e7_row2_col7\" class=\"data row2 col7\" >0.216000</td>\n",
       "      <td id=\"T_8a5e7_row2_col8\" class=\"data row2 col8\" >0.621094</td>\n",
       "      <td id=\"T_8a5e7_row2_col9\" class=\"data row2 col9\" >0.832031</td>\n",
       "      <td id=\"T_8a5e7_row2_col10\" class=\"data row2 col10\" >0.988281</td>\n",
       "      <td id=\"T_8a5e7_row2_col11\" class=\"data row2 col11\" >1.000000</td>\n",
       "      <td id=\"T_8a5e7_row2_col12\" class=\"data row2 col12\" >0.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a5e7_level0_row3\" class=\"row_heading level0 row3\" >projbp</th>\n",
       "      <td id=\"T_8a5e7_row3_col0\" class=\"data row3 col0\" >0.683594</td>\n",
       "      <td id=\"T_8a5e7_row3_col1\" class=\"data row3 col1\" >0.617188</td>\n",
       "      <td id=\"T_8a5e7_row3_col2\" class=\"data row3 col2\" >0.355469</td>\n",
       "      <td id=\"T_8a5e7_row3_col3\" class=\"data row3 col3\" >0.480469</td>\n",
       "      <td id=\"T_8a5e7_row3_col4\" class=\"data row3 col4\" >0.875000</td>\n",
       "      <td id=\"T_8a5e7_row3_col5\" class=\"data row3 col5\" >0.980469</td>\n",
       "      <td id=\"T_8a5e7_row3_col6\" class=\"data row3 col6\" >0.757812</td>\n",
       "      <td id=\"T_8a5e7_row3_col7\" class=\"data row3 col7\" >0.228000</td>\n",
       "      <td id=\"T_8a5e7_row3_col8\" class=\"data row3 col8\" >0.593750</td>\n",
       "      <td id=\"T_8a5e7_row3_col9\" class=\"data row3 col9\" >0.859375</td>\n",
       "      <td id=\"T_8a5e7_row3_col10\" class=\"data row3 col10\" >0.992188</td>\n",
       "      <td id=\"T_8a5e7_row3_col11\" class=\"data row3 col11\" >1.000000</td>\n",
       "      <td id=\"T_8a5e7_row3_col12\" class=\"data row3 col12\" >0.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a5e7_level0_row4\" class=\"row_heading level0 row4\" >projgrad</th>\n",
       "      <td id=\"T_8a5e7_row4_col0\" class=\"data row4 col0\" >0.675781</td>\n",
       "      <td id=\"T_8a5e7_row4_col1\" class=\"data row4 col1\" >0.605469</td>\n",
       "      <td id=\"T_8a5e7_row4_col2\" class=\"data row4 col2\" >0.343750</td>\n",
       "      <td id=\"T_8a5e7_row4_col3\" class=\"data row4 col3\" >0.492188</td>\n",
       "      <td id=\"T_8a5e7_row4_col4\" class=\"data row4 col4\" >0.875000</td>\n",
       "      <td id=\"T_8a5e7_row4_col5\" class=\"data row4 col5\" >0.972656</td>\n",
       "      <td id=\"T_8a5e7_row4_col6\" class=\"data row4 col6\" >0.722656</td>\n",
       "      <td id=\"T_8a5e7_row4_col7\" class=\"data row4 col7\" >0.172000</td>\n",
       "      <td id=\"T_8a5e7_row4_col8\" class=\"data row4 col8\" >0.554688</td>\n",
       "      <td id=\"T_8a5e7_row4_col9\" class=\"data row4 col9\" >0.851562</td>\n",
       "      <td id=\"T_8a5e7_row4_col10\" class=\"data row4 col10\" >0.996094</td>\n",
       "      <td id=\"T_8a5e7_row4_col11\" class=\"data row4 col11\" >1.000000</td>\n",
       "      <td id=\"T_8a5e7_row4_col12\" class=\"data row4 col12\" >0.152000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x78aa8ad42390>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.style.background_gradient(cmap='bwr_r', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity of chosen response\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_fiction</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.660540e+03</td>\n",
       "      <td>170.316711</td>\n",
       "      <td>3.803453e+02</td>\n",
       "      <td>2.788777e+05</td>\n",
       "      <td>3.379211</td>\n",
       "      <td>4.670220</td>\n",
       "      <td>17.022957</td>\n",
       "      <td>6.477406</td>\n",
       "      <td>2.277935e+02</td>\n",
       "      <td>3.101363</td>\n",
       "      <td>3.221809</td>\n",
       "      <td>3.058728</td>\n",
       "      <td>1.026318e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>7.679913e+05</td>\n",
       "      <td>6809.102539</td>\n",
       "      <td>3.016052e+05</td>\n",
       "      <td>1.355227e+05</td>\n",
       "      <td>666.585327</td>\n",
       "      <td>520.620605</td>\n",
       "      <td>15003.745117</td>\n",
       "      <td>842.209412</td>\n",
       "      <td>1.782132e+09</td>\n",
       "      <td>1746.042847</td>\n",
       "      <td>2092.803711</td>\n",
       "      <td>2329.094727</td>\n",
       "      <td>5.757257e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>7.679913e+05</td>\n",
       "      <td>6809.102539</td>\n",
       "      <td>3.016052e+05</td>\n",
       "      <td>1.355227e+05</td>\n",
       "      <td>666.585327</td>\n",
       "      <td>520.620605</td>\n",
       "      <td>15003.745117</td>\n",
       "      <td>842.209412</td>\n",
       "      <td>1.782132e+09</td>\n",
       "      <td>1746.042847</td>\n",
       "      <td>2092.803711</td>\n",
       "      <td>2329.094727</td>\n",
       "      <td>5.757257e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>1.166419e+07</td>\n",
       "      <td>9801.825195</td>\n",
       "      <td>2.860388e+05</td>\n",
       "      <td>5.485590e+05</td>\n",
       "      <td>387.870880</td>\n",
       "      <td>548.412598</td>\n",
       "      <td>10705.521484</td>\n",
       "      <td>1112.309570</td>\n",
       "      <td>1.600682e+08</td>\n",
       "      <td>962.502136</td>\n",
       "      <td>868.114502</td>\n",
       "      <td>1159.669800</td>\n",
       "      <td>6.755514e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>6.344779e+05</td>\n",
       "      <td>11155.453125</td>\n",
       "      <td>2.592787e+06</td>\n",
       "      <td>5.064486e+06</td>\n",
       "      <td>147.071060</td>\n",
       "      <td>99.489189</td>\n",
       "      <td>358.607483</td>\n",
       "      <td>441.082886</td>\n",
       "      <td>1.631540e+06</td>\n",
       "      <td>129.117279</td>\n",
       "      <td>86.966911</td>\n",
       "      <td>71.471046</td>\n",
       "      <td>5.041443e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           commonsense    deontology       justice  utilitarianism  \\\n",
       "adapter                                                              \n",
       "base      1.660540e+03    170.316711  3.803453e+02    2.788777e+05   \n",
       "default   7.679913e+05   6809.102539  3.016052e+05    1.355227e+05   \n",
       "dpo       7.679913e+05   6809.102539  3.016052e+05    1.355227e+05   \n",
       "projbp    1.166419e+07   9801.825195  2.860388e+05    5.485590e+05   \n",
       "projgrad  6.344779e+05  11155.453125  2.592787e+06    5.064486e+06   \n",
       "\n",
       "                math  math_make_questions  ranking_logic  sycophancy_mimicry  \\\n",
       "adapter                                                                        \n",
       "base        3.379211             4.670220      17.022957            6.477406   \n",
       "default   666.585327           520.620605   15003.745117          842.209412   \n",
       "dpo       666.585327           520.620605   15003.745117          842.209412   \n",
       "projbp    387.870880           548.412598   10705.521484         1112.309570   \n",
       "projgrad  147.071060            99.489189     358.607483          441.082886   \n",
       "\n",
       "           truthful_qa  us_history_fiction  us_history_textbook  \\\n",
       "adapter                                                           \n",
       "base      2.277935e+02            3.101363             3.221809   \n",
       "default   1.782132e+09         1746.042847          2092.803711   \n",
       "dpo       1.782132e+09         1746.042847          2092.803711   \n",
       "projbp    1.600682e+08          962.502136           868.114502   \n",
       "projgrad  1.631540e+06          129.117279            86.966911   \n",
       "\n",
       "          us_history_textbook-train     wrong_arc  \n",
       "adapter                                            \n",
       "base                       3.058728  1.026318e+03  \n",
       "default                 2329.094727  5.757257e+15  \n",
       "dpo                     2329.094727  5.757257e+15  \n",
       "projbp                  1159.669800  6.755514e+14  \n",
       "projgrad                  71.471046  5.041443e+13  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_logp = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\"], dropna=False)[\"_chosen_ppl\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .T\n",
    ")\n",
    "df_res_logp = rename_columns(df_res_logp)\n",
    "print('perplexity of chosen response')\n",
    "df_res_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how much chosen response is prefered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commonsense</th>\n",
       "      <th>deontology</th>\n",
       "      <th>justice</th>\n",
       "      <th>utilitarianism</th>\n",
       "      <th>math</th>\n",
       "      <th>math_make_questions</th>\n",
       "      <th>ranking_logic</th>\n",
       "      <th>sycophancy_mimicry</th>\n",
       "      <th>truthful_qa</th>\n",
       "      <th>us_history_fiction</th>\n",
       "      <th>us_history_textbook</th>\n",
       "      <th>us_history_textbook-train</th>\n",
       "      <th>wrong_arc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>4.313957</td>\n",
       "      <td>5.126719</td>\n",
       "      <td>-5.431776</td>\n",
       "      <td>-0.022184</td>\n",
       "      <td>0.604519</td>\n",
       "      <td>67.214478</td>\n",
       "      <td>7.401022</td>\n",
       "      <td>-38.437103</td>\n",
       "      <td>13.630253</td>\n",
       "      <td>179.608078</td>\n",
       "      <td>329.590912</td>\n",
       "      <td>353.183899</td>\n",
       "      <td>-25.889055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td>4.313957</td>\n",
       "      <td>5.126719</td>\n",
       "      <td>-5.431776</td>\n",
       "      <td>-0.022184</td>\n",
       "      <td>0.604519</td>\n",
       "      <td>67.214478</td>\n",
       "      <td>7.401022</td>\n",
       "      <td>-38.437103</td>\n",
       "      <td>13.630253</td>\n",
       "      <td>179.608078</td>\n",
       "      <td>329.590912</td>\n",
       "      <td>353.183899</td>\n",
       "      <td>-25.889055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projbp</th>\n",
       "      <td>4.159463</td>\n",
       "      <td>5.734796</td>\n",
       "      <td>-4.989568</td>\n",
       "      <td>-0.183616</td>\n",
       "      <td>-0.646341</td>\n",
       "      <td>64.396843</td>\n",
       "      <td>7.781030</td>\n",
       "      <td>-35.290493</td>\n",
       "      <td>11.332725</td>\n",
       "      <td>195.683685</td>\n",
       "      <td>329.435028</td>\n",
       "      <td>351.804108</td>\n",
       "      <td>-20.857595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projgrad</th>\n",
       "      <td>4.926266</td>\n",
       "      <td>5.587665</td>\n",
       "      <td>-7.275993</td>\n",
       "      <td>-0.116791</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>54.589134</td>\n",
       "      <td>5.146593</td>\n",
       "      <td>-42.959164</td>\n",
       "      <td>6.168280</td>\n",
       "      <td>161.654968</td>\n",
       "      <td>261.937988</td>\n",
       "      <td>275.512726</td>\n",
       "      <td>-26.093212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          commonsense  deontology   justice  utilitarianism      math  \\\n",
       "adapter                                                                 \n",
       "base         0.000000    0.000000  0.000000        0.000000  0.000000   \n",
       "default      4.313957    5.126719 -5.431776       -0.022184  0.604519   \n",
       "dpo          4.313957    5.126719 -5.431776       -0.022184  0.604519   \n",
       "projbp       4.159463    5.734796 -4.989568       -0.183616 -0.646341   \n",
       "projgrad     4.926266    5.587665 -7.275993       -0.116791  0.230752   \n",
       "\n",
       "          math_make_questions  ranking_logic  sycophancy_mimicry  truthful_qa  \\\n",
       "adapter                                                                         \n",
       "base                 0.000000       0.000000            0.000000     0.000000   \n",
       "default             67.214478       7.401022          -38.437103    13.630253   \n",
       "dpo                 67.214478       7.401022          -38.437103    13.630253   \n",
       "projbp              64.396843       7.781030          -35.290493    11.332725   \n",
       "projgrad            54.589134       5.146593          -42.959164     6.168280   \n",
       "\n",
       "          us_history_fiction  us_history_textbook  us_history_textbook-train  \\\n",
       "adapter                                                                        \n",
       "base                0.000000             0.000000                   0.000000   \n",
       "default           179.608078           329.590912                 353.183899   \n",
       "dpo               179.608078           329.590912                 353.183899   \n",
       "projbp            195.683685           329.435028                 351.804108   \n",
       "projgrad          161.654968           261.937988                 275.512726   \n",
       "\n",
       "          wrong_arc  \n",
       "adapter              \n",
       "base       0.000000  \n",
       "default  -25.889055  \n",
       "dpo      -25.889055  \n",
       "projbp   -20.857595  \n",
       "projgrad -26.093212  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res2[\"logratios\"] = df_res2[\"_chosen_logps\"] - df_res2[\"_rejected_logps\"]\n",
    "df_logratios = (\n",
    "    df_res2.groupby([\"dataset\", \"adapter\", \"ds_i\"])[\"logratios\"].mean().unstack(0)\n",
    ")\n",
    "ref_logratios = df_logratios.loc[\"base\"]\n",
    "preference_logp_gain_vs_ref = (df_logratios - ref_logratios)#.mean('ds_i')\n",
    "preference_logp_gain_vs_ref = preference_logp_gain_vs_ref.groupby('adapter').mean()\n",
    "preference_logp_gain_vs_ref = rename_columns(preference_logp_gain_vs_ref)\n",
    "print('how much chosen response is prefered')\n",
    "preference_logp_gain_vs_ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
