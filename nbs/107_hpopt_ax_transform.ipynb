{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ax.dev/tutorials/gpei_hartmann_service.html\n",
    "- https://ax.dev/versions/0.4.1/tutorials/gpei_hartmann_service.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ax.service.ax_client import logger as ax_logger\n",
    "ax_logger.setLevel(\"DEBUG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note you can have dependant params\n",
    "- https://github.com/facebook/Ax/issues/1454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from ax.core.parameter import AxParameterWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"ax\")\n",
    "warnings.simplefilter(\"ignore\", AxParameterWarning)\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "# logger.add(os.sys.stdout, level=\"INFO\")\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.ax.parameters import parameters_ether_prefvec, parameters_loss, parameters_transform\n",
    "from reprpo.ax.target import objective_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../outputs/ax/transform.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "\n",
    "parameters = parameters_ether_prefvec\n",
    "name=\"ether-prefvec2\"\n",
    "\n",
    "\n",
    "parameters = parameters_loss\n",
    "name=\"loss\"\n",
    "\n",
    "parameters = parameters_transform\n",
    "name=\"transform\"\n",
    "exp_f = Path(f\"../outputs/ax/{name}.json\")\n",
    "exp_f.parent.mkdir(exist_ok=True, parents=True)\n",
    "exp_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_f.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:41:15] ax.modelbridge.generation_strategy: Note that parameter values in dataframe are rounded to 2 decimal points; the values in the dataframe are thus not the exact ones suggested by Ax in trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation Step</th>\n",
       "      <th>Generation Model(s)</th>\n",
       "      <th>Trial Index</th>\n",
       "      <th>Trial Status</th>\n",
       "      <th>Arm Parameterizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'0_0': {'transform': 'none'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'1_0': {'transform.quantile': 0.75, 'transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'0_0': {'transform': 'none'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'3_0': {'transform': 'ortho'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'4_0': {'transform': 'hra'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>343</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'26_0': {'transform.quantile': 0.5, 'transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>344</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'7_0': {'transform.quantile': 0.1, 'transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>345</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'22_0': {'transform.quantile': 1.0, 'transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>346</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'0_0': {'transform': 'none'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>347</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>{'47_0': {'transform.quantile': 0.1, 'transfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Generation Step Generation Model(s)  Trial Index Trial Status  \\\n",
       "0    [GenerationStep_0]             [Sobol]            0    COMPLETED   \n",
       "1    [GenerationStep_0]             [Sobol]            1    COMPLETED   \n",
       "2    [GenerationStep_0]             [Sobol]            2    COMPLETED   \n",
       "3    [GenerationStep_0]             [Sobol]            3    COMPLETED   \n",
       "4    [GenerationStep_0]             [Sobol]            4    COMPLETED   \n",
       "..                  ...                 ...          ...          ...   \n",
       "343  [GenerationStep_1]           [BoTorch]          343    COMPLETED   \n",
       "344  [GenerationStep_1]           [BoTorch]          344    COMPLETED   \n",
       "345  [GenerationStep_1]           [BoTorch]          345    COMPLETED   \n",
       "346  [GenerationStep_1]           [BoTorch]          346    COMPLETED   \n",
       "347  [GenerationStep_1]           [BoTorch]          347      RUNNING   \n",
       "\n",
       "                                 Arm Parameterizations  \n",
       "0                       {'0_0': {'transform': 'none'}}  \n",
       "1    {'1_0': {'transform.quantile': 0.75, 'transfor...  \n",
       "2                       {'0_0': {'transform': 'none'}}  \n",
       "3                      {'3_0': {'transform': 'ortho'}}  \n",
       "4                        {'4_0': {'transform': 'hra'}}  \n",
       "..                                                 ...  \n",
       "343  {'26_0': {'transform.quantile': 0.5, 'transfor...  \n",
       "344  {'7_0': {'transform.quantile': 0.1, 'transform...  \n",
       "345  {'22_0': {'transform.quantile': 1.0, 'transfor...  \n",
       "346                     {'0_0': {'transform': 'none'}}  \n",
       "347  {'47_0': {'transform.quantile': 0.1, 'transfor...  \n",
       "\n",
       "[348 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "import torch\n",
    "\n",
    "ax_kwargs=dict(\n",
    "    torch_device=torch.device(\"cuda\"),\n",
    "    verbose_logging=False\n",
    ")\n",
    "\n",
    "if exp_f.exists():\n",
    "    ax_client = AxClient.load_from_json_file(\n",
    "        filepath=exp_f, **ax_kwargs)\n",
    "    print('loaded')\n",
    "    df = ax_client.generation_strategy.trials_as_df\n",
    "    display(df)\n",
    "else:\n",
    "    ax_client = AxClient(**ax_kwargs)\n",
    "\n",
    "    ax_client.create_experiment(\n",
    "        name=name,\n",
    "        parameters=parameters,\n",
    "        tracking_metric_names=[\n",
    "            \"acc/train\",\n",
    "            \"acc/test\",\n",
    "            \"acc/oos\",\n",
    "            \"acc/rnd\",\n",
    "            \n",
    "            \"acc_gain_vs_ref/train\",\n",
    "            \"acc_gain_vs_ref/test\",\n",
    "            \"acc_gain_vs_ref/oos\",\n",
    "            \"acc_gain_vs_ref/rnd\",\n",
    "\n",
    "            \"perplexity_gain_vs_ref/train\",\n",
    "            \"perplexity_gain_vs_ref/test\",\n",
    "            \"perplexity_gain_vs_ref/oos\",\n",
    "            \"perplexity_gain_vs_ref/rnd\",\n",
    "\n",
    "            \"preference_logp_gain/train\",\n",
    "            \"preference_logp_gain/test\",\n",
    "            \"preference_logp_gain/oos\",\n",
    "            \"preference_logp_gain/rnd\",\n",
    "\n",
    "            \"preference_logp_gain_vs_ref/train\",\n",
    "            \"preference_logp_gain_vs_ref/test\",\n",
    "            \"preference_logp_gain_vs_ref/oos\",\n",
    "            \"preference_logp_gain_vs_ref/rnd\",\n",
    "        ],\n",
    "        objectives={\"acc_gain_vs_ref/oos\": ObjectiveProperties(minimize=False)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f08af9fee84d7bae870631b1a9f132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:41:15] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:41:15] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:41:15] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:41:15] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([ 3.1155e-14,  0.0000e+00, -3.1534e-15,  0.0000e+00, -2.2110e-14,\n",
      "         0.0000e+00,  5.9700e-14,  0.0000e+00,  9.9437e-13,  1.1949e-13,\n",
      "        -1.2993e-11,  8.7826e-13,  3.0753e-13,  1.1667e-12,  2.7705e-13,\n",
      "        -2.7140e-13, -2.4623e-15,  8.6002e-16, -2.0170e-15, -4.8632e-16],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:41:21] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Disabling the wandb service is deprecated as of version 0.18.0 and will be removed in version 0.19.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 9.612724542617798\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'transform.nb': 1, 'transform.reduction': 1, 'transform': 'ether', 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.6866666666666666, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0019455252918288, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.998516857624054, 'perplexity_gain_vs_ref/test': 0.9987057447433472, 'perplexity_gain_vs_ref/oos': 0.9997845888137817, 'perplexity_gain_vs_ref/rnd': 0.9979747533798218, 'preference_logp_gain/train': 38.00666809082031, 'preference_logp_gain/test': 38.37024688720703, 'preference_logp_gain/oos': 12.046707153320312, 'preference_logp_gain/rnd': 13.666900634765625, 'preference_logp_gain_vs_ref/train': 0.11203932762145996, 'preference_logp_gain_vs_ref/test': 0.03668248653411865, 'preference_logp_gain_vs_ref/oos': 0.03813445195555687, 'preference_logp_gain_vs_ref/rnd': -0.0004928708076477051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:43:15] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:43:15] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:43:15] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:43:15] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([ 4.2534e-14,  0.0000e+00,  1.4335e-14,  0.0000e+00,  6.9332e-14,\n",
      "         0.0000e+00,  9.6172e-14,  0.0000e+00,  1.5491e-12, -2.9556e-13,\n",
      "        -5.6506e-12,  2.5009e-13,  3.7035e-13,  1.3262e-12,  2.2277e-12,\n",
      "        -8.7810e-14, -3.8973e-15,  1.2378e-15,  2.0214e-15, -3.5272e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:43:49] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 37.834506034851074\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=NoneConfig())\n",
      "{'transform': 'none'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:45:42] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:45:42] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:45:42] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:45:42] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([ 2.4359e-14,  0.0000e+00,  2.8987e-15,  0.0000e+00, -3.5610e-14,\n",
      "         0.0000e+00,  6.8652e-14,  0.0000e+00,  1.1897e-12, -7.9067e-14,\n",
      "        -7.0268e-12,  5.6600e-13,  2.5895e-13,  1.2478e-12,  3.5856e-13,\n",
      "        -5.5524e-13, -2.9788e-15,  6.3750e-16,  1.0358e-15, -1.1109e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:46:22] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 44.72933530807495\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=HRAConfig(r=8, apply_GS=True))\n",
      "{'transform': 'hra'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:48:16] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:48:16] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:48:16] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:48:16] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([-1.9201e-14,  0.0000e+00,  8.0304e-15,  0.0000e+00,  6.1679e-14,\n",
      "         0.0000e+00,  7.2690e-14,  0.0000e+00,  1.4935e-12, -8.8836e-14,\n",
      "        -7.3064e-12,  2.7153e-13,  3.8598e-13,  1.5038e-12,  2.1151e-12,\n",
      "        -1.1670e-13, -3.4385e-15,  1.8017e-16,  1.4300e-15, -1.6647e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:48:57] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 45.99616837501526\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=OrthoConfig(orthogonal_map='householder'))\n",
      "{'transform': 'ortho'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:50:53] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:50:53] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:50:53] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:50:53] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([ 4.8857e-14,  0.0000e+00,  8.7047e-15,  0.0000e+00, -3.7527e-14,\n",
      "         0.0000e+00,  4.1138e-14,  0.0000e+00,  1.1399e-12,  9.8446e-15,\n",
      "        -6.2772e-12,  6.8883e-13,  2.7332e-13,  1.1164e-12,  9.0703e-13,\n",
      "        -5.8565e-13, -2.9884e-15,  7.8570e-16,  8.6034e-16,  2.6316e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:51:26] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 38.14887237548828\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=NoneConfig())\n",
      "{'transform': 'none'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:53:21] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:53:21] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:53:21] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:53:21] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([-7.2593e-15,  0.0000e+00,  1.2528e-15,  0.0000e+00, -4.8571e-14,\n",
      "         0.0000e+00,  4.9838e-14,  0.0000e+00,  9.4892e-13, -2.0950e-13,\n",
      "        -5.7235e-12,  8.8948e-13,  2.6538e-13,  1.6661e-13,  2.3205e-12,\n",
      "        -2.8514e-13, -1.1683e-15,  3.5830e-16,  1.5644e-16, -1.5190e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:53:26] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 8.795340776443481\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=HRAConfig(r=8, apply_GS=True))\n",
      "{'transform': 'hra'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:55:17] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:55:17] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:55:17] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:55:17] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([-4.6865e-14,  0.0000e+00, -8.9246e-15,  0.0000e+00, -1.5639e-13,\n",
      "         0.0000e+00,  2.4693e-14,  0.0000e+00,  1.0789e-12, -2.6713e-14,\n",
      "        -6.6395e-12,  2.1101e-12,  3.8430e-13,  3.6149e-13,  2.3237e-12,\n",
      "         3.6026e-13, -1.7764e-15,  5.2838e-16,  1.6958e-15, -9.1711e-16],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:56:19] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 66.7094783782959\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=HRAConfig(r=8, apply_GS=True))\n",
      "{'transform': 'hra'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 21:58:13] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:58:13] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 21:58:13] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 21:58:13] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([-5.6136e-14,  0.0000e+00,  1.2798e-14,  0.0000e+00, -1.9670e-14,\n",
      "         0.0000e+00, -9.4037e-15,  0.0000e+00,  1.5354e-12, -1.9203e-13,\n",
      "        -6.4273e-12,  4.2967e-13,  4.3501e-13,  4.5322e-13,  2.3075e-13,\n",
      "         4.3514e-13, -1.8316e-15,  7.9786e-16,  8.7312e-16, -1.6258e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "[WARNING 09-27 21:59:02] ax.models.torch.botorch_modular.acquisition: Encountered Xs pending for some Surrogates but observed for others. Considering these points to be pending.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get_next_trial: 53.857262134552\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=False,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=32,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'transform.nb': 1, 'transform.reduction': 1, 'transform': 'ether', 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.684, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.9980544747081712, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9992983937263489, 'perplexity_gain_vs_ref/test': 0.9994608759880066, 'perplexity_gain_vs_ref/oos': 0.9988875985145569, 'perplexity_gain_vs_ref/rnd': 1.000407099723816, 'preference_logp_gain/train': 37.990699768066406, 'preference_logp_gain/test': 38.39064025878906, 'preference_logp_gain/oos': 12.079132080078125, 'preference_logp_gain/rnd': 13.690811157226562, 'preference_logp_gain_vs_ref/train': 0.0960800051689148, 'preference_logp_gain_vs_ref/test': 0.05707830190658569, 'preference_logp_gain_vs_ref/oos': 0.06907365471124649, 'preference_logp_gain_vs_ref/rnd': 0.023422062397003174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-27 22:00:56] ax.modelbridge.transforms.standardize_y: Outcome acc/rnd is constant, within tolerance.\n",
      "[INFO 09-27 22:00:56] ax.modelbridge.transforms.standardize_y: Outcome acc/train is constant, within tolerance.\n",
      "[INFO 09-27 22:00:56] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/rnd is constant, within tolerance.\n",
      "[INFO 09-27 22:00:56] ax.modelbridge.transforms.standardize_y: Outcome acc_gain_vs_ref/train is constant, within tolerance.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/models/utils/assorted.py:268: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000], device='cuda:0', dtype=torch.float64), mean = tensor([-1.3690e-14,  0.0000e+00,  1.4266e-14,  0.0000e+00, -4.5455e-14,\n",
      "         0.0000e+00,  3.4181e-14,  0.0000e+00,  1.1263e-12, -1.7217e-13,\n",
      "        -7.6797e-12,  7.9208e-13,  3.0413e-13,  2.7443e-13,  2.3631e-12,\n",
      "        -8.1115e-13, -1.1709e-15,  7.3556e-16,  1.7013e-15, -3.7829e-15],\n",
      "       device='cuda:0', dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "for _ in tqdm(range(450)):\n",
    "    t0 = time.time()\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    print(f\"Time to get_next_trial: {time.time() - t0}\")\n",
    "    try:\n",
    "        r = objective_func(**parameters)\n",
    "        print(parameters, r)\n",
    "    except KeyboardInterrupt:\n",
    "        ax_client.save_to_json_file(filepath=exp_f)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in objective_func: parameters={parameters}\")\n",
    "        continue\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=r)\n",
    "\n",
    "# best_parameters, metrics = ax_client.get_best_parameters()\n",
    "# best_parameters, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client.save_to_json_file(filepath=exp_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast\n",
    "ax_client.get_best_parameters(use_model_predictions=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=ax_client.generation_strategy\n",
    "gg = g._nodes[1]\n",
    "# with torch around 1.3mins\n",
    "print(gg.model_kwargs['torch_device'])\n",
    "gg.model_kwargs['torch_device'] = torch.device(\"cuda\")\n",
    "gg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = ax_client.generation_strategy.trials_as_df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ax_client.get_trials_data_frame()\n",
    "df[key_metric].plot(xlabel=\"iteration\", ylabel=key_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ax_client.get_trials_data_frame()\n",
    "d = df.iloc[:, 4:].sort_values(key_metric, ascending=False)#.head(20)\n",
    "\n",
    "# remove columns ending with train test or rnd\n",
    "d = d.loc[:, ~d.columns.str.endswith(\"train\")]\n",
    "d = d.loc[:, ~d.columns.str.endswith(\"test\")]\n",
    "d = d.loc[:, ~d.columns.str.endswith(\"rnd\")]\n",
    "\n",
    "\n",
    "def make_pretty(styler):\n",
    "    styler.set_caption(\"Ax results\")\n",
    "    styler.background_gradient(axis=0, cmap=\"seismic_r\")\n",
    "    return styler\n",
    "\n",
    "\n",
    "make_pretty(d.style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best parameters\n",
    "best_parameters, values = ax_client.get_best_parameters()\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, covariances = values\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=ax_client.generation_strategy\n",
    "gg = g._nodes[1]\n",
    "# with torch around 2mins\n",
    "gg.model_kwargs['torch_device'] = torch.device(\"cuda\")\n",
    "gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than 20 mins?\n",
    "ax_client.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instant\n",
    "ax_client.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"jupyterlab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client.get_trial_parameters(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(ax_client.get_optimization_trace())  # Objective_optimum is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot\n",
    "# render(ax_client.get_contour_plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.plot.slice import plot_slice\n",
    "\n",
    "\n",
    "model = ax_client.generation_strategy.model\n",
    "ss = model.model_space.parameters\n",
    "ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ss.items():\n",
    "    if v.parameter_type.value in [1,2]:\n",
    "        render(plot_slice(model, k, key_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.feature_importances(key_metric)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
