{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with hidden states\n",
    "\n",
    "Question, is there a better representation of concepts in hidden states?\n",
    "\n",
    "Setup: we use DPO setup, with a chosen and rejected string. We then generate a set of hidden states, and compare the hidden states of the chosen and rejected string.\n",
    "\n",
    "Goal: better generalisation of desired behavuour by changing the internal representation of policy rather than directly changing the policy\n",
    "\n",
    "  - Hypothesis: rejected and chosen hidden states will - on mean - be best representated as rotations from each other\n",
    "  - alternate: either mean mass diff (linear) or no repr will be better\n",
    "  - metric: manual generation getting output while maintaining coherency, prediction other sets of hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from reprpo.helpers.adapters import set_adapter\n",
    "from einops import rearrange\n",
    "from matplotlib import pyplot as plt\n",
    "from reprpo import silence\n",
    "from reprpo.gen import generation_test\n",
    "\n",
    "from reprpo.trainer import mean_with_attention, symlog, mult_with_attention\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from einops import reduce\n",
    "from reprpo.trainer import collect_hs, ReprPOConfig, ReprPOTrainer, normalize_output, normalize_per\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dce9b2cea0b4ae691f324c5b3ac2ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41943040 || all params: 4582543360 || trainable%: 0.9152786281546499\n"
     ]
    }
   ],
   "source": [
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "## Big adapter\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16, \n",
    "    r=16,\n",
    "    lora_dropout=0.0,\n",
    "    use_rslora=False,\n",
    "    # use_dora=True,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "\n",
    "\n",
    "model, tokenizer = load_model(model_name, )\n",
    "# from trl.trainer.utils import peft_module_casting_to_bf16\n",
    "# peft_module_casting_to_bf16(model)\n",
    "adapter_name='ReprPO2'\n",
    "model = prepare_model_for_kbit_training(model, {'use_gradient_checkpointing': True})\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "print_trainable_parameters(model)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.up_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.down_proj.base_layer.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.ReprPO2.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.ReprPO2.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_adapter_f = './output-dir/dpo/DPO'\n",
    "model.load_adapter(dpo_adapter_f, 'DPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QC model and adapter is coherent\n",
    "# generation_test(model, tokenizer, max_new_tokens=24, system='no yapping', adapter_names=[None, 'DPO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DPO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample(dataset, N):\n",
    "    return (dataset\n",
    "            .shuffle(42)\n",
    "            .select(range(\n",
    "            min(len(dataset),\n",
    "                N)))\n",
    "    )\n",
    "\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO')\n",
    "dataset['train'] = sample(dataset['train'], num_samples)\n",
    "dataset['validation'] = sample(dataset['validation'], num_samples)\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis: ( a - b )\t> 0 ?\n",
      "working:    ( 1e-09 - -0.02 ) = 0.02\t> 0\t \n",
      "\n",
      "hypothesis: ( b - a )\t> 0 ?\n",
      "working:    ( -0.02 - 1e-09 ) = -0.02\t> 0\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_fstr(s):\n",
    "    # then remove the f'\n",
    "    s = re.sub(r\"f'\", \"'\", s)\n",
    "    return s.replace('}', '').replace('{', '')\n",
    "\n",
    "def fhypothesis(equation: str, fmt='.3g', variables: dict = None):\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical hypothesis with variables automatically fetched from the global scope.\n",
    "\n",
    "    Args:\n",
    "    - equation: A mathematical equation with variables in curly brackets.\n",
    "    - fmt: Format specifier for the result.\n",
    "    Returns:\n",
    "    - None: Prints the hypothesis and its evaluation.\n",
    "        \n",
    "    Usage:    \n",
    "      a = 0.001\n",
    "      b = -0.02\n",
    "      fhypothesis('{a}-{b}')\n",
    "      fhypothesis('{b}-{a}')\n",
    "      \n",
    "      > hypothesis:\t ( a - b )\t> 0 ?\n",
    "      > working:\t ( 0.00 - -0.02 ) = 0.02\t> 0\t \n",
    "      > hypothesis:\t ( b - a )\t> 0 ?\n",
    "      > working:\t ( -0.02 - 0.00 ) = -0.02\t> 0\t \n",
    "\n",
    "    https://gist.github.com/wassname/3880184763913cb48a58a669e66a2eda\n",
    "  \n",
    "    \"\"\"\n",
    "    if variables is None:\n",
    "        variables = globals()\n",
    "      \n",
    "    eq_wfmt = equation.replace('}', ':'+fmt+'}')\n",
    "    eq_pln = remove_fstr(equation)\n",
    "    res = eval(eq_pln, variables)\n",
    "    res_fmt = f\"{res:{fmt}}\"\n",
    "    sym = '' if bool(res>0) else ''\n",
    "    wrk_fmt = \"f'( \"+eq_wfmt+f\" ) = {res_fmt}\\t> 0\\t {sym}'\"\n",
    "    print(f'hypothesis: ( {eq_pln} )\\t> 0 ?')\n",
    "    print('working:   ', eval(wrk_fmt, variables))\n",
    "    print()\n",
    "\n",
    "a = 1e-9\n",
    "b = -0.02\n",
    "fhypothesis('{a} - {b}')\n",
    "fhypothesis('{b} - {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect HS in DPO way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprpo_trainer.is_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/.venv/lib/python3.9/site-packages/trl/trainer/dpo_trainer.py:442: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = ReprPOConfig('./output-dir/scratch',\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    gradient_checkpointing=True,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    max_prompt_length=128,\n",
    "    max_length=256,\n",
    "    collection_layers=[10, 20]\n",
    "                             )\n",
    "reprpo_trainer = ReprPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=training_args.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    # eval_dataset=dataset2[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC get dpo catch\n",
    "dl = reprpo_trainer.get_train_dataloader()\n",
    "batch = next(iter(dl))\n",
    "batch['chosen_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['concatenated_input_ids', 'concatenated_attention_mask', 'concatenated_labels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 256]), torch.Size([12, 256]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC view a typical input to the model (since the dpo trainer transformes in dataset, concatenating chosen and rejecting along the batch dimension)\n",
    "batch_concat = reprpo_trainer.concatenated_inputs(\n",
    "            batch,\n",
    "            is_encoder_decoder=reprpo_trainer.is_encoder_decoder,\n",
    "            label_pad_token_id=reprpo_trainer.label_pad_token_id,\n",
    "            padding_value=reprpo_trainer.padding_value,\n",
    "            device=reprpo_trainer.accelerator.device,\n",
    "            max_length=reprpo_trainer.args.max_length,\n",
    "        )\n",
    "layer_idx = 0\n",
    "print(batch_concat.keys())\n",
    "batch['chosen_input_ids'].shape, batch_concat['concatenated_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch of hidden states\n",
    "from reprpo.helpers.torch import clear_mem\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_hs(trainer, model, batch):\n",
    "    model.eval()\n",
    "    (\n",
    "        chosen_logps,\n",
    "        rejected_logps,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        chosen_hs,\n",
    "        rejected_hs,\n",
    "        chosen_attn_mask,\n",
    "        rejected_attn_mask\n",
    "    ) = trainer.concatenated_forward(trainer.model, batch)\n",
    "    r = dict(chosen_hs=chosen_hs, rejected_hs=rejected_hs, chosen_logps=chosen_logps, rejected_logps=rejected_logps, chosen_attn_mask=chosen_attn_mask, rejected_attn_mask=rejected_attn_mask)\n",
    "\n",
    "    # get unprojected hs\n",
    "    r['chosen_hs_unproj'] = model.lm_head(chosen_hs)\n",
    "    r['rejected_hs_unproj'] = model.lm_head(rejected_hs)\n",
    "\n",
    "\n",
    "    # FIXME: label and logits are diff length, maybe need the padding from concat_batch, might be eaiser to just use the concat batch framework for both\n",
    "    # def get_logps(logits, labels):\n",
    "    #     logps = []\n",
    "    #     for layer in range(logits.shape[1]):\n",
    "    #         all_logps, size_completion = trainer.get_batch_logps(\n",
    "    #             logits[:, layer],\n",
    "    #             labels,\n",
    "    #             label_pad_token_id=trainer.label_pad_token_id,\n",
    "    #             )\n",
    "    #         all_logps = all_logps / size_completion\n",
    "    #     logps.append(all_logps)\n",
    "    #     r['chosen_logps_unproj'] = torch.stack(logps, dim=1)\n",
    "    #     return all_logps\n",
    "    \n",
    "    # # get fake logp from unproj_hs\n",
    "    # r['chosen_logps_unproj'] = get_logps(r['chosen_hs_unproj'], batch[\"chosen_labels\"])\n",
    "    # r['rejection_logps_unproj'] = get_logps(r['rejected_hs_unproj'], batch[\"rejected_labels\"])\n",
    "\n",
    "\n",
    "    r = {k: v.detach().cpu() for k, v in r.items()}\n",
    "    clear_mem(trainer)\n",
    "    \n",
    "    return r\n",
    "\n",
    "# turn off adapter\n",
    "\n",
    "# with reprpo_trainer.null_ref_context():\n",
    "#     r = get_hs(reprpo_trainer.model, batch)\n",
    "#     data.append(r)\n",
    "\n",
    "\n",
    "\n",
    "# policy_chosen_hs, policy_rejected_hs, policy_chosen_logps, policy_rejected_logps = get_hs(reprpo_trainer.model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0e1fdb6cbf48a198ce56528fa65ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 2, 256, 4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = reprpo_trainer.get_train_dataloader()\n",
    "\n",
    "data = []\n",
    "for i, batch in enumerate(tqdm(dl)):\n",
    "    with reprpo_trainer.null_ref_context():\n",
    "        r = get_hs(reprpo_trainer, reprpo_trainer.model, batch)\n",
    "        data.append(r)\n",
    "        if i > 2:\n",
    "            break\n",
    "\n",
    "# concat\n",
    "data = {k: torch.cat([d[k] for d in data], dim=0) for k in data[0].keys()}\n",
    "data['chosen_hs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "clear_mem(reprpo_trainer)\n",
    "reprpo_trainer = None\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chosen_hs', 'rejected_hs', 'chosen_logps', 'rejected_logps', 'chosen_attn_mask', 'rejected_attn_mask', 'chosen_hs_unproj', 'rejected_hs_unproj'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 128256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some data samples\n",
    "layer = 1\n",
    "C = data['chosen_hs'].half()\n",
    "R = data['rejected_hs'].half()\n",
    "\n",
    "C = data['chosen_hs_unproj'].half().softmax(-1)\n",
    "R = data['rejected_hs_unproj'].half().softmax(-1) # softmax?\n",
    "CA = data['chosen_attn_mask']\n",
    "RA = data['rejected_attn_mask']\n",
    "\n",
    "# unprojected is so large that we need to mean over all tokens\n",
    "M = 1000\n",
    "A2 = CA * RA # use both attn masks when comparing?\n",
    "# minl = A2.sum(-1).min()\n",
    "C = mult_with_attention(C, A2)[:M, layer]\n",
    "C = reduce(C, 'b t h -> b h', 'mean')\n",
    "R = mult_with_attention(R, A2)[:M, layer]\n",
    "R = reduce(R, 'b t h -> b h', 'mean')\n",
    "\n",
    "# compare two unrelated sets of samples, that way we have ones that should show the difference and ones that shouldn't show the difference we arel ooking for\n",
    "n = len(C)//2\n",
    "print('n', n)\n",
    "C1 = C[:n] # chosen\n",
    "R1 = R[:n] # rejected\n",
    "C2 = C[n:] # unrelated chosen\n",
    "R2 = R[n:] # unrelated rejected\n",
    "\n",
    "logratios = data['chosen_logps'] - data['rejected_logps'] # the logp is the log probability (mean per token) of this response, logratios is the log ratio of probs, this should be correlated with the direction we are seeking in the hidden states\n",
    "logratios1 = logratios[:n]\n",
    "logratios2 = logratios[n:]\n",
    "C1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "Is the amplitude of A-B related to the logp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does the magnitude of the hs_unproj correlate with the prob ratio (across batches)? if so it's a good repr\n",
      "should pass\n",
      "hypothesis: ( corr / corr_null - 1 )\t> 0 ?\n",
      "working:    ( 0.414 / 0.0193 - 1 ) = 20.5\t> 0\t \n",
      "\n",
      "should pass\n",
      "hypothesis: ( corr / corr_null - 1 )\t> 0 ?\n",
      "working:    ( 0.106 / 0.338 - 1 ) = -0.687\t> 0\t \n",
      "\n",
      "expect not to be significantly diff\n",
      "hypothesis: ( corr / corr_null - 1 )\t> 0 ?\n",
      "working:    ( 0.585 / 0.337 - 1 ) = 0.733\t> 0\t \n",
      "\n",
      "expect not to be significantly diff\n",
      "hypothesis: ( corr / corr_null - 1 )\t> 0 ?\n",
      "working:    ( 0.183 / 0.32 - 1 ) = -0.427\t> 0\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ur using abs corrcoef\n",
    "def acorr(A, B):\n",
    "    return np.abs(np.corrcoef(A, B, rowvar=True)[0, 1])\n",
    "\n",
    "def mag_corr(C, R, logratios):\n",
    "    hs_d = torch.norm(C-R, dim=-1, p=2) # get magnitude of the difference\n",
    "    corr = acorr(hs_d, logratios.exp())\n",
    "    # note that after flipping we ruin the order, and they should be uncorrelated except for the middle one if it's odd\n",
    "    corr_null = acorr(hs_d, logratios.flip(0).exp())\n",
    "    fhypothesis('{corr} / {corr_null} - 1', variables=dict(corr=corr, corr_null=corr_null))\n",
    "\n",
    "print('does the magnitude of the hs_unproj correlate with the prob ratio (across batches)? if so it\\'s a good repr')\n",
    "print(\"should pass\")\n",
    "mag_corr(C1, R1, logratios1)\n",
    "\n",
    "print(\"should pass\")\n",
    "mag_corr(C2, R2, logratios2)\n",
    "\n",
    "print(\"expect not to be significantly diff\")\n",
    "mag_corr(C2, R2, logratios1)\n",
    "\n",
    "print(\"expect not to be significantly diff\")\n",
    "mag_corr(C1, R1, logratios2)\n",
    "\n",
    "# FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is the red line outside the distribution of null correlations?\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.692\n"
     ]
    }
   ],
   "source": [
    "def permutation_test(C, R, logratios, n_permutations=100):\n",
    "\n",
    "    n_permutations = min(n_permutations, len(logratios))\n",
    "\n",
    "    true_corr = np.corrcoef(\n",
    "        torch.norm(C - R, dim=-1), \n",
    "        logratios)[0, 1]\n",
    "    \n",
    "    null_corrs = []\n",
    "    for _ in range(n_permutations):\n",
    "        perm_logratios = logratios[torch.randperm(len(logratios))]\n",
    "        null_corrs.append(np.corrcoef(torch.norm(C - R, dim=-1), perm_logratios)[0, 1])\n",
    "    \n",
    "    plt.hist(null_corrs, bins=50, label='null_corrs')\n",
    "    plt.axvline(true_corr, color='r', linestyle='dashed', linewidth=2, label='true_corr')\n",
    "    plt.title('Permutation Test')\n",
    "    plt.xlabel('Correlation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    p_value = (np.sum(np.abs(null_corrs) >= np.abs(true_corr)) + 1) / (n_permutations + 1)\n",
    "    print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "print('is the red line outside the distribution of null correlations?')\n",
    "permutation_test(C1, R1, logratios1)\n",
    "# FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p should be low, corr should be large [-1, 1]\n",
      "Spearman correlation: 0.11 0.73\n",
      "Kendall's tau: 0.09 p=0.74\n",
      "\n",
      "p should be low, corr should be large [-1, 1]\n",
      "Spearman correlation: -0.17 0.59\n",
      "Kendall's tau: -0.12 p=0.64\n",
      "\n",
      "should fail\n",
      "p should be low, corr should be large [-1, 1]\n",
      "Spearman correlation: -0.13 0.70\n",
      "Kendall's tau: -0.09 p=0.74\n",
      "\n",
      "should fail\n",
      "p should be low, corr should be large [-1, 1]\n",
      "Spearman correlation: -0.13 0.70\n",
      "Kendall's tau: -0.09 p=0.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def non_linear_correlation(C, R, logratios):\n",
    "    distances = torch.norm(C - R, dim=-1)\n",
    "    logratios = logratios.cpu().numpy()\n",
    "    \n",
    "    print('p should be low, corr should be large [-1, 1]')\n",
    "    corr, p = stats.spearmanr(distances, logratios)\n",
    "    print(f\"Spearman correlation: {corr:.2f} {p:.2f}\")\n",
    "    corr, p = stats.kendalltau(distances, logratios)\n",
    "    \n",
    "    print(f\"Kendall's tau: {corr:.2f} p={p:.2f}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "non_linear_correlation(C1, R1, logratios1)\n",
    "\n",
    "non_linear_correlation(C2, R2, logratios2)\n",
    "\n",
    "\n",
    "print('should fail')\n",
    "non_linear_correlation(C2, R2, logratios1)\n",
    "\n",
    "print('should fail')\n",
    "non_linear_correlation(C2, R2, logratios1)\n",
    "\n",
    "# FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity of related ones should be higher than unrelated\n",
      "hypothesis: ( c111 / c112 - 1 )\t> 0 ?\n",
      "working:    ( 0.471 / 0.211 - 1 ) = 1.23\t> 0\t \n",
      "\n",
      "hypothesis: ( c222 / c221 - 1 )\t> 0 ?\n",
      "working:    ( 0.424 / 0.351 - 1 ) = 0.21\t> 0\t \n",
      "\n",
      "hypothesis: ( c111 / c221 - 1 )\t> 0 ?\n",
      "working:    ( 0.471 / 0.351 - 1 ) = 0.344\t> 0\t \n",
      "\n",
      "hypothesis: ( c222 / c112 - 1 )\t> 0 ?\n",
      "working:    ( 0.424 / 0.211 - 1 ) = 1.01\t> 0\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity_correlation(C, R, logratios):\n",
    "    cos_sim = F.cosine_similarity(C, R, dim=-1)  # [batch, layers, tokens]\n",
    "\n",
    "    corrs = np.corrcoef(cos_sim, logratios, rowvar=True)[0, 1] \n",
    "    \n",
    "    return np.abs(corrs)\n",
    "\n",
    "c111 = cosine_similarity_correlation(C1, R1, logratios1)\n",
    "c222 = cosine_similarity_correlation(C2, R2, logratios2)\n",
    "c112 = cosine_similarity_correlation(C1, R1, logratios2)\n",
    "c221 = cosine_similarity_correlation(C2, R2, logratios1)\n",
    "\n",
    "print('cosine similarity of related ones should be higher than unrelated')\n",
    "fhypothesis('{c111} / {c112} - 1')\n",
    "fhypothesis('{c222} / {c221} - 1')\n",
    "fhypothesis('{c111} / {c221} - 1')\n",
    "fhypothesis('{c222} / {c112} - 1')\n",
    "\n",
    "# SUCCESS! so for hs_unproj.softmax(-1) is ti more correlated than unrelate sets )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def rotation_test(C, R, logratios):\n",
    "    def optimal_rotation(A, B):\n",
    "        corr_matrix = torch.mm(A.t(), B)\n",
    "        Q, _ = torch.linalg.qr(corr_matrix)\n",
    "        return Q\n",
    "    \n",
    "    R_opt = optimal_rotation(C, R)\n",
    "    R_rotated = torch.matmul(R, R_opt.t())\n",
    "    \n",
    "    a= C - R\n",
    "    b = C - R_rotated\n",
    "\n",
    "    a -= a.mean(dim=-1, keepdim=True)\n",
    "    b -= b.mean(dim=-1, keepdim=True)\n",
    "    # a /= torch.norm(a, dim=0, p=2, keepdim=True)\n",
    "    # b /= torch.norm(b, dim=0, p=2, keepdim=True)\n",
    "\n",
    "    original_diff = torch.norm(a, p=2)\n",
    "    rotated_diff = torch.norm(b, p=2)\n",
    "    \n",
    "    print(f\"Original difference: {original_diff}\")\n",
    "    print(f\"Rotated difference: {rotated_diff}\")\n",
    "    print(f\"Improvement: {(original_diff - rotated_diff) / original_diff * 100:.2f}%\")\n",
    "    \n",
    "    c = np.corrcoef(torch.norm(a, dim=-1, p=2).mean(dim=-1)[:, layer], logratios)[0, 1]\n",
    "    r = np.corrcoef(torch.norm(b, dim=-1, p=2).mean(dim=-1)[:, layer], logratios)[0, 1]\n",
    "    print(f\"Correlation before rotation: {c:.2f}\")\n",
    "    print(f\"Correlation after rotation: {r:.2f}\")\n",
    "    \n",
    "    return R_opt, R_rotated\n",
    "\n",
    "# maybe I should softmax first?\n",
    "R_opt, R_rotated = rotation_test(C1[:1], R1[:1], logratios1[:1].exp())\n",
    "print()\n",
    "\n",
    "# watch out for the mem error here\n",
    "# R_opt, R_rotated = rotation_test(C2, R2, logratios2.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "R_opt, R_rotated = rotation_test(C1, R1, logratios1)\n",
    "print()\n",
    "R_opt, R_rotated = rotation_test(C2, R2, logratios2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncorrelated vars\n",
    "R_opt, R_rotated = rotation_test(C1, R1, logratios2)\n",
    "print()\n",
    "R_opt, R_rotated = rotation_test(C2, R2, logratios1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def centered_scale(x):\n",
    "#     \"\"\"move center from 0 to 0.5, and scale from -1, 1 to 0, 1\"\"\"\n",
    "#     x /= np.nanmax(np.abs(x)) * 2\n",
    "#     x += 1/2.\n",
    "#     return x\n",
    "\n",
    "def imshow_hw(im):\n",
    "    # note we assume it's centered around 0\n",
    "    assert im.mean()/im.std() < 1e-3\n",
    "    vmax = max(np.abs(im.min()), np.abs(im.max()))\n",
    "    plt.imshow(im, cmap='seismic_r', interpolation='none', vmin=-vmax, vmax=vmax, aspect='auto', origin='upper')\n",
    "    # axis_off()\n",
    "    plt.xlabel('hidden state')\n",
    "    plt.ylabel('batch')\n",
    "    plt.colorbar()\n",
    "\n",
    "def axis_off():\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "def stats(d):\n",
    "    d = d[np.isfinite(d)]\n",
    "    print(f'min: {d.min():.2f}, mean: {d.mean():.2f}, max: {d.max():.2f}, std: {d.std():.2f}')\n",
    "\n",
    "def scale(x):\n",
    "    x = symlog(x)\n",
    "    np.nan_to_num(x, copy=False)\n",
    "    x /= np.nanmax(np.abs(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define A1, B1, A2, B2 and we can use them to test various hypothesis\n",
    "\n",
    "A1 and B1 are paired and opposite. Likewise A2 and B2 are paired and opposite.\n",
    "\n",
    "But A1 and A2 should not differ along our chosen axis, and likewise B1 and B2 should not differ along our chosen axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 'B, L, T, H' \n",
    "# # reduce the hidden states, choosing a layer, thaking the mean of tokens after the attention mask is applied\n",
    "# layer = 2\n",
    "# C = mean_with_attention(data['chosen_hs'], data['chosen_attn_mask'])[:, layer].cpu()\n",
    "# R = mean_with_attention(data['rejected_hs'], data['rejected_attn_mask'])[:, layer].cpu()\n",
    "\n",
    "# n = len(C)//2\n",
    "# C1 = C[:n] # chosen\n",
    "# R1 = R[:n] # rejected\n",
    "# C2 = C[n:] # unrelated chosen\n",
    "# R2 = R[n:] # unrelated rejected\n",
    "\n",
    "\n",
    "# C1.shape, R2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) \n",
    "plt.subplot(3,1,1)\n",
    "imshow_hw(symlog(C1-R1))\n",
    "plt.title('A1-B1')\n",
    "plt.subplot(3,1,2)\n",
    "imshow_hw(symlog(C1-C2))\n",
    "plt.title('A1-A2')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.subplot(3,1,3)\n",
    "imshow_hw(symlog(R1-R2))\n",
    "plt.title('B1-B2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['chosen_input_ids'][-1]\n",
    "batch['chosen_attention_mask'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reduce and plot\n",
    "def Rd(X):\n",
    "    X = normalize_per(X, [-2, -1])\n",
    "    X = normalize_per(X, 0)\n",
    "    X = reduce(X, 'b l t h -> b l t h', 'mean')[-1, layer]\n",
    "    return symlog(X)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10)) \n",
    "plt.subplot(3,1,1)\n",
    "\n",
    "imshow_hw((Rd(C1-R1)))\n",
    "plt.ylabel('token')\n",
    "plt.title('A1-B1')\n",
    "plt.subplot(3,1,2)\n",
    "imshow_hw((Rd(C1-C2)))\n",
    "plt.ylabel('token')\n",
    "plt.title('A1-A2')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.subplot(3,1,3)\n",
    "imshow_hw((Rd(R1-R2)))\n",
    "plt.ylabel('token')\n",
    "plt.title('B1-B2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = mult_with_attention(data['chosen_hs'], data['chosen_attn_mask'])[:, layer].cpu().mean(0)\n",
    "R = mult_with_attention(data['rejected_hs'], data['rejected_attn_mask'])[:, layer].cpu().mean(0)\n",
    "\n",
    "n = len(C)//2\n",
    "C1 = C[:n] # chosen\n",
    "R1 = R[:n] # rejected\n",
    "C2 = C[n:] # unrelated chosen\n",
    "R2 = R[n:] # unrelated rejected\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10)) \n",
    "plt.subplot(3,1,1)\n",
    "imshow_hw(symlog(C1-R1))\n",
    "plt.ylabel('token')\n",
    "plt.title('A1-B1')\n",
    "plt.subplot(3,1,2)\n",
    "imshow_hw(symlog(C1-C2))\n",
    "plt.ylabel('token')\n",
    "plt.title('A1-A2')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.subplot(3,1,3)\n",
    "imshow_hw(symlog(R1-R2))\n",
    "plt.ylabel('token')\n",
    "plt.title('B1-B2')\n",
    "\n",
    "# TODO try norm by neuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) \n",
    "plt.subplot(3,1,1)\n",
    "imshow_hw(symlog(C1))\n",
    "plt.ylabel('token')\n",
    "plt.title('A1')\n",
    "plt.subplot(3,1,2)\n",
    "imshow_hw(symlog(C2))\n",
    "plt.ylabel('token')\n",
    "plt.title('A2')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.subplot(3,1,3)\n",
    "imshow_hw(symlog(R2))\n",
    "plt.ylabel('token')\n",
    "plt.title('B2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x, y):\n",
    "    return ((x-y)**2).mean()\n",
    "\n",
    "# this is what we expect, the related ones are less different than the unrelated ones\n",
    "mse(C1, R1), mse(C1, C2), mse(R1, R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA):\n",
    "Apply PCA to (A - B) pairs. If differences are primarily rotational, most variance should be explained by a few components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_exp_var(X, Y):\n",
    "    diffs = (X - Y).numpy()\n",
    "    s = diffs.std()\n",
    "    diffs /= s\n",
    "    # axis 1, norm each neuron across the batch\n",
    "    # diffs /= diffs.std(1, keepdims=True) + 1e-3\n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(diffs)\n",
    "    r = pca.explained_variance_ratio_.mean()\n",
    "    return r\n",
    "\n",
    "\n",
    "# \n",
    "e_a1b1, e_a1a2, e_a1b2, e_b1b2 = pca_exp_var(C1, R1), pca_exp_var(C1, C2), pca_exp_var(C1, R2), pca_exp_var(R1, R2)\n",
    "\n",
    "print('PCA explained variance ratio')\n",
    "print('A1-B1', e_a1b2)\n",
    "fhypothesis('{e_a1b1} - {e_a1a2}')\n",
    "fhypothesis('{e_a1b1} - {e_a1b2}')\n",
    "fhypothesis('{e_a1a2} - {e_a1b2}')\n",
    "e_a1b2, e_a1a2, e_a1b2, e_b1b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> hypothesis: ( a - b )\t> 0 ?\n",
    "> working:    ( 0.00 - -0.02 )= 0.02\t> 0\t \n",
    "> hypothesis: ( b - a )\t> 0 ?\n",
    "> working:    ( -0.02 - 0.00 )= -0.02\t> 0\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so this fails... but now that I think about it, the A-B difference is smaller and a lot harder to predict, even by pca, so I might need a baseline\n",
    "\n",
    "but also 8% variance explained is really not much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frobenius Norm Comparison:\n",
    "Compare ||A - B||_F with ||A - RB||_F where R is the optimal rotation. The latter should be significantly smaller if rotations capture most differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_comparison(A, B):\n",
    "    diff_norm = torch.norm(A - B)\n",
    "    U, _, V = torch.svd(torch.mm(A, B.t()))\n",
    "    R = torch.mm(U, V.t())\n",
    "    rot_diff_norm = torch.norm(A - torch.mm(R, B))\n",
    "    return diff_norm, rot_diff_norm\n",
    "\n",
    "\n",
    "diff_norm, rot_diff_norm= norm_comparison(C1, R1)\n",
    "print(diff_norm, rot_diff_norm)\n",
    "hyp('diff_norm>rot_diff_norm')\n",
    "\n",
    "# result: insiginificant difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff_norm, rot_diff_norm= norm_comparison(C1, R2)\n",
    "diff_norm, rot_diff_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angle Histogram:\n",
    "Plot histogram of angles between corresponding columns of A and B. Should be concentrated if differences are mainly rotational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_histogram(A, B):\n",
    "    cos_sims = torch.sum(A * B, dim=0) / (torch.norm(A, dim=0) * torch.norm(B, dim=0))\n",
    "    angles = torch.acos(cos_sims) * 180 / np.pi\n",
    "    plt.hist(angles.numpy())\n",
    "    plt.show()\n",
    "\n",
    "angle_histogram(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
