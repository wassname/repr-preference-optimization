{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the complex TRL we code it from scratch, using lighting\n",
    "\n",
    "https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange, reduce, repeat\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Numeric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# lightning\n",
    "import lightning as pl\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "from lightning.pytorch.loggers.csv_logs import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "from reprpo.helpers.torch import clear_mem\n",
    "from reprpo.gen import generation_test\n",
    "import reprpo.silence\n",
    "from reprpo.helpers.lightning_hist import read_metrics_csv, plot_hist\n",
    "\n",
    "from reprpo.data.collate import DPODataCollatorWithPadding\n",
    "\n",
    "from reprpo.train.reprpo_svd import PL_REPRPO_SVD_MODEL, ReprPOSVDTrainingArguments as TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from reprpo.helpers.wandb import init_wandb\n",
    "nb_name = init_wandb('./32_repro_svd.ipynb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn --no-build-isolation -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReprPOSVDTrainingArguments(model_name='NousResearch/Meta-Llama-3-8B', use_bnb=False, use_gradient_checkpointing=False, use_inputs=True, n_epochs=1, batch_size=16, lr=1e-05, weight_decay=0.0, n_samples=13500, max_length=128, max_prompt_length=64, alpha=0.1, quantile=0.75, dual_svd=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_name='NousResearch/Meta-Llama-3-8B',\n",
    "    batch_size=16, lr=1e-5,\n",
    "                         n_samples = 1500 * 3 * 3,\n",
    "\n",
    "    use_bnb=False,\n",
    "                         \n",
    "                         alpha=0.1,\n",
    "                         dual_svd=False,\n",
    "                         quantile=0.75\n",
    "                         )\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f88ddee81f8495996195c0e39eeacc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "\n",
    "model, tokenizer = load_model(args.model_name, bnb=args.use_bnb )\n",
    "\n",
    "# if args.use_gradient_checkpointing:\n",
    "# model.enable_input_require_grads()\n",
    "\n",
    "# # also freeze base model's layers :'(\n",
    "# WAIT THIS CAUSES NO GRAD\n",
    "# model = prepare_model_for_kbit_training(model, {\n",
    "#     'use_gradient_checkpointing': args.use_gradient_checkpointing,\n",
    "#         'use_reentrant': False\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is from trl https://github.com/huggingface/trl/blob/cbcaa46cd3c02c0e7f724b764c5848ae73796de7/trl/trainer/utils.py#L747\n",
    "# # not sure if it's needed but `prepare_model_for_kbit_training` doesn't seem to do this ,despite claiming to\n",
    "# def peft_module_casting_to_bf16(model):\n",
    "#     for name, module in model.named_modules():\n",
    "#         if isinstance(module, torch.nn.LayerNorm) or \"norm\" in name:\n",
    "#             module = module.to(torch.float32)\n",
    "\n",
    "# peft_module_casting_to_bf16(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13631488 || all params: 8043892736 || trainable%: 0.16946382115456393\n"
     ]
    }
   ],
   "source": [
    "from peft.tuners import BOFTConfig, OFTConfig, LoraConfig, IA3Config\n",
    "adapter_name='ReprPO'\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16, \n",
    "    r=16,\n",
    "    use_rslora=True,\n",
    "    # use_dora=True,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        # FIXME: I'm not sure we can do LORA on the layer we are targeting?\n",
    "        # \"qkv_proj\",\n",
    "          \"gate_up_proj\", # in\n",
    "        \"down_proj\",  \"o_proj\", # out\n",
    "                    ], # PHI3\n",
    ")\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c# \n",
      "===\n",
      "C# (pronounced \"C sharp\") is a modern, object-oriented programming language developed by Microsoft. It is widely used for building various types of applications, including web applications, desktop applications, mobile applications, and games. C# is similar to other programming languages such as Java and C++, and it is known for its simplicity and ease of use. C# is a powerful language that provides a rich set of libraries and frameworks that make it easy to build robust and scalable applications.\n",
      "\n",
      "Here is a brief overview of some key features of C#:\n",
      "\n",
      "1. Object-oriented: C# is an object-oriented language, which means it uses the concept of objects to represent real-world entities and their behavior.\n",
      "\n",
      "2. Cross-platform: C# can be used to build applications for multiple platforms, including Windows, macOS, and Linux.\n",
      "\n",
      "3. Strongly typed: C# is a strongly typed language, which means that variables must be declared with a specific type, and their type cannot be changed at runtime.\n",
      "\n",
      "4. Event-driven: C# uses an event-driven programming model, which means that programs are built around the concept of events, such as user input or network activity.\n",
      "\n",
      "5. Garbage-collected: C# has a garbage collector that automatically manages memory allocation and deallocation, making it easier to write memory-efficient and robust applications.\n",
      "\n",
      "6. Community-driven: C# has a large and active community of developers, who contribute to the language and its libraries through open-source projects and other initiatives.\n",
      "\n",
      "Overall, C# is a versatile and powerful programming language that is widely used for building a variety of applications.\n",
      "---\n",
      "C# is a high-level, object-oriented programming language developed by Microsoft as part of its .NET initiative. It was created as a modern alternative to Java and supports a variety of programming paradigms, including imperative, functional, and event-driven. C# is primarily used for Windows application development, but it can also be used for web, mobile, and game development. The language is designed to be safe, secure, and efficient, and it provides developers with a rich set of libraries and tools for building robust and scalable applications. C# is also widely used in the game development industry, particularly in the development of games for the Xbox 360 and Xbox One consoles.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO').map(lambda x: {\n",
    "    'prompt': x['prompt']+ ' '})\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')\n",
    "\n",
    "# QC one row\n",
    "r = dataset2['train'][0]\n",
    "print(r['prompt'])\n",
    "print('===')\n",
    "print(r['chosen'])\n",
    "print('---')\n",
    "print(r['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "\n",
    "We use huggingface datasets, which are pretokenized. So that we can stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_row(feature, tokenizer, args: TrainingArguments):\n",
    "    \"\"\"\n",
    "    Tokenize a single row from a DPO specific dataset.\n",
    "\n",
    "    see https://github.com/huggingface/trl/blob/main/trl/trainer/dpo_trainer.py#L784\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"chosen\"] = tokenizer(feature[\"chosen\"])[\"input_ids\"]\n",
    "    batch[\"rejected\"] = tokenizer(feature[\"rejected\"])[\"input_ids\"]\n",
    "    batch[\"prompt\"] = tokenizer(feature[\"prompt\"])[\"input_ids\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7bee91c7ca44269b2c36938d0a8ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b7f4087769492aa661a8b002f8011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/373 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'chosen', 'rejected'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = dataset2.map(lambda x: tokenize_row(x, tokenizer, args), batched=True, writer_batch_size=10)\n",
    "dataset3['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_collate_fn = DPODataCollatorWithPadding(pad_token_id=tokenizer.pad_token_id, \n",
    "                                                  tokenizer=tokenizer,\n",
    "                                                  max_length=args.max_length,\n",
    "                                                  mask_prompt_tokens=True,\n",
    "                                                  max_prompt_length=args.max_prompt_length,\n",
    "                                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = dataset3\n",
    "dl_train = DataLoader(ds['train'], batch_size=args.batch_size, collate_fn=custom_collate_fn)\n",
    "\n",
    "dl_val = DataLoader(ds['validation'], batch_size=args.batch_size, collate_fn=custom_collate_fn)\n",
    "\n",
    "# QC\n",
    "batch = next(iter(dl_train))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QC\n",
    "# loss, info = compute_dpo_loss_batch(batch, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://lightning.ai/docs/pytorch/latest/notebooks/lightning_examples/text-transformers.html\n",
    "- https://gist.github.com/wassname/e29d02b5026a531e13912cf768e6fdc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_steps = args.n_samples // args.batch_size\n",
    "max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from reprpo.train.lightning import GenCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft SVD: 25.00% of singular values kept, with tau=5.11, Smean=4.62, Smax=90.03, Smin=1.26\n"
     ]
    }
   ],
   "source": [
    "pl_model = PL_REPRPO_SVD_MODEL(model,\n",
    "                 weight_decay=args.weight_decay,\n",
    "                lr=args.lr,\n",
    "                num_iterations=max_steps,\n",
    "                batch_size=args.batch_size,\n",
    "                alpha=args.alpha,\n",
    "                quantile=args.quantile,\n",
    "                dual_svd=args.dual_svd,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_batch_size = max(16, args.batch_size)\n",
    "accumulate_grad_batches = np.ceil(ideal_batch_size/args.batch_size).astype(int)\n",
    "accumulate_grad_batches, args.batch_size*accumulate_grad_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/repr-preference-optimization-92Myqgn3-py3.10/lib/python3.10/site-packages/lightning/fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir ../outputs/32_repro_svd_2024-08-17_04-35-28\n"
     ]
    }
   ],
   "source": [
    "timestamp = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = f\"{nb_name}_{timestamp}\"\n",
    "save_dir = f\"../outputs/{run_name}\"\n",
    "Path(save_dir).mkdir(exist_ok=True, parents=True)\n",
    "print('save_dir', save_dir)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        max_steps=max_steps,\n",
    "        gradient_clip_val=1,\n",
    "        precision=\"bf16\",\n",
    "        log_every_n_steps=1,\n",
    "        accumulate_grad_batches=accumulate_grad_batches,\n",
    "        callbacks=[\n",
    "            LearningRateMonitor(logging_interval='step'),\n",
    "            GenCallback(every=max_steps//20),\n",
    "        ],\n",
    "        logger=[\n",
    "            CSVLogger(name=run_name, save_dir=save_dir, flush_logs_every_n_steps=5),\n",
    "            WandbLogger(name=run_name, save_dir=save_dir),\n",
    "        ],\n",
    "        default_root_dir=save_dir,\n",
    "\n",
    "        # fast_dev_run=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type                 | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | _model | PeftModelForCausalLM | 8.0 B  | train\n",
      "--------------------------------------------------------\n",
      "13.6 M    Trainable params\n",
      "8.0 B     Non-trainable params\n",
      "8.0 B     Total params\n",
      "32,175.571Total estimated model params size (MB)\n",
      "1097      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2943abb50cb749bd83688d1db058bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated on batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/repr-preference-optimization/reprpo/gen.py:239: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 83\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 125\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 167\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 209\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 251\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "Generated on batch 293\n",
      "**Question**\n",
      "```\n",
      "<<SYS>>\n",
      "tldr, markdown\n",
      "<</SYS>>\n",
      "\n",
      "<|begin_of_text|>[INST] Q1: (100 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning. [/INST]\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "` \n",
      "\n",
      "<</INST>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q1>>\n",
      "\n",
      "<</Q`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "trainer.fit(pl_model, dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = read_metrics_csv(trainer.logger.experiment.metrics_file_path).bfill().ffill()\n",
    "plot_hist(df_hist, ['loss', 'acc', 'auroc'])\n",
    "display(df_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, s=\"Q1: (30 words): Which Science Fiction Utopia is preferable and why? [The Polity, The Culture, Permutation City, 2 more]', \", max_new_tokens=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from reprpo.gen import get_model_generations\n",
    "get_model_generations(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.helpers.shypothesis import shypothesis\n",
    "from reprpo.evaluate import evaluate_adapters\n",
    "from open_pref_eval.plot.radar import radar_plot\n",
    "\n",
    "res, df_res2 = evaluate_adapters(model, tokenizer, batch_size=args.batch_size, N=144)\n",
    "radar_plot(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print acc for journal\n",
    "c  = df_res2.groupby(['adapter', 'dataset']).count().min().min()\n",
    "print(f\"â­ run={nb_name}, N={c}\")\n",
    "print()\n",
    "print(res[::-1].T[::-1].T.round(3).to_markdown()\n",
    "      )\n",
    "print()\n",
    "print('args =', args)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('did acc improve')\n",
    "acc_pi = res[adapter_name]['help_steer2-dpo'].item()\n",
    "acc_ref = res['base']['help_steer2-dpo'].item()\n",
    "shypothesis('acc_pi>acc_ref', locals())\n",
    "\n",
    "\n",
    "acc_pi_ood = res[adapter_name]['truthful_qa_binary'].item()\n",
    "acc_ref_ood = res['base']['truthful_qa_binary'].item()\n",
    "shypothesis('acc_pi_ood>acc_ref_ood', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('did coherence improve?, (measured by mean prob per token) higher is better')\n",
    "r = df_res2.groupby(['adapter', 'dataset'], dropna=False)['_chosen_logps'].mean().unstack()\n",
    "r = np.exp(r)\n",
    "display(r)\n",
    "\n",
    "coherency_pi = float(r.T[adapter_name]['help_steer2-dpo'])\n",
    "coherency_ref = float(r.T['base']['help_steer2-dpo'])\n",
    "shypothesis('coherency_pi>coherency_ref', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('are we biased by the length of the string? Ideally no correlation')\n",
    "a, b = df_res2['_l_chosen'], df_res2['_l_rejected']\n",
    "x = (a-b)/(a+b)\n",
    "plt.plot(x, df_res2['_logratio'], 'o')\n",
    "plt.xlabel('chosen longer')\n",
    "plt.ylabel('chosen more likely')\n",
    "\n",
    "# Damn this is not ideal....\n",
    "a = df_res2['_l_chosen'] / df_res2['_l_rejected']\n",
    "b = df_res2['prob']\n",
    "\n",
    "m = np.isfinite(a) & np.isfinite(b)\n",
    "a = a[m]\n",
    "b = b[m]\n",
    "corr_length = np.corrcoef(a, b)[1,0]\n",
    "print(f'{corr_length:.2f} (0 is ideal) correlation between length ratio and prob:')\n",
    "shypothesis('corr_length<0.25', locals())\n",
    "\n",
    "\n",
    "print(f'is the ds bised? {a.mean()/b.mean():.2f} (1 is ideal)')\n",
    "a=df_res2['prob']>0\n",
    "b=x>=0\n",
    "acc_bad = (a==b).mean()\n",
    "print(f'{acc_bad:.2%} (0.5 is ideal) how often does it accurately pick the longer one :( ')\n",
    "\n",
    "shypothesis('acc_bad<0.75', locals())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repr",
   "language": "python",
   "name": "repr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
