{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ax.dev/tutorials/gpei_hartmann_service.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms\n",
    "\n",
    "# training_args = tyro.extras.overridable_config_cli(experiment_configs)\n",
    "# training_args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_kwargs = dict(\n",
    "    verbose=0,\n",
    "    base_model= 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', # ideally would be SFT\n",
    "    batch_size=76,\n",
    "    load_in_4bit=True,\n",
    "    collection_layers_side = [8, 10, 12, 14, 16, 18],\n",
    "    eval_samples=24,\n",
    ")\n",
    "\n",
    "def override(cfg, overrides):\n",
    "    for k, v in overrides.items():\n",
    "        if hasattr(cfg, k):\n",
    "            setattr(cfg, k, v)\n",
    "        else:\n",
    "            print(f\"WARNING: {k} not found in config\")\n",
    "    return cfg\n",
    "\n",
    "def objective_func(**kwargs):\n",
    "    cfg = experiment_configs['side-ether-prefvec'][1]\n",
    "    override(cfg, kwargs)\n",
    "    override(cfg, tuner_kwargs)\n",
    "    print(cfg)\n",
    "    return train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'operator' has no attribute 'attrsetter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[1;32m      4\u001b[0m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss.eps\u001b[39m\u001b[38;5;124m'\u001b[39m)(cfg)\n\u001b[0;32m----> 5\u001b[0m \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrsetter\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'operator' has no attribute 'attrsetter'"
     ]
    }
   ],
   "source": [
    "cfg=experiment_configs['side-ether-prefvec'][1]\n",
    "cfg.loss.eps\n",
    "import operator\n",
    "operator.attrgetter('loss.eps')(cfg)\n",
    "operator.attrsetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = objective_func()\n",
    "# r.valuue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note you can have dependant params\n",
    "- https://github.com/facebook/Ax/issues/1454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"ax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-24 13:47:28] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter Î². If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter use_dpo_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"use_dpo_loss\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"use_dpo_loss\". Defaulting to `True` for parameters of `ParameterType` BOOL. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter use_nll_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"use_nll_loss\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"use_nll_loss\". Defaulting to `True` for parameters of `ParameterType` BOOL. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter weight_tokens. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"weight_tokens\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"weight_tokens\". Defaulting to `True` for parameters of `ParameterType` BOOL. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter use_orth_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"use_orth_loss\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/utils/instantiation.py:248: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"use_orth_loss\". Defaulting to `True` for parameters of `ParameterType` BOOL. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 09-24 13:47:28] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[1e-06, 0.4], log_scale=True), RangeParameter(name='Î²', parameter_type=FLOAT, range=[1e-06, 0.4], log_scale=True), ChoiceParameter(name='use_dpo_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='use_nll_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='weight_tokens', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='use_orth_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True)], parameter_constraints=[]).\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=6 num_trials=None use_batch_trials=False\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=12\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=12\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 09-24 13:47:28] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 12 trials, BoTorch for subsequent trials]). Iterations after 12 will take longer to generate due to model-fitting.\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:463: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n",
      "[INFO 09-24 13:47:28] ax.service.ax_client: Generated new trial 0 with parameters {'lr': 0.000192, 'Î²': 0.000436, 'use_dpo_loss': False, 'use_nll_loss': False, 'weight_tokens': False, 'use_orth_loss': False} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Î² not found in config\n",
      "WARNING: use_dpo_loss not found in config\n",
      "WARNING: use_nll_loss not found in config\n",
      "WARNING: weight_tokens not found in config\n",
      "WARNING: use_orth_loss not found in config\n",
      "ReprPOConfig(dataset='us_history_textbook', verbose=1, dev=False, load_in_4bit=True, load_in_8bit=False, use_gradient_checkpointing=False, batch_size=76, n_samples=1800, eval_samples=24, max_length=196, max_prompt_length=96, base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0', lr=0.00019195269673638238, collection_layers_side=[8, 10, 12, 14, 16, 18], collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj', 'base_model.model.model.layers.{layer}.mlp.down_proj'), collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj', 'base_model.model.model.layers.{layer}.self_attn.k_proj', 'base_model.model.model.layers.{layer}.self_attn.v_proj', 'base_model.model.model.layers.{layer}.mlp.gate_proj', 'base_model.model.model.layers.{layer}.mlp.up_proj'), collect_input=True, loss=PrefVecLossConfig(eps=1e-12, Î²=0.2, use_orth_loss=True, use_angle_loss=False, use_dpo_loss=True, use_nll_loss=True, weight_tokens=False), transform=ETHERConfig(nb=4, Htype='etherplus', ether_dropout=0.0, flip_side=False, reduction=4))\n",
      "|\u001b[1mINFO\u001b[0m| ********************************************************************************\n",
      "|\u001b[1mINFO\u001b[0m| PL_MODEL {PL_MODEL}\n",
      "|\u001b[1mINFO\u001b[0m| training_args\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=1,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=76,\n",
      "             n_samples=1800,\n",
      "             eval_samples=24,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00019195269673638238,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    Î²=0.2,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=4,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=4))\n",
      "|\u001b[1mINFO\u001b[0m| Using WANDB_GROUP=us_history_textbook-TinyLlama-1.1B-Chat-v1.0\n",
      "|\u001b[1mINFO\u001b[0m| Using finetune_name=side-ETHER-PrefVec_us_history_textbook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0ckj5oxz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23f9a3b4cc243968af8fed35171c233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.057 MB of 0.057 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>ââââââââââââââââââââââââ</td></tr><tr><td>lr-AdamW8bit</td><td>âââââââââââââââââââââââ</td></tr><tr><td>res/acc/oos</td><td>â</td></tr><tr><td>res/acc/rnd</td><td>â</td></tr><tr><td>res/acc/test</td><td>â</td></tr><tr><td>res/acc/train</td><td>â</td></tr><tr><td>res/coherency[cho-rej]/oos</td><td>â</td></tr><tr><td>res/coherency[cho-rej]/rnd</td><td>â</td></tr><tr><td>res/coherency[cho-rej]/test</td><td>â</td></tr><tr><td>res/coherency[cho-rej]/train</td><td>â</td></tr><tr><td>res/coherency[pi-base]/oos</td><td>â</td></tr><tr><td>res/coherency[pi-base]/rnd</td><td>â</td></tr><tr><td>res/coherency[pi-base]/test</td><td>â</td></tr><tr><td>res/coherency[pi-base]/train</td><td>â</td></tr><tr><td>res/relrel_acc/oos</td><td>â</td></tr><tr><td>res/relrel_acc/rnd</td><td>â</td></tr><tr><td>res/relrel_acc/test</td><td>â</td></tr><tr><td>res/â­rel_acc/oos</td><td>â</td></tr><tr><td>res/â­rel_acc/rnd</td><td>â</td></tr><tr><td>res/â­rel_acc/test</td><td>â</td></tr><tr><td>res/â­rel_acc/train</td><td>â</td></tr><tr><td>train/_cho_cosine_similarity_epoch</td><td>â</td></tr><tr><td>train/_cho_cosine_similarity_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/_cho_orthorgonal2pref_epoch</td><td>â</td></tr><tr><td>train/_cho_orthorgonal2pref_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/_ref_orthorgonal2pref_epoch</td><td>â</td></tr><tr><td>train/_ref_orthorgonal2pref_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/_rej_cosine_similarity_epoch</td><td>â</td></tr><tr><td>train/_rej_cosine_similarity_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/_signed_cho_pref_epoch</td><td>â</td></tr><tr><td>train/_signed_cho_pref_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/_signed_rej_pref_epoch</td><td>â</td></tr><tr><td>train/_signed_rej_pref_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/chosen_rewards_epoch</td><td>â</td></tr><tr><td>train/chosen_rewards_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/dpo_loss_epoch</td><td>â</td></tr><tr><td>train/dpo_loss_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/logits_epoch</td><td>â</td></tr><tr><td>train/logits_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_angle_epoch</td><td>â</td></tr><tr><td>train/loss_angle_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_cho_orth_epoch</td><td>â</td></tr><tr><td>train/loss_cho_orth_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_cho_proj_epoch</td><td>â</td></tr><tr><td>train/loss_cho_proj_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_dpo_retain_epoch</td><td>â</td></tr><tr><td>train/loss_dpo_retain_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_epoch</td><td>â</td></tr><tr><td>train/loss_nll_retain_epoch</td><td>â</td></tr><tr><td>train/loss_nll_retain_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_reroute_epoch</td><td>â</td></tr><tr><td>train/loss_reroute_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_retain_epoch</td><td>â</td></tr><tr><td>train/loss_retain_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/loss_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/model_logratios_epoch</td><td>â</td></tr><tr><td>train/model_logratios_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/nll_loss_ratio_epoch</td><td>â</td></tr><tr><td>train/nll_loss_ratio_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/ptheta_epoch</td><td>â</td></tr><tr><td>train/ptheta_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/reference_logratios_epoch</td><td>â</td></tr><tr><td>train/reference_logratios_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/rejected_rewards_epoch</td><td>â</td></tr><tr><td>train/rejected_rewards_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/retain_cosine_epoch</td><td>â</td></tr><tr><td>train/retain_cosine_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>train/rr_cosine_epoch</td><td>â</td></tr><tr><td>train/rr_cosine_step</td><td>âââââââââââââââââââââââ</td></tr><tr><td>trainer/global_step</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>lr-AdamW8bit</td><td>0.0</td></tr><tr><td>res/acc/oos</td><td>0.66933</td></tr><tr><td>res/acc/rnd</td><td>0.95833</td></tr><tr><td>res/acc/test</td><td>0.91667</td></tr><tr><td>res/acc/train</td><td>1</td></tr><tr><td>res/coherency[cho-rej]/oos</td><td>10.80367</td></tr><tr><td>res/coherency[cho-rej]/rnd</td><td>9.82061</td></tr><tr><td>res/coherency[cho-rej]/test</td><td>31.64805</td></tr><tr><td>res/coherency[cho-rej]/train</td><td>33.04581</td></tr><tr><td>res/coherency[pi-base]/oos</td><td>0.25766</td></tr><tr><td>res/coherency[pi-base]/rnd</td><td>0.05877</td></tr><tr><td>res/coherency[pi-base]/test</td><td>0.76347</td></tr><tr><td>res/coherency[pi-base]/train</td><td>0.63512</td></tr><tr><td>res/relrel_acc/oos</td><td>199601.7984</td></tr><tr><td>res/relrel_acc/rnd</td><td>1</td></tr><tr><td>res/relrel_acc/test</td><td>1</td></tr><tr><td>res/â­rel_acc/oos</td><td>0.1996</td></tr><tr><td>res/â­rel_acc/rnd</td><td>0</td></tr><tr><td>res/â­rel_acc/test</td><td>0</td></tr><tr><td>res/â­rel_acc/train</td><td>0</td></tr><tr><td>train/_cho_cosine_similarity_epoch</td><td>0.08643</td></tr><tr><td>train/_cho_cosine_similarity_step</td><td>0.11691</td></tr><tr><td>train/_cho_orthorgonal2pref_epoch</td><td>8325598145413120.0</td></tr><tr><td>train/_cho_orthorgonal2pref_step</td><td>7.073771193316147e+16</td></tr><tr><td>train/_ref_orthorgonal2pref_epoch</td><td>8674810125090816.0</td></tr><tr><td>train/_ref_orthorgonal2pref_step</td><td>6.075436969125478e+16</td></tr><tr><td>train/_rej_cosine_similarity_epoch</td><td>0.08129</td></tr><tr><td>train/_rej_cosine_similarity_step</td><td>0.09919</td></tr><tr><td>train/_signed_cho_pref_epoch</td><td>-8325598145413120.0</td></tr><tr><td>train/_signed_cho_pref_step</td><td>-7.073771193316147e+16</td></tr><tr><td>train/_signed_rej_pref_epoch</td><td>-8674810125090816.0</td></tr><tr><td>train/_signed_rej_pref_step</td><td>-6.075436969125478e+16</td></tr><tr><td>train/chosen_rewards_epoch</td><td>0.25696</td></tr><tr><td>train/chosen_rewards_step</td><td>0.41391</td></tr><tr><td>train/dpo_loss_epoch</td><td>0.67829</td></tr><tr><td>train/dpo_loss_step</td><td>0.66758</td></tr><tr><td>train/logits_epoch</td><td>0.30429</td></tr><tr><td>train/logits_step</td><td>0.52595</td></tr><tr><td>train/loss_angle_epoch</td><td>1.83228</td></tr><tr><td>train/loss_angle_step</td><td>1.7839</td></tr><tr><td>train/loss_cho_orth_epoch</td><td>1.4178937738572595e+17</td></tr><tr><td>train/loss_cho_orth_step</td><td>2.882818813995254e+17</td></tr><tr><td>train/loss_cho_proj_epoch</td><td>4.535828202966221e+16</td></tr><tr><td>train/loss_cho_proj_step</td><td>1.8914845275036058e+17</td></tr><tr><td>train/loss_dpo_retain_epoch</td><td>0.04814</td></tr><tr><td>train/loss_dpo_retain_step</td><td>0.03537</td></tr><tr><td>train/loss_epoch</td><td>0.06868</td></tr><tr><td>train/loss_nll_retain_epoch</td><td>0.00137</td></tr><tr><td>train/loss_nll_retain_step</td><td>0.00032</td></tr><tr><td>train/loss_reroute_epoch</td><td>0.01916</td></tr><tr><td>train/loss_reroute_step</td><td>0.06316</td></tr><tr><td>train/loss_retain_epoch</td><td>0.04951</td></tr><tr><td>train/loss_retain_step</td><td>0.03568</td></tr><tr><td>train/loss_step</td><td>0.09884</td></tr><tr><td>train/model_logratios_epoch</td><td>36.6828</td></tr><tr><td>train/model_logratios_step</td><td>36.17981</td></tr><tr><td>train/nll_loss_ratio_epoch</td><td>-0.00451</td></tr><tr><td>train/nll_loss_ratio_step</td><td>-0.01026</td></tr><tr><td>train/ptheta_epoch</td><td>0.30429</td></tr><tr><td>train/ptheta_step</td><td>0.52595</td></tr><tr><td>train/reference_logratios_epoch</td><td>36.37851</td></tr><tr><td>train/reference_logratios_step</td><td>35.65386</td></tr><tr><td>train/rejected_rewards_epoch</td><td>-0.04733</td></tr><tr><td>train/rejected_rewards_step</td><td>-0.11204</td></tr><tr><td>train/retain_cosine_epoch</td><td>0.94786</td></tr><tr><td>train/retain_cosine_step</td><td>0.95693</td></tr><tr><td>train/rr_cosine_epoch</td><td>0.75889</td></tr><tr><td>train/rr_cosine_step</td><td>0.77654</td></tr><tr><td>trainer/global_step</td><td>22</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">side-ETHER-PrefVec/133435</strong> at: <a href='https://wandb.ai/wassname/reprpo2/runs/0ckj5oxz' target=\"_blank\">https://wandb.ai/wassname/reprpo2/runs/0ckj5oxz</a><br/> View project at: <a href='https://wandb.ai/wassname/reprpo2' target=\"_blank\">https://wandb.ai/wassname/reprpo2</a><br/>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 4 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_133435-0ckj5oxz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0ckj5oxz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/repr-preference-optimization/nbs/wandb/run-20240924_134728-v0fv7u3e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wassname/reprpo2/runs/v0fv7u3e' target=\"_blank\">side-ETHER-PrefVec/134728</a></strong> to <a href='https://wandb.ai/wassname/reprpo2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wassname/reprpo2' target=\"_blank\">https://wandb.ai/wassname/reprpo2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wassname/reprpo2/runs/v0fv7u3e' target=\"_blank\">https://wandb.ai/wassname/reprpo2/runs/v0fv7u3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9011200 || all params: 624617472 || trainable%: 1.4426749817206521\n",
      "|\u001b[1mINFO\u001b[0m| Prompts truncated 66.83%\n",
      "|\u001b[1mINFO\u001b[0m| Chosens truncated 24.33%\n",
      "|\u001b[1mINFO\u001b[0m| WANDB url = https://wandb.ai/wassname/reprpo2/runs/v0fv7u3e\n",
      "|\u001b[1mINFO\u001b[0m| max optimiser steps 23\n",
      "|\u001b[1mINFO\u001b[0m| accumulate_grad_batches 1\n",
      "|\u001b[1mINFO\u001b[0m| accumulated batch size 76\n",
      "|\u001b[1mINFO\u001b[0m| epochs 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c91c7191cc424d982caea3beb65e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30144f4131ae473abb3a2ecc9f8fa81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated on batch 4\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`side-ETHER-PrefVec_us_history_textbook` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the \"The Polity\" by Neal Asher, a society that values individual`\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`base` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the Society of Permutation City by Greg Egan.\n",
      "\n",
      "Why: Perm`\n",
      "|\u001b[1mINFO\u001b[0m| ================================================================================\n",
      "\n",
      "Generated on batch 9\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`side-ETHER-PrefVec_us_history_textbook` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the \"The Polity\" by Neal Asher, a science fiction society that`\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`base` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the Society of Permutation City by Greg Egan.\n",
      "\n",
      "Why: Perm`\n",
      "|\u001b[1mINFO\u001b[0m| ================================================================================\n",
      "\n",
      "Generated on batch 14\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`side-ETHER-PrefVec_us_history_textbook` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the \"The Polity\" by Neal Asher, a science fiction society that`\n",
      "|\u001b[1mINFO\u001b[0m| --------------------------------------------------------------------------------\n",
      "|\u001b[1mINFO\u001b[0m| **Adapter:`base` generation**`\n",
      "|\u001b[1mINFO\u001b[0m| `Q1: (100 words): I would prefer to live in the Society of Permutation City by Greg Egan.\n",
      "\n",
      "Why: Perm`\n",
      "|\u001b[1mINFO\u001b[0m| ================================================================================\n"
     ]
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from ax.utils.measurement.synthetic_functions import branin\n",
    "\n",
    "\n",
    "ax_client = AxClient(verbose_logging=False)\n",
    "ax_client.create_experiment(\n",
    "    name=\"branin_test_experiment\",\n",
    "    parameters=[\n",
    "         {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\"name\": \"Î²\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\n",
    "            \"name\": \"use_dpo_loss\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [False, True],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"use_nll_loss\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [False, True],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"weight_tokens\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [False, True],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"use_orth_loss\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [False, True],\n",
    "        },\n",
    "    ],\n",
    "    objectives={\"objective_func\": ObjectiveProperties(minimize=False)},\n",
    ")\n",
    "\n",
    "for _ in range(15):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=objective_func(**parameters))\n",
    "\n",
    "best_parameters, metrics = ax_client.get_best_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, best_values, experiment, model = optimize(\n",
    "    #  experiment_name=\"test\",\n",
    "    # objective_name=\"hartmann6\",\n",
    "        parameters=[\n",
    "          {\n",
    "            \"name\": \"lr\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"x2\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [-10.0, 10.0],\n",
    "          },\n",
    "        ],\n",
    "        # returns acc improvement on oos\n",
    "        evaluation_function=objective_func,\n",
    "        minimize=False,\n",
    "        total_trials=30,  # Optional.\n",
    "    )\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
