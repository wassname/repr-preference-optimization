{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ax.dev/tutorials/gpei_hartmann_service.html\n",
    "- https://ax.dev/versions/0.4.1/tutorials/gpei_hartmann_service.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms\n",
    "\n",
    "# training_args = tyro.extras.overridable_config_cli(experiment_configs)\n",
    "# training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def setattrattr(cfg, k, v):\n",
    "    \"\"\"\n",
    "    Sets an attr even it's like o.a.b\n",
    "    \"\"\"\n",
    "    if \".\" in k:\n",
    "        k, k2 = k.split(\".\")\n",
    "        # print(k, k2)\n",
    "        # print(getattr(cfg, k))\n",
    "        return setattrattr(getattr(cfg, k), k2, v)\n",
    "    else:\n",
    "        # print(cfg, k, v)\n",
    "        return setattr(cfg, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick 2m per run\n",
    "tuner_kwargs = dict(\n",
    "    verbose=0,\n",
    "    base_model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # ideally would be SFT\n",
    "    batch_size=64,\n",
    "    load_in_4bit=True,\n",
    "    collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
    "    eval_samples=64,\n",
    ")\n",
    "\n",
    "\n",
    "def override(cfg, overrides):\n",
    "    for k, v in overrides.items():\n",
    "        try:\n",
    "            setattrattr(cfg, k, v)\n",
    "        except ValueError:\n",
    "            print(f\"WARNING: {k} not found in config\")\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def objective_func(**kwargs):\n",
    "    cfg = copy.deepcopy(experiment_configs[\"side-ether-prefvec\"][1])\n",
    "    override(cfg, tuner_kwargs)\n",
    "    override(cfg, kwargs)\n",
    "    r = train(cfg)\n",
    "    # print('r', r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../outputs/ax/ether-prefvec2.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "name=\"ether-prefvec2\"\n",
    "exp_f = Path(f\"../outputs/ax/{name}.json\")\n",
    "exp_f.parent.mkdir(exist_ok=True, parents=True)\n",
    "exp_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note you can have dependant params\n",
    "- https://github.com/facebook/Ax/issues/1454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from ax.core.parameter import AxParameterWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"ax\")\n",
    "warnings.simplefilter(\"ignore\", AxParameterWarning)\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "# logger.add(os.sys.stdout, level=\"INFO\")\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter collect_input. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter collect_hs. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter loss.β. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter loss.use_dpo_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter loss.use_nll_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter loss.use_angle_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter loss.weight_tokens. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.BOOL for parameter loss.use_orth_loss. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter transform.nb. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.STRING for parameter transform.Htype. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter transform.reduction. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 09-25 14:04:22] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[1e-06, 0.4], log_scale=True), ChoiceParameter(name='collect_input', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='collect_hs', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), RangeParameter(name='loss.β', parameter_type=FLOAT, range=[1e-06, 2.0], log_scale=True), ChoiceParameter(name='loss.use_dpo_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='loss.use_nll_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='loss.use_angle_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='loss.weight_tokens', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), ChoiceParameter(name='loss.use_orth_loss', parameter_type=BOOL, values=[False, True], is_ordered=True, sort_values=True), RangeParameter(name='transform.nb', parameter_type=INT, range=[1, 64]), ChoiceParameter(name='transform.Htype', parameter_type=STRING, values=['ether', 'etherplus', 'oft', 'etherplusHH'], is_ordered=False, sort_values=False), RangeParameter(name='transform.reduction', parameter_type=INT, range=[1, 128])], parameter_constraints=[]).\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=12 num_trials=None use_batch_trials=False\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=24\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=24\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 09-25 14:04:22] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 24 trials, BoTorch for subsequent trials]). Iterations after 24 will take longer to generate due to model-fitting.\n"
     ]
    }
   ],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "\n",
    "if exp_f.exists():\n",
    "    ax_client = AxClient.load_from_json_file(filepath=exp_f, verbose_logging=False)\n",
    "else:\n",
    "    ax_client = AxClient(verbose_logging=False)\n",
    "\n",
    "    ax_client.create_experiment(\n",
    "        name=name,\n",
    "        parameters=[\n",
    "            # main\n",
    "            {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "            {\"name\": \"collect_input\", \"type\": \"choice\", \"values\": [False, True]},\n",
    "            {\"name\": \"collect_hs\", \"type\": \"choice\", \"values\": [False, True]},\n",
    "            # {\n",
    "            #     \"name\": \"loss\",\n",
    "            #     \"type\": \"choice\",\n",
    "            #     \"values\": [\"mse\", \"prefvec\", \"rank\"],\n",
    "            #     \"dependents\": {\n",
    "            #         \"prefvec\": [\"loss.β\", \"loss.use_dpo_loss\",\"loss.use_nll_loss\",\"loss.weight_tokens\",\"loss.use_orth_loss\",],\n",
    "            #         \"rank\": [\"loss.α\"],\n",
    "            #         \"mse\": [\"loss.α\"],\n",
    "            #     },\n",
    "            # },\n",
    "            # {\n",
    "            #     \"name\": \"transform\",\n",
    "            #     \"type\": \"choice\",\n",
    "            #     \"values\": [\"ether\", \"svd\", \"ortho\", \"none\", \"hra\"],\n",
    "            #     \"dependents\": {\n",
    "            #         \"ether\": [\"transform.nb\", \"transform.Htype\", \"transform.reduction\"],\n",
    "            #         \"svd\": [\"transform.quantile\", \"transform.dual_svd\"],\n",
    "            #     },\n",
    "            # },\n",
    "            # NOT prefvec\n",
    "            # {\n",
    "            #     \"name\": \"loss.α\",\n",
    "            #     \"type\": \"range\",\n",
    "            #     \"bounds\": [1.e-6, 2.],\n",
    "            #     \"log_scale\": True,\n",
    "            # },\n",
    "            # # SVD\n",
    "            # {\n",
    "            #     \"name\": \"transform.quantile\",\n",
    "            #     \"type\": \"choice\",\n",
    "            #     \"values\": [0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "            # },\n",
    "            # {\n",
    "            #     \"name\": \"transform.dual_svd\",\n",
    "            #     \"type\": \"choice\",\n",
    "            #     \"values\": [False, True],\n",
    "            # },\n",
    "            # prefvec\n",
    "            {\n",
    "                \"name\": \"loss.β\",\n",
    "                \"type\": \"range\",\n",
    "                \"bounds\": [1.e-6, 2.],\n",
    "                \"log_scale\": True,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"loss.use_dpo_loss\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [False, True],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"loss.use_nll_loss\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [False, True],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"loss.use_angle_loss\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [False, True],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"loss.weight_tokens\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [False, True],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"loss.use_orth_loss\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [False, True],\n",
    "            },\n",
    "            # ether\n",
    "            {\n",
    "                \"name\": \"transform.nb\",\n",
    "                \"type\": \"range\",\n",
    "                \"bounds\": [1, 64],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"transform.Htype\",\n",
    "                \"type\": \"choice\",\n",
    "                \"values\": [\"ether\", \"etherplus\", \"oft\", \"etherplusHH\"],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"transform.reduction\",\n",
    "                \"type\": \"range\",\n",
    "                \"bounds\": [1, 128],\n",
    "            },\n",
    "        ],\n",
    "        tracking_metric_names=[\n",
    "            \"acc/train\",\n",
    "            \"acc/test\",\n",
    "            \"acc/oos\",\n",
    "            \"acc/rnd\",\n",
    "            \n",
    "            \"acc_gain_vs_ref/train\",\n",
    "            \"acc_gain_vs_ref/test\",\n",
    "            \"acc_gain_vs_ref/oos\",\n",
    "            \"acc_gain_vs_ref/rnd\",\n",
    "\n",
    "            \"perplexity_gain_vs_ref/train\",\n",
    "            \"perplexity_gain_vs_ref/test\",\n",
    "            \"perplexity_gain_vs_ref/oos\",\n",
    "            \"perplexity_gain_vs_ref/rnd\",\n",
    "\n",
    "            \"preference_logp_gain/train\",\n",
    "            \"preference_logp_gain/test\",\n",
    "            \"preference_logp_gain/oos\",\n",
    "            \"preference_logp_gain/rnd\",\n",
    "\n",
    "            \"preference_logp_gain_vs_ref/train\",\n",
    "            \"preference_logp_gain_vs_ref/test\",\n",
    "            \"preference_logp_gain_vs_ref/oos\",\n",
    "            \"preference_logp_gain_vs_ref/rnd\",\n",
    "        ],\n",
    "        objectives={\"acc_gain_vs_ref/oos\": ObjectiveProperties(minimize=False)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233509f0438342a781061ba5335d2267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Disabling the wandb service is deprecated as of version 0.18.0 and will be removed in version 0.19.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=4.698871626213426e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.35858300660942233,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=12,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=120))\n",
      "{'lr': 4.698871626213426e-06, 'collect_input': False, 'collect_hs': True, 'loss.β': 0.35858300660942233, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 12, 'transform.reduction': 120, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6693333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.001996007984032, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9968014359474182, 'perplexity_gain_vs_ref/test': 0.9969602823257446, 'perplexity_gain_vs_ref/oos': 0.996770977973938, 'perplexity_gain_vs_ref/rnd': 0.9987797141075134, 'preference_logp_gain/train': 36.44829559326172, 'preference_logp_gain/test': 37.21131896972656, 'preference_logp_gain/oos': 10.733551025390625, 'preference_logp_gain/rnd': 13.583717346191406, 'preference_logp_gain_vs_ref/train': 0.3019052743911743, 'preference_logp_gain_vs_ref/test': 0.19602108001708984, 'preference_logp_gain_vs_ref/oos': 0.1978931427001953, 'preference_logp_gain_vs_ref/rnd': 0.09829875826835632}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.3572583640746265,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0007706472049200012,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=41,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=46))\n",
      "{'lr': 0.3572583640746265, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.0007706472049200012, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 41, 'transform.reduction': 46, 'transform.Htype': 'etherplusHH'} {'acc/train': 0.71875, 'acc/test': 0.6875, 'acc/oos': 0.2786666666666667, 'acc/rnd': 0.71875, 'acc_gain_vs_ref/train': 0.71875, 'acc_gain_vs_ref/test': 0.7096774193548387, 'acc_gain_vs_ref/oos': 0.4171656686626746, 'acc_gain_vs_ref/rnd': 0.7796610169491526, 'perplexity_gain_vs_ref/train': 88334.140625, 'perplexity_gain_vs_ref/test': 72358.609375, 'perplexity_gain_vs_ref/oos': 84983.15625, 'perplexity_gain_vs_ref/rnd': 68335.1640625, 'preference_logp_gain/train': 30.4256591796875, 'preference_logp_gain/test': 31.38885498046875, 'preference_logp_gain/oos': -110.2327880859375, 'preference_logp_gain/rnd': 41.3778076171875, 'preference_logp_gain_vs_ref/train': -5.720680236816406, 'preference_logp_gain_vs_ref/test': -5.626469135284424, 'preference_logp_gain_vs_ref/oos': -118.04021453857422, 'preference_logp_gain_vs_ref/rnd': 27.89240074157715}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.003455992730323428,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.008030648693693677,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=53,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=15))\n",
      "{'lr': 0.003455992730323428, 'collect_input': False, 'collect_hs': True, 'loss.β': 0.008030648693693677, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 53, 'transform.reduction': 15, 'transform.Htype': 'etherplus'} {'acc/train': 0.875, 'acc/test': 0.6875, 'acc/oos': 0.31733333333333336, 'acc/rnd': 0.6875, 'acc_gain_vs_ref/train': 0.875, 'acc_gain_vs_ref/test': 0.7096774193548387, 'acc_gain_vs_ref/oos': 0.4750499001996008, 'acc_gain_vs_ref/rnd': 0.7457627118644068, 'perplexity_gain_vs_ref/train': 2303.694580078125, 'perplexity_gain_vs_ref/test': 2329.24072265625, 'perplexity_gain_vs_ref/oos': 2493.921142578125, 'perplexity_gain_vs_ref/rnd': 8279.5068359375, 'preference_logp_gain/train': 48.46600341796875, 'preference_logp_gain/test': 51.06048583984375, 'preference_logp_gain/oos': -66.19140625, 'preference_logp_gain/rnd': 31.40740966796875, 'preference_logp_gain_vs_ref/train': 12.31960678100586, 'preference_logp_gain_vs_ref/test': 14.045190811157227, 'preference_logp_gain_vs_ref/oos': -75.04939270019531, 'preference_logp_gain_vs_ref/rnd': 17.921985626220703}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=2.8890163539258293e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.7882442158180859e-06,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=24,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=85))\n",
      "{'lr': 2.8890163539258293e-05, 'collect_input': True, 'collect_hs': False, 'loss.β': 1.7882442158180859e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 24, 'transform.reduction': 85, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.0103399753570557, 'perplexity_gain_vs_ref/test': 1.0180883407592773, 'perplexity_gain_vs_ref/oos': 1.00557541847229, 'perplexity_gain_vs_ref/rnd': 1.0218966007232666, 'preference_logp_gain/train': 35.71295928955078, 'preference_logp_gain/test': 36.346839904785156, 'preference_logp_gain/oos': 10.281410217285156, 'preference_logp_gain/rnd': 13.325325012207031, 'preference_logp_gain_vs_ref/train': -0.4334293007850647, 'preference_logp_gain_vs_ref/test': -0.6684661507606506, 'preference_logp_gain_vs_ref/oos': -0.25471803545951843, 'preference_logp_gain_vs_ref/rnd': -0.1600969433784485}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00035834334618317664,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.303786095460835e-05,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=38,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=75))\n",
      "{'lr': 0.00035834334618317664, 'collect_input': False, 'collect_hs': False, 'loss.β': 1.303786095460835e-05, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 38, 'transform.reduction': 75, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.7373333333333333, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.1037924151696605, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.0836400985717773, 'perplexity_gain_vs_ref/test': 1.0808323621749878, 'perplexity_gain_vs_ref/oos': 0.9996697902679443, 'perplexity_gain_vs_ref/rnd': 1.2727062702178955, 'preference_logp_gain/train': 41.76219940185547, 'preference_logp_gain/test': 41.56468963623047, 'preference_logp_gain/oos': 16.21595001220703, 'preference_logp_gain/rnd': 15.622299194335938, 'preference_logp_gain_vs_ref/train': 5.615800857543945, 'preference_logp_gain_vs_ref/test': 4.549378395080566, 'preference_logp_gain_vs_ref/oos': 5.63604736328125, 'preference_logp_gain_vs_ref/rnd': 2.13688325881958}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.002098327710966113,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.03714489927074638,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=7,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=17))\n",
      "{'lr': 0.002098327710966113, 'collect_input': True, 'collect_hs': True, 'loss.β': 0.03714489927074638, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 7, 'transform.reduction': 17, 'transform.Htype': 'etherplus'} {'acc/train': 0.984375, 'acc/test': 0.984375, 'acc/oos': 0.6213333333333333, 'acc/rnd': 0.84375, 'acc_gain_vs_ref/train': 0.984375, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 0.9301397205588822, 'acc_gain_vs_ref/rnd': 0.9152542372881356, 'perplexity_gain_vs_ref/train': 6.7669997215271, 'perplexity_gain_vs_ref/test': 6.4377007484436035, 'perplexity_gain_vs_ref/oos': 6.255143642425537, 'perplexity_gain_vs_ref/rnd': 26.274063110351562, 'preference_logp_gain/train': 53.734344482421875, 'preference_logp_gain/test': 64.20783996582031, 'preference_logp_gain/oos': 14.208282470703125, 'preference_logp_gain/rnd': 20.402145385742188, 'preference_logp_gain_vs_ref/train': 17.58795738220215, 'preference_logp_gain_vs_ref/test': 27.19253158569336, 'preference_logp_gain_vs_ref/oos': 3.8143370151519775, 'preference_logp_gain_vs_ref/rnd': 6.916714668273926}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.028712215564126738,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.00010597631460408278,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=27,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=52))\n",
      "{'lr': 0.028712215564126738, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.00010597631460408278, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 27, 'transform.reduction': 52, 'transform.Htype': 'etherplusHH'} {'acc/train': 0.84375, 'acc/test': 0.734375, 'acc/oos': 0.29333333333333333, 'acc/rnd': 0.75, 'acc_gain_vs_ref/train': 0.84375, 'acc_gain_vs_ref/test': 0.7580645161290323, 'acc_gain_vs_ref/oos': 0.43912175648702595, 'acc_gain_vs_ref/rnd': 0.8135593220338984, 'perplexity_gain_vs_ref/train': 4673.3154296875, 'perplexity_gain_vs_ref/test': 4586.6318359375, 'perplexity_gain_vs_ref/oos': 4980.39599609375, 'perplexity_gain_vs_ref/rnd': 7768.2880859375, 'preference_logp_gain/train': 52.2535400390625, 'preference_logp_gain/test': 51.90325927734375, 'preference_logp_gain/oos': -77.89617919921875, 'preference_logp_gain/rnd': 33.6561279296875, 'preference_logp_gain_vs_ref/train': 16.107173919677734, 'preference_logp_gain_vs_ref/test': 14.887975692749023, 'preference_logp_gain_vs_ref/oos': -86.84037017822266, 'preference_logp_gain_vs_ref/rnd': 20.170696258544922}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=7.812586068518406e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0774514465562157,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=58,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=106))\n",
      "{'lr': 7.812586068518406e-06, 'collect_input': True, 'collect_hs': True, 'loss.β': 0.0774514465562157, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 58, 'transform.reduction': 106, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.6666666666666666, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 0.9980039920159679, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.0049269199371338, 'perplexity_gain_vs_ref/test': 1.005981206893921, 'perplexity_gain_vs_ref/oos': 1.0039275884628296, 'perplexity_gain_vs_ref/rnd': 1.003177523612976, 'preference_logp_gain/train': 35.870086669921875, 'preference_logp_gain/test': 36.87278747558594, 'preference_logp_gain/oos': 10.308425903320312, 'preference_logp_gain/rnd': 13.410423278808594, 'preference_logp_gain_vs_ref/train': -0.2763136625289917, 'preference_logp_gain_vs_ref/test': -0.14251482486724854, 'preference_logp_gain_vs_ref/oos': -0.22265514731407166, 'preference_logp_gain_vs_ref/rnd': -0.07499551773071289}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.55680609747122e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.009993798169637547,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=20,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=7))\n",
      "{'lr': 1.55680609747122e-05, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.009993798169637547, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 20, 'transform.reduction': 7, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.676, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0119760479041917, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9872053861618042, 'perplexity_gain_vs_ref/test': 0.9876432418823242, 'perplexity_gain_vs_ref/oos': 0.9944398999214172, 'perplexity_gain_vs_ref/rnd': 1.0029851198196411, 'preference_logp_gain/train': 37.149078369140625, 'preference_logp_gain/test': 37.97444152832031, 'preference_logp_gain/oos': 11.095878601074219, 'preference_logp_gain/rnd': 13.627632141113281, 'preference_logp_gain_vs_ref/train': 1.0026836395263672, 'preference_logp_gain_vs_ref/test': 0.9591434597969055, 'preference_logp_gain_vs_ref/oos': 0.5528822541236877, 'preference_logp_gain_vs_ref/rnd': 0.14220944046974182}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.04596746929222199,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.1820547997117876e-05,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=49,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=93))\n",
      "{'lr': 0.04596746929222199, 'collect_input': True, 'collect_hs': True, 'loss.β': 2.1820547997117876e-05, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 49, 'transform.reduction': 93, 'transform.Htype': 'etherplus'} {'acc/train': 0.75, 'acc/test': 0.671875, 'acc/oos': 0.288, 'acc/rnd': 0.671875, 'acc_gain_vs_ref/train': 0.75, 'acc_gain_vs_ref/test': 0.6935483870967742, 'acc_gain_vs_ref/oos': 0.43113772455089816, 'acc_gain_vs_ref/rnd': 0.7288135593220338, 'perplexity_gain_vs_ref/train': 34627.64453125, 'perplexity_gain_vs_ref/test': 30204.228515625, 'perplexity_gain_vs_ref/oos': 37448.0625, 'perplexity_gain_vs_ref/rnd': 23964.212890625, 'preference_logp_gain/train': 30.32843017578125, 'preference_logp_gain/test': 30.61810302734375, 'preference_logp_gain/oos': -99.359619140625, 'preference_logp_gain/rnd': 35.3134765625, 'preference_logp_gain_vs_ref/train': -5.81790828704834, 'preference_logp_gain_vs_ref/test': -6.397210597991943, 'preference_logp_gain_vs_ref/oos': -107.9263916015625, 'preference_logp_gain_vs_ref/rnd': 21.828094482421875}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0010195677863621164,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.2835718987665737,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=45,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 0.0010195677863621164, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.2835718987665737, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 45, 'transform.reduction': 128, 'transform.Htype': 'oft'} {'acc/train': 0.9375, 'acc/test': 0.875, 'acc/oos': 0.4, 'acc/rnd': 0.859375, 'acc_gain_vs_ref/train': 0.9375, 'acc_gain_vs_ref/test': 0.9032258064516129, 'acc_gain_vs_ref/oos': 0.5988023952095808, 'acc_gain_vs_ref/rnd': 0.9322033898305084, 'perplexity_gain_vs_ref/train': 13.399880409240723, 'perplexity_gain_vs_ref/test': 11.817564964294434, 'perplexity_gain_vs_ref/oos': 12.382243156433105, 'perplexity_gain_vs_ref/rnd': 6.014145374298096, 'preference_logp_gain/train': 23.538604736328125, 'preference_logp_gain/test': 26.618072509765625, 'preference_logp_gain/oos': -20.381439208984375, 'preference_logp_gain/rnd': 15.1072998046875, 'preference_logp_gain_vs_ref/train': -12.607768058776855, 'preference_logp_gain_vs_ref/test': -10.39723014831543, 'preference_logp_gain_vs_ref/oos': -30.110780715942383, 'preference_logp_gain_vs_ref/rnd': 1.6218698024749756}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00020933926182404528,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=6.416751808736935e-05,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=16,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=38))\n",
      "{'lr': 0.00020933926182404528, 'collect_input': True, 'collect_hs': True, 'loss.β': 6.416751808736935e-05, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 16, 'transform.reduction': 38, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6893333333333334, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.031936127744511, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9756624102592468, 'perplexity_gain_vs_ref/test': 0.9464591145515442, 'perplexity_gain_vs_ref/oos': 1.012729287147522, 'perplexity_gain_vs_ref/rnd': 1.0136010646820068, 'preference_logp_gain/train': 39.97502899169922, 'preference_logp_gain/test': 40.69718933105469, 'preference_logp_gain/oos': 12.418792724609375, 'preference_logp_gain/rnd': 14.201766967773438, 'preference_logp_gain_vs_ref/train': 3.828631639480591, 'preference_logp_gain_vs_ref/test': 3.6818947792053223, 'preference_logp_gain_vs_ref/oos': 1.860869288444519, 'preference_logp_gain_vs_ref/rnd': 0.716341495513916}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00010555272984829231,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0005213008241761173,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=62,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=60))\n",
      "{'lr': 0.00010555272984829231, 'collect_input': False, 'collect_hs': True, 'loss.β': 0.0005213008241761173, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 62, 'transform.reduction': 60, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6813333333333333, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0199600798403192, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 0.9816659092903137, 'perplexity_gain_vs_ref/test': 0.9726932048797607, 'perplexity_gain_vs_ref/oos': 0.9918701648712158, 'perplexity_gain_vs_ref/rnd': 1.0045653581619263, 'preference_logp_gain/train': 38.936546325683594, 'preference_logp_gain/test': 39.74977111816406, 'preference_logp_gain/oos': 11.952629089355469, 'preference_logp_gain/rnd': 14.112205505371094, 'preference_logp_gain_vs_ref/train': 2.7901506423950195, 'preference_logp_gain_vs_ref/test': 2.734468698501587, 'preference_logp_gain_vs_ref/oos': 1.3963993787765503, 'preference_logp_gain_vs_ref/rnd': 0.6267848014831543}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.015133282998751179,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.4663785227241388,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=31,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=98))\n",
      "{'lr': 0.015133282998751179, 'collect_input': True, 'collect_hs': False, 'loss.β': 1.4663785227241388, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 31, 'transform.reduction': 98, 'transform.Htype': 'etherplus'} {'acc/train': 0.796875, 'acc/test': 0.671875, 'acc/oos': 0.284, 'acc/rnd': 0.71875, 'acc_gain_vs_ref/train': 0.796875, 'acc_gain_vs_ref/test': 0.6935483870967742, 'acc_gain_vs_ref/oos': 0.42514970059880236, 'acc_gain_vs_ref/rnd': 0.7796610169491526, 'perplexity_gain_vs_ref/train': 31593.111328125, 'perplexity_gain_vs_ref/test': 33031.1640625, 'perplexity_gain_vs_ref/oos': 40658.578125, 'perplexity_gain_vs_ref/rnd': 34293.328125, 'preference_logp_gain/train': 42.78057861328125, 'preference_logp_gain/test': 40.28948974609375, 'preference_logp_gain/oos': -99.6361083984375, 'preference_logp_gain/rnd': 32.51171875, 'preference_logp_gain_vs_ref/train': 6.634173393249512, 'preference_logp_gain_vs_ref/test': 3.274188995361328, 'preference_logp_gain_vs_ref/oos': -108.27523803710938, 'preference_logp_gain_vs_ref/rnd': 19.026287078857422}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.09497583589770942,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.683706018055974e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=3,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=67))\n",
      "{'lr': 0.09497583589770942, 'collect_input': False, 'collect_hs': True, 'loss.β': 2.683706018055974e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 3, 'transform.reduction': 67, 'transform.Htype': 'ether'} {'acc/train': 0.734375, 'acc/test': 0.703125, 'acc/oos': 0.2853333333333333, 'acc/rnd': 0.703125, 'acc_gain_vs_ref/train': 0.734375, 'acc_gain_vs_ref/test': 0.7258064516129032, 'acc_gain_vs_ref/oos': 0.4271457085828343, 'acc_gain_vs_ref/rnd': 0.7627118644067796, 'perplexity_gain_vs_ref/train': 1195.7823486328125, 'perplexity_gain_vs_ref/test': 1207.346435546875, 'perplexity_gain_vs_ref/oos': 1370.9052734375, 'perplexity_gain_vs_ref/rnd': 2127.954833984375, 'preference_logp_gain/train': 29.9306640625, 'preference_logp_gain/test': 27.97705078125, 'preference_logp_gain/oos': -71.671630859375, 'preference_logp_gain/rnd': 23.7464599609375, 'preference_logp_gain_vs_ref/train': -6.215750694274902, 'preference_logp_gain_vs_ref/test': -9.038240432739258, 'preference_logp_gain_vs_ref/oos': -80.57445526123047, 'preference_logp_gain_vs_ref/rnd': 10.261028289794922}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.0004624280563796e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0019378602724613445,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=34,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=25))\n",
      "{'lr': 1.0004624280563796e-06, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.0019378602724613445, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 34, 'transform.reduction': 25, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6666666666666666, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.9980039920159679, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9984340667724609, 'perplexity_gain_vs_ref/test': 0.9992678165435791, 'perplexity_gain_vs_ref/oos': 0.9992719292640686, 'perplexity_gain_vs_ref/rnd': 1.0011934041976929, 'preference_logp_gain/train': 36.219757080078125, 'preference_logp_gain/test': 36.99506378173828, 'preference_logp_gain/oos': 10.571739196777344, 'preference_logp_gain/rnd': 13.523818969726562, 'preference_logp_gain_vs_ref/train': 0.07337087392807007, 'preference_logp_gain_vs_ref/test': -0.020242631435394287, 'preference_logp_gain_vs_ref/oos': 0.0418788306415081, 'preference_logp_gain_vs_ref/rnd': 0.038398414850234985}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.65774250705158e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.00018060281162503327,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=5,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=92))\n",
      "{'lr': 1.65774250705158e-06, 'collect_input': False, 'collect_hs': True, 'loss.β': 0.00018060281162503327, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 5, 'transform.reduction': 92, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6666666666666666, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.9980039920159679, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.0000650882720947, 'perplexity_gain_vs_ref/test': 0.9999496936798096, 'perplexity_gain_vs_ref/oos': 1.0007363557815552, 'perplexity_gain_vs_ref/rnd': 1.0022127628326416, 'preference_logp_gain/train': 36.15174865722656, 'preference_logp_gain/test': 36.99024200439453, 'preference_logp_gain/oos': 10.512680053710938, 'preference_logp_gain/rnd': 13.458335876464844, 'preference_logp_gain_vs_ref/train': 0.005355179309844971, 'preference_logp_gain_vs_ref/test': -0.02505546808242798, 'preference_logp_gain_vs_ref/oos': -0.022142140194773674, 'preference_logp_gain_vs_ref/rnd': -0.027078449726104736}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.1286462784537999,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.1265004118579566,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=40,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=2))\n",
      "{'lr': 0.1286462784537999, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.1265004118579566, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 40, 'transform.reduction': 2, 'transform.Htype': 'ether'} {'acc/train': 0.734375, 'acc/test': 0.671875, 'acc/oos': 0.29733333333333334, 'acc/rnd': 0.75, 'acc_gain_vs_ref/train': 0.734375, 'acc_gain_vs_ref/test': 0.6935483870967742, 'acc_gain_vs_ref/oos': 0.44510978043912175, 'acc_gain_vs_ref/rnd': 0.8135593220338984, 'perplexity_gain_vs_ref/train': 2786387.75, 'perplexity_gain_vs_ref/test': 2198425.0, 'perplexity_gain_vs_ref/oos': 2201614.25, 'perplexity_gain_vs_ref/rnd': 1994397.75, 'preference_logp_gain/train': 38.238037109375, 'preference_logp_gain/test': 42.32421875, 'preference_logp_gain/oos': -139.9290771484375, 'preference_logp_gain/rnd': 50.43133544921875, 'preference_logp_gain_vs_ref/train': 2.0916194915771484, 'preference_logp_gain_vs_ref/test': 5.308945655822754, 'preference_logp_gain_vs_ref/oos': -147.57627868652344, 'preference_logp_gain_vs_ref/rnd': 36.94590377807617}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.009154668024203753,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=7.98271637927006e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=60,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=35))\n",
      "{'lr': 0.009154668024203753, 'collect_input': False, 'collect_hs': True, 'loss.β': 7.98271637927006e-06, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 60, 'transform.reduction': 35, 'transform.Htype': 'etherplusHH'} {'acc/train': 0.84375, 'acc/test': 0.796875, 'acc/oos': 0.312, 'acc/rnd': 0.703125, 'acc_gain_vs_ref/train': 0.84375, 'acc_gain_vs_ref/test': 0.8225806451612904, 'acc_gain_vs_ref/oos': 0.467065868263473, 'acc_gain_vs_ref/rnd': 0.7627118644067796, 'perplexity_gain_vs_ref/train': 2262.873046875, 'perplexity_gain_vs_ref/test': 2186.693359375, 'perplexity_gain_vs_ref/oos': 2635.162109375, 'perplexity_gain_vs_ref/rnd': 9958.1123046875, 'preference_logp_gain/train': 52.10809326171875, 'preference_logp_gain/test': 54.5528564453125, 'preference_logp_gain/oos': -64.79779052734375, 'preference_logp_gain/rnd': 31.33514404296875, 'preference_logp_gain_vs_ref/train': 15.961662292480469, 'preference_logp_gain_vs_ref/test': 17.537525177001953, 'preference_logp_gain_vs_ref/oos': -73.80260467529297, 'preference_logp_gain_vs_ref/rnd': 17.849740982055664}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=7.811080318415609e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.021795996532242123,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=25,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=121))\n",
      "{'lr': 7.811080318415609e-05, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.021795996532242123, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 25, 'transform.reduction': 121, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6866666666666666, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.027944111776447, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9710134863853455, 'perplexity_gain_vs_ref/test': 0.9678762555122375, 'perplexity_gain_vs_ref/oos': 1.0016664266586304, 'perplexity_gain_vs_ref/rnd': 1.0010006427764893, 'preference_logp_gain/train': 37.30104064941406, 'preference_logp_gain/test': 38.01335144042969, 'preference_logp_gain/oos': 11.385246276855469, 'preference_logp_gain/rnd': 13.547157287597656, 'preference_logp_gain_vs_ref/train': 1.154651165008545, 'preference_logp_gain_vs_ref/test': 0.998047947883606, 'preference_logp_gain_vs_ref/oos': 0.8402025103569031, 'preference_logp_gain_vs_ref/rnd': 0.06173768639564514}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00012623557406452626,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.005296543653947226,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=43,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=103))\n",
      "{'lr': 0.00012623557406452626, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.005296543653947226, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 43, 'transform.reduction': 103, 'transform.Htype': 'oft'} {'acc/train': 0.984375, 'acc/test': 0.984375, 'acc/oos': 0.6533333333333333, 'acc/rnd': 0.890625, 'acc_gain_vs_ref/train': 0.984375, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 0.9780439121756487, 'acc_gain_vs_ref/rnd': 0.9661016949152542, 'perplexity_gain_vs_ref/train': 1.0598920583724976, 'perplexity_gain_vs_ref/test': 1.0698574781417847, 'perplexity_gain_vs_ref/oos': 1.060175895690918, 'perplexity_gain_vs_ref/rnd': 1.017646312713623, 'preference_logp_gain/train': 33.99803161621094, 'preference_logp_gain/test': 34.61621856689453, 'preference_logp_gain/oos': 8.692955017089844, 'preference_logp_gain/rnd': 12.865524291992188, 'preference_logp_gain_vs_ref/train': -2.1483678817749023, 'preference_logp_gain_vs_ref/test': -2.399088144302368, 'preference_logp_gain_vs_ref/oos': -1.8295536041259766, 'preference_logp_gain_vs_ref/rnd': -0.6198916435241699}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0007521065373884186,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.2306486058482005e-06,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=10,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=61))\n",
      "{'lr': 0.0007521065373884186, 'collect_input': True, 'collect_hs': True, 'loss.β': 1.2306486058482005e-06, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 10, 'transform.reduction': 61, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 1.0, 'acc/oos': 0.7, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.032258064516129, 'acc_gain_vs_ref/oos': 1.0479041916167664, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.0232654809951782, 'perplexity_gain_vs_ref/test': 1.019690990447998, 'perplexity_gain_vs_ref/oos': 1.143231749534607, 'perplexity_gain_vs_ref/rnd': 1.1855682134628296, 'preference_logp_gain/train': 46.60700988769531, 'preference_logp_gain/test': 47.50093078613281, 'preference_logp_gain/oos': 15.991378784179688, 'preference_logp_gain/rnd': 16.274383544921875, 'preference_logp_gain_vs_ref/train': 10.460611343383789, 'preference_logp_gain_vs_ref/test': 10.48563003540039, 'preference_logp_gain_vs_ref/oos': 5.466858863830566, 'preference_logp_gain_vs_ref/rnd': 2.788961410522461}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.07592938448684022,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.5210600046089048,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=22,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=32))\n",
      "{'lr': 0.07592938448684022, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.5210600046089048, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 22, 'transform.reduction': 32, 'transform.Htype': 'etherplus'} {'acc/train': 0.859375, 'acc/test': 0.78125, 'acc/oos': 0.31733333333333336, 'acc/rnd': 0.734375, 'acc_gain_vs_ref/train': 0.859375, 'acc_gain_vs_ref/test': 0.8064516129032258, 'acc_gain_vs_ref/oos': 0.4750499001996008, 'acc_gain_vs_ref/rnd': 0.7966101694915254, 'perplexity_gain_vs_ref/train': 3269.099365234375, 'perplexity_gain_vs_ref/test': 3303.930419921875, 'perplexity_gain_vs_ref/oos': 3795.77490234375, 'perplexity_gain_vs_ref/rnd': 12640.9228515625, 'preference_logp_gain/train': 50.9908447265625, 'preference_logp_gain/test': 54.4256591796875, 'preference_logp_gain/oos': -67.06829833984375, 'preference_logp_gain/rnd': 33.2021484375, 'preference_logp_gain_vs_ref/train': 14.844412803649902, 'preference_logp_gain_vs_ref/test': 17.410362243652344, 'preference_logp_gain_vs_ref/oos': -75.8723373413086, 'preference_logp_gain_vs_ref/rnd': 19.716693878173828}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=2.1021399279224485e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.001168445395095981,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=55,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=70))\n",
      "{'lr': 2.1021399279224485e-05, 'collect_input': True, 'collect_hs': True, 'loss.β': 0.001168445395095981, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 55, 'transform.reduction': 70, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.0025922060012817, 'perplexity_gain_vs_ref/test': 1.0038784742355347, 'perplexity_gain_vs_ref/oos': 1.002771019935608, 'perplexity_gain_vs_ref/rnd': 1.0008018016815186, 'preference_logp_gain/train': 36.01422882080078, 'preference_logp_gain/test': 36.78794860839844, 'preference_logp_gain/oos': 10.44482421875, 'preference_logp_gain/rnd': 13.443824768066406, 'preference_logp_gain_vs_ref/train': -0.13217198848724365, 'preference_logp_gain_vs_ref/test': -0.2273486852645874, 'preference_logp_gain_vs_ref/oos': -0.09093284606933594, 'preference_logp_gain_vs_ref/rnd': -0.04159173369407654}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=7.585446896806926e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=9.218600121161602e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=37,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=14))\n",
      "{'lr': 7.585446896806926e-05, 'collect_input': False, 'collect_hs': True, 'loss.β': 9.218600121161602e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 37, 'transform.reduction': 14, 'transform.Htype': 'etherplusHH'} {'acc/train': 0.953125, 'acc/test': 0.953125, 'acc/oos': 0.58, 'acc/rnd': 0.890625, 'acc_gain_vs_ref/train': 0.953125, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 0.8682634730538921, 'acc_gain_vs_ref/rnd': 0.9661016949152542, 'perplexity_gain_vs_ref/train': 1.349668264389038, 'perplexity_gain_vs_ref/test': 1.4025899171829224, 'perplexity_gain_vs_ref/oos': 1.2736358642578125, 'perplexity_gain_vs_ref/rnd': 1.1350303888320923, 'preference_logp_gain/train': 29.4998779296875, 'preference_logp_gain/test': 31.682785034179688, 'preference_logp_gain/oos': 2.7295379638671875, 'preference_logp_gain/rnd': 12.133224487304688, 'preference_logp_gain_vs_ref/train': -6.646519660949707, 'preference_logp_gain_vs_ref/test': -5.332525253295898, 'preference_logp_gain_vs_ref/oos': -7.7468061447143555, 'preference_logp_gain_vs_ref/rnd': -1.3521950244903564}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004757196994046286,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0015111374707235672,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=89))\n",
      "{'lr': 0.0004757196994046286, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.0015111374707235672, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 1, 'transform.reduction': 89, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.6946666666666667, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0399201596806387, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 0.9885639548301697, 'perplexity_gain_vs_ref/test': 0.9666915535926819, 'perplexity_gain_vs_ref/oos': 1.083717942237854, 'perplexity_gain_vs_ref/rnd': 1.0766898393630981, 'preference_logp_gain/train': 43.11762237548828, 'preference_logp_gain/test': 43.993141174316406, 'preference_logp_gain/oos': 13.840850830078125, 'preference_logp_gain/rnd': 14.957740783691406, 'preference_logp_gain_vs_ref/train': 6.9712324142456055, 'preference_logp_gain_vs_ref/test': 6.977834224700928, 'preference_logp_gain_vs_ref/oos': 3.279360771179199, 'preference_logp_gain_vs_ref/rnd': 1.4723225831985474}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00029571634802862834,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=33))\n",
      "{'lr': 0.00029571634802862834, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 33, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.712, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0658682634730539, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 1.030477523803711, 'perplexity_gain_vs_ref/test': 1.028868317604065, 'perplexity_gain_vs_ref/oos': 0.971264660358429, 'perplexity_gain_vs_ref/rnd': 1.0935907363891602, 'preference_logp_gain/train': 38.83184814453125, 'preference_logp_gain/test': 38.92280578613281, 'preference_logp_gain/oos': 13.771766662597656, 'preference_logp_gain/rnd': 14.951995849609375, 'preference_logp_gain_vs_ref/train': 2.6854467391967773, 'preference_logp_gain_vs_ref/test': 1.9075019359588623, 'preference_logp_gain_vs_ref/oos': 3.2000176906585693, 'preference_logp_gain_vs_ref/rnd': 1.4665725231170654}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'us_history_textbook' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_textbook/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:42 2024).\n",
      "Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'us_history_fiction' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_fiction/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:48 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'us_history_fiction' at /root/.cache/huggingface/datasets/wassname___genies_preferences/us_history_fiction/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:00:48 2024).\n",
      "Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since wassname/genies_preferences couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'math_make_questions' at /root/.cache/huggingface/datasets/wassname___genies_preferences/math_make_questions/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:01:10 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'math_make_questions' at /root/.cache/huggingface/datasets/wassname___genies_preferences/math_make_questions/0.0.0/9e92ec3b21e9800bb26e9f7cdc5792103b651b15 (last modified on Wed Sep 25 15:01:10 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00019311629320111775,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=42,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 0.00019311629320111775, 'collect_input': True, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 42, 'transform.reduction': 128, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.688, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.029940119760479, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 0.9703460931777954, 'perplexity_gain_vs_ref/test': 0.948865532875061, 'perplexity_gain_vs_ref/oos': 1.0101691484451294, 'perplexity_gain_vs_ref/rnd': 1.0025055408477783, 'preference_logp_gain/train': 39.78376770019531, 'preference_logp_gain/test': 40.644012451171875, 'preference_logp_gain/oos': 12.311004638671875, 'preference_logp_gain/rnd': 14.354385375976562, 'preference_logp_gain_vs_ref/train': 3.6373748779296875, 'preference_logp_gain_vs_ref/test': 3.6287004947662354, 'preference_logp_gain_vs_ref/oos': 1.7510929107666016, 'preference_logp_gain_vs_ref/rnd': 0.8689616322517395}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.6173941683589071e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=10,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 1.6173941683589071e-06, 'collect_input': True, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 10, 'transform.reduction': 1, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.668, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9975405335426331, 'perplexity_gain_vs_ref/test': 0.9986706376075745, 'perplexity_gain_vs_ref/oos': 1.0000954866409302, 'perplexity_gain_vs_ref/rnd': 1.0015602111816406, 'preference_logp_gain/train': 36.29328918457031, 'preference_logp_gain/test': 37.076271057128906, 'preference_logp_gain/oos': 10.570198059082031, 'preference_logp_gain/rnd': 13.484283447265625, 'preference_logp_gain_vs_ref/train': 0.14689397811889648, 'preference_logp_gain_vs_ref/test': 0.060968995094299316, 'preference_logp_gain_vs_ref/oos': 0.03084336407482624, 'preference_logp_gain_vs_ref/rnd': -0.0011369884014129639}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 15:27:25] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.8174077223017635e-05,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=64,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=98))\n",
      "{'lr': 1.8174077223017635e-05, 'collect_input': False, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 64, 'transform.reduction': 98, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.676, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0119760479041917, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9883041977882385, 'perplexity_gain_vs_ref/test': 0.9889522194862366, 'perplexity_gain_vs_ref/oos': 0.9957842230796814, 'perplexity_gain_vs_ref/rnd': 1.0018030405044556, 'preference_logp_gain/train': 37.027801513671875, 'preference_logp_gain/test': 37.865577697753906, 'preference_logp_gain/oos': 11.055770874023438, 'preference_logp_gain/rnd': 13.627021789550781, 'preference_logp_gain_vs_ref/train': 0.8814170360565186, 'preference_logp_gain_vs_ref/test': 0.8502703309059143, 'preference_logp_gain_vs_ref/oos': 0.5172352194786072, 'preference_logp_gain_vs_ref/rnd': 0.14160221815109253}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 15:38:25] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004311289520020512,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=25,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 0.0004311289520020512, 'collect_input': True, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 25, 'transform.reduction': 1, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.712, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0658682634730539, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.5764493942260742, 'perplexity_gain_vs_ref/test': 1.549848198890686, 'perplexity_gain_vs_ref/oos': 1.6879045963287354, 'perplexity_gain_vs_ref/rnd': 1.2234423160552979, 'preference_logp_gain/train': 48.14741516113281, 'preference_logp_gain/test': 50.45838928222656, 'preference_logp_gain/oos': 19.9580078125, 'preference_logp_gain/rnd': 17.416717529296875, 'preference_logp_gain_vs_ref/train': 12.001035690307617, 'preference_logp_gain_vs_ref/test': 13.44308853149414, 'preference_logp_gain_vs_ref/oos': 9.501607894897461, 'preference_logp_gain_vs_ref/rnd': 3.9312944412231445}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0003821996542183384,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=37,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 0.0003821996542183384, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 37, 'transform.reduction': 128, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 1.0, 'acc/oos': 0.7013333333333334, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.032258064516129, 'acc_gain_vs_ref/oos': 1.0499001996007984, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9890734553337097, 'perplexity_gain_vs_ref/test': 0.960928738117218, 'perplexity_gain_vs_ref/oos': 1.0358247756958008, 'perplexity_gain_vs_ref/rnd': 1.0421539545059204, 'preference_logp_gain/train': 42.30052185058594, 'preference_logp_gain/test': 44.839805603027344, 'preference_logp_gain/oos': 14.187911987304688, 'preference_logp_gain/rnd': 14.620780944824219, 'preference_logp_gain_vs_ref/train': 6.154132843017578, 'preference_logp_gain_vs_ref/test': 7.824507713317871, 'preference_logp_gain_vs_ref/oos': 3.6482551097869873, 'preference_logp_gain_vs_ref/rnd': 1.1353610754013062}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0006532682889838686,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 0.0006532682889838686, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 1, 'transform.reduction': 1, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.6853333333333333, 'acc/rnd': 0.890625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.0259481037924152, 'acc_gain_vs_ref/rnd': 0.9661016949152542, 'perplexity_gain_vs_ref/train': 1.0317176580429077, 'perplexity_gain_vs_ref/test': 1.0333291292190552, 'perplexity_gain_vs_ref/oos': 0.9898015856742859, 'perplexity_gain_vs_ref/rnd': 1.1639001369476318, 'preference_logp_gain/train': 37.70514678955078, 'preference_logp_gain/test': 39.08131408691406, 'preference_logp_gain/oos': 11.943954467773438, 'preference_logp_gain/rnd': 14.538299560546875, 'preference_logp_gain_vs_ref/train': 1.5587522983551025, 'preference_logp_gain_vs_ref/test': 2.0660109519958496, 'preference_logp_gain_vs_ref/oos': 1.3763493299484253, 'preference_logp_gain_vs_ref/rnd': 1.0528792142868042}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=64,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 1e-06, 'collect_input': False, 'collect_hs': True, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 64, 'transform.reduction': 128, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9997307062149048, 'perplexity_gain_vs_ref/test': 0.9992906451225281, 'perplexity_gain_vs_ref/oos': 1.0001442432403564, 'perplexity_gain_vs_ref/rnd': 1.0029640197753906, 'preference_logp_gain/train': 36.10734558105469, 'preference_logp_gain/test': 36.99302673339844, 'preference_logp_gain/oos': 10.517158508300781, 'preference_logp_gain/rnd': 13.459114074707031, 'preference_logp_gain_vs_ref/train': -0.03905224800109863, 'preference_logp_gain_vs_ref/test': -0.022277116775512695, 'preference_logp_gain_vs_ref/oos': -0.018766749650239944, 'preference_logp_gain_vs_ref/rnd': -0.026305705308914185}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 16:23:16] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=2.299695442734178e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=24,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 2.299695442734178e-06, 'collect_input': False, 'collect_hs': True, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': True, 'loss.use_orth_loss': False, 'transform.nb': 24, 'transform.reduction': 1, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.000899314880371, 'perplexity_gain_vs_ref/test': 1.0017746686935425, 'perplexity_gain_vs_ref/oos': 1.00018310546875, 'perplexity_gain_vs_ref/rnd': 1.0022118091583252, 'preference_logp_gain/train': 36.15888977050781, 'preference_logp_gain/test': 36.978782653808594, 'preference_logp_gain/oos': 10.491424560546875, 'preference_logp_gain/rnd': 13.47265625, 'preference_logp_gain_vs_ref/train': 0.012506306171417236, 'preference_logp_gain_vs_ref/test': -0.03651416301727295, 'preference_logp_gain_vs_ref/oos': -0.039254311472177505, 'preference_logp_gain_vs_ref/rnd': -0.012770324945449829}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00028987139558125225,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=64,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 0.00028987139558125225, 'collect_input': True, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 64, 'transform.reduction': 1, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6893333333333334, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.031936127744511, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9836574792861938, 'perplexity_gain_vs_ref/test': 0.9861262440681458, 'perplexity_gain_vs_ref/oos': 0.9880066514015198, 'perplexity_gain_vs_ref/rnd': 1.03155517578125, 'preference_logp_gain/train': 38.25682067871094, 'preference_logp_gain/test': 38.80238342285156, 'preference_logp_gain/oos': 12.183128356933594, 'preference_logp_gain/rnd': 14.02947998046875, 'preference_logp_gain_vs_ref/train': 2.1104211807250977, 'preference_logp_gain_vs_ref/test': 1.7870744466781616, 'preference_logp_gain_vs_ref/oos': 1.6322726011276245, 'preference_logp_gain_vs_ref/rnd': 0.5440618991851807}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00022301989182166532,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=2))\n",
      "{'lr': 0.00022301989182166532, 'collect_input': False, 'collect_hs': True, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 2, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6853333333333333, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0259481037924152, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9741042256355286, 'perplexity_gain_vs_ref/test': 0.9770622253417969, 'perplexity_gain_vs_ref/oos': 0.9793345928192139, 'perplexity_gain_vs_ref/rnd': 1.0038373470306396, 'preference_logp_gain/train': 38.107566833496094, 'preference_logp_gain/test': 38.68218994140625, 'preference_logp_gain/oos': 11.771842956542969, 'preference_logp_gain/rnd': 13.85498046875, 'preference_logp_gain_vs_ref/train': 1.9611718654632568, 'preference_logp_gain_vs_ref/test': 1.6668901443481445, 'preference_logp_gain_vs_ref/oos': 1.2301809787750244, 'preference_logp_gain_vs_ref/rnd': 0.3695570230484009}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 17:00:56] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004929435553744471,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=65))\n",
      "{'lr': 0.0004929435553744471, 'collect_input': False, 'collect_hs': True, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 65, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.7186666666666667, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0758483033932136, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 1.0690209865570068, 'perplexity_gain_vs_ref/test': 1.011253833770752, 'perplexity_gain_vs_ref/oos': 1.0994696617126465, 'perplexity_gain_vs_ref/rnd': 1.0410876274108887, 'preference_logp_gain/train': 44.838470458984375, 'preference_logp_gain/test': 48.93205261230469, 'preference_logp_gain/oos': 17.088287353515625, 'preference_logp_gain/rnd': 16.26385498046875, 'preference_logp_gain_vs_ref/train': 8.692073822021484, 'preference_logp_gain_vs_ref/test': 11.916753768920898, 'preference_logp_gain_vs_ref/oos': 6.464683532714844, 'preference_logp_gain_vs_ref/rnd': 2.778437852859497}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.0273068510906487e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=57,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 1.0273068510906487e-06, 'collect_input': True, 'collect_hs': True, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 57, 'transform.reduction': 1, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6666666666666666, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.9980039920159679, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9996426105499268, 'perplexity_gain_vs_ref/test': 1.0007845163345337, 'perplexity_gain_vs_ref/oos': 1.0000532865524292, 'perplexity_gain_vs_ref/rnd': 1.0029488801956177, 'preference_logp_gain/train': 36.116912841796875, 'preference_logp_gain/test': 36.950347900390625, 'preference_logp_gain/oos': 10.52276611328125, 'preference_logp_gain/rnd': 13.438568115234375, 'preference_logp_gain_vs_ref/train': -0.029468297958374023, 'preference_logp_gain_vs_ref/test': -0.06494903564453125, 'preference_logp_gain_vs_ref/oos': -0.015868186950683594, 'preference_logp_gain_vs_ref/rnd': -0.04685533046722412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 17:25:14] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n",
      "[INFO 09-25 17:25:14] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0005301425105697182,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 0.0005301425105697182, 'collect_input': False, 'collect_hs': True, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 128, 'transform.Htype': 'etherplusHH'} {'acc/train': 0.984375, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 0.984375, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 2.2088747024536133, 'perplexity_gain_vs_ref/test': 2.0767505168914795, 'perplexity_gain_vs_ref/oos': 2.3190457820892334, 'perplexity_gain_vs_ref/rnd': 1.4651826620101929, 'preference_logp_gain/train': 47.14881896972656, 'preference_logp_gain/test': 50.478912353515625, 'preference_logp_gain/oos': 14.709915161132812, 'preference_logp_gain/rnd': 19.628944396972656, 'preference_logp_gain_vs_ref/train': 11.002423286437988, 'preference_logp_gain_vs_ref/test': 13.46360969543457, 'preference_logp_gain_vs_ref/oos': 4.559641361236572, 'preference_logp_gain_vs_ref/rnd': 6.143524169921875}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00042994805407384814,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0005215552597076294,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 0.00042994805407384814, 'collect_input': True, 'collect_hs': False, 'loss.β': 0.0005215552597076294, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 1, 'transform.reduction': 1, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.692, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0359281437125747, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9772722721099854, 'perplexity_gain_vs_ref/test': 0.9507331848144531, 'perplexity_gain_vs_ref/oos': 1.050317406654358, 'perplexity_gain_vs_ref/rnd': 1.0368072986602783, 'preference_logp_gain/train': 42.248329162597656, 'preference_logp_gain/test': 43.444305419921875, 'preference_logp_gain/oos': 13.0045166015625, 'preference_logp_gain/rnd': 15.069290161132812, 'preference_logp_gain_vs_ref/train': 6.101944446563721, 'preference_logp_gain_vs_ref/test': 6.428999900817871, 'preference_logp_gain_vs_ref/oos': 2.4432685375213623, 'preference_logp_gain_vs_ref/rnd': 1.583876132965088}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 17:56:24] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00028782301272903255,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=31,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=65))\n",
      "{'lr': 0.00028782301272903255, 'collect_input': False, 'collect_hs': True, 'loss.β': 2.0, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 31, 'transform.reduction': 65, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.6853333333333333, 'acc/rnd': 0.9375, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0259481037924152, 'acc_gain_vs_ref/rnd': 1.0169491525423728, 'perplexity_gain_vs_ref/train': 1.0107500553131104, 'perplexity_gain_vs_ref/test': 0.9925280809402466, 'perplexity_gain_vs_ref/oos': 1.0142154693603516, 'perplexity_gain_vs_ref/rnd': 1.0350940227508545, 'preference_logp_gain/train': 40.712318420410156, 'preference_logp_gain/test': 41.61143493652344, 'preference_logp_gain/oos': 12.629692077636719, 'preference_logp_gain/rnd': 14.701873779296875, 'preference_logp_gain_vs_ref/train': 4.565921783447266, 'preference_logp_gain_vs_ref/test': 4.596121788024902, 'preference_logp_gain_vs_ref/oos': 2.0374937057495117, 'preference_logp_gain_vs_ref/rnd': 1.216454267501831}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 18:16:20] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00010509713959707121,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=35,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=63))\n",
      "{'lr': 0.00010509713959707121, 'collect_input': False, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 35, 'transform.reduction': 63, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.7026666666666667, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0518962075848304, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9726800322532654, 'perplexity_gain_vs_ref/test': 0.9676178693771362, 'perplexity_gain_vs_ref/oos': 0.9984386563301086, 'perplexity_gain_vs_ref/rnd': 1.0154454708099365, 'preference_logp_gain/train': 40.55816650390625, 'preference_logp_gain/test': 41.249290466308594, 'preference_logp_gain/oos': 13.117408752441406, 'preference_logp_gain/rnd': 14.474479675292969, 'preference_logp_gain_vs_ref/train': 4.411779880523682, 'preference_logp_gain_vs_ref/test': 4.233987808227539, 'preference_logp_gain_vs_ref/oos': 2.5744802951812744, 'preference_logp_gain_vs_ref/rnd': 0.9890559315681458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 18:36:04] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=True,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=18,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 1e-06, 'collect_input': True, 'collect_hs': True, 'loss.β': 2.0, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 18, 'transform.reduction': 128, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.668, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.0, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 0.9983823895454407, 'perplexity_gain_vs_ref/test': 1.0001649856567383, 'perplexity_gain_vs_ref/oos': 0.9987879991531372, 'perplexity_gain_vs_ref/rnd': 1.0015162229537964, 'preference_logp_gain/train': 36.311431884765625, 'preference_logp_gain/test': 36.993743896484375, 'preference_logp_gain/oos': 10.58538818359375, 'preference_logp_gain/rnd': 13.444389343261719, 'preference_logp_gain_vs_ref/train': 0.16504055261611938, 'preference_logp_gain_vs_ref/test': -0.02155250310897827, 'preference_logp_gain_vs_ref/oos': 0.05520667880773544, 'preference_logp_gain_vs_ref/rnd': -0.04103156924247742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 18:55:47] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1.518572645007845e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=False,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=True,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=41,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=128))\n",
      "{'lr': 1.518572645007845e-06, 'collect_input': False, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': True, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': False, 'transform.nb': 41, 'transform.reduction': 128, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.997456967830658, 'perplexity_gain_vs_ref/test': 0.9984127879142761, 'perplexity_gain_vs_ref/oos': 0.999020516872406, 'perplexity_gain_vs_ref/rnd': 0.9996848106384277, 'preference_logp_gain/train': 36.25586700439453, 'preference_logp_gain/test': 37.1220703125, 'preference_logp_gain/oos': 10.568374633789062, 'preference_logp_gain/rnd': 13.506126403808594, 'preference_logp_gain_vs_ref/train': 0.10948503017425537, 'preference_logp_gain_vs_ref/test': 0.1067613959312439, 'preference_logp_gain_vs_ref/oos': 0.03639412671327591, 'preference_logp_gain_vs_ref/rnd': 0.020707935094833374}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.000415815679460023,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=5,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=56))\n",
      "{'lr': 0.000415815679460023, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 5, 'transform.reduction': 56, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.7413333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.1097804391217563, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.2100658416748047, 'perplexity_gain_vs_ref/test': 1.1992459297180176, 'perplexity_gain_vs_ref/oos': 1.0752215385437012, 'perplexity_gain_vs_ref/rnd': 1.406664252281189, 'preference_logp_gain/train': 42.760589599609375, 'preference_logp_gain/test': 42.735206604003906, 'preference_logp_gain/oos': 16.893653869628906, 'preference_logp_gain/rnd': 16.469284057617188, 'preference_logp_gain_vs_ref/train': 6.614192962646484, 'preference_logp_gain_vs_ref/test': 5.719898700714111, 'preference_logp_gain_vs_ref/oos': 6.362765789031982, 'preference_logp_gain_vs_ref/rnd': 2.983863353729248}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004107693958763461,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=10,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=57))\n",
      "{'lr': 0.0004107693958763461, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 10, 'transform.reduction': 57, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.7386666666666667, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.1057884231536925, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.1943583488464355, 'perplexity_gain_vs_ref/test': 1.1835724115371704, 'perplexity_gain_vs_ref/oos': 1.063995599746704, 'perplexity_gain_vs_ref/rnd': 1.3807976245880127, 'preference_logp_gain/train': 42.60270690917969, 'preference_logp_gain/test': 42.539573669433594, 'preference_logp_gain/oos': 16.835586547851562, 'preference_logp_gain/rnd': 16.362388610839844, 'preference_logp_gain_vs_ref/train': 6.4563140869140625, 'preference_logp_gain_vs_ref/test': 5.524270057678223, 'preference_logp_gain_vs_ref/oos': 6.299283027648926, 'preference_logp_gain_vs_ref/rnd': 2.8769731521606445}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 19:57:55] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=5.989903332998635e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=True,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=True),\n",
      "             transform=ETHERConfig(nb=64,\n",
      "                                   Htype='etherplus',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=1))\n",
      "{'lr': 5.989903332998635e-06, 'collect_input': True, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': True, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': True, 'loss.use_orth_loss': True, 'transform.nb': 64, 'transform.reduction': 1, 'transform.Htype': 'etherplus'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6706666666666666, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.0039920159680638, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 0.9926235675811768, 'perplexity_gain_vs_ref/test': 0.9918175339698792, 'perplexity_gain_vs_ref/oos': 0.9966323375701904, 'perplexity_gain_vs_ref/rnd': 1.002620816230774, 'preference_logp_gain/train': 36.56249237060547, 'preference_logp_gain/test': 37.472938537597656, 'preference_logp_gain/oos': 10.790855407714844, 'preference_logp_gain/rnd': 13.548301696777344, 'preference_logp_gain_vs_ref/train': 0.4161055088043213, 'preference_logp_gain_vs_ref/test': 0.45763999223709106, 'preference_logp_gain_vs_ref/oos': 0.2573660612106323, 'preference_logp_gain_vs_ref/rnd': 0.06287699937820435}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00040317748855126076,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=6,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=60))\n",
      "{'lr': 0.00040317748855126076, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 6, 'transform.reduction': 60, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.744, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.1137724550898203, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.1705505847930908, 'perplexity_gain_vs_ref/test': 1.162666916847229, 'perplexity_gain_vs_ref/oos': 1.0499708652496338, 'perplexity_gain_vs_ref/rnd': 1.356394648551941, 'preference_logp_gain/train': 42.46107482910156, 'preference_logp_gain/test': 42.42094421386719, 'preference_logp_gain/oos': 16.725189208984375, 'preference_logp_gain/rnd': 16.179222106933594, 'preference_logp_gain_vs_ref/train': 6.314675331115723, 'preference_logp_gain_vs_ref/test': 5.405640602111816, 'preference_logp_gain_vs_ref/oos': 6.188189506530762, 'preference_logp_gain_vs_ref/rnd': 2.6938042640686035}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00041720411305126546,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=3.2371833529607453e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=63))\n",
      "{'lr': 0.00041720411305126546, 'collect_input': False, 'collect_hs': False, 'loss.β': 3.2371833529607453e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 63, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.74, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.1077844311377245, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.2182788848876953, 'perplexity_gain_vs_ref/test': 1.2015684843063354, 'perplexity_gain_vs_ref/oos': 1.0775288343429565, 'perplexity_gain_vs_ref/rnd': 1.4243495464324951, 'preference_logp_gain/train': 42.801795959472656, 'preference_logp_gain/test': 42.87126922607422, 'preference_logp_gain/oos': 16.93695068359375, 'preference_logp_gain/rnd': 16.562835693359375, 'preference_logp_gain_vs_ref/train': 6.655407905578613, 'preference_logp_gain_vs_ref/test': 5.855974197387695, 'preference_logp_gain_vs_ref/oos': 6.41400146484375, 'preference_logp_gain_vs_ref/rnd': 3.0774154663085938}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004418719390630454,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=62))\n",
      "{'lr': 0.0004418719390630454, 'collect_input': False, 'collect_hs': False, 'loss.β': 1e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 62, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.7373333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.1037924151696605, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.3258453607559204, 'perplexity_gain_vs_ref/test': 1.2949308156967163, 'perplexity_gain_vs_ref/oos': 1.1563940048217773, 'perplexity_gain_vs_ref/rnd': 1.5936737060546875, 'preference_logp_gain/train': 43.08363342285156, 'preference_logp_gain/test': 43.27727508544922, 'preference_logp_gain/oos': 17.071502685546875, 'preference_logp_gain/rnd': 17.086380004882812, 'preference_logp_gain_vs_ref/train': 6.9372406005859375, 'preference_logp_gain_vs_ref/test': 6.261966705322266, 'preference_logp_gain_vs_ref/oos': 6.592074394226074, 'preference_logp_gain_vs_ref/rnd': 3.600961685180664}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-25 21:24:43] ax.modelbridge.base: Untransformed parameter 2.0000000000000004 greater than upper bound 2.0, clamping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=1e-06,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=True,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.0,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=False,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=64,\n",
      "                                   Htype='oft',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=113))\n",
      "{'lr': 1e-06, 'collect_input': True, 'collect_hs': False, 'loss.β': 2.0, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': False, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 64, 'transform.reduction': 113, 'transform.Htype': 'oft'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.6653333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 0.996007984031936, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.0006335973739624, 'perplexity_gain_vs_ref/test': 1.0005558729171753, 'perplexity_gain_vs_ref/oos': 0.9994261264801025, 'perplexity_gain_vs_ref/rnd': 1.0023038387298584, 'preference_logp_gain/train': 36.125083923339844, 'preference_logp_gain/test': 37.00445556640625, 'preference_logp_gain/oos': 10.498367309570312, 'preference_logp_gain/rnd': 13.469688415527344, 'preference_logp_gain_vs_ref/train': -0.02130812406539917, 'preference_logp_gain_vs_ref/test': -0.010841786861419678, 'preference_logp_gain_vs_ref/oos': -0.034688547253608704, 'preference_logp_gain_vs_ref/rnd': -0.01573270559310913}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00040713635723268945,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.757810039421647e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=16,\n",
      "                                   Htype='etherplusHH',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=61))\n",
      "{'lr': 0.00040713635723268945, 'collect_input': False, 'collect_hs': False, 'loss.β': 1.757810039421647e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 16, 'transform.reduction': 61, 'transform.Htype': 'etherplusHH'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.7413333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.1097804391217563, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.185949683189392, 'perplexity_gain_vs_ref/test': 1.1800588369369507, 'perplexity_gain_vs_ref/oos': 1.056136965751648, 'perplexity_gain_vs_ref/rnd': 1.3839099407196045, 'preference_logp_gain/train': 42.587127685546875, 'preference_logp_gain/test': 42.50196838378906, 'preference_logp_gain/oos': 16.81359100341797, 'preference_logp_gain/rnd': 16.15019989013672, 'preference_logp_gain_vs_ref/train': 6.440735340118408, 'preference_logp_gain_vs_ref/test': 5.486655235290527, 'preference_logp_gain_vs_ref/oos': 6.273643970489502, 'preference_logp_gain_vs_ref/rnd': 2.664778709411621}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.0004261621671421556,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=5.3300657315173626e-05,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=3,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=55))\n",
      "{'lr': 0.0004261621671421556, 'collect_input': False, 'collect_hs': False, 'loss.β': 5.3300657315173626e-05, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 3, 'transform.reduction': 55, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.984375, 'acc/oos': 0.7413333333333333, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0161290322580645, 'acc_gain_vs_ref/oos': 1.1097804391217563, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.2555763721466064, 'perplexity_gain_vs_ref/test': 1.2329649925231934, 'perplexity_gain_vs_ref/oos': 1.1065224409103394, 'perplexity_gain_vs_ref/rnd': 1.4801479578018188, 'preference_logp_gain/train': 43.34673309326172, 'preference_logp_gain/test': 43.281715393066406, 'preference_logp_gain/oos': 17.095062255859375, 'preference_logp_gain/rnd': 16.67627716064453, 'preference_logp_gain_vs_ref/train': 7.200347900390625, 'preference_logp_gain_vs_ref/test': 6.266417503356934, 'preference_logp_gain_vs_ref/oos': 6.5843095779418945, 'preference_logp_gain_vs_ref/rnd': 3.190854787826538}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00040787708279030625,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.1946955496206682e-05,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=9,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=57))\n",
      "{'lr': 0.00040787708279030625, 'collect_input': False, 'collect_hs': False, 'loss.β': 1.1946955496206682e-05, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 9, 'transform.reduction': 57, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.96875, 'acc/oos': 0.7426666666666667, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.0, 'acc_gain_vs_ref/oos': 1.1117764471057885, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.189222812652588, 'perplexity_gain_vs_ref/test': 1.1773892641067505, 'perplexity_gain_vs_ref/oos': 1.058746337890625, 'perplexity_gain_vs_ref/rnd': 1.366542935371399, 'preference_logp_gain/train': 42.64555358886719, 'preference_logp_gain/test': 42.50621795654297, 'preference_logp_gain/oos': 16.856361389160156, 'preference_logp_gain/rnd': 16.30614471435547, 'preference_logp_gain_vs_ref/train': 6.499155521392822, 'preference_logp_gain_vs_ref/test': 5.490918159484863, 'preference_logp_gain_vs_ref/oos': 6.310842514038086, 'preference_logp_gain_vs_ref/rnd': 2.820723533630371}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00039156415057960576,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=1.1122945323421548e-05,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=7,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=58))\n",
      "{'lr': 0.00039156415057960576, 'collect_input': False, 'collect_hs': False, 'loss.β': 1.1122945323421548e-05, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 7, 'transform.reduction': 58, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.7333333333333333, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0978043912175648, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.1453779935836792, 'perplexity_gain_vs_ref/test': 1.1427714824676514, 'perplexity_gain_vs_ref/oos': 1.029964566230774, 'perplexity_gain_vs_ref/rnd': 1.329445242881775, 'preference_logp_gain/train': 42.259010314941406, 'preference_logp_gain/test': 42.06370544433594, 'preference_logp_gain/oos': 16.529815673828125, 'preference_logp_gain/rnd': 15.900909423828125, 'preference_logp_gain_vs_ref/train': 6.112614154815674, 'preference_logp_gain_vs_ref/test': 5.048397064208984, 'preference_logp_gain_vs_ref/oos': 5.9720869064331055, 'preference_logp_gain_vs_ref/rnd': 2.4154834747314453}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00046985905336517734,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=2.9048337759908553e-06,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=15,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=56))\n",
      "{'lr': 0.00046985905336517734, 'collect_input': False, 'collect_hs': False, 'loss.β': 2.9048337759908553e-06, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 15, 'transform.reduction': 56, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 1.0, 'acc/oos': 0.7253333333333334, 'acc/rnd': 0.90625, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 1.032258064516129, 'acc_gain_vs_ref/oos': 1.0858283433133733, 'acc_gain_vs_ref/rnd': 0.9830508474576272, 'perplexity_gain_vs_ref/train': 1.512744426727295, 'perplexity_gain_vs_ref/test': 1.4680854082107544, 'perplexity_gain_vs_ref/oos': 1.2942821979522705, 'perplexity_gain_vs_ref/rnd': 1.956413984298706, 'preference_logp_gain/train': 43.03251647949219, 'preference_logp_gain/test': 43.69712829589844, 'preference_logp_gain/oos': 17.068878173828125, 'preference_logp_gain/rnd': 18.02301025390625, 'preference_logp_gain_vs_ref/train': 6.886122703552246, 'preference_logp_gain_vs_ref/test': 6.681823253631592, 'preference_logp_gain_vs_ref/oos': 6.606750965118408, 'preference_logp_gain_vs_ref/rnd': 4.537591934204102}\n",
      "ReprPOConfig(dataset='us_history_textbook',\n",
      "             verbose=0,\n",
      "             dev=False,\n",
      "             load_in_4bit=True,\n",
      "             load_in_8bit=False,\n",
      "             use_gradient_checkpointing=False,\n",
      "             batch_size=64,\n",
      "             n_samples=1800,\n",
      "             eval_samples=64,\n",
      "             max_length=196,\n",
      "             max_prompt_length=96,\n",
      "             base_model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
      "             lr=0.00038459414696895695,\n",
      "             collection_layers_side=[8, 10, 12, 14, 16, 18],\n",
      "             collection_keys_in=('base_model.model.model.layers.{layer}.self_attn.o_proj',\n",
      "                                 'base_model.model.model.layers.{layer}.mlp.down_proj'),\n",
      "             collection_keys_out=('base_model.model.model.layers.{layer}.self_attn.q_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.k_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.self_attn.v_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.gate_proj',\n",
      "                                  'base_model.model.model.layers.{layer}.mlp.up_proj'),\n",
      "             collect_input=False,\n",
      "             collect_hs=False,\n",
      "             loss=PrefVecLossConfig(eps=1e-12,\n",
      "                                    β=0.0003723267436959242,\n",
      "                                    use_orth_loss=True,\n",
      "                                    use_angle_loss=True,\n",
      "                                    use_dpo_loss=False,\n",
      "                                    use_nll_loss=False,\n",
      "                                    weight_tokens=False),\n",
      "             transform=ETHERConfig(nb=1,\n",
      "                                   Htype='ether',\n",
      "                                   ether_dropout=0.0,\n",
      "                                   flip_side=False,\n",
      "                                   reduction=56))\n",
      "{'lr': 0.00038459414696895695, 'collect_input': False, 'collect_hs': False, 'loss.β': 0.0003723267436959242, 'loss.use_dpo_loss': False, 'loss.use_nll_loss': False, 'loss.use_angle_loss': True, 'loss.weight_tokens': False, 'loss.use_orth_loss': True, 'transform.nb': 1, 'transform.reduction': 56, 'transform.Htype': 'ether'} {'acc/train': 1.0, 'acc/test': 0.953125, 'acc/oos': 0.7333333333333333, 'acc/rnd': 0.921875, 'acc_gain_vs_ref/train': 1.0, 'acc_gain_vs_ref/test': 0.9838709677419355, 'acc_gain_vs_ref/oos': 1.0978043912175648, 'acc_gain_vs_ref/rnd': 1.0, 'perplexity_gain_vs_ref/train': 1.1209113597869873, 'perplexity_gain_vs_ref/test': 1.123300552368164, 'perplexity_gain_vs_ref/oos': 1.0450124740600586, 'perplexity_gain_vs_ref/rnd': 1.275344729423523, 'preference_logp_gain/train': 43.19176483154297, 'preference_logp_gain/test': 42.83184814453125, 'preference_logp_gain/oos': 16.709701538085938, 'preference_logp_gain/rnd': 16.213424682617188, 'preference_logp_gain_vs_ref/train': 7.045368194580078, 'preference_logp_gain_vs_ref/test': 5.81654167175293, 'preference_logp_gain_vs_ref/oos': 6.140002250671387, 'preference_logp_gain_vs_ref/rnd': 2.72800874710083}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m450\u001b[39m)):\n\u001b[0;32m----> 4\u001b[0m     parameters, trial_index \u001b[38;5;241m=\u001b[39m \u001b[43max_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         r \u001b[38;5;241m=\u001b[39m objective_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/utils/common/executils.py:167\u001b[0m, in \u001b[0;36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             wait_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    164\u001b[0m                 MAX_WAIT_SECONDS, initial_wait_seconds \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    165\u001b[0m             )\n\u001b[1;32m    166\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(wait_interval)\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_return_on_suppression\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/ax_client.py:543\u001b[0m, in \u001b[0;36mAxClient.get_next_trial\u001b[0;34m(self, ttl_seconds, force, fixed_features)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OptimizationShouldStop(message\u001b[38;5;241m=\u001b[39mglobal_stopping_message)\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mnew_trial(\n\u001b[0;32m--> 543\u001b[0m         generator_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_new_generator_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_features\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    546\u001b[0m         ttl_seconds\u001b[38;5;241m=\u001b[39mttl_seconds,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxParallelismReachedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_stopping_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/service/ax_client.py:1781\u001b[0m, in \u001b[0;36mAxClient._gen_new_generator_run\u001b[0;34m(self, n, fixed_features)\u001b[0m\n\u001b[1;32m   1773\u001b[0m fixed_feats \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1774\u001b[0m     InstantiationBase\u001b[38;5;241m.\u001b[39mmake_fixed_observation_features(\n\u001b[1;32m   1775\u001b[0m         fixed_features\u001b[38;5;241m=\u001b[39mfixed_features\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m )\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m with_rng_seed(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_seed):\n\u001b[0;32m-> 1781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnot_none\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_strategy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pending_observation_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/generation_strategy.py:372\u001b[0m, in \u001b[0;36mGenerationStrategy.gen\u001b[0;34m(self, experiment, data, n, pending_observations, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m(\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    339\u001b[0m     experiment: Experiment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    344\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GeneratorRun:\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Produce the next points in the experiment. Additional kwargs passed to\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    this method are propagated directly to the underlying model's `gen`, along\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    with the `model_gen_kwargs` set on the current generation node.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m            resuggesting points that are currently being evaluated.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_multiple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_generator_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/generation_strategy.py:773\u001b[0m, in \u001b[0;36mGenerationStrategy._gen_multiple\u001b[0;34m(self, experiment, num_generator_runs, data, n, pending_observations, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment \u001b[38;5;241m=\u001b[39m experiment\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_transition_to_next_node()\n\u001b[0;32m--> 773\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_current_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# Get GeneratorRun limit that respects the node's transition criterion that\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# affect the number of generator runs that can be produced.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m gr_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curr\u001b[38;5;241m.\u001b[39mgenerator_run_limit(raise_generation_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/generation_strategy.py:852\u001b[0m, in \u001b[0;36mGenerationStrategy._fit_current_model\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits or update the model on the current generation node (does not move\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03mbetween generation nodes).\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m        strategy will obtain the data via ``experiment.lookup_data``.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    851\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mlookup_data() \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_curr\u001b[38;5;241m.\u001b[39m_fitted_model\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/generation_node.py:237\u001b[0m, in \u001b[0;36mGenerationNode.fit\u001b[0;34m(self, experiment, data, search_space, optimization_config, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_spec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_specs:\n\u001b[1;32m    233\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_spec\u001b[38;5;241m.\u001b[39mmodel_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with data for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_indices_in_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[0;32m--> 237\u001b[0m     \u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stores the fitted model as `model_spec._fitted_model`\u001b[39;49;00m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_state_from_last_generator_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/model_spec.py:141\u001b[0m, in \u001b[0;36mModelSpec.fit\u001b[0;34m(self, experiment, data, **model_kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_to_update(\n\u001b[1;32m    134\u001b[0m     experiment\u001b[38;5;241m=\u001b[39mexperiment, combined_model_kwargs\u001b[38;5;241m=\u001b[39mcombined_model_kwargs\n\u001b[1;32m    135\u001b[0m ):\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Update the data on the modelbridge and call `_fit`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# This will skip model fitting if the data has not changed.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     observations, search_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_model\u001b[38;5;241m.\u001b[39m_process_and_transform_data(\n\u001b[1;32m    139\u001b[0m         experiment\u001b[38;5;241m=\u001b[39mexperiment, data\u001b[38;5;241m=\u001b[39mdata\n\u001b[1;32m    140\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitted_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_if_implemented\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_so_far\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Fit from scratch.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_enum(\n\u001b[1;32m    148\u001b[0m         experiment\u001b[38;5;241m=\u001b[39mexperiment,\n\u001b[1;32m    149\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcombined_model_kwargs,\n\u001b[1;32m    151\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/base.py:236\u001b[0m, in \u001b[0;36mModelBridge._fit_if_implemented\u001b[0;34m(self, search_space, observations, time_so_far)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     t_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     increment \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m t_fit_start \u001b[38;5;241m+\u001b[39m time_so_far\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m increment\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/modelbridge/torch.py:653\u001b[0m, in \u001b[0;36mTorchModelBridge._fit\u001b[0;34m(self, model, search_space, observations, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidate_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/models/torch/botorch_modular/model.py:338\u001b[0m, in \u001b[0;36mBoTorchModel.fit\u001b[0;34m(self, datasets, search_space_digest, candidate_metadata, state_dicts, refit, **additional_model_inputs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     subset_datasets \u001b[38;5;241m=\u001b[39m get_subset_datasets(\n\u001b[1;32m    335\u001b[0m         datasets\u001b[38;5;241m=\u001b[39mdatasets, subset_outcome_names\u001b[38;5;241m=\u001b[39msubset_outcome_names\n\u001b[1;32m    336\u001b[0m     )\n\u001b[1;32m    337\u001b[0m     surrogate\u001b[38;5;241m.\u001b[39mmodel_options\u001b[38;5;241m.\u001b[39mupdate(additional_model_inputs)\n\u001b[0;32m--> 338\u001b[0m     \u001b[43msurrogate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstate_dicts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Step 3. Output order of outcomes must match input order, but now outcomes are\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# grouped according to surrogate. Compute the permutation from surrogate order\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# to input ordering.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m surrogate_order \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/models/torch/botorch_modular/surrogate.py:567\u001b[0m, in \u001b[0;36mSurrogate.fit\u001b[0;34m(self, datasets, search_space_digest, candidate_metadata, state_dict, refit)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m         submodel_state_dict \u001b[38;5;241m=\u001b[39m state_dict\n\u001b[0;32m--> 567\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbotorch_model_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbotorch_model_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmodel_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    575\u001b[0m outcome_names\u001b[38;5;241m.\u001b[39mextend(dataset\u001b[38;5;241m.\u001b[39moutcome_names)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/models/torch/botorch_modular/surrogate.py:471\u001b[0m, in \u001b[0;36mSurrogate._construct_model\u001b[0;34m(self, dataset, search_space_digest, botorch_model_class, state_dict, refit)\u001b[0m\n\u001b[1;32m    469\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m refit:\n\u001b[0;32m--> 471\u001b[0m     \u001b[43mfit_botorch_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmll_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmll_options\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submodels[outcome_names] \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_datasets[outcome_names] \u001b[38;5;241m=\u001b[39m dataset\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/ax/models/torch/botorch_modular/utils.py:301\u001b[0m, in \u001b[0;36mfit_botorch_model\u001b[0;34m(model, mll_class, mll_options)\u001b[0m\n\u001b[1;32m    299\u001b[0m     mll_options \u001b[38;5;241m=\u001b[39m mll_options \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    300\u001b[0m     mll \u001b[38;5;241m=\u001b[39m mll_class(likelihood\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mlikelihood, model\u001b[38;5;241m=\u001b[39mm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmll_options)\n\u001b[0;32m--> 301\u001b[0m     \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is currently not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/fit.py:105\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[0;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFitGPyTorchMLL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/utils/dispatcher.py:93\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(types\u001b[38;5;241m=\u001b[39mtypes)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_iter(\u001b[38;5;241m*\u001b[39mtypes)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/fit.py:205\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[0;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, pick_best_of_all_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list, debug(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    204\u001b[0m     simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[0;32m--> 205\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Resolve warnings and determine whether or not to retry\u001b[39;00m\n\u001b[1;32m    208\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/fit.py:94\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_scipy\u001b[0;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclosure_kwargs)\n\u001b[0;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mscipy_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m OptimizationStatus\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[1;32m    104\u001b[0m     warn(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`scipy_minimize` terminated with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, displaying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m         OptimizationWarning,\n\u001b[1;32m    108\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/core.py:110\u001b[0m, in \u001b[0;36mscipy_minimize\u001b[0;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[0m\n\u001b[1;32m    102\u001b[0m         result \u001b[38;5;241m=\u001b[39m OptimizationResult(\n\u001b[1;32m    103\u001b[0m             step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(call_counter),\n\u001b[1;32m    104\u001b[0m             fval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(wrapped_closure(x)[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    105\u001b[0m             status\u001b[38;5;241m=\u001b[39mOptimizationStatus\u001b[38;5;241m.\u001b[39mRUNNING,\n\u001b[1;32m    106\u001b[0m             runtime\u001b[38;5;241m=\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time,\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(parameters, result)  \u001b[38;5;66;03m# pyre-ignore [29]\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_closure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_float64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Post-processing and outcome handling\u001b[39;00m\n\u001b[1;32m    122\u001b[0m wrapped_closure\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m asarray(raw\u001b[38;5;241m.\u001b[39mx)  \u001b[38;5;66;03m# set parameter state to optimal values\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/utils/timeout.py:83\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod .* cannot handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/closures/core.py:152\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     value_tensor, grad_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_array(value_tensor)\n\u001b[1;32m    154\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_ndarray(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/closures/core.py:66\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Tensor, \u001b[38;5;28mtuple\u001b[39m[Optional[Tensor], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_manager():\n\u001b[0;32m---> 66\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m         value \u001b[38;5;241m=\u001b[39m values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(values)\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(value)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/botorch/optim/closures/model_closures.py:179\u001b[0m, in \u001b[0;36m_get_loss_closure_exact_internal.<locals>.closure\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# The inputs will get transformed in forward here.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m model_output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_inputs)\n\u001b[0;32m--> 179\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# During model training, the model inputs get transformed in the forward\u001b[39;49;00m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pass. The train_inputs property is not transformed yet, so we need to\u001b[39;49;00m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# transform it before passing it to the likelihood for consistency.\u001b[39;49;00m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlog_likelihood\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:82\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN observation policy \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported by ExactMarginalLogLikelihood!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/gpytorch/distributions/multivariate_normal.py:171\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mSee :py:meth:`torch.distributions.Distribution.log_prob\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m<torch.distributions.distribution.Distribution.log_prob>`.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mfast_computations\u001b[38;5;241m.\u001b[39mlog_prob\u001b[38;5;241m.\u001b[39moff():\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py:249\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m    248\u001b[0m diff \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\n\u001b[0;32m--> 249\u001b[0m M \u001b[38;5;241m=\u001b[39m _batch_mahalanobis(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m, diff)\n\u001b[1;32m    250\u001b[0m half_log_det \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m+\u001b[39m M) \u001b[38;5;241m-\u001b[39m half_log_det\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/gpytorch/distributions/multivariate_normal.py:88\u001b[0m, in \u001b[0;36mMultivariateNormal._unbroadcasted_scale_tril\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unbroadcasted_scale_tril\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mislazy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;66;03m# cache root decoposition\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m         ust \u001b[38;5;241m=\u001b[39m to_dense(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_covariance_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril \u001b[38;5;241m=\u001b[39m ust\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__unbroadcasted_scale_tril\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:1311\u001b[0m, in \u001b[0;36mLinearOperator.cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;129m@_implements\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky)\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcholesky\u001b[39m(\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m], upper: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# returns TriangularLinearOperator\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;124;03m    Cholesky-factorizes the LinearOperator.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m    :param upper: Upper triangular or lower triangular factor (default: False).\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m    :return: Cholesky factor (lower or upper triangular)\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1311\u001b[0m     chol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[1;32m   1313\u001b[0m         chol \u001b[38;5;241m=\u001b[39m chol\u001b[38;5;241m.\u001b[39m_transpose_nonbatch()\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m/workspace/repr-preference-optimization/.venv/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:528\u001b[0m, in \u001b[0;36mLinearOperator._cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(evaluated_mat\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39msqrt())\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# contiguous call is necessary here\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m cholesky \u001b[38;5;241m=\u001b[39m \u001b[43mpsd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluated_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(cholesky, upper\u001b[38;5;241m=\u001b[39mupper)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for _ in tqdm(range(450)):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    try:\n",
    "        r = objective_func(**parameters)\n",
    "        print(parameters, r)\n",
    "    except KeyboardInterrupt:\n",
    "        ax_client.save_to_json_file(filepath=exp_f)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in objective_func: parameters={parameters}\")\n",
    "        continue\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=r)\n",
    "\n",
    "best_parameters, metrics = ax_client.get_best_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client.save_to_json_file(filepath=exp_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-26 00:00:01] ax.modelbridge.generation_strategy: Note that parameter values in dataframe are rounded to 2 decimal points; the values in the dataframe are thus not the exact ones suggested by Ax in trials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation Step</th>\n",
       "      <th>Generation Model(s)</th>\n",
       "      <th>Trial Index</th>\n",
       "      <th>Trial Status</th>\n",
       "      <th>Arm Parameterizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'0_0': {'lr': 0.0, 'collect_input': False, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'1_0': {'lr': 0.36, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'2_0': {'lr': 0.0, 'collect_input': False, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'3_0': {'lr': 0.0, 'collect_input': True, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'4_0': {'lr': 0.0, 'collect_input': False, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'5_0': {'lr': 0.0, 'collect_input': True, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'6_0': {'lr': 0.03, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>7</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'7_0': {'lr': 0.0, 'collect_input': True, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>8</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'8_0': {'lr': 0.0, 'collect_input': False, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'9_0': {'lr': 0.05, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'10_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'11_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'12_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'13_0': {'lr': 0.02, 'collect_input': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'14_0': {'lr': 0.09, 'collect_input': False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>15</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'15_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>16</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'16_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>17</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'17_0': {'lr': 0.13, 'collect_input': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>18</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'18_0': {'lr': 0.01, 'collect_input': False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>19</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'19_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>20</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'20_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'21_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>22</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'22_0': {'lr': 0.08, 'collect_input': False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[GenerationStep_0]</td>\n",
       "      <td>[Sobol]</td>\n",
       "      <td>23</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'23_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>24</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'24_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>25</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'25_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>26</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'26_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>27</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'27_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>28</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'28_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>29</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'29_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>30</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'30_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>31</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'31_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>32</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'32_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>33</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'33_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>34</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'34_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>35</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'35_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>36</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'36_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>37</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'37_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>38</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'38_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>39</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'39_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>40</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'40_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>41</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'41_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>42</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'42_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>43</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'43_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>44</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'44_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>45</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'45_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>46</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'46_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>47</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'47_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>48</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'48_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>49</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'49_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>50</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'50_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>51</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'51_0': {'lr': 0.0, 'collect_input': True, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>52</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'52_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>53</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'53_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>54</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'54_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>55</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'55_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>56</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'56_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[GenerationStep_1]</td>\n",
       "      <td>[BoTorch]</td>\n",
       "      <td>57</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>{'57_0': {'lr': 0.0, 'collect_input': False, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Generation Step Generation Model(s)  Trial Index Trial Status  \\\n",
       "0   [GenerationStep_0]             [Sobol]            0    COMPLETED   \n",
       "1   [GenerationStep_0]             [Sobol]            1    COMPLETED   \n",
       "2   [GenerationStep_0]             [Sobol]            2    COMPLETED   \n",
       "3   [GenerationStep_0]             [Sobol]            3    COMPLETED   \n",
       "4   [GenerationStep_0]             [Sobol]            4    COMPLETED   \n",
       "5   [GenerationStep_0]             [Sobol]            5    COMPLETED   \n",
       "6   [GenerationStep_0]             [Sobol]            6    COMPLETED   \n",
       "7   [GenerationStep_0]             [Sobol]            7    COMPLETED   \n",
       "8   [GenerationStep_0]             [Sobol]            8    COMPLETED   \n",
       "9   [GenerationStep_0]             [Sobol]            9    COMPLETED   \n",
       "10  [GenerationStep_0]             [Sobol]           10    COMPLETED   \n",
       "11  [GenerationStep_0]             [Sobol]           11    COMPLETED   \n",
       "12  [GenerationStep_0]             [Sobol]           12    COMPLETED   \n",
       "13  [GenerationStep_0]             [Sobol]           13    COMPLETED   \n",
       "14  [GenerationStep_0]             [Sobol]           14    COMPLETED   \n",
       "15  [GenerationStep_0]             [Sobol]           15    COMPLETED   \n",
       "16  [GenerationStep_0]             [Sobol]           16    COMPLETED   \n",
       "17  [GenerationStep_0]             [Sobol]           17    COMPLETED   \n",
       "18  [GenerationStep_0]             [Sobol]           18    COMPLETED   \n",
       "19  [GenerationStep_0]             [Sobol]           19    COMPLETED   \n",
       "20  [GenerationStep_0]             [Sobol]           20    COMPLETED   \n",
       "21  [GenerationStep_0]             [Sobol]           21    COMPLETED   \n",
       "22  [GenerationStep_0]             [Sobol]           22    COMPLETED   \n",
       "23  [GenerationStep_0]             [Sobol]           23    COMPLETED   \n",
       "24  [GenerationStep_1]           [BoTorch]           24    COMPLETED   \n",
       "25  [GenerationStep_1]           [BoTorch]           25    COMPLETED   \n",
       "26  [GenerationStep_1]           [BoTorch]           26    COMPLETED   \n",
       "27  [GenerationStep_1]           [BoTorch]           27    COMPLETED   \n",
       "28  [GenerationStep_1]           [BoTorch]           28    COMPLETED   \n",
       "29  [GenerationStep_1]           [BoTorch]           29    COMPLETED   \n",
       "30  [GenerationStep_1]           [BoTorch]           30    COMPLETED   \n",
       "31  [GenerationStep_1]           [BoTorch]           31    COMPLETED   \n",
       "32  [GenerationStep_1]           [BoTorch]           32    COMPLETED   \n",
       "33  [GenerationStep_1]           [BoTorch]           33    COMPLETED   \n",
       "34  [GenerationStep_1]           [BoTorch]           34    COMPLETED   \n",
       "35  [GenerationStep_1]           [BoTorch]           35    COMPLETED   \n",
       "36  [GenerationStep_1]           [BoTorch]           36    COMPLETED   \n",
       "37  [GenerationStep_1]           [BoTorch]           37    COMPLETED   \n",
       "38  [GenerationStep_1]           [BoTorch]           38    COMPLETED   \n",
       "39  [GenerationStep_1]           [BoTorch]           39    COMPLETED   \n",
       "40  [GenerationStep_1]           [BoTorch]           40    COMPLETED   \n",
       "41  [GenerationStep_1]           [BoTorch]           41    COMPLETED   \n",
       "42  [GenerationStep_1]           [BoTorch]           42    COMPLETED   \n",
       "43  [GenerationStep_1]           [BoTorch]           43    COMPLETED   \n",
       "44  [GenerationStep_1]           [BoTorch]           44    COMPLETED   \n",
       "45  [GenerationStep_1]           [BoTorch]           45    COMPLETED   \n",
       "46  [GenerationStep_1]           [BoTorch]           46    COMPLETED   \n",
       "47  [GenerationStep_1]           [BoTorch]           47    COMPLETED   \n",
       "48  [GenerationStep_1]           [BoTorch]           48    COMPLETED   \n",
       "49  [GenerationStep_1]           [BoTorch]           49    COMPLETED   \n",
       "50  [GenerationStep_1]           [BoTorch]           50    COMPLETED   \n",
       "51  [GenerationStep_1]           [BoTorch]           51    COMPLETED   \n",
       "52  [GenerationStep_1]           [BoTorch]           52    COMPLETED   \n",
       "53  [GenerationStep_1]           [BoTorch]           53    COMPLETED   \n",
       "54  [GenerationStep_1]           [BoTorch]           54    COMPLETED   \n",
       "55  [GenerationStep_1]           [BoTorch]           55    COMPLETED   \n",
       "56  [GenerationStep_1]           [BoTorch]           56    COMPLETED   \n",
       "57  [GenerationStep_1]           [BoTorch]           57    COMPLETED   \n",
       "\n",
       "                                Arm Parameterizations  \n",
       "0   {'0_0': {'lr': 0.0, 'collect_input': False, 'c...  \n",
       "1   {'1_0': {'lr': 0.36, 'collect_input': True, 'c...  \n",
       "2   {'2_0': {'lr': 0.0, 'collect_input': False, 'c...  \n",
       "3   {'3_0': {'lr': 0.0, 'collect_input': True, 'co...  \n",
       "4   {'4_0': {'lr': 0.0, 'collect_input': False, 'c...  \n",
       "5   {'5_0': {'lr': 0.0, 'collect_input': True, 'co...  \n",
       "6   {'6_0': {'lr': 0.03, 'collect_input': False, '...  \n",
       "7   {'7_0': {'lr': 0.0, 'collect_input': True, 'co...  \n",
       "8   {'8_0': {'lr': 0.0, 'collect_input': False, 'c...  \n",
       "9   {'9_0': {'lr': 0.05, 'collect_input': True, 'c...  \n",
       "10  {'10_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "11  {'11_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "12  {'12_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "13  {'13_0': {'lr': 0.02, 'collect_input': True, '...  \n",
       "14  {'14_0': {'lr': 0.09, 'collect_input': False, ...  \n",
       "15  {'15_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "16  {'16_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "17  {'17_0': {'lr': 0.13, 'collect_input': True, '...  \n",
       "18  {'18_0': {'lr': 0.01, 'collect_input': False, ...  \n",
       "19  {'19_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "20  {'20_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "21  {'21_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "22  {'22_0': {'lr': 0.08, 'collect_input': False, ...  \n",
       "23  {'23_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "24  {'24_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "25  {'25_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "26  {'26_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "27  {'27_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "28  {'28_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "29  {'29_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "30  {'30_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "31  {'31_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "32  {'32_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "33  {'33_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "34  {'34_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "35  {'35_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "36  {'36_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "37  {'37_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "38  {'38_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "39  {'39_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "40  {'40_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "41  {'41_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "42  {'42_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "43  {'43_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "44  {'44_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "45  {'45_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "46  {'46_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "47  {'47_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "48  {'48_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "49  {'49_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "50  {'50_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "51  {'51_0': {'lr': 0.0, 'collect_input': True, 'c...  \n",
       "52  {'52_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "53  {'53_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "54  {'54_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "55  {'55_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "56  {'56_0': {'lr': 0.0, 'collect_input': False, '...  \n",
       "57  {'57_0': {'lr': 0.0, 'collect_input': False, '...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = ax_client.generation_strategy.trials_as_df\n",
    "# d = df['Arm Parameterizations'].values\n",
    "# pd.DataFrame([next(iter(dd.values())) for dd in d])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 09-26 00:00:28] ax.service.utils.report_utils: Column reason missing for all trials. Not appending column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_93ff9_row0_col0, #T_93ff9_row0_col1, #T_93ff9_row0_col2, #T_93ff9_row0_col3, #T_93ff9_row0_col4, #T_93ff9_row0_col5, #T_93ff9_row0_col6, #T_93ff9_row0_col7, #T_93ff9_row0_col8, #T_93ff9_row0_col9, #T_93ff9_row0_col10, #T_93ff9_row0_col11, #T_93ff9_row0_col12, #T_93ff9_row0_col13, #T_93ff9_row0_col14, #T_93ff9_row0_col15, #T_93ff9_row0_col16, #T_93ff9_row0_col17, #T_93ff9_row0_col18, #T_93ff9_row0_col19, #T_93ff9_row0_col20, #T_93ff9_row0_col23, #T_93ff9_row0_col29, #T_93ff9_row0_col30, #T_93ff9_row1_col0, #T_93ff9_row1_col1, #T_93ff9_row1_col2, #T_93ff9_row1_col3, #T_93ff9_row1_col4, #T_93ff9_row1_col5, #T_93ff9_row1_col6, #T_93ff9_row1_col7, #T_93ff9_row1_col8, #T_93ff9_row1_col9, #T_93ff9_row1_col10, #T_93ff9_row1_col11, #T_93ff9_row1_col12, #T_93ff9_row1_col13, #T_93ff9_row1_col14, #T_93ff9_row1_col15, #T_93ff9_row1_col16, #T_93ff9_row1_col17, #T_93ff9_row1_col18, #T_93ff9_row1_col19, #T_93ff9_row1_col20, #T_93ff9_row1_col23, #T_93ff9_row1_col29, #T_93ff9_row1_col30, #T_93ff9_row2_col0, #T_93ff9_row2_col1, #T_93ff9_row2_col2, #T_93ff9_row2_col3, #T_93ff9_row2_col4, #T_93ff9_row2_col5, #T_93ff9_row2_col6, #T_93ff9_row2_col7, #T_93ff9_row2_col8, #T_93ff9_row2_col9, #T_93ff9_row2_col10, #T_93ff9_row2_col11, #T_93ff9_row2_col12, #T_93ff9_row2_col13, #T_93ff9_row2_col14, #T_93ff9_row2_col15, #T_93ff9_row2_col16, #T_93ff9_row2_col17, #T_93ff9_row2_col18, #T_93ff9_row2_col19, #T_93ff9_row2_col20, #T_93ff9_row2_col23, #T_93ff9_row2_col29, #T_93ff9_row2_col30, #T_93ff9_row3_col0, #T_93ff9_row3_col1, #T_93ff9_row3_col2, #T_93ff9_row3_col3, #T_93ff9_row3_col4, #T_93ff9_row3_col5, #T_93ff9_row3_col6, #T_93ff9_row3_col7, #T_93ff9_row3_col8, #T_93ff9_row3_col9, #T_93ff9_row3_col10, #T_93ff9_row3_col11, #T_93ff9_row3_col12, #T_93ff9_row3_col13, #T_93ff9_row3_col14, #T_93ff9_row3_col15, #T_93ff9_row3_col16, #T_93ff9_row3_col17, #T_93ff9_row3_col18, #T_93ff9_row3_col19, #T_93ff9_row3_col20, #T_93ff9_row3_col23, #T_93ff9_row3_col29, #T_93ff9_row3_col30, #T_93ff9_row4_col0, #T_93ff9_row4_col1, #T_93ff9_row4_col2, #T_93ff9_row4_col3, #T_93ff9_row4_col4, #T_93ff9_row4_col5, #T_93ff9_row4_col6, #T_93ff9_row4_col7, #T_93ff9_row4_col8, #T_93ff9_row4_col9, #T_93ff9_row4_col10, #T_93ff9_row4_col11, #T_93ff9_row4_col12, #T_93ff9_row4_col13, #T_93ff9_row4_col14, #T_93ff9_row4_col15, #T_93ff9_row4_col16, #T_93ff9_row4_col17, #T_93ff9_row4_col18, #T_93ff9_row4_col19, #T_93ff9_row4_col20, #T_93ff9_row4_col23, #T_93ff9_row4_col29, #T_93ff9_row4_col30, #T_93ff9_row5_col0, #T_93ff9_row5_col1, #T_93ff9_row5_col2, #T_93ff9_row5_col3, #T_93ff9_row5_col4, #T_93ff9_row5_col5, #T_93ff9_row5_col6, #T_93ff9_row5_col7, #T_93ff9_row5_col8, #T_93ff9_row5_col9, #T_93ff9_row5_col10, #T_93ff9_row5_col11, #T_93ff9_row5_col12, #T_93ff9_row5_col13, #T_93ff9_row5_col14, #T_93ff9_row5_col15, #T_93ff9_row5_col16, #T_93ff9_row5_col17, #T_93ff9_row5_col18, #T_93ff9_row5_col19, #T_93ff9_row5_col20, #T_93ff9_row5_col23, #T_93ff9_row5_col29, #T_93ff9_row5_col30, #T_93ff9_row6_col0, #T_93ff9_row6_col1, #T_93ff9_row6_col2, #T_93ff9_row6_col3, #T_93ff9_row6_col4, #T_93ff9_row6_col5, #T_93ff9_row6_col6, #T_93ff9_row6_col7, #T_93ff9_row6_col8, #T_93ff9_row6_col9, #T_93ff9_row6_col10, #T_93ff9_row6_col11, #T_93ff9_row6_col12, #T_93ff9_row6_col13, #T_93ff9_row6_col14, #T_93ff9_row6_col15, #T_93ff9_row6_col16, #T_93ff9_row6_col17, #T_93ff9_row6_col18, #T_93ff9_row6_col19, #T_93ff9_row6_col20, #T_93ff9_row6_col23, #T_93ff9_row6_col29, #T_93ff9_row6_col30, #T_93ff9_row7_col0, #T_93ff9_row7_col1, #T_93ff9_row7_col2, #T_93ff9_row7_col3, #T_93ff9_row7_col4, #T_93ff9_row7_col5, #T_93ff9_row7_col6, #T_93ff9_row7_col7, #T_93ff9_row7_col8, #T_93ff9_row7_col9, #T_93ff9_row7_col10, #T_93ff9_row7_col11, #T_93ff9_row7_col12, #T_93ff9_row7_col13, #T_93ff9_row7_col14, #T_93ff9_row7_col15, #T_93ff9_row7_col16, #T_93ff9_row7_col17, #T_93ff9_row7_col18, #T_93ff9_row7_col19, #T_93ff9_row7_col20, #T_93ff9_row7_col23, #T_93ff9_row7_col29, #T_93ff9_row7_col30, #T_93ff9_row8_col0, #T_93ff9_row8_col1, #T_93ff9_row8_col2, #T_93ff9_row8_col3, #T_93ff9_row8_col4, #T_93ff9_row8_col5, #T_93ff9_row8_col6, #T_93ff9_row8_col7, #T_93ff9_row8_col8, #T_93ff9_row8_col9, #T_93ff9_row8_col10, #T_93ff9_row8_col11, #T_93ff9_row8_col12, #T_93ff9_row8_col13, #T_93ff9_row8_col14, #T_93ff9_row8_col15, #T_93ff9_row8_col16, #T_93ff9_row8_col17, #T_93ff9_row8_col18, #T_93ff9_row8_col19, #T_93ff9_row8_col20, #T_93ff9_row8_col23, #T_93ff9_row8_col29, #T_93ff9_row8_col30, #T_93ff9_row9_col0, #T_93ff9_row9_col1, #T_93ff9_row9_col2, #T_93ff9_row9_col3, #T_93ff9_row9_col4, #T_93ff9_row9_col5, #T_93ff9_row9_col6, #T_93ff9_row9_col7, #T_93ff9_row9_col8, #T_93ff9_row9_col9, #T_93ff9_row9_col10, #T_93ff9_row9_col11, #T_93ff9_row9_col12, #T_93ff9_row9_col13, #T_93ff9_row9_col14, #T_93ff9_row9_col15, #T_93ff9_row9_col16, #T_93ff9_row9_col17, #T_93ff9_row9_col18, #T_93ff9_row9_col19, #T_93ff9_row9_col20, #T_93ff9_row9_col23, #T_93ff9_row9_col29, #T_93ff9_row9_col30, #T_93ff9_row10_col0, #T_93ff9_row10_col1, #T_93ff9_row10_col2, #T_93ff9_row10_col3, #T_93ff9_row10_col4, #T_93ff9_row10_col5, #T_93ff9_row10_col6, #T_93ff9_row10_col7, #T_93ff9_row10_col8, #T_93ff9_row10_col9, #T_93ff9_row10_col10, #T_93ff9_row10_col11, #T_93ff9_row10_col12, #T_93ff9_row10_col13, #T_93ff9_row10_col14, #T_93ff9_row10_col15, #T_93ff9_row10_col16, #T_93ff9_row10_col17, #T_93ff9_row10_col18, #T_93ff9_row10_col19, #T_93ff9_row10_col20, #T_93ff9_row10_col23, #T_93ff9_row10_col29, #T_93ff9_row10_col30, #T_93ff9_row11_col0, #T_93ff9_row11_col1, #T_93ff9_row11_col2, #T_93ff9_row11_col3, #T_93ff9_row11_col4, #T_93ff9_row11_col5, #T_93ff9_row11_col6, #T_93ff9_row11_col7, #T_93ff9_row11_col8, #T_93ff9_row11_col9, #T_93ff9_row11_col10, #T_93ff9_row11_col11, #T_93ff9_row11_col12, #T_93ff9_row11_col13, #T_93ff9_row11_col14, #T_93ff9_row11_col15, #T_93ff9_row11_col16, #T_93ff9_row11_col17, #T_93ff9_row11_col18, #T_93ff9_row11_col19, #T_93ff9_row11_col20, #T_93ff9_row11_col23, #T_93ff9_row11_col29, #T_93ff9_row11_col30, #T_93ff9_row12_col0, #T_93ff9_row12_col1, #T_93ff9_row12_col2, #T_93ff9_row12_col3, #T_93ff9_row12_col4, #T_93ff9_row12_col5, #T_93ff9_row12_col6, #T_93ff9_row12_col7, #T_93ff9_row12_col8, #T_93ff9_row12_col9, #T_93ff9_row12_col10, #T_93ff9_row12_col11, #T_93ff9_row12_col12, #T_93ff9_row12_col13, #T_93ff9_row12_col14, #T_93ff9_row12_col15, #T_93ff9_row12_col16, #T_93ff9_row12_col17, #T_93ff9_row12_col18, #T_93ff9_row12_col19, #T_93ff9_row12_col20, #T_93ff9_row12_col23, #T_93ff9_row12_col29, #T_93ff9_row12_col30, #T_93ff9_row13_col0, #T_93ff9_row13_col1, #T_93ff9_row13_col2, #T_93ff9_row13_col3, #T_93ff9_row13_col4, #T_93ff9_row13_col5, #T_93ff9_row13_col6, #T_93ff9_row13_col7, #T_93ff9_row13_col8, #T_93ff9_row13_col9, #T_93ff9_row13_col10, #T_93ff9_row13_col11, #T_93ff9_row13_col12, #T_93ff9_row13_col13, #T_93ff9_row13_col14, #T_93ff9_row13_col15, #T_93ff9_row13_col16, #T_93ff9_row13_col17, #T_93ff9_row13_col18, #T_93ff9_row13_col19, #T_93ff9_row13_col20, #T_93ff9_row13_col23, #T_93ff9_row13_col29, #T_93ff9_row13_col30, #T_93ff9_row14_col0, #T_93ff9_row14_col1, #T_93ff9_row14_col2, #T_93ff9_row14_col3, #T_93ff9_row14_col4, #T_93ff9_row14_col5, #T_93ff9_row14_col6, #T_93ff9_row14_col7, #T_93ff9_row14_col8, #T_93ff9_row14_col9, #T_93ff9_row14_col10, #T_93ff9_row14_col11, #T_93ff9_row14_col12, #T_93ff9_row14_col13, #T_93ff9_row14_col14, #T_93ff9_row14_col15, #T_93ff9_row14_col16, #T_93ff9_row14_col17, #T_93ff9_row14_col18, #T_93ff9_row14_col19, #T_93ff9_row14_col20, #T_93ff9_row14_col23, #T_93ff9_row14_col29, #T_93ff9_row14_col30, #T_93ff9_row15_col0, #T_93ff9_row15_col1, #T_93ff9_row15_col2, #T_93ff9_row15_col3, #T_93ff9_row15_col4, #T_93ff9_row15_col5, #T_93ff9_row15_col6, #T_93ff9_row15_col7, #T_93ff9_row15_col8, #T_93ff9_row15_col9, #T_93ff9_row15_col10, #T_93ff9_row15_col11, #T_93ff9_row15_col12, #T_93ff9_row15_col13, #T_93ff9_row15_col14, #T_93ff9_row15_col15, #T_93ff9_row15_col16, #T_93ff9_row15_col17, #T_93ff9_row15_col18, #T_93ff9_row15_col19, #T_93ff9_row15_col20, #T_93ff9_row15_col23, #T_93ff9_row15_col29, #T_93ff9_row15_col30, #T_93ff9_row16_col0, #T_93ff9_row16_col1, #T_93ff9_row16_col2, #T_93ff9_row16_col3, #T_93ff9_row16_col4, #T_93ff9_row16_col5, #T_93ff9_row16_col6, #T_93ff9_row16_col7, #T_93ff9_row16_col8, #T_93ff9_row16_col9, #T_93ff9_row16_col10, #T_93ff9_row16_col11, #T_93ff9_row16_col12, #T_93ff9_row16_col13, #T_93ff9_row16_col14, #T_93ff9_row16_col15, #T_93ff9_row16_col16, #T_93ff9_row16_col17, #T_93ff9_row16_col18, #T_93ff9_row16_col19, #T_93ff9_row16_col20, #T_93ff9_row16_col23, #T_93ff9_row16_col29, #T_93ff9_row16_col30, #T_93ff9_row17_col0, #T_93ff9_row17_col1, #T_93ff9_row17_col2, #T_93ff9_row17_col3, #T_93ff9_row17_col4, #T_93ff9_row17_col5, #T_93ff9_row17_col6, #T_93ff9_row17_col7, #T_93ff9_row17_col8, #T_93ff9_row17_col9, #T_93ff9_row17_col10, #T_93ff9_row17_col11, #T_93ff9_row17_col12, #T_93ff9_row17_col13, #T_93ff9_row17_col14, #T_93ff9_row17_col15, #T_93ff9_row17_col16, #T_93ff9_row17_col17, #T_93ff9_row17_col18, #T_93ff9_row17_col19, #T_93ff9_row17_col20, #T_93ff9_row17_col23, #T_93ff9_row17_col29, #T_93ff9_row17_col30, #T_93ff9_row18_col0, #T_93ff9_row18_col1, #T_93ff9_row18_col2, #T_93ff9_row18_col3, #T_93ff9_row18_col4, #T_93ff9_row18_col5, #T_93ff9_row18_col6, #T_93ff9_row18_col7, #T_93ff9_row18_col8, #T_93ff9_row18_col9, #T_93ff9_row18_col10, #T_93ff9_row18_col11, #T_93ff9_row18_col12, #T_93ff9_row18_col13, #T_93ff9_row18_col14, #T_93ff9_row18_col15, #T_93ff9_row18_col16, #T_93ff9_row18_col17, #T_93ff9_row18_col18, #T_93ff9_row18_col19, #T_93ff9_row18_col20, #T_93ff9_row18_col23, #T_93ff9_row18_col29, #T_93ff9_row18_col30, #T_93ff9_row19_col0, #T_93ff9_row19_col1, #T_93ff9_row19_col2, #T_93ff9_row19_col3, #T_93ff9_row19_col4, #T_93ff9_row19_col5, #T_93ff9_row19_col6, #T_93ff9_row19_col7, #T_93ff9_row19_col8, #T_93ff9_row19_col9, #T_93ff9_row19_col10, #T_93ff9_row19_col11, #T_93ff9_row19_col12, #T_93ff9_row19_col13, #T_93ff9_row19_col14, #T_93ff9_row19_col15, #T_93ff9_row19_col16, #T_93ff9_row19_col17, #T_93ff9_row19_col18, #T_93ff9_row19_col19, #T_93ff9_row19_col20, #T_93ff9_row19_col23, #T_93ff9_row19_col29, #T_93ff9_row19_col30, #T_93ff9_row20_col0, #T_93ff9_row20_col1, #T_93ff9_row20_col2, #T_93ff9_row20_col3, #T_93ff9_row20_col4, #T_93ff9_row20_col5, #T_93ff9_row20_col6, #T_93ff9_row20_col7, #T_93ff9_row20_col8, #T_93ff9_row20_col9, #T_93ff9_row20_col10, #T_93ff9_row20_col11, #T_93ff9_row20_col12, #T_93ff9_row20_col13, #T_93ff9_row20_col14, #T_93ff9_row20_col15, #T_93ff9_row20_col16, #T_93ff9_row20_col17, #T_93ff9_row20_col18, #T_93ff9_row20_col19, #T_93ff9_row20_col20, #T_93ff9_row20_col23, #T_93ff9_row20_col29, #T_93ff9_row20_col30, #T_93ff9_row21_col0, #T_93ff9_row21_col1, #T_93ff9_row21_col2, #T_93ff9_row21_col3, #T_93ff9_row21_col4, #T_93ff9_row21_col5, #T_93ff9_row21_col6, #T_93ff9_row21_col7, #T_93ff9_row21_col8, #T_93ff9_row21_col9, #T_93ff9_row21_col10, #T_93ff9_row21_col11, #T_93ff9_row21_col12, #T_93ff9_row21_col13, #T_93ff9_row21_col14, #T_93ff9_row21_col15, #T_93ff9_row21_col16, #T_93ff9_row21_col17, #T_93ff9_row21_col18, #T_93ff9_row21_col19, #T_93ff9_row21_col20, #T_93ff9_row21_col23, #T_93ff9_row21_col29, #T_93ff9_row21_col30, #T_93ff9_row22_col0, #T_93ff9_row22_col1, #T_93ff9_row22_col2, #T_93ff9_row22_col3, #T_93ff9_row22_col4, #T_93ff9_row22_col5, #T_93ff9_row22_col6, #T_93ff9_row22_col7, #T_93ff9_row22_col8, #T_93ff9_row22_col9, #T_93ff9_row22_col10, #T_93ff9_row22_col11, #T_93ff9_row22_col12, #T_93ff9_row22_col13, #T_93ff9_row22_col14, #T_93ff9_row22_col15, #T_93ff9_row22_col16, #T_93ff9_row22_col17, #T_93ff9_row22_col18, #T_93ff9_row22_col19, #T_93ff9_row22_col20, #T_93ff9_row22_col23, #T_93ff9_row22_col29, #T_93ff9_row22_col30, #T_93ff9_row23_col0, #T_93ff9_row23_col1, #T_93ff9_row23_col2, #T_93ff9_row23_col3, #T_93ff9_row23_col4, #T_93ff9_row23_col5, #T_93ff9_row23_col6, #T_93ff9_row23_col7, #T_93ff9_row23_col8, #T_93ff9_row23_col9, #T_93ff9_row23_col10, #T_93ff9_row23_col11, #T_93ff9_row23_col12, #T_93ff9_row23_col13, #T_93ff9_row23_col14, #T_93ff9_row23_col15, #T_93ff9_row23_col16, #T_93ff9_row23_col17, #T_93ff9_row23_col18, #T_93ff9_row23_col19, #T_93ff9_row23_col20, #T_93ff9_row23_col23, #T_93ff9_row23_col29, #T_93ff9_row23_col30, #T_93ff9_row24_col0, #T_93ff9_row24_col1, #T_93ff9_row24_col2, #T_93ff9_row24_col3, #T_93ff9_row24_col4, #T_93ff9_row24_col5, #T_93ff9_row24_col6, #T_93ff9_row24_col7, #T_93ff9_row24_col8, #T_93ff9_row24_col9, #T_93ff9_row24_col10, #T_93ff9_row24_col11, #T_93ff9_row24_col12, #T_93ff9_row24_col13, #T_93ff9_row24_col14, #T_93ff9_row24_col15, #T_93ff9_row24_col16, #T_93ff9_row24_col17, #T_93ff9_row24_col18, #T_93ff9_row24_col19, #T_93ff9_row24_col20, #T_93ff9_row24_col23, #T_93ff9_row24_col29, #T_93ff9_row24_col30, #T_93ff9_row25_col0, #T_93ff9_row25_col1, #T_93ff9_row25_col2, #T_93ff9_row25_col3, #T_93ff9_row25_col4, #T_93ff9_row25_col5, #T_93ff9_row25_col6, #T_93ff9_row25_col7, #T_93ff9_row25_col8, #T_93ff9_row25_col9, #T_93ff9_row25_col10, #T_93ff9_row25_col11, #T_93ff9_row25_col12, #T_93ff9_row25_col13, #T_93ff9_row25_col14, #T_93ff9_row25_col15, #T_93ff9_row25_col16, #T_93ff9_row25_col17, #T_93ff9_row25_col18, #T_93ff9_row25_col19, #T_93ff9_row25_col20, #T_93ff9_row25_col23, #T_93ff9_row25_col29, #T_93ff9_row25_col30, #T_93ff9_row26_col0, #T_93ff9_row26_col1, #T_93ff9_row26_col2, #T_93ff9_row26_col3, #T_93ff9_row26_col4, #T_93ff9_row26_col5, #T_93ff9_row26_col6, #T_93ff9_row26_col7, #T_93ff9_row26_col8, #T_93ff9_row26_col9, #T_93ff9_row26_col10, #T_93ff9_row26_col11, #T_93ff9_row26_col12, #T_93ff9_row26_col13, #T_93ff9_row26_col14, #T_93ff9_row26_col15, #T_93ff9_row26_col16, #T_93ff9_row26_col17, #T_93ff9_row26_col18, #T_93ff9_row26_col19, #T_93ff9_row26_col20, #T_93ff9_row26_col23, #T_93ff9_row26_col29, #T_93ff9_row26_col30, #T_93ff9_row27_col0, #T_93ff9_row27_col1, #T_93ff9_row27_col2, #T_93ff9_row27_col3, #T_93ff9_row27_col4, #T_93ff9_row27_col5, #T_93ff9_row27_col6, #T_93ff9_row27_col7, #T_93ff9_row27_col8, #T_93ff9_row27_col9, #T_93ff9_row27_col10, #T_93ff9_row27_col11, #T_93ff9_row27_col12, #T_93ff9_row27_col13, #T_93ff9_row27_col14, #T_93ff9_row27_col15, #T_93ff9_row27_col16, #T_93ff9_row27_col17, #T_93ff9_row27_col18, #T_93ff9_row27_col19, #T_93ff9_row27_col20, #T_93ff9_row27_col23, #T_93ff9_row27_col29, #T_93ff9_row27_col30, #T_93ff9_row28_col0, #T_93ff9_row28_col1, #T_93ff9_row28_col2, #T_93ff9_row28_col3, #T_93ff9_row28_col4, #T_93ff9_row28_col5, #T_93ff9_row28_col6, #T_93ff9_row28_col7, #T_93ff9_row28_col8, #T_93ff9_row28_col9, #T_93ff9_row28_col10, #T_93ff9_row28_col11, #T_93ff9_row28_col12, #T_93ff9_row28_col13, #T_93ff9_row28_col14, #T_93ff9_row28_col15, #T_93ff9_row28_col16, #T_93ff9_row28_col17, #T_93ff9_row28_col18, #T_93ff9_row28_col19, #T_93ff9_row28_col20, #T_93ff9_row28_col23, #T_93ff9_row28_col29, #T_93ff9_row28_col30, #T_93ff9_row29_col0, #T_93ff9_row29_col1, #T_93ff9_row29_col2, #T_93ff9_row29_col3, #T_93ff9_row29_col4, #T_93ff9_row29_col5, #T_93ff9_row29_col6, #T_93ff9_row29_col7, #T_93ff9_row29_col8, #T_93ff9_row29_col9, #T_93ff9_row29_col10, #T_93ff9_row29_col11, #T_93ff9_row29_col12, #T_93ff9_row29_col13, #T_93ff9_row29_col14, #T_93ff9_row29_col15, #T_93ff9_row29_col16, #T_93ff9_row29_col17, #T_93ff9_row29_col18, #T_93ff9_row29_col19, #T_93ff9_row29_col20, #T_93ff9_row29_col23, #T_93ff9_row29_col29, #T_93ff9_row29_col30, #T_93ff9_row30_col0, #T_93ff9_row30_col1, #T_93ff9_row30_col2, #T_93ff9_row30_col3, #T_93ff9_row30_col4, #T_93ff9_row30_col5, #T_93ff9_row30_col6, #T_93ff9_row30_col7, #T_93ff9_row30_col8, #T_93ff9_row30_col9, #T_93ff9_row30_col10, #T_93ff9_row30_col11, #T_93ff9_row30_col12, #T_93ff9_row30_col13, #T_93ff9_row30_col14, #T_93ff9_row30_col15, #T_93ff9_row30_col16, #T_93ff9_row30_col17, #T_93ff9_row30_col18, #T_93ff9_row30_col19, #T_93ff9_row30_col20, #T_93ff9_row30_col23, #T_93ff9_row30_col29, #T_93ff9_row30_col30, #T_93ff9_row31_col0, #T_93ff9_row31_col1, #T_93ff9_row31_col2, #T_93ff9_row31_col3, #T_93ff9_row31_col4, #T_93ff9_row31_col5, #T_93ff9_row31_col6, #T_93ff9_row31_col7, #T_93ff9_row31_col8, #T_93ff9_row31_col9, #T_93ff9_row31_col10, #T_93ff9_row31_col11, #T_93ff9_row31_col12, #T_93ff9_row31_col13, #T_93ff9_row31_col14, #T_93ff9_row31_col15, #T_93ff9_row31_col16, #T_93ff9_row31_col17, #T_93ff9_row31_col18, #T_93ff9_row31_col19, #T_93ff9_row31_col20, #T_93ff9_row31_col23, #T_93ff9_row31_col29, #T_93ff9_row31_col30, #T_93ff9_row32_col0, #T_93ff9_row32_col1, #T_93ff9_row32_col2, #T_93ff9_row32_col3, #T_93ff9_row32_col4, #T_93ff9_row32_col5, #T_93ff9_row32_col6, #T_93ff9_row32_col7, #T_93ff9_row32_col8, #T_93ff9_row32_col9, #T_93ff9_row32_col10, #T_93ff9_row32_col11, #T_93ff9_row32_col12, #T_93ff9_row32_col13, #T_93ff9_row32_col14, #T_93ff9_row32_col15, #T_93ff9_row32_col16, #T_93ff9_row32_col17, #T_93ff9_row32_col18, #T_93ff9_row32_col19, #T_93ff9_row32_col20, #T_93ff9_row32_col23, #T_93ff9_row32_col29, #T_93ff9_row32_col30, #T_93ff9_row33_col0, #T_93ff9_row33_col1, #T_93ff9_row33_col2, #T_93ff9_row33_col3, #T_93ff9_row33_col4, #T_93ff9_row33_col5, #T_93ff9_row33_col6, #T_93ff9_row33_col7, #T_93ff9_row33_col8, #T_93ff9_row33_col9, #T_93ff9_row33_col10, #T_93ff9_row33_col11, #T_93ff9_row33_col12, #T_93ff9_row33_col13, #T_93ff9_row33_col14, #T_93ff9_row33_col15, #T_93ff9_row33_col16, #T_93ff9_row33_col17, #T_93ff9_row33_col18, #T_93ff9_row33_col19, #T_93ff9_row33_col20, #T_93ff9_row33_col23, #T_93ff9_row33_col29, #T_93ff9_row33_col30, #T_93ff9_row34_col0, #T_93ff9_row34_col1, #T_93ff9_row34_col2, #T_93ff9_row34_col3, #T_93ff9_row34_col4, #T_93ff9_row34_col5, #T_93ff9_row34_col6, #T_93ff9_row34_col7, #T_93ff9_row34_col8, #T_93ff9_row34_col9, #T_93ff9_row34_col10, #T_93ff9_row34_col11, #T_93ff9_row34_col12, #T_93ff9_row34_col13, #T_93ff9_row34_col14, #T_93ff9_row34_col15, #T_93ff9_row34_col16, #T_93ff9_row34_col17, #T_93ff9_row34_col18, #T_93ff9_row34_col19, #T_93ff9_row34_col20, #T_93ff9_row34_col23, #T_93ff9_row34_col29, #T_93ff9_row34_col30, #T_93ff9_row35_col0, #T_93ff9_row35_col1, #T_93ff9_row35_col2, #T_93ff9_row35_col3, #T_93ff9_row35_col4, #T_93ff9_row35_col5, #T_93ff9_row35_col6, #T_93ff9_row35_col7, #T_93ff9_row35_col8, #T_93ff9_row35_col9, #T_93ff9_row35_col10, #T_93ff9_row35_col11, #T_93ff9_row35_col12, #T_93ff9_row35_col13, #T_93ff9_row35_col14, #T_93ff9_row35_col15, #T_93ff9_row35_col16, #T_93ff9_row35_col17, #T_93ff9_row35_col18, #T_93ff9_row35_col19, #T_93ff9_row35_col20, #T_93ff9_row35_col23, #T_93ff9_row35_col29, #T_93ff9_row35_col30, #T_93ff9_row36_col0, #T_93ff9_row36_col1, #T_93ff9_row36_col2, #T_93ff9_row36_col3, #T_93ff9_row36_col4, #T_93ff9_row36_col5, #T_93ff9_row36_col6, #T_93ff9_row36_col7, #T_93ff9_row36_col8, #T_93ff9_row36_col9, #T_93ff9_row36_col10, #T_93ff9_row36_col11, #T_93ff9_row36_col12, #T_93ff9_row36_col13, #T_93ff9_row36_col14, #T_93ff9_row36_col15, #T_93ff9_row36_col16, #T_93ff9_row36_col17, #T_93ff9_row36_col18, #T_93ff9_row36_col19, #T_93ff9_row36_col20, #T_93ff9_row36_col23, #T_93ff9_row36_col29, #T_93ff9_row36_col30, #T_93ff9_row37_col0, #T_93ff9_row37_col1, #T_93ff9_row37_col2, #T_93ff9_row37_col3, #T_93ff9_row37_col4, #T_93ff9_row37_col5, #T_93ff9_row37_col6, #T_93ff9_row37_col7, #T_93ff9_row37_col8, #T_93ff9_row37_col9, #T_93ff9_row37_col10, #T_93ff9_row37_col11, #T_93ff9_row37_col12, #T_93ff9_row37_col13, #T_93ff9_row37_col14, #T_93ff9_row37_col15, #T_93ff9_row37_col16, #T_93ff9_row37_col17, #T_93ff9_row37_col18, #T_93ff9_row37_col19, #T_93ff9_row37_col20, #T_93ff9_row37_col23, #T_93ff9_row37_col29, #T_93ff9_row37_col30, #T_93ff9_row38_col0, #T_93ff9_row38_col1, #T_93ff9_row38_col2, #T_93ff9_row38_col3, #T_93ff9_row38_col4, #T_93ff9_row38_col5, #T_93ff9_row38_col6, #T_93ff9_row38_col7, #T_93ff9_row38_col8, #T_93ff9_row38_col9, #T_93ff9_row38_col10, #T_93ff9_row38_col11, #T_93ff9_row38_col12, #T_93ff9_row38_col13, #T_93ff9_row38_col14, #T_93ff9_row38_col15, #T_93ff9_row38_col16, #T_93ff9_row38_col17, #T_93ff9_row38_col18, #T_93ff9_row38_col19, #T_93ff9_row38_col20, #T_93ff9_row38_col23, #T_93ff9_row38_col29, #T_93ff9_row38_col30, #T_93ff9_row39_col0, #T_93ff9_row39_col1, #T_93ff9_row39_col2, #T_93ff9_row39_col3, #T_93ff9_row39_col4, #T_93ff9_row39_col5, #T_93ff9_row39_col6, #T_93ff9_row39_col7, #T_93ff9_row39_col8, #T_93ff9_row39_col9, #T_93ff9_row39_col10, #T_93ff9_row39_col11, #T_93ff9_row39_col12, #T_93ff9_row39_col13, #T_93ff9_row39_col14, #T_93ff9_row39_col15, #T_93ff9_row39_col16, #T_93ff9_row39_col17, #T_93ff9_row39_col18, #T_93ff9_row39_col19, #T_93ff9_row39_col20, #T_93ff9_row39_col23, #T_93ff9_row39_col29, #T_93ff9_row39_col30, #T_93ff9_row40_col0, #T_93ff9_row40_col1, #T_93ff9_row40_col2, #T_93ff9_row40_col3, #T_93ff9_row40_col4, #T_93ff9_row40_col5, #T_93ff9_row40_col6, #T_93ff9_row40_col7, #T_93ff9_row40_col8, #T_93ff9_row40_col9, #T_93ff9_row40_col10, #T_93ff9_row40_col11, #T_93ff9_row40_col12, #T_93ff9_row40_col13, #T_93ff9_row40_col14, #T_93ff9_row40_col15, #T_93ff9_row40_col16, #T_93ff9_row40_col17, #T_93ff9_row40_col18, #T_93ff9_row40_col19, #T_93ff9_row40_col20, #T_93ff9_row40_col23, #T_93ff9_row40_col29, #T_93ff9_row40_col30, #T_93ff9_row41_col0, #T_93ff9_row41_col1, #T_93ff9_row41_col2, #T_93ff9_row41_col3, #T_93ff9_row41_col4, #T_93ff9_row41_col5, #T_93ff9_row41_col6, #T_93ff9_row41_col7, #T_93ff9_row41_col8, #T_93ff9_row41_col9, #T_93ff9_row41_col10, #T_93ff9_row41_col11, #T_93ff9_row41_col12, #T_93ff9_row41_col13, #T_93ff9_row41_col14, #T_93ff9_row41_col15, #T_93ff9_row41_col16, #T_93ff9_row41_col17, #T_93ff9_row41_col18, #T_93ff9_row41_col19, #T_93ff9_row41_col20, #T_93ff9_row41_col23, #T_93ff9_row41_col29, #T_93ff9_row41_col30, #T_93ff9_row42_col0, #T_93ff9_row42_col1, #T_93ff9_row42_col2, #T_93ff9_row42_col3, #T_93ff9_row42_col4, #T_93ff9_row42_col5, #T_93ff9_row42_col6, #T_93ff9_row42_col7, #T_93ff9_row42_col8, #T_93ff9_row42_col9, #T_93ff9_row42_col10, #T_93ff9_row42_col11, #T_93ff9_row42_col12, #T_93ff9_row42_col13, #T_93ff9_row42_col14, #T_93ff9_row42_col15, #T_93ff9_row42_col16, #T_93ff9_row42_col17, #T_93ff9_row42_col18, #T_93ff9_row42_col19, #T_93ff9_row42_col20, #T_93ff9_row42_col23, #T_93ff9_row42_col29, #T_93ff9_row42_col30, #T_93ff9_row43_col0, #T_93ff9_row43_col1, #T_93ff9_row43_col2, #T_93ff9_row43_col3, #T_93ff9_row43_col4, #T_93ff9_row43_col5, #T_93ff9_row43_col6, #T_93ff9_row43_col7, #T_93ff9_row43_col8, #T_93ff9_row43_col9, #T_93ff9_row43_col10, #T_93ff9_row43_col11, #T_93ff9_row43_col12, #T_93ff9_row43_col13, #T_93ff9_row43_col14, #T_93ff9_row43_col15, #T_93ff9_row43_col16, #T_93ff9_row43_col17, #T_93ff9_row43_col18, #T_93ff9_row43_col19, #T_93ff9_row43_col20, #T_93ff9_row43_col23, #T_93ff9_row43_col29, #T_93ff9_row43_col30, #T_93ff9_row44_col0, #T_93ff9_row44_col1, #T_93ff9_row44_col2, #T_93ff9_row44_col3, #T_93ff9_row44_col4, #T_93ff9_row44_col5, #T_93ff9_row44_col6, #T_93ff9_row44_col7, #T_93ff9_row44_col8, #T_93ff9_row44_col9, #T_93ff9_row44_col10, #T_93ff9_row44_col11, #T_93ff9_row44_col12, #T_93ff9_row44_col13, #T_93ff9_row44_col14, #T_93ff9_row44_col15, #T_93ff9_row44_col16, #T_93ff9_row44_col17, #T_93ff9_row44_col18, #T_93ff9_row44_col19, #T_93ff9_row44_col20, #T_93ff9_row44_col23, #T_93ff9_row44_col29, #T_93ff9_row44_col30, #T_93ff9_row45_col0, #T_93ff9_row45_col1, #T_93ff9_row45_col2, #T_93ff9_row45_col3, #T_93ff9_row45_col4, #T_93ff9_row45_col5, #T_93ff9_row45_col6, #T_93ff9_row45_col7, #T_93ff9_row45_col8, #T_93ff9_row45_col9, #T_93ff9_row45_col10, #T_93ff9_row45_col11, #T_93ff9_row45_col12, #T_93ff9_row45_col13, #T_93ff9_row45_col14, #T_93ff9_row45_col15, #T_93ff9_row45_col16, #T_93ff9_row45_col17, #T_93ff9_row45_col18, #T_93ff9_row45_col19, #T_93ff9_row45_col20, #T_93ff9_row45_col23, #T_93ff9_row45_col29, #T_93ff9_row45_col30, #T_93ff9_row46_col0, #T_93ff9_row46_col1, #T_93ff9_row46_col2, #T_93ff9_row46_col3, #T_93ff9_row46_col4, #T_93ff9_row46_col5, #T_93ff9_row46_col6, #T_93ff9_row46_col7, #T_93ff9_row46_col8, #T_93ff9_row46_col9, #T_93ff9_row46_col10, #T_93ff9_row46_col11, #T_93ff9_row46_col12, #T_93ff9_row46_col13, #T_93ff9_row46_col14, #T_93ff9_row46_col15, #T_93ff9_row46_col16, #T_93ff9_row46_col17, #T_93ff9_row46_col18, #T_93ff9_row46_col19, #T_93ff9_row46_col20, #T_93ff9_row46_col23, #T_93ff9_row46_col29, #T_93ff9_row46_col30, #T_93ff9_row47_col0, #T_93ff9_row47_col1, #T_93ff9_row47_col2, #T_93ff9_row47_col3, #T_93ff9_row47_col4, #T_93ff9_row47_col5, #T_93ff9_row47_col6, #T_93ff9_row47_col7, #T_93ff9_row47_col8, #T_93ff9_row47_col9, #T_93ff9_row47_col10, #T_93ff9_row47_col11, #T_93ff9_row47_col12, #T_93ff9_row47_col13, #T_93ff9_row47_col14, #T_93ff9_row47_col15, #T_93ff9_row47_col16, #T_93ff9_row47_col17, #T_93ff9_row47_col18, #T_93ff9_row47_col19, #T_93ff9_row47_col20, #T_93ff9_row47_col23, #T_93ff9_row47_col29, #T_93ff9_row47_col30, #T_93ff9_row48_col0, #T_93ff9_row48_col1, #T_93ff9_row48_col2, #T_93ff9_row48_col3, #T_93ff9_row48_col4, #T_93ff9_row48_col5, #T_93ff9_row48_col6, #T_93ff9_row48_col7, #T_93ff9_row48_col8, #T_93ff9_row48_col9, #T_93ff9_row48_col10, #T_93ff9_row48_col11, #T_93ff9_row48_col12, #T_93ff9_row48_col13, #T_93ff9_row48_col14, #T_93ff9_row48_col15, #T_93ff9_row48_col16, #T_93ff9_row48_col17, #T_93ff9_row48_col18, #T_93ff9_row48_col19, #T_93ff9_row48_col20, #T_93ff9_row48_col23, #T_93ff9_row48_col29, #T_93ff9_row48_col30, #T_93ff9_row49_col0, #T_93ff9_row49_col1, #T_93ff9_row49_col2, #T_93ff9_row49_col3, #T_93ff9_row49_col4, #T_93ff9_row49_col5, #T_93ff9_row49_col6, #T_93ff9_row49_col7, #T_93ff9_row49_col8, #T_93ff9_row49_col9, #T_93ff9_row49_col10, #T_93ff9_row49_col11, #T_93ff9_row49_col12, #T_93ff9_row49_col13, #T_93ff9_row49_col14, #T_93ff9_row49_col15, #T_93ff9_row49_col16, #T_93ff9_row49_col17, #T_93ff9_row49_col18, #T_93ff9_row49_col19, #T_93ff9_row49_col20, #T_93ff9_row49_col23, #T_93ff9_row49_col29, #T_93ff9_row49_col30, #T_93ff9_row50_col0, #T_93ff9_row50_col1, #T_93ff9_row50_col2, #T_93ff9_row50_col3, #T_93ff9_row50_col4, #T_93ff9_row50_col5, #T_93ff9_row50_col6, #T_93ff9_row50_col7, #T_93ff9_row50_col8, #T_93ff9_row50_col10, #T_93ff9_row50_col11, #T_93ff9_row50_col12, #T_93ff9_row50_col13, #T_93ff9_row50_col14, #T_93ff9_row50_col15, #T_93ff9_row50_col16, #T_93ff9_row50_col17, #T_93ff9_row50_col18, #T_93ff9_row50_col19, #T_93ff9_row50_col20, #T_93ff9_row50_col23, #T_93ff9_row50_col29, #T_93ff9_row50_col30, #T_93ff9_row51_col0, #T_93ff9_row51_col1, #T_93ff9_row51_col2, #T_93ff9_row51_col3, #T_93ff9_row51_col4, #T_93ff9_row51_col5, #T_93ff9_row51_col6, #T_93ff9_row51_col7, #T_93ff9_row51_col8, #T_93ff9_row51_col9, #T_93ff9_row51_col10, #T_93ff9_row51_col11, #T_93ff9_row51_col12, #T_93ff9_row51_col13, #T_93ff9_row51_col14, #T_93ff9_row51_col15, #T_93ff9_row51_col16, #T_93ff9_row51_col17, #T_93ff9_row51_col18, #T_93ff9_row51_col19, #T_93ff9_row51_col20, #T_93ff9_row51_col23, #T_93ff9_row51_col29, #T_93ff9_row51_col30, #T_93ff9_row52_col0, #T_93ff9_row52_col1, #T_93ff9_row52_col2, #T_93ff9_row52_col3, #T_93ff9_row52_col4, #T_93ff9_row52_col5, #T_93ff9_row52_col6, #T_93ff9_row52_col7, #T_93ff9_row52_col12, #T_93ff9_row52_col13, #T_93ff9_row52_col14, #T_93ff9_row52_col15, #T_93ff9_row52_col16, #T_93ff9_row52_col17, #T_93ff9_row52_col18, #T_93ff9_row52_col19, #T_93ff9_row52_col20, #T_93ff9_row52_col23, #T_93ff9_row52_col29, #T_93ff9_row52_col30, #T_93ff9_row53_col0, #T_93ff9_row53_col1, #T_93ff9_row53_col2, #T_93ff9_row53_col3, #T_93ff9_row53_col4, #T_93ff9_row53_col5, #T_93ff9_row53_col6, #T_93ff9_row53_col7, #T_93ff9_row53_col8, #T_93ff9_row53_col9, #T_93ff9_row53_col10, #T_93ff9_row53_col11, #T_93ff9_row53_col12, #T_93ff9_row53_col13, #T_93ff9_row53_col14, #T_93ff9_row53_col15, #T_93ff9_row53_col16, #T_93ff9_row53_col17, #T_93ff9_row53_col18, #T_93ff9_row53_col19, #T_93ff9_row53_col20, #T_93ff9_row53_col23, #T_93ff9_row53_col29, #T_93ff9_row53_col30, #T_93ff9_row54_col0, #T_93ff9_row54_col1, #T_93ff9_row54_col2, #T_93ff9_row54_col3, #T_93ff9_row54_col4, #T_93ff9_row54_col5, #T_93ff9_row54_col6, #T_93ff9_row54_col7, #T_93ff9_row54_col12, #T_93ff9_row54_col13, #T_93ff9_row54_col14, #T_93ff9_row54_col15, #T_93ff9_row54_col16, #T_93ff9_row54_col17, #T_93ff9_row54_col18, #T_93ff9_row54_col19, #T_93ff9_row54_col20, #T_93ff9_row54_col23, #T_93ff9_row54_col29, #T_93ff9_row54_col30, #T_93ff9_row55_col0, #T_93ff9_row55_col1, #T_93ff9_row55_col2, #T_93ff9_row55_col3, #T_93ff9_row55_col4, #T_93ff9_row55_col5, #T_93ff9_row55_col6, #T_93ff9_row55_col7, #T_93ff9_row55_col8, #T_93ff9_row55_col9, #T_93ff9_row55_col10, #T_93ff9_row55_col11, #T_93ff9_row55_col12, #T_93ff9_row55_col13, #T_93ff9_row55_col14, #T_93ff9_row55_col15, #T_93ff9_row55_col16, #T_93ff9_row55_col17, #T_93ff9_row55_col18, #T_93ff9_row55_col19, #T_93ff9_row55_col20, #T_93ff9_row55_col23, #T_93ff9_row55_col29, #T_93ff9_row55_col30, #T_93ff9_row56_col0, #T_93ff9_row56_col1, #T_93ff9_row56_col2, #T_93ff9_row56_col3, #T_93ff9_row56_col4, #T_93ff9_row56_col5, #T_93ff9_row56_col6, #T_93ff9_row56_col7, #T_93ff9_row56_col12, #T_93ff9_row56_col13, #T_93ff9_row56_col14, #T_93ff9_row56_col15, #T_93ff9_row56_col16, #T_93ff9_row56_col17, #T_93ff9_row56_col18, #T_93ff9_row56_col19, #T_93ff9_row56_col20, #T_93ff9_row56_col23, #T_93ff9_row56_col29, #T_93ff9_row56_col30, #T_93ff9_row57_col0, #T_93ff9_row57_col1, #T_93ff9_row57_col2, #T_93ff9_row57_col3, #T_93ff9_row57_col4, #T_93ff9_row57_col5, #T_93ff9_row57_col6, #T_93ff9_row57_col7, #T_93ff9_row57_col12, #T_93ff9_row57_col13, #T_93ff9_row57_col14, #T_93ff9_row57_col15, #T_93ff9_row57_col16, #T_93ff9_row57_col17, #T_93ff9_row57_col18, #T_93ff9_row57_col19, #T_93ff9_row57_col20, #T_93ff9_row57_col23, #T_93ff9_row57_col29, #T_93ff9_row57_col30 {\n",
       "  background-color: #800000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row50_col9 {\n",
       "  background-color: #820000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row52_col8 {\n",
       "  background-color: #0000e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row52_col9 {\n",
       "  background-color: #2121ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row52_col10 {\n",
       "  background-color: #0000e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row52_col11 {\n",
       "  background-color: #00004c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row54_col8, #T_93ff9_row54_col11, #T_93ff9_row56_col8, #T_93ff9_row56_col9, #T_93ff9_row56_col10 {\n",
       "  background-color: #860000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row54_col9, #T_93ff9_row54_col10, #T_93ff9_row56_col11 {\n",
       "  background-color: #840000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row57_col8 {\n",
       "  background-color: #8e0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row57_col9, #T_93ff9_row57_col10 {\n",
       "  background-color: #8c0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93ff9_row57_col11 {\n",
       "  background-color: #900000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_93ff9\">\n",
       "  <caption>Ax results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_93ff9_level0_col0\" class=\"col_heading level0 col0\" >acc/oos</th>\n",
       "      <th id=\"T_93ff9_level0_col1\" class=\"col_heading level0 col1\" >acc/rnd</th>\n",
       "      <th id=\"T_93ff9_level0_col2\" class=\"col_heading level0 col2\" >acc/test</th>\n",
       "      <th id=\"T_93ff9_level0_col3\" class=\"col_heading level0 col3\" >acc/train</th>\n",
       "      <th id=\"T_93ff9_level0_col4\" class=\"col_heading level0 col4\" >acc_gain_vs_ref/oos</th>\n",
       "      <th id=\"T_93ff9_level0_col5\" class=\"col_heading level0 col5\" >acc_gain_vs_ref/rnd</th>\n",
       "      <th id=\"T_93ff9_level0_col6\" class=\"col_heading level0 col6\" >acc_gain_vs_ref/test</th>\n",
       "      <th id=\"T_93ff9_level0_col7\" class=\"col_heading level0 col7\" >acc_gain_vs_ref/train</th>\n",
       "      <th id=\"T_93ff9_level0_col8\" class=\"col_heading level0 col8\" >perplexity_gain_vs_ref/oos</th>\n",
       "      <th id=\"T_93ff9_level0_col9\" class=\"col_heading level0 col9\" >perplexity_gain_vs_ref/rnd</th>\n",
       "      <th id=\"T_93ff9_level0_col10\" class=\"col_heading level0 col10\" >perplexity_gain_vs_ref/test</th>\n",
       "      <th id=\"T_93ff9_level0_col11\" class=\"col_heading level0 col11\" >perplexity_gain_vs_ref/train</th>\n",
       "      <th id=\"T_93ff9_level0_col12\" class=\"col_heading level0 col12\" >preference_logp_gain/oos</th>\n",
       "      <th id=\"T_93ff9_level0_col13\" class=\"col_heading level0 col13\" >preference_logp_gain/rnd</th>\n",
       "      <th id=\"T_93ff9_level0_col14\" class=\"col_heading level0 col14\" >preference_logp_gain/test</th>\n",
       "      <th id=\"T_93ff9_level0_col15\" class=\"col_heading level0 col15\" >preference_logp_gain/train</th>\n",
       "      <th id=\"T_93ff9_level0_col16\" class=\"col_heading level0 col16\" >preference_logp_gain_vs_ref/oos</th>\n",
       "      <th id=\"T_93ff9_level0_col17\" class=\"col_heading level0 col17\" >preference_logp_gain_vs_ref/rnd</th>\n",
       "      <th id=\"T_93ff9_level0_col18\" class=\"col_heading level0 col18\" >preference_logp_gain_vs_ref/test</th>\n",
       "      <th id=\"T_93ff9_level0_col19\" class=\"col_heading level0 col19\" >preference_logp_gain_vs_ref/train</th>\n",
       "      <th id=\"T_93ff9_level0_col20\" class=\"col_heading level0 col20\" >lr</th>\n",
       "      <th id=\"T_93ff9_level0_col21\" class=\"col_heading level0 col21\" >collect_input</th>\n",
       "      <th id=\"T_93ff9_level0_col22\" class=\"col_heading level0 col22\" >collect_hs</th>\n",
       "      <th id=\"T_93ff9_level0_col23\" class=\"col_heading level0 col23\" >loss.β</th>\n",
       "      <th id=\"T_93ff9_level0_col24\" class=\"col_heading level0 col24\" >loss.use_dpo_loss</th>\n",
       "      <th id=\"T_93ff9_level0_col25\" class=\"col_heading level0 col25\" >loss.use_nll_loss</th>\n",
       "      <th id=\"T_93ff9_level0_col26\" class=\"col_heading level0 col26\" >loss.use_angle_loss</th>\n",
       "      <th id=\"T_93ff9_level0_col27\" class=\"col_heading level0 col27\" >loss.weight_tokens</th>\n",
       "      <th id=\"T_93ff9_level0_col28\" class=\"col_heading level0 col28\" >loss.use_orth_loss</th>\n",
       "      <th id=\"T_93ff9_level0_col29\" class=\"col_heading level0 col29\" >transform.nb</th>\n",
       "      <th id=\"T_93ff9_level0_col30\" class=\"col_heading level0 col30\" >transform.reduction</th>\n",
       "      <th id=\"T_93ff9_level0_col31\" class=\"col_heading level0 col31\" >transform.Htype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row0\" class=\"row_heading level0 row0\" >48</th>\n",
       "      <td id=\"T_93ff9_row0_col0\" class=\"data row0 col0\" >0.744000</td>\n",
       "      <td id=\"T_93ff9_row0_col1\" class=\"data row0 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row0_col2\" class=\"data row0 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row0_col4\" class=\"data row0 col4\" >1.113772</td>\n",
       "      <td id=\"T_93ff9_row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row0_col6\" class=\"data row0 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row0_col7\" class=\"data row0 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row0_col8\" class=\"data row0 col8\" >1.049971</td>\n",
       "      <td id=\"T_93ff9_row0_col9\" class=\"data row0 col9\" >1.356395</td>\n",
       "      <td id=\"T_93ff9_row0_col10\" class=\"data row0 col10\" >1.162667</td>\n",
       "      <td id=\"T_93ff9_row0_col11\" class=\"data row0 col11\" >1.170551</td>\n",
       "      <td id=\"T_93ff9_row0_col12\" class=\"data row0 col12\" >16.725189</td>\n",
       "      <td id=\"T_93ff9_row0_col13\" class=\"data row0 col13\" >16.179222</td>\n",
       "      <td id=\"T_93ff9_row0_col14\" class=\"data row0 col14\" >42.420944</td>\n",
       "      <td id=\"T_93ff9_row0_col15\" class=\"data row0 col15\" >42.461075</td>\n",
       "      <td id=\"T_93ff9_row0_col16\" class=\"data row0 col16\" >6.188190</td>\n",
       "      <td id=\"T_93ff9_row0_col17\" class=\"data row0 col17\" >2.693804</td>\n",
       "      <td id=\"T_93ff9_row0_col18\" class=\"data row0 col18\" >5.405641</td>\n",
       "      <td id=\"T_93ff9_row0_col19\" class=\"data row0 col19\" >6.314675</td>\n",
       "      <td id=\"T_93ff9_row0_col20\" class=\"data row0 col20\" >0.000403</td>\n",
       "      <td id=\"T_93ff9_row0_col21\" class=\"data row0 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row0_col22\" class=\"data row0 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row0_col23\" class=\"data row0 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row0_col24\" class=\"data row0 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row0_col25\" class=\"data row0 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row0_col26\" class=\"data row0 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row0_col27\" class=\"data row0 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row0_col28\" class=\"data row0 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row0_col29\" class=\"data row0 col29\" >6</td>\n",
       "      <td id=\"T_93ff9_row0_col30\" class=\"data row0 col30\" >60</td>\n",
       "      <td id=\"T_93ff9_row0_col31\" class=\"data row0 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row1\" class=\"row_heading level0 row1\" >54</th>\n",
       "      <td id=\"T_93ff9_row1_col0\" class=\"data row1 col0\" >0.742667</td>\n",
       "      <td id=\"T_93ff9_row1_col1\" class=\"data row1 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row1_col2\" class=\"data row1 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row1_col4\" class=\"data row1 col4\" >1.111776</td>\n",
       "      <td id=\"T_93ff9_row1_col5\" class=\"data row1 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row1_col8\" class=\"data row1 col8\" >1.058746</td>\n",
       "      <td id=\"T_93ff9_row1_col9\" class=\"data row1 col9\" >1.366543</td>\n",
       "      <td id=\"T_93ff9_row1_col10\" class=\"data row1 col10\" >1.177389</td>\n",
       "      <td id=\"T_93ff9_row1_col11\" class=\"data row1 col11\" >1.189223</td>\n",
       "      <td id=\"T_93ff9_row1_col12\" class=\"data row1 col12\" >16.856361</td>\n",
       "      <td id=\"T_93ff9_row1_col13\" class=\"data row1 col13\" >16.306145</td>\n",
       "      <td id=\"T_93ff9_row1_col14\" class=\"data row1 col14\" >42.506218</td>\n",
       "      <td id=\"T_93ff9_row1_col15\" class=\"data row1 col15\" >42.645554</td>\n",
       "      <td id=\"T_93ff9_row1_col16\" class=\"data row1 col16\" >6.310843</td>\n",
       "      <td id=\"T_93ff9_row1_col17\" class=\"data row1 col17\" >2.820724</td>\n",
       "      <td id=\"T_93ff9_row1_col18\" class=\"data row1 col18\" >5.490918</td>\n",
       "      <td id=\"T_93ff9_row1_col19\" class=\"data row1 col19\" >6.499156</td>\n",
       "      <td id=\"T_93ff9_row1_col20\" class=\"data row1 col20\" >0.000408</td>\n",
       "      <td id=\"T_93ff9_row1_col21\" class=\"data row1 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row1_col22\" class=\"data row1 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row1_col23\" class=\"data row1 col23\" >0.000012</td>\n",
       "      <td id=\"T_93ff9_row1_col24\" class=\"data row1 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row1_col25\" class=\"data row1 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row1_col26\" class=\"data row1 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row1_col27\" class=\"data row1 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row1_col28\" class=\"data row1 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row1_col29\" class=\"data row1 col29\" >9</td>\n",
       "      <td id=\"T_93ff9_row1_col30\" class=\"data row1 col30\" >57</td>\n",
       "      <td id=\"T_93ff9_row1_col31\" class=\"data row1 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row2\" class=\"row_heading level0 row2\" >45</th>\n",
       "      <td id=\"T_93ff9_row2_col0\" class=\"data row2 col0\" >0.741333</td>\n",
       "      <td id=\"T_93ff9_row2_col1\" class=\"data row2 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row2_col2\" class=\"data row2 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row2_col4\" class=\"data row2 col4\" >1.109780</td>\n",
       "      <td id=\"T_93ff9_row2_col5\" class=\"data row2 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row2_col6\" class=\"data row2 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row2_col7\" class=\"data row2 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row2_col8\" class=\"data row2 col8\" >1.075222</td>\n",
       "      <td id=\"T_93ff9_row2_col9\" class=\"data row2 col9\" >1.406664</td>\n",
       "      <td id=\"T_93ff9_row2_col10\" class=\"data row2 col10\" >1.199246</td>\n",
       "      <td id=\"T_93ff9_row2_col11\" class=\"data row2 col11\" >1.210066</td>\n",
       "      <td id=\"T_93ff9_row2_col12\" class=\"data row2 col12\" >16.893654</td>\n",
       "      <td id=\"T_93ff9_row2_col13\" class=\"data row2 col13\" >16.469284</td>\n",
       "      <td id=\"T_93ff9_row2_col14\" class=\"data row2 col14\" >42.735207</td>\n",
       "      <td id=\"T_93ff9_row2_col15\" class=\"data row2 col15\" >42.760590</td>\n",
       "      <td id=\"T_93ff9_row2_col16\" class=\"data row2 col16\" >6.362766</td>\n",
       "      <td id=\"T_93ff9_row2_col17\" class=\"data row2 col17\" >2.983863</td>\n",
       "      <td id=\"T_93ff9_row2_col18\" class=\"data row2 col18\" >5.719899</td>\n",
       "      <td id=\"T_93ff9_row2_col19\" class=\"data row2 col19\" >6.614193</td>\n",
       "      <td id=\"T_93ff9_row2_col20\" class=\"data row2 col20\" >0.000416</td>\n",
       "      <td id=\"T_93ff9_row2_col21\" class=\"data row2 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row2_col22\" class=\"data row2 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row2_col23\" class=\"data row2 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row2_col24\" class=\"data row2 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row2_col25\" class=\"data row2 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row2_col26\" class=\"data row2 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row2_col27\" class=\"data row2 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row2_col28\" class=\"data row2 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row2_col29\" class=\"data row2 col29\" >5</td>\n",
       "      <td id=\"T_93ff9_row2_col30\" class=\"data row2 col30\" >56</td>\n",
       "      <td id=\"T_93ff9_row2_col31\" class=\"data row2 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row3\" class=\"row_heading level0 row3\" >53</th>\n",
       "      <td id=\"T_93ff9_row3_col0\" class=\"data row3 col0\" >0.741333</td>\n",
       "      <td id=\"T_93ff9_row3_col1\" class=\"data row3 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row3_col2\" class=\"data row3 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row3_col4\" class=\"data row3 col4\" >1.109780</td>\n",
       "      <td id=\"T_93ff9_row3_col5\" class=\"data row3 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row3_col6\" class=\"data row3 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row3_col7\" class=\"data row3 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row3_col8\" class=\"data row3 col8\" >1.106522</td>\n",
       "      <td id=\"T_93ff9_row3_col9\" class=\"data row3 col9\" >1.480148</td>\n",
       "      <td id=\"T_93ff9_row3_col10\" class=\"data row3 col10\" >1.232965</td>\n",
       "      <td id=\"T_93ff9_row3_col11\" class=\"data row3 col11\" >1.255576</td>\n",
       "      <td id=\"T_93ff9_row3_col12\" class=\"data row3 col12\" >17.095062</td>\n",
       "      <td id=\"T_93ff9_row3_col13\" class=\"data row3 col13\" >16.676277</td>\n",
       "      <td id=\"T_93ff9_row3_col14\" class=\"data row3 col14\" >43.281715</td>\n",
       "      <td id=\"T_93ff9_row3_col15\" class=\"data row3 col15\" >43.346733</td>\n",
       "      <td id=\"T_93ff9_row3_col16\" class=\"data row3 col16\" >6.584310</td>\n",
       "      <td id=\"T_93ff9_row3_col17\" class=\"data row3 col17\" >3.190855</td>\n",
       "      <td id=\"T_93ff9_row3_col18\" class=\"data row3 col18\" >6.266418</td>\n",
       "      <td id=\"T_93ff9_row3_col19\" class=\"data row3 col19\" >7.200348</td>\n",
       "      <td id=\"T_93ff9_row3_col20\" class=\"data row3 col20\" >0.000426</td>\n",
       "      <td id=\"T_93ff9_row3_col21\" class=\"data row3 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row3_col22\" class=\"data row3 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row3_col23\" class=\"data row3 col23\" >0.000053</td>\n",
       "      <td id=\"T_93ff9_row3_col24\" class=\"data row3 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row3_col25\" class=\"data row3 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row3_col26\" class=\"data row3 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row3_col27\" class=\"data row3 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row3_col28\" class=\"data row3 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row3_col29\" class=\"data row3 col29\" >3</td>\n",
       "      <td id=\"T_93ff9_row3_col30\" class=\"data row3 col30\" >55</td>\n",
       "      <td id=\"T_93ff9_row3_col31\" class=\"data row3 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row4\" class=\"row_heading level0 row4\" >52</th>\n",
       "      <td id=\"T_93ff9_row4_col0\" class=\"data row4 col0\" >0.741333</td>\n",
       "      <td id=\"T_93ff9_row4_col1\" class=\"data row4 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row4_col2\" class=\"data row4 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row4_col4\" class=\"data row4 col4\" >1.109780</td>\n",
       "      <td id=\"T_93ff9_row4_col5\" class=\"data row4 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row4_col7\" class=\"data row4 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row4_col8\" class=\"data row4 col8\" >1.056137</td>\n",
       "      <td id=\"T_93ff9_row4_col9\" class=\"data row4 col9\" >1.383910</td>\n",
       "      <td id=\"T_93ff9_row4_col10\" class=\"data row4 col10\" >1.180059</td>\n",
       "      <td id=\"T_93ff9_row4_col11\" class=\"data row4 col11\" >1.185950</td>\n",
       "      <td id=\"T_93ff9_row4_col12\" class=\"data row4 col12\" >16.813591</td>\n",
       "      <td id=\"T_93ff9_row4_col13\" class=\"data row4 col13\" >16.150200</td>\n",
       "      <td id=\"T_93ff9_row4_col14\" class=\"data row4 col14\" >42.501968</td>\n",
       "      <td id=\"T_93ff9_row4_col15\" class=\"data row4 col15\" >42.587128</td>\n",
       "      <td id=\"T_93ff9_row4_col16\" class=\"data row4 col16\" >6.273644</td>\n",
       "      <td id=\"T_93ff9_row4_col17\" class=\"data row4 col17\" >2.664779</td>\n",
       "      <td id=\"T_93ff9_row4_col18\" class=\"data row4 col18\" >5.486655</td>\n",
       "      <td id=\"T_93ff9_row4_col19\" class=\"data row4 col19\" >6.440735</td>\n",
       "      <td id=\"T_93ff9_row4_col20\" class=\"data row4 col20\" >0.000407</td>\n",
       "      <td id=\"T_93ff9_row4_col21\" class=\"data row4 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row4_col22\" class=\"data row4 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row4_col23\" class=\"data row4 col23\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row4_col24\" class=\"data row4 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row4_col25\" class=\"data row4 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row4_col26\" class=\"data row4 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row4_col27\" class=\"data row4 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row4_col28\" class=\"data row4 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row4_col29\" class=\"data row4 col29\" >16</td>\n",
       "      <td id=\"T_93ff9_row4_col30\" class=\"data row4 col30\" >61</td>\n",
       "      <td id=\"T_93ff9_row4_col31\" class=\"data row4 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row5\" class=\"row_heading level0 row5\" >49</th>\n",
       "      <td id=\"T_93ff9_row5_col0\" class=\"data row5 col0\" >0.740000</td>\n",
       "      <td id=\"T_93ff9_row5_col1\" class=\"data row5 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row5_col2\" class=\"data row5 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row5_col3\" class=\"data row5 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row5_col4\" class=\"data row5 col4\" >1.107784</td>\n",
       "      <td id=\"T_93ff9_row5_col5\" class=\"data row5 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row5_col6\" class=\"data row5 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row5_col7\" class=\"data row5 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row5_col8\" class=\"data row5 col8\" >1.077529</td>\n",
       "      <td id=\"T_93ff9_row5_col9\" class=\"data row5 col9\" >1.424350</td>\n",
       "      <td id=\"T_93ff9_row5_col10\" class=\"data row5 col10\" >1.201568</td>\n",
       "      <td id=\"T_93ff9_row5_col11\" class=\"data row5 col11\" >1.218279</td>\n",
       "      <td id=\"T_93ff9_row5_col12\" class=\"data row5 col12\" >16.936951</td>\n",
       "      <td id=\"T_93ff9_row5_col13\" class=\"data row5 col13\" >16.562836</td>\n",
       "      <td id=\"T_93ff9_row5_col14\" class=\"data row5 col14\" >42.871269</td>\n",
       "      <td id=\"T_93ff9_row5_col15\" class=\"data row5 col15\" >42.801796</td>\n",
       "      <td id=\"T_93ff9_row5_col16\" class=\"data row5 col16\" >6.414001</td>\n",
       "      <td id=\"T_93ff9_row5_col17\" class=\"data row5 col17\" >3.077415</td>\n",
       "      <td id=\"T_93ff9_row5_col18\" class=\"data row5 col18\" >5.855974</td>\n",
       "      <td id=\"T_93ff9_row5_col19\" class=\"data row5 col19\" >6.655408</td>\n",
       "      <td id=\"T_93ff9_row5_col20\" class=\"data row5 col20\" >0.000417</td>\n",
       "      <td id=\"T_93ff9_row5_col21\" class=\"data row5 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row5_col22\" class=\"data row5 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row5_col23\" class=\"data row5 col23\" >0.000003</td>\n",
       "      <td id=\"T_93ff9_row5_col24\" class=\"data row5 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row5_col25\" class=\"data row5 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row5_col26\" class=\"data row5 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row5_col27\" class=\"data row5 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row5_col28\" class=\"data row5 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row5_col29\" class=\"data row5 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row5_col30\" class=\"data row5 col30\" >63</td>\n",
       "      <td id=\"T_93ff9_row5_col31\" class=\"data row5 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row6\" class=\"row_heading level0 row6\" >46</th>\n",
       "      <td id=\"T_93ff9_row6_col0\" class=\"data row6 col0\" >0.738667</td>\n",
       "      <td id=\"T_93ff9_row6_col1\" class=\"data row6 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row6_col2\" class=\"data row6 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row6_col4\" class=\"data row6 col4\" >1.105788</td>\n",
       "      <td id=\"T_93ff9_row6_col5\" class=\"data row6 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row6_col6\" class=\"data row6 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row6_col7\" class=\"data row6 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row6_col8\" class=\"data row6 col8\" >1.063996</td>\n",
       "      <td id=\"T_93ff9_row6_col9\" class=\"data row6 col9\" >1.380798</td>\n",
       "      <td id=\"T_93ff9_row6_col10\" class=\"data row6 col10\" >1.183572</td>\n",
       "      <td id=\"T_93ff9_row6_col11\" class=\"data row6 col11\" >1.194358</td>\n",
       "      <td id=\"T_93ff9_row6_col12\" class=\"data row6 col12\" >16.835587</td>\n",
       "      <td id=\"T_93ff9_row6_col13\" class=\"data row6 col13\" >16.362389</td>\n",
       "      <td id=\"T_93ff9_row6_col14\" class=\"data row6 col14\" >42.539574</td>\n",
       "      <td id=\"T_93ff9_row6_col15\" class=\"data row6 col15\" >42.602707</td>\n",
       "      <td id=\"T_93ff9_row6_col16\" class=\"data row6 col16\" >6.299283</td>\n",
       "      <td id=\"T_93ff9_row6_col17\" class=\"data row6 col17\" >2.876973</td>\n",
       "      <td id=\"T_93ff9_row6_col18\" class=\"data row6 col18\" >5.524270</td>\n",
       "      <td id=\"T_93ff9_row6_col19\" class=\"data row6 col19\" >6.456314</td>\n",
       "      <td id=\"T_93ff9_row6_col20\" class=\"data row6 col20\" >0.000411</td>\n",
       "      <td id=\"T_93ff9_row6_col21\" class=\"data row6 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row6_col22\" class=\"data row6 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row6_col23\" class=\"data row6 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row6_col24\" class=\"data row6 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row6_col25\" class=\"data row6 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row6_col26\" class=\"data row6 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row6_col27\" class=\"data row6 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row6_col28\" class=\"data row6 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row6_col29\" class=\"data row6 col29\" >10</td>\n",
       "      <td id=\"T_93ff9_row6_col30\" class=\"data row6 col30\" >57</td>\n",
       "      <td id=\"T_93ff9_row6_col31\" class=\"data row6 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row7\" class=\"row_heading level0 row7\" >4</th>\n",
       "      <td id=\"T_93ff9_row7_col0\" class=\"data row7 col0\" >0.737333</td>\n",
       "      <td id=\"T_93ff9_row7_col1\" class=\"data row7 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row7_col2\" class=\"data row7 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row7_col3\" class=\"data row7 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row7_col4\" class=\"data row7 col4\" >1.103792</td>\n",
       "      <td id=\"T_93ff9_row7_col5\" class=\"data row7 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row7_col6\" class=\"data row7 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row7_col8\" class=\"data row7 col8\" >0.999670</td>\n",
       "      <td id=\"T_93ff9_row7_col9\" class=\"data row7 col9\" >1.272706</td>\n",
       "      <td id=\"T_93ff9_row7_col10\" class=\"data row7 col10\" >1.080832</td>\n",
       "      <td id=\"T_93ff9_row7_col11\" class=\"data row7 col11\" >1.083640</td>\n",
       "      <td id=\"T_93ff9_row7_col12\" class=\"data row7 col12\" >16.215950</td>\n",
       "      <td id=\"T_93ff9_row7_col13\" class=\"data row7 col13\" >15.622299</td>\n",
       "      <td id=\"T_93ff9_row7_col14\" class=\"data row7 col14\" >41.564690</td>\n",
       "      <td id=\"T_93ff9_row7_col15\" class=\"data row7 col15\" >41.762199</td>\n",
       "      <td id=\"T_93ff9_row7_col16\" class=\"data row7 col16\" >5.636047</td>\n",
       "      <td id=\"T_93ff9_row7_col17\" class=\"data row7 col17\" >2.136883</td>\n",
       "      <td id=\"T_93ff9_row7_col18\" class=\"data row7 col18\" >4.549378</td>\n",
       "      <td id=\"T_93ff9_row7_col19\" class=\"data row7 col19\" >5.615801</td>\n",
       "      <td id=\"T_93ff9_row7_col20\" class=\"data row7 col20\" >0.000358</td>\n",
       "      <td id=\"T_93ff9_row7_col21\" class=\"data row7 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row7_col22\" class=\"data row7 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row7_col23\" class=\"data row7 col23\" >0.000013</td>\n",
       "      <td id=\"T_93ff9_row7_col24\" class=\"data row7 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row7_col25\" class=\"data row7 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row7_col26\" class=\"data row7 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row7_col27\" class=\"data row7 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row7_col28\" class=\"data row7 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row7_col29\" class=\"data row7 col29\" >38</td>\n",
       "      <td id=\"T_93ff9_row7_col30\" class=\"data row7 col30\" >75</td>\n",
       "      <td id=\"T_93ff9_row7_col31\" class=\"data row7 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row8\" class=\"row_heading level0 row8\" >50</th>\n",
       "      <td id=\"T_93ff9_row8_col0\" class=\"data row8 col0\" >0.737333</td>\n",
       "      <td id=\"T_93ff9_row8_col1\" class=\"data row8 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row8_col2\" class=\"data row8 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row8_col3\" class=\"data row8 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row8_col4\" class=\"data row8 col4\" >1.103792</td>\n",
       "      <td id=\"T_93ff9_row8_col5\" class=\"data row8 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row8_col6\" class=\"data row8 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row8_col7\" class=\"data row8 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row8_col8\" class=\"data row8 col8\" >1.156394</td>\n",
       "      <td id=\"T_93ff9_row8_col9\" class=\"data row8 col9\" >1.593674</td>\n",
       "      <td id=\"T_93ff9_row8_col10\" class=\"data row8 col10\" >1.294931</td>\n",
       "      <td id=\"T_93ff9_row8_col11\" class=\"data row8 col11\" >1.325845</td>\n",
       "      <td id=\"T_93ff9_row8_col12\" class=\"data row8 col12\" >17.071503</td>\n",
       "      <td id=\"T_93ff9_row8_col13\" class=\"data row8 col13\" >17.086380</td>\n",
       "      <td id=\"T_93ff9_row8_col14\" class=\"data row8 col14\" >43.277275</td>\n",
       "      <td id=\"T_93ff9_row8_col15\" class=\"data row8 col15\" >43.083633</td>\n",
       "      <td id=\"T_93ff9_row8_col16\" class=\"data row8 col16\" >6.592074</td>\n",
       "      <td id=\"T_93ff9_row8_col17\" class=\"data row8 col17\" >3.600962</td>\n",
       "      <td id=\"T_93ff9_row8_col18\" class=\"data row8 col18\" >6.261967</td>\n",
       "      <td id=\"T_93ff9_row8_col19\" class=\"data row8 col19\" >6.937241</td>\n",
       "      <td id=\"T_93ff9_row8_col20\" class=\"data row8 col20\" >0.000442</td>\n",
       "      <td id=\"T_93ff9_row8_col21\" class=\"data row8 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row8_col22\" class=\"data row8 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row8_col23\" class=\"data row8 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row8_col24\" class=\"data row8 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row8_col25\" class=\"data row8 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row8_col26\" class=\"data row8 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row8_col27\" class=\"data row8 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row8_col28\" class=\"data row8 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row8_col29\" class=\"data row8 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row8_col30\" class=\"data row8 col30\" >62</td>\n",
       "      <td id=\"T_93ff9_row8_col31\" class=\"data row8 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row9\" class=\"row_heading level0 row9\" >57</th>\n",
       "      <td id=\"T_93ff9_row9_col0\" class=\"data row9 col0\" >0.733333</td>\n",
       "      <td id=\"T_93ff9_row9_col1\" class=\"data row9 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row9_col2\" class=\"data row9 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row9_col3\" class=\"data row9 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row9_col4\" class=\"data row9 col4\" >1.097804</td>\n",
       "      <td id=\"T_93ff9_row9_col5\" class=\"data row9 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row9_col6\" class=\"data row9 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row9_col7\" class=\"data row9 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row9_col8\" class=\"data row9 col8\" >1.045012</td>\n",
       "      <td id=\"T_93ff9_row9_col9\" class=\"data row9 col9\" >1.275345</td>\n",
       "      <td id=\"T_93ff9_row9_col10\" class=\"data row9 col10\" >1.123301</td>\n",
       "      <td id=\"T_93ff9_row9_col11\" class=\"data row9 col11\" >1.120911</td>\n",
       "      <td id=\"T_93ff9_row9_col12\" class=\"data row9 col12\" >16.709702</td>\n",
       "      <td id=\"T_93ff9_row9_col13\" class=\"data row9 col13\" >16.213425</td>\n",
       "      <td id=\"T_93ff9_row9_col14\" class=\"data row9 col14\" >42.831848</td>\n",
       "      <td id=\"T_93ff9_row9_col15\" class=\"data row9 col15\" >43.191765</td>\n",
       "      <td id=\"T_93ff9_row9_col16\" class=\"data row9 col16\" >6.140002</td>\n",
       "      <td id=\"T_93ff9_row9_col17\" class=\"data row9 col17\" >2.728009</td>\n",
       "      <td id=\"T_93ff9_row9_col18\" class=\"data row9 col18\" >5.816542</td>\n",
       "      <td id=\"T_93ff9_row9_col19\" class=\"data row9 col19\" >7.045368</td>\n",
       "      <td id=\"T_93ff9_row9_col20\" class=\"data row9 col20\" >0.000385</td>\n",
       "      <td id=\"T_93ff9_row9_col21\" class=\"data row9 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row9_col22\" class=\"data row9 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row9_col23\" class=\"data row9 col23\" >0.000372</td>\n",
       "      <td id=\"T_93ff9_row9_col24\" class=\"data row9 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row9_col25\" class=\"data row9 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row9_col26\" class=\"data row9 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row9_col27\" class=\"data row9 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row9_col28\" class=\"data row9 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row9_col29\" class=\"data row9 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row9_col30\" class=\"data row9 col30\" >56</td>\n",
       "      <td id=\"T_93ff9_row9_col31\" class=\"data row9 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row10\" class=\"row_heading level0 row10\" >55</th>\n",
       "      <td id=\"T_93ff9_row10_col0\" class=\"data row10 col0\" >0.733333</td>\n",
       "      <td id=\"T_93ff9_row10_col1\" class=\"data row10 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row10_col2\" class=\"data row10 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row10_col3\" class=\"data row10 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row10_col4\" class=\"data row10 col4\" >1.097804</td>\n",
       "      <td id=\"T_93ff9_row10_col5\" class=\"data row10 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row10_col6\" class=\"data row10 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row10_col7\" class=\"data row10 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row10_col8\" class=\"data row10 col8\" >1.029965</td>\n",
       "      <td id=\"T_93ff9_row10_col9\" class=\"data row10 col9\" >1.329445</td>\n",
       "      <td id=\"T_93ff9_row10_col10\" class=\"data row10 col10\" >1.142771</td>\n",
       "      <td id=\"T_93ff9_row10_col11\" class=\"data row10 col11\" >1.145378</td>\n",
       "      <td id=\"T_93ff9_row10_col12\" class=\"data row10 col12\" >16.529816</td>\n",
       "      <td id=\"T_93ff9_row10_col13\" class=\"data row10 col13\" >15.900909</td>\n",
       "      <td id=\"T_93ff9_row10_col14\" class=\"data row10 col14\" >42.063705</td>\n",
       "      <td id=\"T_93ff9_row10_col15\" class=\"data row10 col15\" >42.259010</td>\n",
       "      <td id=\"T_93ff9_row10_col16\" class=\"data row10 col16\" >5.972087</td>\n",
       "      <td id=\"T_93ff9_row10_col17\" class=\"data row10 col17\" >2.415483</td>\n",
       "      <td id=\"T_93ff9_row10_col18\" class=\"data row10 col18\" >5.048397</td>\n",
       "      <td id=\"T_93ff9_row10_col19\" class=\"data row10 col19\" >6.112614</td>\n",
       "      <td id=\"T_93ff9_row10_col20\" class=\"data row10 col20\" >0.000392</td>\n",
       "      <td id=\"T_93ff9_row10_col21\" class=\"data row10 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row10_col22\" class=\"data row10 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row10_col23\" class=\"data row10 col23\" >0.000011</td>\n",
       "      <td id=\"T_93ff9_row10_col24\" class=\"data row10 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row10_col25\" class=\"data row10 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row10_col26\" class=\"data row10 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row10_col27\" class=\"data row10 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row10_col28\" class=\"data row10 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row10_col29\" class=\"data row10 col29\" >7</td>\n",
       "      <td id=\"T_93ff9_row10_col30\" class=\"data row10 col30\" >58</td>\n",
       "      <td id=\"T_93ff9_row10_col31\" class=\"data row10 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row11\" class=\"row_heading level0 row11\" >56</th>\n",
       "      <td id=\"T_93ff9_row11_col0\" class=\"data row11 col0\" >0.725333</td>\n",
       "      <td id=\"T_93ff9_row11_col1\" class=\"data row11 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row11_col2\" class=\"data row11 col2\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row11_col3\" class=\"data row11 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row11_col4\" class=\"data row11 col4\" >1.085828</td>\n",
       "      <td id=\"T_93ff9_row11_col5\" class=\"data row11 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row11_col6\" class=\"data row11 col6\" >1.032258</td>\n",
       "      <td id=\"T_93ff9_row11_col7\" class=\"data row11 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row11_col8\" class=\"data row11 col8\" >1.294282</td>\n",
       "      <td id=\"T_93ff9_row11_col9\" class=\"data row11 col9\" >1.956414</td>\n",
       "      <td id=\"T_93ff9_row11_col10\" class=\"data row11 col10\" >1.468085</td>\n",
       "      <td id=\"T_93ff9_row11_col11\" class=\"data row11 col11\" >1.512744</td>\n",
       "      <td id=\"T_93ff9_row11_col12\" class=\"data row11 col12\" >17.068878</td>\n",
       "      <td id=\"T_93ff9_row11_col13\" class=\"data row11 col13\" >18.023010</td>\n",
       "      <td id=\"T_93ff9_row11_col14\" class=\"data row11 col14\" >43.697128</td>\n",
       "      <td id=\"T_93ff9_row11_col15\" class=\"data row11 col15\" >43.032516</td>\n",
       "      <td id=\"T_93ff9_row11_col16\" class=\"data row11 col16\" >6.606751</td>\n",
       "      <td id=\"T_93ff9_row11_col17\" class=\"data row11 col17\" >4.537592</td>\n",
       "      <td id=\"T_93ff9_row11_col18\" class=\"data row11 col18\" >6.681823</td>\n",
       "      <td id=\"T_93ff9_row11_col19\" class=\"data row11 col19\" >6.886123</td>\n",
       "      <td id=\"T_93ff9_row11_col20\" class=\"data row11 col20\" >0.000470</td>\n",
       "      <td id=\"T_93ff9_row11_col21\" class=\"data row11 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row11_col22\" class=\"data row11 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row11_col23\" class=\"data row11 col23\" >0.000003</td>\n",
       "      <td id=\"T_93ff9_row11_col24\" class=\"data row11 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row11_col25\" class=\"data row11 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row11_col26\" class=\"data row11 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row11_col27\" class=\"data row11 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row11_col28\" class=\"data row11 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row11_col29\" class=\"data row11 col29\" >15</td>\n",
       "      <td id=\"T_93ff9_row11_col30\" class=\"data row11 col30\" >56</td>\n",
       "      <td id=\"T_93ff9_row11_col31\" class=\"data row11 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row12\" class=\"row_heading level0 row12\" >37</th>\n",
       "      <td id=\"T_93ff9_row12_col0\" class=\"data row12 col0\" >0.718667</td>\n",
       "      <td id=\"T_93ff9_row12_col1\" class=\"data row12 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row12_col2\" class=\"data row12 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row12_col3\" class=\"data row12 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row12_col4\" class=\"data row12 col4\" >1.075848</td>\n",
       "      <td id=\"T_93ff9_row12_col5\" class=\"data row12 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row12_col6\" class=\"data row12 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row12_col7\" class=\"data row12 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row12_col8\" class=\"data row12 col8\" >1.099470</td>\n",
       "      <td id=\"T_93ff9_row12_col9\" class=\"data row12 col9\" >1.041088</td>\n",
       "      <td id=\"T_93ff9_row12_col10\" class=\"data row12 col10\" >1.011254</td>\n",
       "      <td id=\"T_93ff9_row12_col11\" class=\"data row12 col11\" >1.069021</td>\n",
       "      <td id=\"T_93ff9_row12_col12\" class=\"data row12 col12\" >17.088287</td>\n",
       "      <td id=\"T_93ff9_row12_col13\" class=\"data row12 col13\" >16.263855</td>\n",
       "      <td id=\"T_93ff9_row12_col14\" class=\"data row12 col14\" >48.932053</td>\n",
       "      <td id=\"T_93ff9_row12_col15\" class=\"data row12 col15\" >44.838470</td>\n",
       "      <td id=\"T_93ff9_row12_col16\" class=\"data row12 col16\" >6.464684</td>\n",
       "      <td id=\"T_93ff9_row12_col17\" class=\"data row12 col17\" >2.778438</td>\n",
       "      <td id=\"T_93ff9_row12_col18\" class=\"data row12 col18\" >11.916754</td>\n",
       "      <td id=\"T_93ff9_row12_col19\" class=\"data row12 col19\" >8.692074</td>\n",
       "      <td id=\"T_93ff9_row12_col20\" class=\"data row12 col20\" >0.000493</td>\n",
       "      <td id=\"T_93ff9_row12_col21\" class=\"data row12 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row12_col22\" class=\"data row12 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row12_col23\" class=\"data row12 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row12_col24\" class=\"data row12 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row12_col25\" class=\"data row12 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row12_col26\" class=\"data row12 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row12_col27\" class=\"data row12 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row12_col28\" class=\"data row12 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row12_col29\" class=\"data row12 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row12_col30\" class=\"data row12 col30\" >65</td>\n",
       "      <td id=\"T_93ff9_row12_col31\" class=\"data row12 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row13\" class=\"row_heading level0 row13\" >26</th>\n",
       "      <td id=\"T_93ff9_row13_col0\" class=\"data row13 col0\" >0.712000</td>\n",
       "      <td id=\"T_93ff9_row13_col1\" class=\"data row13 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row13_col2\" class=\"data row13 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row13_col3\" class=\"data row13 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row13_col4\" class=\"data row13 col4\" >1.065868</td>\n",
       "      <td id=\"T_93ff9_row13_col5\" class=\"data row13 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row13_col6\" class=\"data row13 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row13_col7\" class=\"data row13 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row13_col8\" class=\"data row13 col8\" >0.971265</td>\n",
       "      <td id=\"T_93ff9_row13_col9\" class=\"data row13 col9\" >1.093591</td>\n",
       "      <td id=\"T_93ff9_row13_col10\" class=\"data row13 col10\" >1.028868</td>\n",
       "      <td id=\"T_93ff9_row13_col11\" class=\"data row13 col11\" >1.030478</td>\n",
       "      <td id=\"T_93ff9_row13_col12\" class=\"data row13 col12\" >13.771767</td>\n",
       "      <td id=\"T_93ff9_row13_col13\" class=\"data row13 col13\" >14.951996</td>\n",
       "      <td id=\"T_93ff9_row13_col14\" class=\"data row13 col14\" >38.922806</td>\n",
       "      <td id=\"T_93ff9_row13_col15\" class=\"data row13 col15\" >38.831848</td>\n",
       "      <td id=\"T_93ff9_row13_col16\" class=\"data row13 col16\" >3.200018</td>\n",
       "      <td id=\"T_93ff9_row13_col17\" class=\"data row13 col17\" >1.466573</td>\n",
       "      <td id=\"T_93ff9_row13_col18\" class=\"data row13 col18\" >1.907502</td>\n",
       "      <td id=\"T_93ff9_row13_col19\" class=\"data row13 col19\" >2.685447</td>\n",
       "      <td id=\"T_93ff9_row13_col20\" class=\"data row13 col20\" >0.000296</td>\n",
       "      <td id=\"T_93ff9_row13_col21\" class=\"data row13 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row13_col22\" class=\"data row13 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row13_col23\" class=\"data row13 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row13_col24\" class=\"data row13 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row13_col25\" class=\"data row13 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row13_col26\" class=\"data row13 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row13_col27\" class=\"data row13 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row13_col28\" class=\"data row13 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row13_col29\" class=\"data row13 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row13_col30\" class=\"data row13 col30\" >33</td>\n",
       "      <td id=\"T_93ff9_row13_col31\" class=\"data row13 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row14\" class=\"row_heading level0 row14\" >30</th>\n",
       "      <td id=\"T_93ff9_row14_col0\" class=\"data row14 col0\" >0.712000</td>\n",
       "      <td id=\"T_93ff9_row14_col1\" class=\"data row14 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row14_col2\" class=\"data row14 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row14_col3\" class=\"data row14 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row14_col4\" class=\"data row14 col4\" >1.065868</td>\n",
       "      <td id=\"T_93ff9_row14_col5\" class=\"data row14 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row14_col6\" class=\"data row14 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row14_col7\" class=\"data row14 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row14_col8\" class=\"data row14 col8\" >1.687905</td>\n",
       "      <td id=\"T_93ff9_row14_col9\" class=\"data row14 col9\" >1.223442</td>\n",
       "      <td id=\"T_93ff9_row14_col10\" class=\"data row14 col10\" >1.549848</td>\n",
       "      <td id=\"T_93ff9_row14_col11\" class=\"data row14 col11\" >1.576449</td>\n",
       "      <td id=\"T_93ff9_row14_col12\" class=\"data row14 col12\" >19.958008</td>\n",
       "      <td id=\"T_93ff9_row14_col13\" class=\"data row14 col13\" >17.416718</td>\n",
       "      <td id=\"T_93ff9_row14_col14\" class=\"data row14 col14\" >50.458389</td>\n",
       "      <td id=\"T_93ff9_row14_col15\" class=\"data row14 col15\" >48.147415</td>\n",
       "      <td id=\"T_93ff9_row14_col16\" class=\"data row14 col16\" >9.501608</td>\n",
       "      <td id=\"T_93ff9_row14_col17\" class=\"data row14 col17\" >3.931294</td>\n",
       "      <td id=\"T_93ff9_row14_col18\" class=\"data row14 col18\" >13.443089</td>\n",
       "      <td id=\"T_93ff9_row14_col19\" class=\"data row14 col19\" >12.001036</td>\n",
       "      <td id=\"T_93ff9_row14_col20\" class=\"data row14 col20\" >0.000431</td>\n",
       "      <td id=\"T_93ff9_row14_col21\" class=\"data row14 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row14_col22\" class=\"data row14 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row14_col23\" class=\"data row14 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row14_col24\" class=\"data row14 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row14_col25\" class=\"data row14 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row14_col26\" class=\"data row14 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row14_col27\" class=\"data row14 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row14_col28\" class=\"data row14 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row14_col29\" class=\"data row14 col29\" >25</td>\n",
       "      <td id=\"T_93ff9_row14_col30\" class=\"data row14 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row14_col31\" class=\"data row14 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row15\" class=\"row_heading level0 row15\" >42</th>\n",
       "      <td id=\"T_93ff9_row15_col0\" class=\"data row15 col0\" >0.702667</td>\n",
       "      <td id=\"T_93ff9_row15_col1\" class=\"data row15 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row15_col2\" class=\"data row15 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row15_col3\" class=\"data row15 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row15_col4\" class=\"data row15 col4\" >1.051896</td>\n",
       "      <td id=\"T_93ff9_row15_col5\" class=\"data row15 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row15_col6\" class=\"data row15 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row15_col7\" class=\"data row15 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row15_col8\" class=\"data row15 col8\" >0.998439</td>\n",
       "      <td id=\"T_93ff9_row15_col9\" class=\"data row15 col9\" >1.015445</td>\n",
       "      <td id=\"T_93ff9_row15_col10\" class=\"data row15 col10\" >0.967618</td>\n",
       "      <td id=\"T_93ff9_row15_col11\" class=\"data row15 col11\" >0.972680</td>\n",
       "      <td id=\"T_93ff9_row15_col12\" class=\"data row15 col12\" >13.117409</td>\n",
       "      <td id=\"T_93ff9_row15_col13\" class=\"data row15 col13\" >14.474480</td>\n",
       "      <td id=\"T_93ff9_row15_col14\" class=\"data row15 col14\" >41.249290</td>\n",
       "      <td id=\"T_93ff9_row15_col15\" class=\"data row15 col15\" >40.558167</td>\n",
       "      <td id=\"T_93ff9_row15_col16\" class=\"data row15 col16\" >2.574480</td>\n",
       "      <td id=\"T_93ff9_row15_col17\" class=\"data row15 col17\" >0.989056</td>\n",
       "      <td id=\"T_93ff9_row15_col18\" class=\"data row15 col18\" >4.233988</td>\n",
       "      <td id=\"T_93ff9_row15_col19\" class=\"data row15 col19\" >4.411780</td>\n",
       "      <td id=\"T_93ff9_row15_col20\" class=\"data row15 col20\" >0.000105</td>\n",
       "      <td id=\"T_93ff9_row15_col21\" class=\"data row15 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row15_col22\" class=\"data row15 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row15_col23\" class=\"data row15 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row15_col24\" class=\"data row15 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row15_col25\" class=\"data row15 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row15_col26\" class=\"data row15 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row15_col27\" class=\"data row15 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row15_col28\" class=\"data row15 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row15_col29\" class=\"data row15 col29\" >35</td>\n",
       "      <td id=\"T_93ff9_row15_col30\" class=\"data row15 col30\" >63</td>\n",
       "      <td id=\"T_93ff9_row15_col31\" class=\"data row15 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row16\" class=\"row_heading level0 row16\" >31</th>\n",
       "      <td id=\"T_93ff9_row16_col0\" class=\"data row16 col0\" >0.701333</td>\n",
       "      <td id=\"T_93ff9_row16_col1\" class=\"data row16 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row16_col2\" class=\"data row16 col2\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row16_col3\" class=\"data row16 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row16_col4\" class=\"data row16 col4\" >1.049900</td>\n",
       "      <td id=\"T_93ff9_row16_col5\" class=\"data row16 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row16_col6\" class=\"data row16 col6\" >1.032258</td>\n",
       "      <td id=\"T_93ff9_row16_col7\" class=\"data row16 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row16_col8\" class=\"data row16 col8\" >1.035825</td>\n",
       "      <td id=\"T_93ff9_row16_col9\" class=\"data row16 col9\" >1.042154</td>\n",
       "      <td id=\"T_93ff9_row16_col10\" class=\"data row16 col10\" >0.960929</td>\n",
       "      <td id=\"T_93ff9_row16_col11\" class=\"data row16 col11\" >0.989073</td>\n",
       "      <td id=\"T_93ff9_row16_col12\" class=\"data row16 col12\" >14.187912</td>\n",
       "      <td id=\"T_93ff9_row16_col13\" class=\"data row16 col13\" >14.620781</td>\n",
       "      <td id=\"T_93ff9_row16_col14\" class=\"data row16 col14\" >44.839806</td>\n",
       "      <td id=\"T_93ff9_row16_col15\" class=\"data row16 col15\" >42.300522</td>\n",
       "      <td id=\"T_93ff9_row16_col16\" class=\"data row16 col16\" >3.648255</td>\n",
       "      <td id=\"T_93ff9_row16_col17\" class=\"data row16 col17\" >1.135361</td>\n",
       "      <td id=\"T_93ff9_row16_col18\" class=\"data row16 col18\" >7.824508</td>\n",
       "      <td id=\"T_93ff9_row16_col19\" class=\"data row16 col19\" >6.154133</td>\n",
       "      <td id=\"T_93ff9_row16_col20\" class=\"data row16 col20\" >0.000382</td>\n",
       "      <td id=\"T_93ff9_row16_col21\" class=\"data row16 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row16_col22\" class=\"data row16 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row16_col23\" class=\"data row16 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row16_col24\" class=\"data row16 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row16_col25\" class=\"data row16 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row16_col26\" class=\"data row16 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row16_col27\" class=\"data row16 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row16_col28\" class=\"data row16 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row16_col29\" class=\"data row16 col29\" >37</td>\n",
       "      <td id=\"T_93ff9_row16_col30\" class=\"data row16 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row16_col31\" class=\"data row16 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row17\" class=\"row_heading level0 row17\" >21</th>\n",
       "      <td id=\"T_93ff9_row17_col0\" class=\"data row17 col0\" >0.700000</td>\n",
       "      <td id=\"T_93ff9_row17_col1\" class=\"data row17 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row17_col2\" class=\"data row17 col2\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row17_col3\" class=\"data row17 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row17_col4\" class=\"data row17 col4\" >1.047904</td>\n",
       "      <td id=\"T_93ff9_row17_col5\" class=\"data row17 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row17_col6\" class=\"data row17 col6\" >1.032258</td>\n",
       "      <td id=\"T_93ff9_row17_col7\" class=\"data row17 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row17_col8\" class=\"data row17 col8\" >1.143232</td>\n",
       "      <td id=\"T_93ff9_row17_col9\" class=\"data row17 col9\" >1.185568</td>\n",
       "      <td id=\"T_93ff9_row17_col10\" class=\"data row17 col10\" >1.019691</td>\n",
       "      <td id=\"T_93ff9_row17_col11\" class=\"data row17 col11\" >1.023265</td>\n",
       "      <td id=\"T_93ff9_row17_col12\" class=\"data row17 col12\" >15.991379</td>\n",
       "      <td id=\"T_93ff9_row17_col13\" class=\"data row17 col13\" >16.274384</td>\n",
       "      <td id=\"T_93ff9_row17_col14\" class=\"data row17 col14\" >47.500931</td>\n",
       "      <td id=\"T_93ff9_row17_col15\" class=\"data row17 col15\" >46.607010</td>\n",
       "      <td id=\"T_93ff9_row17_col16\" class=\"data row17 col16\" >5.466859</td>\n",
       "      <td id=\"T_93ff9_row17_col17\" class=\"data row17 col17\" >2.788961</td>\n",
       "      <td id=\"T_93ff9_row17_col18\" class=\"data row17 col18\" >10.485630</td>\n",
       "      <td id=\"T_93ff9_row17_col19\" class=\"data row17 col19\" >10.460611</td>\n",
       "      <td id=\"T_93ff9_row17_col20\" class=\"data row17 col20\" >0.000752</td>\n",
       "      <td id=\"T_93ff9_row17_col21\" class=\"data row17 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row17_col22\" class=\"data row17 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row17_col23\" class=\"data row17 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row17_col24\" class=\"data row17 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row17_col25\" class=\"data row17 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row17_col26\" class=\"data row17 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row17_col27\" class=\"data row17 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row17_col28\" class=\"data row17 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row17_col29\" class=\"data row17 col29\" >10</td>\n",
       "      <td id=\"T_93ff9_row17_col30\" class=\"data row17 col30\" >61</td>\n",
       "      <td id=\"T_93ff9_row17_col31\" class=\"data row17 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row18\" class=\"row_heading level0 row18\" >25</th>\n",
       "      <td id=\"T_93ff9_row18_col0\" class=\"data row18 col0\" >0.694667</td>\n",
       "      <td id=\"T_93ff9_row18_col1\" class=\"data row18 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row18_col2\" class=\"data row18 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row18_col3\" class=\"data row18 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row18_col4\" class=\"data row18 col4\" >1.039920</td>\n",
       "      <td id=\"T_93ff9_row18_col5\" class=\"data row18 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row18_col6\" class=\"data row18 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row18_col7\" class=\"data row18 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row18_col8\" class=\"data row18 col8\" >1.083718</td>\n",
       "      <td id=\"T_93ff9_row18_col9\" class=\"data row18 col9\" >1.076690</td>\n",
       "      <td id=\"T_93ff9_row18_col10\" class=\"data row18 col10\" >0.966692</td>\n",
       "      <td id=\"T_93ff9_row18_col11\" class=\"data row18 col11\" >0.988564</td>\n",
       "      <td id=\"T_93ff9_row18_col12\" class=\"data row18 col12\" >13.840851</td>\n",
       "      <td id=\"T_93ff9_row18_col13\" class=\"data row18 col13\" >14.957741</td>\n",
       "      <td id=\"T_93ff9_row18_col14\" class=\"data row18 col14\" >43.993141</td>\n",
       "      <td id=\"T_93ff9_row18_col15\" class=\"data row18 col15\" >43.117622</td>\n",
       "      <td id=\"T_93ff9_row18_col16\" class=\"data row18 col16\" >3.279361</td>\n",
       "      <td id=\"T_93ff9_row18_col17\" class=\"data row18 col17\" >1.472323</td>\n",
       "      <td id=\"T_93ff9_row18_col18\" class=\"data row18 col18\" >6.977834</td>\n",
       "      <td id=\"T_93ff9_row18_col19\" class=\"data row18 col19\" >6.971232</td>\n",
       "      <td id=\"T_93ff9_row18_col20\" class=\"data row18 col20\" >0.000476</td>\n",
       "      <td id=\"T_93ff9_row18_col21\" class=\"data row18 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row18_col22\" class=\"data row18 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row18_col23\" class=\"data row18 col23\" >0.001511</td>\n",
       "      <td id=\"T_93ff9_row18_col24\" class=\"data row18 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row18_col25\" class=\"data row18 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row18_col26\" class=\"data row18 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row18_col27\" class=\"data row18 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row18_col28\" class=\"data row18 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row18_col29\" class=\"data row18 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row18_col30\" class=\"data row18 col30\" >89</td>\n",
       "      <td id=\"T_93ff9_row18_col31\" class=\"data row18 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row19\" class=\"row_heading level0 row19\" >40</th>\n",
       "      <td id=\"T_93ff9_row19_col0\" class=\"data row19 col0\" >0.692000</td>\n",
       "      <td id=\"T_93ff9_row19_col1\" class=\"data row19 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row19_col2\" class=\"data row19 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row19_col3\" class=\"data row19 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row19_col4\" class=\"data row19 col4\" >1.035928</td>\n",
       "      <td id=\"T_93ff9_row19_col5\" class=\"data row19 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row19_col6\" class=\"data row19 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row19_col7\" class=\"data row19 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row19_col8\" class=\"data row19 col8\" >1.050317</td>\n",
       "      <td id=\"T_93ff9_row19_col9\" class=\"data row19 col9\" >1.036807</td>\n",
       "      <td id=\"T_93ff9_row19_col10\" class=\"data row19 col10\" >0.950733</td>\n",
       "      <td id=\"T_93ff9_row19_col11\" class=\"data row19 col11\" >0.977272</td>\n",
       "      <td id=\"T_93ff9_row19_col12\" class=\"data row19 col12\" >13.004517</td>\n",
       "      <td id=\"T_93ff9_row19_col13\" class=\"data row19 col13\" >15.069290</td>\n",
       "      <td id=\"T_93ff9_row19_col14\" class=\"data row19 col14\" >43.444305</td>\n",
       "      <td id=\"T_93ff9_row19_col15\" class=\"data row19 col15\" >42.248329</td>\n",
       "      <td id=\"T_93ff9_row19_col16\" class=\"data row19 col16\" >2.443269</td>\n",
       "      <td id=\"T_93ff9_row19_col17\" class=\"data row19 col17\" >1.583876</td>\n",
       "      <td id=\"T_93ff9_row19_col18\" class=\"data row19 col18\" >6.429000</td>\n",
       "      <td id=\"T_93ff9_row19_col19\" class=\"data row19 col19\" >6.101944</td>\n",
       "      <td id=\"T_93ff9_row19_col20\" class=\"data row19 col20\" >0.000430</td>\n",
       "      <td id=\"T_93ff9_row19_col21\" class=\"data row19 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row19_col22\" class=\"data row19 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row19_col23\" class=\"data row19 col23\" >0.000522</td>\n",
       "      <td id=\"T_93ff9_row19_col24\" class=\"data row19 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row19_col25\" class=\"data row19 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row19_col26\" class=\"data row19 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row19_col27\" class=\"data row19 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row19_col28\" class=\"data row19 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row19_col29\" class=\"data row19 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row19_col30\" class=\"data row19 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row19_col31\" class=\"data row19 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row20\" class=\"row_heading level0 row20\" >35</th>\n",
       "      <td id=\"T_93ff9_row20_col0\" class=\"data row20 col0\" >0.689333</td>\n",
       "      <td id=\"T_93ff9_row20_col1\" class=\"data row20 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row20_col2\" class=\"data row20 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row20_col3\" class=\"data row20 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row20_col4\" class=\"data row20 col4\" >1.031936</td>\n",
       "      <td id=\"T_93ff9_row20_col5\" class=\"data row20 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row20_col6\" class=\"data row20 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row20_col7\" class=\"data row20 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row20_col8\" class=\"data row20 col8\" >0.988007</td>\n",
       "      <td id=\"T_93ff9_row20_col9\" class=\"data row20 col9\" >1.031555</td>\n",
       "      <td id=\"T_93ff9_row20_col10\" class=\"data row20 col10\" >0.986126</td>\n",
       "      <td id=\"T_93ff9_row20_col11\" class=\"data row20 col11\" >0.983657</td>\n",
       "      <td id=\"T_93ff9_row20_col12\" class=\"data row20 col12\" >12.183128</td>\n",
       "      <td id=\"T_93ff9_row20_col13\" class=\"data row20 col13\" >14.029480</td>\n",
       "      <td id=\"T_93ff9_row20_col14\" class=\"data row20 col14\" >38.802383</td>\n",
       "      <td id=\"T_93ff9_row20_col15\" class=\"data row20 col15\" >38.256821</td>\n",
       "      <td id=\"T_93ff9_row20_col16\" class=\"data row20 col16\" >1.632273</td>\n",
       "      <td id=\"T_93ff9_row20_col17\" class=\"data row20 col17\" >0.544062</td>\n",
       "      <td id=\"T_93ff9_row20_col18\" class=\"data row20 col18\" >1.787074</td>\n",
       "      <td id=\"T_93ff9_row20_col19\" class=\"data row20 col19\" >2.110421</td>\n",
       "      <td id=\"T_93ff9_row20_col20\" class=\"data row20 col20\" >0.000290</td>\n",
       "      <td id=\"T_93ff9_row20_col21\" class=\"data row20 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row20_col22\" class=\"data row20 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row20_col23\" class=\"data row20 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row20_col24\" class=\"data row20 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row20_col25\" class=\"data row20 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row20_col26\" class=\"data row20 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row20_col27\" class=\"data row20 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row20_col28\" class=\"data row20 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row20_col29\" class=\"data row20 col29\" >64</td>\n",
       "      <td id=\"T_93ff9_row20_col30\" class=\"data row20 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row20_col31\" class=\"data row20 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row21\" class=\"row_heading level0 row21\" >11</th>\n",
       "      <td id=\"T_93ff9_row21_col0\" class=\"data row21 col0\" >0.689333</td>\n",
       "      <td id=\"T_93ff9_row21_col1\" class=\"data row21 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row21_col2\" class=\"data row21 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row21_col3\" class=\"data row21 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row21_col4\" class=\"data row21 col4\" >1.031936</td>\n",
       "      <td id=\"T_93ff9_row21_col5\" class=\"data row21 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row21_col6\" class=\"data row21 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row21_col7\" class=\"data row21 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row21_col8\" class=\"data row21 col8\" >1.012729</td>\n",
       "      <td id=\"T_93ff9_row21_col9\" class=\"data row21 col9\" >1.013601</td>\n",
       "      <td id=\"T_93ff9_row21_col10\" class=\"data row21 col10\" >0.946459</td>\n",
       "      <td id=\"T_93ff9_row21_col11\" class=\"data row21 col11\" >0.975662</td>\n",
       "      <td id=\"T_93ff9_row21_col12\" class=\"data row21 col12\" >12.418793</td>\n",
       "      <td id=\"T_93ff9_row21_col13\" class=\"data row21 col13\" >14.201767</td>\n",
       "      <td id=\"T_93ff9_row21_col14\" class=\"data row21 col14\" >40.697189</td>\n",
       "      <td id=\"T_93ff9_row21_col15\" class=\"data row21 col15\" >39.975029</td>\n",
       "      <td id=\"T_93ff9_row21_col16\" class=\"data row21 col16\" >1.860869</td>\n",
       "      <td id=\"T_93ff9_row21_col17\" class=\"data row21 col17\" >0.716341</td>\n",
       "      <td id=\"T_93ff9_row21_col18\" class=\"data row21 col18\" >3.681895</td>\n",
       "      <td id=\"T_93ff9_row21_col19\" class=\"data row21 col19\" >3.828632</td>\n",
       "      <td id=\"T_93ff9_row21_col20\" class=\"data row21 col20\" >0.000209</td>\n",
       "      <td id=\"T_93ff9_row21_col21\" class=\"data row21 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row21_col22\" class=\"data row21 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row21_col23\" class=\"data row21 col23\" >0.000064</td>\n",
       "      <td id=\"T_93ff9_row21_col24\" class=\"data row21 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row21_col25\" class=\"data row21 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row21_col26\" class=\"data row21 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row21_col27\" class=\"data row21 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row21_col28\" class=\"data row21 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row21_col29\" class=\"data row21 col29\" >16</td>\n",
       "      <td id=\"T_93ff9_row21_col30\" class=\"data row21 col30\" >38</td>\n",
       "      <td id=\"T_93ff9_row21_col31\" class=\"data row21 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row22\" class=\"row_heading level0 row22\" >27</th>\n",
       "      <td id=\"T_93ff9_row22_col0\" class=\"data row22 col0\" >0.688000</td>\n",
       "      <td id=\"T_93ff9_row22_col1\" class=\"data row22 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row22_col2\" class=\"data row22 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row22_col3\" class=\"data row22 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row22_col4\" class=\"data row22 col4\" >1.029940</td>\n",
       "      <td id=\"T_93ff9_row22_col5\" class=\"data row22 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row22_col6\" class=\"data row22 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row22_col7\" class=\"data row22 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row22_col8\" class=\"data row22 col8\" >1.010169</td>\n",
       "      <td id=\"T_93ff9_row22_col9\" class=\"data row22 col9\" >1.002506</td>\n",
       "      <td id=\"T_93ff9_row22_col10\" class=\"data row22 col10\" >0.948866</td>\n",
       "      <td id=\"T_93ff9_row22_col11\" class=\"data row22 col11\" >0.970346</td>\n",
       "      <td id=\"T_93ff9_row22_col12\" class=\"data row22 col12\" >12.311005</td>\n",
       "      <td id=\"T_93ff9_row22_col13\" class=\"data row22 col13\" >14.354385</td>\n",
       "      <td id=\"T_93ff9_row22_col14\" class=\"data row22 col14\" >40.644012</td>\n",
       "      <td id=\"T_93ff9_row22_col15\" class=\"data row22 col15\" >39.783768</td>\n",
       "      <td id=\"T_93ff9_row22_col16\" class=\"data row22 col16\" >1.751093</td>\n",
       "      <td id=\"T_93ff9_row22_col17\" class=\"data row22 col17\" >0.868962</td>\n",
       "      <td id=\"T_93ff9_row22_col18\" class=\"data row22 col18\" >3.628700</td>\n",
       "      <td id=\"T_93ff9_row22_col19\" class=\"data row22 col19\" >3.637375</td>\n",
       "      <td id=\"T_93ff9_row22_col20\" class=\"data row22 col20\" >0.000193</td>\n",
       "      <td id=\"T_93ff9_row22_col21\" class=\"data row22 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row22_col22\" class=\"data row22 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row22_col23\" class=\"data row22 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row22_col24\" class=\"data row22 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row22_col25\" class=\"data row22 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row22_col26\" class=\"data row22 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row22_col27\" class=\"data row22 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row22_col28\" class=\"data row22 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row22_col29\" class=\"data row22 col29\" >42</td>\n",
       "      <td id=\"T_93ff9_row22_col30\" class=\"data row22 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row22_col31\" class=\"data row22 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row23\" class=\"row_heading level0 row23\" >19</th>\n",
       "      <td id=\"T_93ff9_row23_col0\" class=\"data row23 col0\" >0.686667</td>\n",
       "      <td id=\"T_93ff9_row23_col1\" class=\"data row23 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row23_col2\" class=\"data row23 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row23_col3\" class=\"data row23 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row23_col4\" class=\"data row23 col4\" >1.027944</td>\n",
       "      <td id=\"T_93ff9_row23_col5\" class=\"data row23 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row23_col6\" class=\"data row23 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row23_col7\" class=\"data row23 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row23_col8\" class=\"data row23 col8\" >1.001666</td>\n",
       "      <td id=\"T_93ff9_row23_col9\" class=\"data row23 col9\" >1.001001</td>\n",
       "      <td id=\"T_93ff9_row23_col10\" class=\"data row23 col10\" >0.967876</td>\n",
       "      <td id=\"T_93ff9_row23_col11\" class=\"data row23 col11\" >0.971013</td>\n",
       "      <td id=\"T_93ff9_row23_col12\" class=\"data row23 col12\" >11.385246</td>\n",
       "      <td id=\"T_93ff9_row23_col13\" class=\"data row23 col13\" >13.547157</td>\n",
       "      <td id=\"T_93ff9_row23_col14\" class=\"data row23 col14\" >38.013351</td>\n",
       "      <td id=\"T_93ff9_row23_col15\" class=\"data row23 col15\" >37.301041</td>\n",
       "      <td id=\"T_93ff9_row23_col16\" class=\"data row23 col16\" >0.840203</td>\n",
       "      <td id=\"T_93ff9_row23_col17\" class=\"data row23 col17\" >0.061738</td>\n",
       "      <td id=\"T_93ff9_row23_col18\" class=\"data row23 col18\" >0.998048</td>\n",
       "      <td id=\"T_93ff9_row23_col19\" class=\"data row23 col19\" >1.154651</td>\n",
       "      <td id=\"T_93ff9_row23_col20\" class=\"data row23 col20\" >0.000078</td>\n",
       "      <td id=\"T_93ff9_row23_col21\" class=\"data row23 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row23_col22\" class=\"data row23 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row23_col23\" class=\"data row23 col23\" >0.021796</td>\n",
       "      <td id=\"T_93ff9_row23_col24\" class=\"data row23 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row23_col25\" class=\"data row23 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row23_col26\" class=\"data row23 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row23_col27\" class=\"data row23 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row23_col28\" class=\"data row23 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row23_col29\" class=\"data row23 col29\" >25</td>\n",
       "      <td id=\"T_93ff9_row23_col30\" class=\"data row23 col30\" >121</td>\n",
       "      <td id=\"T_93ff9_row23_col31\" class=\"data row23 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row24\" class=\"row_heading level0 row24\" >32</th>\n",
       "      <td id=\"T_93ff9_row24_col0\" class=\"data row24 col0\" >0.685333</td>\n",
       "      <td id=\"T_93ff9_row24_col1\" class=\"data row24 col1\" >0.890625</td>\n",
       "      <td id=\"T_93ff9_row24_col2\" class=\"data row24 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row24_col3\" class=\"data row24 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row24_col4\" class=\"data row24 col4\" >1.025948</td>\n",
       "      <td id=\"T_93ff9_row24_col5\" class=\"data row24 col5\" >0.966102</td>\n",
       "      <td id=\"T_93ff9_row24_col6\" class=\"data row24 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row24_col7\" class=\"data row24 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row24_col8\" class=\"data row24 col8\" >0.989802</td>\n",
       "      <td id=\"T_93ff9_row24_col9\" class=\"data row24 col9\" >1.163900</td>\n",
       "      <td id=\"T_93ff9_row24_col10\" class=\"data row24 col10\" >1.033329</td>\n",
       "      <td id=\"T_93ff9_row24_col11\" class=\"data row24 col11\" >1.031718</td>\n",
       "      <td id=\"T_93ff9_row24_col12\" class=\"data row24 col12\" >11.943954</td>\n",
       "      <td id=\"T_93ff9_row24_col13\" class=\"data row24 col13\" >14.538300</td>\n",
       "      <td id=\"T_93ff9_row24_col14\" class=\"data row24 col14\" >39.081314</td>\n",
       "      <td id=\"T_93ff9_row24_col15\" class=\"data row24 col15\" >37.705147</td>\n",
       "      <td id=\"T_93ff9_row24_col16\" class=\"data row24 col16\" >1.376349</td>\n",
       "      <td id=\"T_93ff9_row24_col17\" class=\"data row24 col17\" >1.052879</td>\n",
       "      <td id=\"T_93ff9_row24_col18\" class=\"data row24 col18\" >2.066011</td>\n",
       "      <td id=\"T_93ff9_row24_col19\" class=\"data row24 col19\" >1.558752</td>\n",
       "      <td id=\"T_93ff9_row24_col20\" class=\"data row24 col20\" >0.000653</td>\n",
       "      <td id=\"T_93ff9_row24_col21\" class=\"data row24 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col22\" class=\"data row24 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col23\" class=\"data row24 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row24_col24\" class=\"data row24 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col25\" class=\"data row24 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row24_col26\" class=\"data row24 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col27\" class=\"data row24 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col28\" class=\"data row24 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row24_col29\" class=\"data row24 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row24_col30\" class=\"data row24 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row24_col31\" class=\"data row24 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row25\" class=\"row_heading level0 row25\" >36</th>\n",
       "      <td id=\"T_93ff9_row25_col0\" class=\"data row25 col0\" >0.685333</td>\n",
       "      <td id=\"T_93ff9_row25_col1\" class=\"data row25 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row25_col2\" class=\"data row25 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row25_col3\" class=\"data row25 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row25_col4\" class=\"data row25 col4\" >1.025948</td>\n",
       "      <td id=\"T_93ff9_row25_col5\" class=\"data row25 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row25_col6\" class=\"data row25 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row25_col7\" class=\"data row25 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row25_col8\" class=\"data row25 col8\" >0.979335</td>\n",
       "      <td id=\"T_93ff9_row25_col9\" class=\"data row25 col9\" >1.003837</td>\n",
       "      <td id=\"T_93ff9_row25_col10\" class=\"data row25 col10\" >0.977062</td>\n",
       "      <td id=\"T_93ff9_row25_col11\" class=\"data row25 col11\" >0.974104</td>\n",
       "      <td id=\"T_93ff9_row25_col12\" class=\"data row25 col12\" >11.771843</td>\n",
       "      <td id=\"T_93ff9_row25_col13\" class=\"data row25 col13\" >13.854980</td>\n",
       "      <td id=\"T_93ff9_row25_col14\" class=\"data row25 col14\" >38.682190</td>\n",
       "      <td id=\"T_93ff9_row25_col15\" class=\"data row25 col15\" >38.107567</td>\n",
       "      <td id=\"T_93ff9_row25_col16\" class=\"data row25 col16\" >1.230181</td>\n",
       "      <td id=\"T_93ff9_row25_col17\" class=\"data row25 col17\" >0.369557</td>\n",
       "      <td id=\"T_93ff9_row25_col18\" class=\"data row25 col18\" >1.666890</td>\n",
       "      <td id=\"T_93ff9_row25_col19\" class=\"data row25 col19\" >1.961172</td>\n",
       "      <td id=\"T_93ff9_row25_col20\" class=\"data row25 col20\" >0.000223</td>\n",
       "      <td id=\"T_93ff9_row25_col21\" class=\"data row25 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row25_col22\" class=\"data row25 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row25_col23\" class=\"data row25 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row25_col24\" class=\"data row25 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row25_col25\" class=\"data row25 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row25_col26\" class=\"data row25 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row25_col27\" class=\"data row25 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row25_col28\" class=\"data row25 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row25_col29\" class=\"data row25 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row25_col30\" class=\"data row25 col30\" >2</td>\n",
       "      <td id=\"T_93ff9_row25_col31\" class=\"data row25 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row26\" class=\"row_heading level0 row26\" >41</th>\n",
       "      <td id=\"T_93ff9_row26_col0\" class=\"data row26 col0\" >0.685333</td>\n",
       "      <td id=\"T_93ff9_row26_col1\" class=\"data row26 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row26_col2\" class=\"data row26 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row26_col3\" class=\"data row26 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row26_col4\" class=\"data row26 col4\" >1.025948</td>\n",
       "      <td id=\"T_93ff9_row26_col5\" class=\"data row26 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row26_col6\" class=\"data row26 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row26_col7\" class=\"data row26 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row26_col8\" class=\"data row26 col8\" >1.014215</td>\n",
       "      <td id=\"T_93ff9_row26_col9\" class=\"data row26 col9\" >1.035094</td>\n",
       "      <td id=\"T_93ff9_row26_col10\" class=\"data row26 col10\" >0.992528</td>\n",
       "      <td id=\"T_93ff9_row26_col11\" class=\"data row26 col11\" >1.010750</td>\n",
       "      <td id=\"T_93ff9_row26_col12\" class=\"data row26 col12\" >12.629692</td>\n",
       "      <td id=\"T_93ff9_row26_col13\" class=\"data row26 col13\" >14.701874</td>\n",
       "      <td id=\"T_93ff9_row26_col14\" class=\"data row26 col14\" >41.611435</td>\n",
       "      <td id=\"T_93ff9_row26_col15\" class=\"data row26 col15\" >40.712318</td>\n",
       "      <td id=\"T_93ff9_row26_col16\" class=\"data row26 col16\" >2.037494</td>\n",
       "      <td id=\"T_93ff9_row26_col17\" class=\"data row26 col17\" >1.216454</td>\n",
       "      <td id=\"T_93ff9_row26_col18\" class=\"data row26 col18\" >4.596122</td>\n",
       "      <td id=\"T_93ff9_row26_col19\" class=\"data row26 col19\" >4.565922</td>\n",
       "      <td id=\"T_93ff9_row26_col20\" class=\"data row26 col20\" >0.000288</td>\n",
       "      <td id=\"T_93ff9_row26_col21\" class=\"data row26 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row26_col22\" class=\"data row26 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row26_col23\" class=\"data row26 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row26_col24\" class=\"data row26 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row26_col25\" class=\"data row26 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row26_col26\" class=\"data row26 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row26_col27\" class=\"data row26 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row26_col28\" class=\"data row26 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row26_col29\" class=\"data row26 col29\" >31</td>\n",
       "      <td id=\"T_93ff9_row26_col30\" class=\"data row26 col30\" >65</td>\n",
       "      <td id=\"T_93ff9_row26_col31\" class=\"data row26 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row27\" class=\"row_heading level0 row27\" >12</th>\n",
       "      <td id=\"T_93ff9_row27_col0\" class=\"data row27 col0\" >0.681333</td>\n",
       "      <td id=\"T_93ff9_row27_col1\" class=\"data row27 col1\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row27_col2\" class=\"data row27 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row27_col3\" class=\"data row27 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row27_col4\" class=\"data row27 col4\" >1.019960</td>\n",
       "      <td id=\"T_93ff9_row27_col5\" class=\"data row27 col5\" >1.016949</td>\n",
       "      <td id=\"T_93ff9_row27_col6\" class=\"data row27 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row27_col7\" class=\"data row27 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row27_col8\" class=\"data row27 col8\" >0.991870</td>\n",
       "      <td id=\"T_93ff9_row27_col9\" class=\"data row27 col9\" >1.004565</td>\n",
       "      <td id=\"T_93ff9_row27_col10\" class=\"data row27 col10\" >0.972693</td>\n",
       "      <td id=\"T_93ff9_row27_col11\" class=\"data row27 col11\" >0.981666</td>\n",
       "      <td id=\"T_93ff9_row27_col12\" class=\"data row27 col12\" >11.952629</td>\n",
       "      <td id=\"T_93ff9_row27_col13\" class=\"data row27 col13\" >14.112206</td>\n",
       "      <td id=\"T_93ff9_row27_col14\" class=\"data row27 col14\" >39.749771</td>\n",
       "      <td id=\"T_93ff9_row27_col15\" class=\"data row27 col15\" >38.936546</td>\n",
       "      <td id=\"T_93ff9_row27_col16\" class=\"data row27 col16\" >1.396399</td>\n",
       "      <td id=\"T_93ff9_row27_col17\" class=\"data row27 col17\" >0.626785</td>\n",
       "      <td id=\"T_93ff9_row27_col18\" class=\"data row27 col18\" >2.734469</td>\n",
       "      <td id=\"T_93ff9_row27_col19\" class=\"data row27 col19\" >2.790151</td>\n",
       "      <td id=\"T_93ff9_row27_col20\" class=\"data row27 col20\" >0.000106</td>\n",
       "      <td id=\"T_93ff9_row27_col21\" class=\"data row27 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row27_col22\" class=\"data row27 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row27_col23\" class=\"data row27 col23\" >0.000521</td>\n",
       "      <td id=\"T_93ff9_row27_col24\" class=\"data row27 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row27_col25\" class=\"data row27 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row27_col26\" class=\"data row27 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row27_col27\" class=\"data row27 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row27_col28\" class=\"data row27 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row27_col29\" class=\"data row27 col29\" >62</td>\n",
       "      <td id=\"T_93ff9_row27_col30\" class=\"data row27 col30\" >60</td>\n",
       "      <td id=\"T_93ff9_row27_col31\" class=\"data row27 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row28\" class=\"row_heading level0 row28\" >29</th>\n",
       "      <td id=\"T_93ff9_row28_col0\" class=\"data row28 col0\" >0.676000</td>\n",
       "      <td id=\"T_93ff9_row28_col1\" class=\"data row28 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row28_col2\" class=\"data row28 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row28_col3\" class=\"data row28 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row28_col4\" class=\"data row28 col4\" >1.011976</td>\n",
       "      <td id=\"T_93ff9_row28_col5\" class=\"data row28 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row28_col6\" class=\"data row28 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row28_col7\" class=\"data row28 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row28_col8\" class=\"data row28 col8\" >0.995784</td>\n",
       "      <td id=\"T_93ff9_row28_col9\" class=\"data row28 col9\" >1.001803</td>\n",
       "      <td id=\"T_93ff9_row28_col10\" class=\"data row28 col10\" >0.988952</td>\n",
       "      <td id=\"T_93ff9_row28_col11\" class=\"data row28 col11\" >0.988304</td>\n",
       "      <td id=\"T_93ff9_row28_col12\" class=\"data row28 col12\" >11.055771</td>\n",
       "      <td id=\"T_93ff9_row28_col13\" class=\"data row28 col13\" >13.627022</td>\n",
       "      <td id=\"T_93ff9_row28_col14\" class=\"data row28 col14\" >37.865578</td>\n",
       "      <td id=\"T_93ff9_row28_col15\" class=\"data row28 col15\" >37.027802</td>\n",
       "      <td id=\"T_93ff9_row28_col16\" class=\"data row28 col16\" >0.517235</td>\n",
       "      <td id=\"T_93ff9_row28_col17\" class=\"data row28 col17\" >0.141602</td>\n",
       "      <td id=\"T_93ff9_row28_col18\" class=\"data row28 col18\" >0.850270</td>\n",
       "      <td id=\"T_93ff9_row28_col19\" class=\"data row28 col19\" >0.881417</td>\n",
       "      <td id=\"T_93ff9_row28_col20\" class=\"data row28 col20\" >0.000018</td>\n",
       "      <td id=\"T_93ff9_row28_col21\" class=\"data row28 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row28_col22\" class=\"data row28 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row28_col23\" class=\"data row28 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row28_col24\" class=\"data row28 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row28_col25\" class=\"data row28 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row28_col26\" class=\"data row28 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row28_col27\" class=\"data row28 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row28_col28\" class=\"data row28 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row28_col29\" class=\"data row28 col29\" >64</td>\n",
       "      <td id=\"T_93ff9_row28_col30\" class=\"data row28 col30\" >98</td>\n",
       "      <td id=\"T_93ff9_row28_col31\" class=\"data row28 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row29\" class=\"row_heading level0 row29\" >8</th>\n",
       "      <td id=\"T_93ff9_row29_col0\" class=\"data row29 col0\" >0.676000</td>\n",
       "      <td id=\"T_93ff9_row29_col1\" class=\"data row29 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row29_col2\" class=\"data row29 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row29_col3\" class=\"data row29 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row29_col4\" class=\"data row29 col4\" >1.011976</td>\n",
       "      <td id=\"T_93ff9_row29_col5\" class=\"data row29 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row29_col6\" class=\"data row29 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row29_col7\" class=\"data row29 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row29_col8\" class=\"data row29 col8\" >0.994440</td>\n",
       "      <td id=\"T_93ff9_row29_col9\" class=\"data row29 col9\" >1.002985</td>\n",
       "      <td id=\"T_93ff9_row29_col10\" class=\"data row29 col10\" >0.987643</td>\n",
       "      <td id=\"T_93ff9_row29_col11\" class=\"data row29 col11\" >0.987205</td>\n",
       "      <td id=\"T_93ff9_row29_col12\" class=\"data row29 col12\" >11.095879</td>\n",
       "      <td id=\"T_93ff9_row29_col13\" class=\"data row29 col13\" >13.627632</td>\n",
       "      <td id=\"T_93ff9_row29_col14\" class=\"data row29 col14\" >37.974442</td>\n",
       "      <td id=\"T_93ff9_row29_col15\" class=\"data row29 col15\" >37.149078</td>\n",
       "      <td id=\"T_93ff9_row29_col16\" class=\"data row29 col16\" >0.552882</td>\n",
       "      <td id=\"T_93ff9_row29_col17\" class=\"data row29 col17\" >0.142209</td>\n",
       "      <td id=\"T_93ff9_row29_col18\" class=\"data row29 col18\" >0.959143</td>\n",
       "      <td id=\"T_93ff9_row29_col19\" class=\"data row29 col19\" >1.002684</td>\n",
       "      <td id=\"T_93ff9_row29_col20\" class=\"data row29 col20\" >0.000016</td>\n",
       "      <td id=\"T_93ff9_row29_col21\" class=\"data row29 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row29_col22\" class=\"data row29 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row29_col23\" class=\"data row29 col23\" >0.009994</td>\n",
       "      <td id=\"T_93ff9_row29_col24\" class=\"data row29 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row29_col25\" class=\"data row29 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row29_col26\" class=\"data row29 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row29_col27\" class=\"data row29 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row29_col28\" class=\"data row29 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row29_col29\" class=\"data row29 col29\" >20</td>\n",
       "      <td id=\"T_93ff9_row29_col30\" class=\"data row29 col30\" >7</td>\n",
       "      <td id=\"T_93ff9_row29_col31\" class=\"data row29 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row30\" class=\"row_heading level0 row30\" >47</th>\n",
       "      <td id=\"T_93ff9_row30_col0\" class=\"data row30 col0\" >0.670667</td>\n",
       "      <td id=\"T_93ff9_row30_col1\" class=\"data row30 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row30_col2\" class=\"data row30 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row30_col3\" class=\"data row30 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row30_col4\" class=\"data row30 col4\" >1.003992</td>\n",
       "      <td id=\"T_93ff9_row30_col5\" class=\"data row30 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row30_col6\" class=\"data row30 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row30_col7\" class=\"data row30 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row30_col8\" class=\"data row30 col8\" >0.996632</td>\n",
       "      <td id=\"T_93ff9_row30_col9\" class=\"data row30 col9\" >1.002621</td>\n",
       "      <td id=\"T_93ff9_row30_col10\" class=\"data row30 col10\" >0.991818</td>\n",
       "      <td id=\"T_93ff9_row30_col11\" class=\"data row30 col11\" >0.992624</td>\n",
       "      <td id=\"T_93ff9_row30_col12\" class=\"data row30 col12\" >10.790855</td>\n",
       "      <td id=\"T_93ff9_row30_col13\" class=\"data row30 col13\" >13.548302</td>\n",
       "      <td id=\"T_93ff9_row30_col14\" class=\"data row30 col14\" >37.472939</td>\n",
       "      <td id=\"T_93ff9_row30_col15\" class=\"data row30 col15\" >36.562492</td>\n",
       "      <td id=\"T_93ff9_row30_col16\" class=\"data row30 col16\" >0.257366</td>\n",
       "      <td id=\"T_93ff9_row30_col17\" class=\"data row30 col17\" >0.062877</td>\n",
       "      <td id=\"T_93ff9_row30_col18\" class=\"data row30 col18\" >0.457640</td>\n",
       "      <td id=\"T_93ff9_row30_col19\" class=\"data row30 col19\" >0.416106</td>\n",
       "      <td id=\"T_93ff9_row30_col20\" class=\"data row30 col20\" >0.000006</td>\n",
       "      <td id=\"T_93ff9_row30_col21\" class=\"data row30 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row30_col22\" class=\"data row30 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row30_col23\" class=\"data row30 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row30_col24\" class=\"data row30 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row30_col25\" class=\"data row30 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row30_col26\" class=\"data row30 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row30_col27\" class=\"data row30 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row30_col28\" class=\"data row30 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row30_col29\" class=\"data row30 col29\" >64</td>\n",
       "      <td id=\"T_93ff9_row30_col30\" class=\"data row30 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row30_col31\" class=\"data row30 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row31\" class=\"row_heading level0 row31\" >0</th>\n",
       "      <td id=\"T_93ff9_row31_col0\" class=\"data row31 col0\" >0.669333</td>\n",
       "      <td id=\"T_93ff9_row31_col1\" class=\"data row31 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row31_col2\" class=\"data row31 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row31_col3\" class=\"data row31 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row31_col4\" class=\"data row31 col4\" >1.001996</td>\n",
       "      <td id=\"T_93ff9_row31_col5\" class=\"data row31 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row31_col6\" class=\"data row31 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row31_col7\" class=\"data row31 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row31_col8\" class=\"data row31 col8\" >0.996771</td>\n",
       "      <td id=\"T_93ff9_row31_col9\" class=\"data row31 col9\" >0.998780</td>\n",
       "      <td id=\"T_93ff9_row31_col10\" class=\"data row31 col10\" >0.996960</td>\n",
       "      <td id=\"T_93ff9_row31_col11\" class=\"data row31 col11\" >0.996801</td>\n",
       "      <td id=\"T_93ff9_row31_col12\" class=\"data row31 col12\" >10.733551</td>\n",
       "      <td id=\"T_93ff9_row31_col13\" class=\"data row31 col13\" >13.583717</td>\n",
       "      <td id=\"T_93ff9_row31_col14\" class=\"data row31 col14\" >37.211319</td>\n",
       "      <td id=\"T_93ff9_row31_col15\" class=\"data row31 col15\" >36.448296</td>\n",
       "      <td id=\"T_93ff9_row31_col16\" class=\"data row31 col16\" >0.197893</td>\n",
       "      <td id=\"T_93ff9_row31_col17\" class=\"data row31 col17\" >0.098299</td>\n",
       "      <td id=\"T_93ff9_row31_col18\" class=\"data row31 col18\" >0.196021</td>\n",
       "      <td id=\"T_93ff9_row31_col19\" class=\"data row31 col19\" >0.301905</td>\n",
       "      <td id=\"T_93ff9_row31_col20\" class=\"data row31 col20\" >0.000005</td>\n",
       "      <td id=\"T_93ff9_row31_col21\" class=\"data row31 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row31_col22\" class=\"data row31 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row31_col23\" class=\"data row31 col23\" >0.358583</td>\n",
       "      <td id=\"T_93ff9_row31_col24\" class=\"data row31 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row31_col25\" class=\"data row31 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row31_col26\" class=\"data row31 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row31_col27\" class=\"data row31 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row31_col28\" class=\"data row31 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row31_col29\" class=\"data row31 col29\" >12</td>\n",
       "      <td id=\"T_93ff9_row31_col30\" class=\"data row31 col30\" >120</td>\n",
       "      <td id=\"T_93ff9_row31_col31\" class=\"data row31 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row32\" class=\"row_heading level0 row32\" >28</th>\n",
       "      <td id=\"T_93ff9_row32_col0\" class=\"data row32 col0\" >0.668000</td>\n",
       "      <td id=\"T_93ff9_row32_col1\" class=\"data row32 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row32_col2\" class=\"data row32 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row32_col3\" class=\"data row32 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row32_col4\" class=\"data row32 col4\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row32_col5\" class=\"data row32 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row32_col6\" class=\"data row32 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row32_col7\" class=\"data row32 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row32_col8\" class=\"data row32 col8\" >1.000095</td>\n",
       "      <td id=\"T_93ff9_row32_col9\" class=\"data row32 col9\" >1.001560</td>\n",
       "      <td id=\"T_93ff9_row32_col10\" class=\"data row32 col10\" >0.998671</td>\n",
       "      <td id=\"T_93ff9_row32_col11\" class=\"data row32 col11\" >0.997541</td>\n",
       "      <td id=\"T_93ff9_row32_col12\" class=\"data row32 col12\" >10.570198</td>\n",
       "      <td id=\"T_93ff9_row32_col13\" class=\"data row32 col13\" >13.484283</td>\n",
       "      <td id=\"T_93ff9_row32_col14\" class=\"data row32 col14\" >37.076271</td>\n",
       "      <td id=\"T_93ff9_row32_col15\" class=\"data row32 col15\" >36.293289</td>\n",
       "      <td id=\"T_93ff9_row32_col16\" class=\"data row32 col16\" >0.030843</td>\n",
       "      <td id=\"T_93ff9_row32_col17\" class=\"data row32 col17\" >-0.001137</td>\n",
       "      <td id=\"T_93ff9_row32_col18\" class=\"data row32 col18\" >0.060969</td>\n",
       "      <td id=\"T_93ff9_row32_col19\" class=\"data row32 col19\" >0.146894</td>\n",
       "      <td id=\"T_93ff9_row32_col20\" class=\"data row32 col20\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row32_col21\" class=\"data row32 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row32_col22\" class=\"data row32 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row32_col23\" class=\"data row32 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row32_col24\" class=\"data row32 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row32_col25\" class=\"data row32 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row32_col26\" class=\"data row32 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row32_col27\" class=\"data row32 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row32_col28\" class=\"data row32 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row32_col29\" class=\"data row32 col29\" >10</td>\n",
       "      <td id=\"T_93ff9_row32_col30\" class=\"data row32 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row32_col31\" class=\"data row32 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row33\" class=\"row_heading level0 row33\" >43</th>\n",
       "      <td id=\"T_93ff9_row33_col0\" class=\"data row33 col0\" >0.668000</td>\n",
       "      <td id=\"T_93ff9_row33_col1\" class=\"data row33 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row33_col2\" class=\"data row33 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row33_col3\" class=\"data row33 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row33_col4\" class=\"data row33 col4\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row33_col5\" class=\"data row33 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row33_col6\" class=\"data row33 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row33_col7\" class=\"data row33 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row33_col8\" class=\"data row33 col8\" >0.998788</td>\n",
       "      <td id=\"T_93ff9_row33_col9\" class=\"data row33 col9\" >1.001516</td>\n",
       "      <td id=\"T_93ff9_row33_col10\" class=\"data row33 col10\" >1.000165</td>\n",
       "      <td id=\"T_93ff9_row33_col11\" class=\"data row33 col11\" >0.998382</td>\n",
       "      <td id=\"T_93ff9_row33_col12\" class=\"data row33 col12\" >10.585388</td>\n",
       "      <td id=\"T_93ff9_row33_col13\" class=\"data row33 col13\" >13.444389</td>\n",
       "      <td id=\"T_93ff9_row33_col14\" class=\"data row33 col14\" >36.993744</td>\n",
       "      <td id=\"T_93ff9_row33_col15\" class=\"data row33 col15\" >36.311432</td>\n",
       "      <td id=\"T_93ff9_row33_col16\" class=\"data row33 col16\" >0.055207</td>\n",
       "      <td id=\"T_93ff9_row33_col17\" class=\"data row33 col17\" >-0.041032</td>\n",
       "      <td id=\"T_93ff9_row33_col18\" class=\"data row33 col18\" >-0.021553</td>\n",
       "      <td id=\"T_93ff9_row33_col19\" class=\"data row33 col19\" >0.165041</td>\n",
       "      <td id=\"T_93ff9_row33_col20\" class=\"data row33 col20\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row33_col21\" class=\"data row33 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row33_col22\" class=\"data row33 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row33_col23\" class=\"data row33 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row33_col24\" class=\"data row33 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row33_col25\" class=\"data row33 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row33_col26\" class=\"data row33 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row33_col27\" class=\"data row33 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row33_col28\" class=\"data row33 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row33_col29\" class=\"data row33 col29\" >18</td>\n",
       "      <td id=\"T_93ff9_row33_col30\" class=\"data row33 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row33_col31\" class=\"data row33 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row34\" class=\"row_heading level0 row34\" >7</th>\n",
       "      <td id=\"T_93ff9_row34_col0\" class=\"data row34 col0\" >0.666667</td>\n",
       "      <td id=\"T_93ff9_row34_col1\" class=\"data row34 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row34_col2\" class=\"data row34 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row34_col3\" class=\"data row34 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row34_col4\" class=\"data row34 col4\" >0.998004</td>\n",
       "      <td id=\"T_93ff9_row34_col5\" class=\"data row34 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row34_col6\" class=\"data row34 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row34_col7\" class=\"data row34 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row34_col8\" class=\"data row34 col8\" >1.003928</td>\n",
       "      <td id=\"T_93ff9_row34_col9\" class=\"data row34 col9\" >1.003178</td>\n",
       "      <td id=\"T_93ff9_row34_col10\" class=\"data row34 col10\" >1.005981</td>\n",
       "      <td id=\"T_93ff9_row34_col11\" class=\"data row34 col11\" >1.004927</td>\n",
       "      <td id=\"T_93ff9_row34_col12\" class=\"data row34 col12\" >10.308426</td>\n",
       "      <td id=\"T_93ff9_row34_col13\" class=\"data row34 col13\" >13.410423</td>\n",
       "      <td id=\"T_93ff9_row34_col14\" class=\"data row34 col14\" >36.872787</td>\n",
       "      <td id=\"T_93ff9_row34_col15\" class=\"data row34 col15\" >35.870087</td>\n",
       "      <td id=\"T_93ff9_row34_col16\" class=\"data row34 col16\" >-0.222655</td>\n",
       "      <td id=\"T_93ff9_row34_col17\" class=\"data row34 col17\" >-0.074996</td>\n",
       "      <td id=\"T_93ff9_row34_col18\" class=\"data row34 col18\" >-0.142515</td>\n",
       "      <td id=\"T_93ff9_row34_col19\" class=\"data row34 col19\" >-0.276314</td>\n",
       "      <td id=\"T_93ff9_row34_col20\" class=\"data row34 col20\" >0.000008</td>\n",
       "      <td id=\"T_93ff9_row34_col21\" class=\"data row34 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row34_col22\" class=\"data row34 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row34_col23\" class=\"data row34 col23\" >0.077451</td>\n",
       "      <td id=\"T_93ff9_row34_col24\" class=\"data row34 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row34_col25\" class=\"data row34 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row34_col26\" class=\"data row34 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row34_col27\" class=\"data row34 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row34_col28\" class=\"data row34 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row34_col29\" class=\"data row34 col29\" >58</td>\n",
       "      <td id=\"T_93ff9_row34_col30\" class=\"data row34 col30\" >106</td>\n",
       "      <td id=\"T_93ff9_row34_col31\" class=\"data row34 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row35\" class=\"row_heading level0 row35\" >38</th>\n",
       "      <td id=\"T_93ff9_row35_col0\" class=\"data row35 col0\" >0.666667</td>\n",
       "      <td id=\"T_93ff9_row35_col1\" class=\"data row35 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row35_col2\" class=\"data row35 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row35_col3\" class=\"data row35 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row35_col4\" class=\"data row35 col4\" >0.998004</td>\n",
       "      <td id=\"T_93ff9_row35_col5\" class=\"data row35 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row35_col6\" class=\"data row35 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row35_col7\" class=\"data row35 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row35_col8\" class=\"data row35 col8\" >1.000053</td>\n",
       "      <td id=\"T_93ff9_row35_col9\" class=\"data row35 col9\" >1.002949</td>\n",
       "      <td id=\"T_93ff9_row35_col10\" class=\"data row35 col10\" >1.000785</td>\n",
       "      <td id=\"T_93ff9_row35_col11\" class=\"data row35 col11\" >0.999643</td>\n",
       "      <td id=\"T_93ff9_row35_col12\" class=\"data row35 col12\" >10.522766</td>\n",
       "      <td id=\"T_93ff9_row35_col13\" class=\"data row35 col13\" >13.438568</td>\n",
       "      <td id=\"T_93ff9_row35_col14\" class=\"data row35 col14\" >36.950348</td>\n",
       "      <td id=\"T_93ff9_row35_col15\" class=\"data row35 col15\" >36.116913</td>\n",
       "      <td id=\"T_93ff9_row35_col16\" class=\"data row35 col16\" >-0.015868</td>\n",
       "      <td id=\"T_93ff9_row35_col17\" class=\"data row35 col17\" >-0.046855</td>\n",
       "      <td id=\"T_93ff9_row35_col18\" class=\"data row35 col18\" >-0.064949</td>\n",
       "      <td id=\"T_93ff9_row35_col19\" class=\"data row35 col19\" >-0.029468</td>\n",
       "      <td id=\"T_93ff9_row35_col20\" class=\"data row35 col20\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row35_col21\" class=\"data row35 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row35_col22\" class=\"data row35 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row35_col23\" class=\"data row35 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row35_col24\" class=\"data row35 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row35_col25\" class=\"data row35 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row35_col26\" class=\"data row35 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row35_col27\" class=\"data row35 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row35_col28\" class=\"data row35 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row35_col29\" class=\"data row35 col29\" >57</td>\n",
       "      <td id=\"T_93ff9_row35_col30\" class=\"data row35 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row35_col31\" class=\"data row35 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row36\" class=\"row_heading level0 row36\" >16</th>\n",
       "      <td id=\"T_93ff9_row36_col0\" class=\"data row36 col0\" >0.666667</td>\n",
       "      <td id=\"T_93ff9_row36_col1\" class=\"data row36 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row36_col2\" class=\"data row36 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row36_col3\" class=\"data row36 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row36_col4\" class=\"data row36 col4\" >0.998004</td>\n",
       "      <td id=\"T_93ff9_row36_col5\" class=\"data row36 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row36_col6\" class=\"data row36 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row36_col7\" class=\"data row36 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row36_col8\" class=\"data row36 col8\" >1.000736</td>\n",
       "      <td id=\"T_93ff9_row36_col9\" class=\"data row36 col9\" >1.002213</td>\n",
       "      <td id=\"T_93ff9_row36_col10\" class=\"data row36 col10\" >0.999950</td>\n",
       "      <td id=\"T_93ff9_row36_col11\" class=\"data row36 col11\" >1.000065</td>\n",
       "      <td id=\"T_93ff9_row36_col12\" class=\"data row36 col12\" >10.512680</td>\n",
       "      <td id=\"T_93ff9_row36_col13\" class=\"data row36 col13\" >13.458336</td>\n",
       "      <td id=\"T_93ff9_row36_col14\" class=\"data row36 col14\" >36.990242</td>\n",
       "      <td id=\"T_93ff9_row36_col15\" class=\"data row36 col15\" >36.151749</td>\n",
       "      <td id=\"T_93ff9_row36_col16\" class=\"data row36 col16\" >-0.022142</td>\n",
       "      <td id=\"T_93ff9_row36_col17\" class=\"data row36 col17\" >-0.027078</td>\n",
       "      <td id=\"T_93ff9_row36_col18\" class=\"data row36 col18\" >-0.025055</td>\n",
       "      <td id=\"T_93ff9_row36_col19\" class=\"data row36 col19\" >0.005355</td>\n",
       "      <td id=\"T_93ff9_row36_col20\" class=\"data row36 col20\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row36_col21\" class=\"data row36 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row36_col22\" class=\"data row36 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row36_col23\" class=\"data row36 col23\" >0.000181</td>\n",
       "      <td id=\"T_93ff9_row36_col24\" class=\"data row36 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row36_col25\" class=\"data row36 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row36_col26\" class=\"data row36 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row36_col27\" class=\"data row36 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row36_col28\" class=\"data row36 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row36_col29\" class=\"data row36 col29\" >5</td>\n",
       "      <td id=\"T_93ff9_row36_col30\" class=\"data row36 col30\" >92</td>\n",
       "      <td id=\"T_93ff9_row36_col31\" class=\"data row36 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row37\" class=\"row_heading level0 row37\" >15</th>\n",
       "      <td id=\"T_93ff9_row37_col0\" class=\"data row37 col0\" >0.666667</td>\n",
       "      <td id=\"T_93ff9_row37_col1\" class=\"data row37 col1\" >0.921875</td>\n",
       "      <td id=\"T_93ff9_row37_col2\" class=\"data row37 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row37_col3\" class=\"data row37 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row37_col4\" class=\"data row37 col4\" >0.998004</td>\n",
       "      <td id=\"T_93ff9_row37_col5\" class=\"data row37 col5\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row37_col6\" class=\"data row37 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row37_col7\" class=\"data row37 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row37_col8\" class=\"data row37 col8\" >0.999272</td>\n",
       "      <td id=\"T_93ff9_row37_col9\" class=\"data row37 col9\" >1.001193</td>\n",
       "      <td id=\"T_93ff9_row37_col10\" class=\"data row37 col10\" >0.999268</td>\n",
       "      <td id=\"T_93ff9_row37_col11\" class=\"data row37 col11\" >0.998434</td>\n",
       "      <td id=\"T_93ff9_row37_col12\" class=\"data row37 col12\" >10.571739</td>\n",
       "      <td id=\"T_93ff9_row37_col13\" class=\"data row37 col13\" >13.523819</td>\n",
       "      <td id=\"T_93ff9_row37_col14\" class=\"data row37 col14\" >36.995064</td>\n",
       "      <td id=\"T_93ff9_row37_col15\" class=\"data row37 col15\" >36.219757</td>\n",
       "      <td id=\"T_93ff9_row37_col16\" class=\"data row37 col16\" >0.041879</td>\n",
       "      <td id=\"T_93ff9_row37_col17\" class=\"data row37 col17\" >0.038398</td>\n",
       "      <td id=\"T_93ff9_row37_col18\" class=\"data row37 col18\" >-0.020243</td>\n",
       "      <td id=\"T_93ff9_row37_col19\" class=\"data row37 col19\" >0.073371</td>\n",
       "      <td id=\"T_93ff9_row37_col20\" class=\"data row37 col20\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row37_col21\" class=\"data row37 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row37_col22\" class=\"data row37 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row37_col23\" class=\"data row37 col23\" >0.001938</td>\n",
       "      <td id=\"T_93ff9_row37_col24\" class=\"data row37 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row37_col25\" class=\"data row37 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row37_col26\" class=\"data row37 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row37_col27\" class=\"data row37 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row37_col28\" class=\"data row37 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row37_col29\" class=\"data row37 col29\" >34</td>\n",
       "      <td id=\"T_93ff9_row37_col30\" class=\"data row37 col30\" >25</td>\n",
       "      <td id=\"T_93ff9_row37_col31\" class=\"data row37 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row38\" class=\"row_heading level0 row38\" >34</th>\n",
       "      <td id=\"T_93ff9_row38_col0\" class=\"data row38 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row38_col1\" class=\"data row38 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row38_col2\" class=\"data row38 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row38_col3\" class=\"data row38 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row38_col4\" class=\"data row38 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row38_col5\" class=\"data row38 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row38_col6\" class=\"data row38 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row38_col7\" class=\"data row38 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row38_col8\" class=\"data row38 col8\" >1.000183</td>\n",
       "      <td id=\"T_93ff9_row38_col9\" class=\"data row38 col9\" >1.002212</td>\n",
       "      <td id=\"T_93ff9_row38_col10\" class=\"data row38 col10\" >1.001775</td>\n",
       "      <td id=\"T_93ff9_row38_col11\" class=\"data row38 col11\" >1.000899</td>\n",
       "      <td id=\"T_93ff9_row38_col12\" class=\"data row38 col12\" >10.491425</td>\n",
       "      <td id=\"T_93ff9_row38_col13\" class=\"data row38 col13\" >13.472656</td>\n",
       "      <td id=\"T_93ff9_row38_col14\" class=\"data row38 col14\" >36.978783</td>\n",
       "      <td id=\"T_93ff9_row38_col15\" class=\"data row38 col15\" >36.158890</td>\n",
       "      <td id=\"T_93ff9_row38_col16\" class=\"data row38 col16\" >-0.039254</td>\n",
       "      <td id=\"T_93ff9_row38_col17\" class=\"data row38 col17\" >-0.012770</td>\n",
       "      <td id=\"T_93ff9_row38_col18\" class=\"data row38 col18\" >-0.036514</td>\n",
       "      <td id=\"T_93ff9_row38_col19\" class=\"data row38 col19\" >0.012506</td>\n",
       "      <td id=\"T_93ff9_row38_col20\" class=\"data row38 col20\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row38_col21\" class=\"data row38 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row38_col22\" class=\"data row38 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row38_col23\" class=\"data row38 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row38_col24\" class=\"data row38 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row38_col25\" class=\"data row38 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row38_col26\" class=\"data row38 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row38_col27\" class=\"data row38 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row38_col28\" class=\"data row38 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row38_col29\" class=\"data row38 col29\" >24</td>\n",
       "      <td id=\"T_93ff9_row38_col30\" class=\"data row38 col30\" >1</td>\n",
       "      <td id=\"T_93ff9_row38_col31\" class=\"data row38 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row39\" class=\"row_heading level0 row39\" >33</th>\n",
       "      <td id=\"T_93ff9_row39_col0\" class=\"data row39 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row39_col1\" class=\"data row39 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row39_col2\" class=\"data row39 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row39_col3\" class=\"data row39 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row39_col4\" class=\"data row39 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row39_col5\" class=\"data row39 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row39_col6\" class=\"data row39 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row39_col7\" class=\"data row39 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row39_col8\" class=\"data row39 col8\" >1.000144</td>\n",
       "      <td id=\"T_93ff9_row39_col9\" class=\"data row39 col9\" >1.002964</td>\n",
       "      <td id=\"T_93ff9_row39_col10\" class=\"data row39 col10\" >0.999291</td>\n",
       "      <td id=\"T_93ff9_row39_col11\" class=\"data row39 col11\" >0.999731</td>\n",
       "      <td id=\"T_93ff9_row39_col12\" class=\"data row39 col12\" >10.517159</td>\n",
       "      <td id=\"T_93ff9_row39_col13\" class=\"data row39 col13\" >13.459114</td>\n",
       "      <td id=\"T_93ff9_row39_col14\" class=\"data row39 col14\" >36.993027</td>\n",
       "      <td id=\"T_93ff9_row39_col15\" class=\"data row39 col15\" >36.107346</td>\n",
       "      <td id=\"T_93ff9_row39_col16\" class=\"data row39 col16\" >-0.018767</td>\n",
       "      <td id=\"T_93ff9_row39_col17\" class=\"data row39 col17\" >-0.026306</td>\n",
       "      <td id=\"T_93ff9_row39_col18\" class=\"data row39 col18\" >-0.022277</td>\n",
       "      <td id=\"T_93ff9_row39_col19\" class=\"data row39 col19\" >-0.039052</td>\n",
       "      <td id=\"T_93ff9_row39_col20\" class=\"data row39 col20\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row39_col21\" class=\"data row39 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row39_col22\" class=\"data row39 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row39_col23\" class=\"data row39 col23\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row39_col24\" class=\"data row39 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row39_col25\" class=\"data row39 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row39_col26\" class=\"data row39 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row39_col27\" class=\"data row39 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row39_col28\" class=\"data row39 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row39_col29\" class=\"data row39 col29\" >64</td>\n",
       "      <td id=\"T_93ff9_row39_col30\" class=\"data row39 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row39_col31\" class=\"data row39 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row40\" class=\"row_heading level0 row40\" >51</th>\n",
       "      <td id=\"T_93ff9_row40_col0\" class=\"data row40 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row40_col1\" class=\"data row40 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row40_col2\" class=\"data row40 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row40_col3\" class=\"data row40 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row40_col4\" class=\"data row40 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row40_col5\" class=\"data row40 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row40_col6\" class=\"data row40 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row40_col7\" class=\"data row40 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row40_col8\" class=\"data row40 col8\" >0.999426</td>\n",
       "      <td id=\"T_93ff9_row40_col9\" class=\"data row40 col9\" >1.002304</td>\n",
       "      <td id=\"T_93ff9_row40_col10\" class=\"data row40 col10\" >1.000556</td>\n",
       "      <td id=\"T_93ff9_row40_col11\" class=\"data row40 col11\" >1.000634</td>\n",
       "      <td id=\"T_93ff9_row40_col12\" class=\"data row40 col12\" >10.498367</td>\n",
       "      <td id=\"T_93ff9_row40_col13\" class=\"data row40 col13\" >13.469688</td>\n",
       "      <td id=\"T_93ff9_row40_col14\" class=\"data row40 col14\" >37.004456</td>\n",
       "      <td id=\"T_93ff9_row40_col15\" class=\"data row40 col15\" >36.125084</td>\n",
       "      <td id=\"T_93ff9_row40_col16\" class=\"data row40 col16\" >-0.034689</td>\n",
       "      <td id=\"T_93ff9_row40_col17\" class=\"data row40 col17\" >-0.015733</td>\n",
       "      <td id=\"T_93ff9_row40_col18\" class=\"data row40 col18\" >-0.010842</td>\n",
       "      <td id=\"T_93ff9_row40_col19\" class=\"data row40 col19\" >-0.021308</td>\n",
       "      <td id=\"T_93ff9_row40_col20\" class=\"data row40 col20\" >0.000001</td>\n",
       "      <td id=\"T_93ff9_row40_col21\" class=\"data row40 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row40_col22\" class=\"data row40 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row40_col23\" class=\"data row40 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row40_col24\" class=\"data row40 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row40_col25\" class=\"data row40 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row40_col26\" class=\"data row40 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row40_col27\" class=\"data row40 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row40_col28\" class=\"data row40 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row40_col29\" class=\"data row40 col29\" >64</td>\n",
       "      <td id=\"T_93ff9_row40_col30\" class=\"data row40 col30\" >113</td>\n",
       "      <td id=\"T_93ff9_row40_col31\" class=\"data row40 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row41\" class=\"row_heading level0 row41\" >23</th>\n",
       "      <td id=\"T_93ff9_row41_col0\" class=\"data row41 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row41_col1\" class=\"data row41 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row41_col2\" class=\"data row41 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row41_col3\" class=\"data row41 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row41_col4\" class=\"data row41 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row41_col5\" class=\"data row41 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row41_col6\" class=\"data row41 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row41_col7\" class=\"data row41 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row41_col8\" class=\"data row41 col8\" >1.002771</td>\n",
       "      <td id=\"T_93ff9_row41_col9\" class=\"data row41 col9\" >1.000802</td>\n",
       "      <td id=\"T_93ff9_row41_col10\" class=\"data row41 col10\" >1.003878</td>\n",
       "      <td id=\"T_93ff9_row41_col11\" class=\"data row41 col11\" >1.002592</td>\n",
       "      <td id=\"T_93ff9_row41_col12\" class=\"data row41 col12\" >10.444824</td>\n",
       "      <td id=\"T_93ff9_row41_col13\" class=\"data row41 col13\" >13.443825</td>\n",
       "      <td id=\"T_93ff9_row41_col14\" class=\"data row41 col14\" >36.787949</td>\n",
       "      <td id=\"T_93ff9_row41_col15\" class=\"data row41 col15\" >36.014229</td>\n",
       "      <td id=\"T_93ff9_row41_col16\" class=\"data row41 col16\" >-0.090933</td>\n",
       "      <td id=\"T_93ff9_row41_col17\" class=\"data row41 col17\" >-0.041592</td>\n",
       "      <td id=\"T_93ff9_row41_col18\" class=\"data row41 col18\" >-0.227349</td>\n",
       "      <td id=\"T_93ff9_row41_col19\" class=\"data row41 col19\" >-0.132172</td>\n",
       "      <td id=\"T_93ff9_row41_col20\" class=\"data row41 col20\" >0.000021</td>\n",
       "      <td id=\"T_93ff9_row41_col21\" class=\"data row41 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col22\" class=\"data row41 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col23\" class=\"data row41 col23\" >0.001168</td>\n",
       "      <td id=\"T_93ff9_row41_col24\" class=\"data row41 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row41_col25\" class=\"data row41 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col26\" class=\"data row41 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col27\" class=\"data row41 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col28\" class=\"data row41 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row41_col29\" class=\"data row41 col29\" >55</td>\n",
       "      <td id=\"T_93ff9_row41_col30\" class=\"data row41 col30\" >70</td>\n",
       "      <td id=\"T_93ff9_row41_col31\" class=\"data row41 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row42\" class=\"row_heading level0 row42\" >44</th>\n",
       "      <td id=\"T_93ff9_row42_col0\" class=\"data row42 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row42_col1\" class=\"data row42 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row42_col2\" class=\"data row42 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row42_col3\" class=\"data row42 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row42_col4\" class=\"data row42 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row42_col5\" class=\"data row42 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row42_col6\" class=\"data row42 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row42_col7\" class=\"data row42 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row42_col8\" class=\"data row42 col8\" >0.999021</td>\n",
       "      <td id=\"T_93ff9_row42_col9\" class=\"data row42 col9\" >0.999685</td>\n",
       "      <td id=\"T_93ff9_row42_col10\" class=\"data row42 col10\" >0.998413</td>\n",
       "      <td id=\"T_93ff9_row42_col11\" class=\"data row42 col11\" >0.997457</td>\n",
       "      <td id=\"T_93ff9_row42_col12\" class=\"data row42 col12\" >10.568375</td>\n",
       "      <td id=\"T_93ff9_row42_col13\" class=\"data row42 col13\" >13.506126</td>\n",
       "      <td id=\"T_93ff9_row42_col14\" class=\"data row42 col14\" >37.122070</td>\n",
       "      <td id=\"T_93ff9_row42_col15\" class=\"data row42 col15\" >36.255867</td>\n",
       "      <td id=\"T_93ff9_row42_col16\" class=\"data row42 col16\" >0.036394</td>\n",
       "      <td id=\"T_93ff9_row42_col17\" class=\"data row42 col17\" >0.020708</td>\n",
       "      <td id=\"T_93ff9_row42_col18\" class=\"data row42 col18\" >0.106761</td>\n",
       "      <td id=\"T_93ff9_row42_col19\" class=\"data row42 col19\" >0.109485</td>\n",
       "      <td id=\"T_93ff9_row42_col20\" class=\"data row42 col20\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row42_col21\" class=\"data row42 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row42_col22\" class=\"data row42 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row42_col23\" class=\"data row42 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row42_col24\" class=\"data row42 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row42_col25\" class=\"data row42 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row42_col26\" class=\"data row42 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row42_col27\" class=\"data row42 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row42_col28\" class=\"data row42 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row42_col29\" class=\"data row42 col29\" >41</td>\n",
       "      <td id=\"T_93ff9_row42_col30\" class=\"data row42 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row42_col31\" class=\"data row42 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row43\" class=\"row_heading level0 row43\" >3</th>\n",
       "      <td id=\"T_93ff9_row43_col0\" class=\"data row43 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row43_col1\" class=\"data row43 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row43_col2\" class=\"data row43 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row43_col3\" class=\"data row43 col3\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row43_col4\" class=\"data row43 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row43_col5\" class=\"data row43 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row43_col6\" class=\"data row43 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row43_col7\" class=\"data row43 col7\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row43_col8\" class=\"data row43 col8\" >1.005575</td>\n",
       "      <td id=\"T_93ff9_row43_col9\" class=\"data row43 col9\" >1.021897</td>\n",
       "      <td id=\"T_93ff9_row43_col10\" class=\"data row43 col10\" >1.018088</td>\n",
       "      <td id=\"T_93ff9_row43_col11\" class=\"data row43 col11\" >1.010340</td>\n",
       "      <td id=\"T_93ff9_row43_col12\" class=\"data row43 col12\" >10.281410</td>\n",
       "      <td id=\"T_93ff9_row43_col13\" class=\"data row43 col13\" >13.325325</td>\n",
       "      <td id=\"T_93ff9_row43_col14\" class=\"data row43 col14\" >36.346840</td>\n",
       "      <td id=\"T_93ff9_row43_col15\" class=\"data row43 col15\" >35.712959</td>\n",
       "      <td id=\"T_93ff9_row43_col16\" class=\"data row43 col16\" >-0.254718</td>\n",
       "      <td id=\"T_93ff9_row43_col17\" class=\"data row43 col17\" >-0.160097</td>\n",
       "      <td id=\"T_93ff9_row43_col18\" class=\"data row43 col18\" >-0.668466</td>\n",
       "      <td id=\"T_93ff9_row43_col19\" class=\"data row43 col19\" >-0.433429</td>\n",
       "      <td id=\"T_93ff9_row43_col20\" class=\"data row43 col20\" >0.000029</td>\n",
       "      <td id=\"T_93ff9_row43_col21\" class=\"data row43 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row43_col22\" class=\"data row43 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row43_col23\" class=\"data row43 col23\" >0.000002</td>\n",
       "      <td id=\"T_93ff9_row43_col24\" class=\"data row43 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row43_col25\" class=\"data row43 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row43_col26\" class=\"data row43 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row43_col27\" class=\"data row43 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row43_col28\" class=\"data row43 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row43_col29\" class=\"data row43 col29\" >24</td>\n",
       "      <td id=\"T_93ff9_row43_col30\" class=\"data row43 col30\" >85</td>\n",
       "      <td id=\"T_93ff9_row43_col31\" class=\"data row43 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row44\" class=\"row_heading level0 row44\" >39</th>\n",
       "      <td id=\"T_93ff9_row44_col0\" class=\"data row44 col0\" >0.665333</td>\n",
       "      <td id=\"T_93ff9_row44_col1\" class=\"data row44 col1\" >0.906250</td>\n",
       "      <td id=\"T_93ff9_row44_col2\" class=\"data row44 col2\" >0.968750</td>\n",
       "      <td id=\"T_93ff9_row44_col3\" class=\"data row44 col3\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row44_col4\" class=\"data row44 col4\" >0.996008</td>\n",
       "      <td id=\"T_93ff9_row44_col5\" class=\"data row44 col5\" >0.983051</td>\n",
       "      <td id=\"T_93ff9_row44_col6\" class=\"data row44 col6\" >1.000000</td>\n",
       "      <td id=\"T_93ff9_row44_col7\" class=\"data row44 col7\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row44_col8\" class=\"data row44 col8\" >2.319046</td>\n",
       "      <td id=\"T_93ff9_row44_col9\" class=\"data row44 col9\" >1.465183</td>\n",
       "      <td id=\"T_93ff9_row44_col10\" class=\"data row44 col10\" >2.076751</td>\n",
       "      <td id=\"T_93ff9_row44_col11\" class=\"data row44 col11\" >2.208875</td>\n",
       "      <td id=\"T_93ff9_row44_col12\" class=\"data row44 col12\" >14.709915</td>\n",
       "      <td id=\"T_93ff9_row44_col13\" class=\"data row44 col13\" >19.628944</td>\n",
       "      <td id=\"T_93ff9_row44_col14\" class=\"data row44 col14\" >50.478912</td>\n",
       "      <td id=\"T_93ff9_row44_col15\" class=\"data row44 col15\" >47.148819</td>\n",
       "      <td id=\"T_93ff9_row44_col16\" class=\"data row44 col16\" >4.559641</td>\n",
       "      <td id=\"T_93ff9_row44_col17\" class=\"data row44 col17\" >6.143524</td>\n",
       "      <td id=\"T_93ff9_row44_col18\" class=\"data row44 col18\" >13.463610</td>\n",
       "      <td id=\"T_93ff9_row44_col19\" class=\"data row44 col19\" >11.002423</td>\n",
       "      <td id=\"T_93ff9_row44_col20\" class=\"data row44 col20\" >0.000530</td>\n",
       "      <td id=\"T_93ff9_row44_col21\" class=\"data row44 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row44_col22\" class=\"data row44 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row44_col23\" class=\"data row44 col23\" >2.000000</td>\n",
       "      <td id=\"T_93ff9_row44_col24\" class=\"data row44 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row44_col25\" class=\"data row44 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row44_col26\" class=\"data row44 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row44_col27\" class=\"data row44 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row44_col28\" class=\"data row44 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row44_col29\" class=\"data row44 col29\" >1</td>\n",
       "      <td id=\"T_93ff9_row44_col30\" class=\"data row44 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row44_col31\" class=\"data row44 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row45\" class=\"row_heading level0 row45\" >20</th>\n",
       "      <td id=\"T_93ff9_row45_col0\" class=\"data row45 col0\" >0.653333</td>\n",
       "      <td id=\"T_93ff9_row45_col1\" class=\"data row45 col1\" >0.890625</td>\n",
       "      <td id=\"T_93ff9_row45_col2\" class=\"data row45 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row45_col3\" class=\"data row45 col3\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row45_col4\" class=\"data row45 col4\" >0.978044</td>\n",
       "      <td id=\"T_93ff9_row45_col5\" class=\"data row45 col5\" >0.966102</td>\n",
       "      <td id=\"T_93ff9_row45_col6\" class=\"data row45 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row45_col7\" class=\"data row45 col7\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row45_col8\" class=\"data row45 col8\" >1.060176</td>\n",
       "      <td id=\"T_93ff9_row45_col9\" class=\"data row45 col9\" >1.017646</td>\n",
       "      <td id=\"T_93ff9_row45_col10\" class=\"data row45 col10\" >1.069857</td>\n",
       "      <td id=\"T_93ff9_row45_col11\" class=\"data row45 col11\" >1.059892</td>\n",
       "      <td id=\"T_93ff9_row45_col12\" class=\"data row45 col12\" >8.692955</td>\n",
       "      <td id=\"T_93ff9_row45_col13\" class=\"data row45 col13\" >12.865524</td>\n",
       "      <td id=\"T_93ff9_row45_col14\" class=\"data row45 col14\" >34.616219</td>\n",
       "      <td id=\"T_93ff9_row45_col15\" class=\"data row45 col15\" >33.998032</td>\n",
       "      <td id=\"T_93ff9_row45_col16\" class=\"data row45 col16\" >-1.829554</td>\n",
       "      <td id=\"T_93ff9_row45_col17\" class=\"data row45 col17\" >-0.619892</td>\n",
       "      <td id=\"T_93ff9_row45_col18\" class=\"data row45 col18\" >-2.399088</td>\n",
       "      <td id=\"T_93ff9_row45_col19\" class=\"data row45 col19\" >-2.148368</td>\n",
       "      <td id=\"T_93ff9_row45_col20\" class=\"data row45 col20\" >0.000126</td>\n",
       "      <td id=\"T_93ff9_row45_col21\" class=\"data row45 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row45_col22\" class=\"data row45 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row45_col23\" class=\"data row45 col23\" >0.005297</td>\n",
       "      <td id=\"T_93ff9_row45_col24\" class=\"data row45 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row45_col25\" class=\"data row45 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row45_col26\" class=\"data row45 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row45_col27\" class=\"data row45 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row45_col28\" class=\"data row45 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row45_col29\" class=\"data row45 col29\" >43</td>\n",
       "      <td id=\"T_93ff9_row45_col30\" class=\"data row45 col30\" >103</td>\n",
       "      <td id=\"T_93ff9_row45_col31\" class=\"data row45 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row46\" class=\"row_heading level0 row46\" >5</th>\n",
       "      <td id=\"T_93ff9_row46_col0\" class=\"data row46 col0\" >0.621333</td>\n",
       "      <td id=\"T_93ff9_row46_col1\" class=\"data row46 col1\" >0.843750</td>\n",
       "      <td id=\"T_93ff9_row46_col2\" class=\"data row46 col2\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row46_col3\" class=\"data row46 col3\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row46_col4\" class=\"data row46 col4\" >0.930140</td>\n",
       "      <td id=\"T_93ff9_row46_col5\" class=\"data row46 col5\" >0.915254</td>\n",
       "      <td id=\"T_93ff9_row46_col6\" class=\"data row46 col6\" >1.016129</td>\n",
       "      <td id=\"T_93ff9_row46_col7\" class=\"data row46 col7\" >0.984375</td>\n",
       "      <td id=\"T_93ff9_row46_col8\" class=\"data row46 col8\" >6.255144</td>\n",
       "      <td id=\"T_93ff9_row46_col9\" class=\"data row46 col9\" >26.274063</td>\n",
       "      <td id=\"T_93ff9_row46_col10\" class=\"data row46 col10\" >6.437701</td>\n",
       "      <td id=\"T_93ff9_row46_col11\" class=\"data row46 col11\" >6.767000</td>\n",
       "      <td id=\"T_93ff9_row46_col12\" class=\"data row46 col12\" >14.208282</td>\n",
       "      <td id=\"T_93ff9_row46_col13\" class=\"data row46 col13\" >20.402145</td>\n",
       "      <td id=\"T_93ff9_row46_col14\" class=\"data row46 col14\" >64.207840</td>\n",
       "      <td id=\"T_93ff9_row46_col15\" class=\"data row46 col15\" >53.734344</td>\n",
       "      <td id=\"T_93ff9_row46_col16\" class=\"data row46 col16\" >3.814337</td>\n",
       "      <td id=\"T_93ff9_row46_col17\" class=\"data row46 col17\" >6.916715</td>\n",
       "      <td id=\"T_93ff9_row46_col18\" class=\"data row46 col18\" >27.192532</td>\n",
       "      <td id=\"T_93ff9_row46_col19\" class=\"data row46 col19\" >17.587957</td>\n",
       "      <td id=\"T_93ff9_row46_col20\" class=\"data row46 col20\" >0.002098</td>\n",
       "      <td id=\"T_93ff9_row46_col21\" class=\"data row46 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row46_col22\" class=\"data row46 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row46_col23\" class=\"data row46 col23\" >0.037145</td>\n",
       "      <td id=\"T_93ff9_row46_col24\" class=\"data row46 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row46_col25\" class=\"data row46 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row46_col26\" class=\"data row46 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row46_col27\" class=\"data row46 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row46_col28\" class=\"data row46 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row46_col29\" class=\"data row46 col29\" >7</td>\n",
       "      <td id=\"T_93ff9_row46_col30\" class=\"data row46 col30\" >17</td>\n",
       "      <td id=\"T_93ff9_row46_col31\" class=\"data row46 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row47\" class=\"row_heading level0 row47\" >24</th>\n",
       "      <td id=\"T_93ff9_row47_col0\" class=\"data row47 col0\" >0.580000</td>\n",
       "      <td id=\"T_93ff9_row47_col1\" class=\"data row47 col1\" >0.890625</td>\n",
       "      <td id=\"T_93ff9_row47_col2\" class=\"data row47 col2\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row47_col3\" class=\"data row47 col3\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row47_col4\" class=\"data row47 col4\" >0.868263</td>\n",
       "      <td id=\"T_93ff9_row47_col5\" class=\"data row47 col5\" >0.966102</td>\n",
       "      <td id=\"T_93ff9_row47_col6\" class=\"data row47 col6\" >0.983871</td>\n",
       "      <td id=\"T_93ff9_row47_col7\" class=\"data row47 col7\" >0.953125</td>\n",
       "      <td id=\"T_93ff9_row47_col8\" class=\"data row47 col8\" >1.273636</td>\n",
       "      <td id=\"T_93ff9_row47_col9\" class=\"data row47 col9\" >1.135030</td>\n",
       "      <td id=\"T_93ff9_row47_col10\" class=\"data row47 col10\" >1.402590</td>\n",
       "      <td id=\"T_93ff9_row47_col11\" class=\"data row47 col11\" >1.349668</td>\n",
       "      <td id=\"T_93ff9_row47_col12\" class=\"data row47 col12\" >2.729538</td>\n",
       "      <td id=\"T_93ff9_row47_col13\" class=\"data row47 col13\" >12.133224</td>\n",
       "      <td id=\"T_93ff9_row47_col14\" class=\"data row47 col14\" >31.682785</td>\n",
       "      <td id=\"T_93ff9_row47_col15\" class=\"data row47 col15\" >29.499878</td>\n",
       "      <td id=\"T_93ff9_row47_col16\" class=\"data row47 col16\" >-7.746806</td>\n",
       "      <td id=\"T_93ff9_row47_col17\" class=\"data row47 col17\" >-1.352195</td>\n",
       "      <td id=\"T_93ff9_row47_col18\" class=\"data row47 col18\" >-5.332525</td>\n",
       "      <td id=\"T_93ff9_row47_col19\" class=\"data row47 col19\" >-6.646520</td>\n",
       "      <td id=\"T_93ff9_row47_col20\" class=\"data row47 col20\" >0.000076</td>\n",
       "      <td id=\"T_93ff9_row47_col21\" class=\"data row47 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row47_col22\" class=\"data row47 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row47_col23\" class=\"data row47 col23\" >0.000009</td>\n",
       "      <td id=\"T_93ff9_row47_col24\" class=\"data row47 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row47_col25\" class=\"data row47 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row47_col26\" class=\"data row47 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row47_col27\" class=\"data row47 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row47_col28\" class=\"data row47 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row47_col29\" class=\"data row47 col29\" >37</td>\n",
       "      <td id=\"T_93ff9_row47_col30\" class=\"data row47 col30\" >14</td>\n",
       "      <td id=\"T_93ff9_row47_col31\" class=\"data row47 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row48\" class=\"row_heading level0 row48\" >10</th>\n",
       "      <td id=\"T_93ff9_row48_col0\" class=\"data row48 col0\" >0.400000</td>\n",
       "      <td id=\"T_93ff9_row48_col1\" class=\"data row48 col1\" >0.859375</td>\n",
       "      <td id=\"T_93ff9_row48_col2\" class=\"data row48 col2\" >0.875000</td>\n",
       "      <td id=\"T_93ff9_row48_col3\" class=\"data row48 col3\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row48_col4\" class=\"data row48 col4\" >0.598802</td>\n",
       "      <td id=\"T_93ff9_row48_col5\" class=\"data row48 col5\" >0.932203</td>\n",
       "      <td id=\"T_93ff9_row48_col6\" class=\"data row48 col6\" >0.903226</td>\n",
       "      <td id=\"T_93ff9_row48_col7\" class=\"data row48 col7\" >0.937500</td>\n",
       "      <td id=\"T_93ff9_row48_col8\" class=\"data row48 col8\" >12.382243</td>\n",
       "      <td id=\"T_93ff9_row48_col9\" class=\"data row48 col9\" >6.014145</td>\n",
       "      <td id=\"T_93ff9_row48_col10\" class=\"data row48 col10\" >11.817565</td>\n",
       "      <td id=\"T_93ff9_row48_col11\" class=\"data row48 col11\" >13.399880</td>\n",
       "      <td id=\"T_93ff9_row48_col12\" class=\"data row48 col12\" >-20.381439</td>\n",
       "      <td id=\"T_93ff9_row48_col13\" class=\"data row48 col13\" >15.107300</td>\n",
       "      <td id=\"T_93ff9_row48_col14\" class=\"data row48 col14\" >26.618073</td>\n",
       "      <td id=\"T_93ff9_row48_col15\" class=\"data row48 col15\" >23.538605</td>\n",
       "      <td id=\"T_93ff9_row48_col16\" class=\"data row48 col16\" >-30.110781</td>\n",
       "      <td id=\"T_93ff9_row48_col17\" class=\"data row48 col17\" >1.621870</td>\n",
       "      <td id=\"T_93ff9_row48_col18\" class=\"data row48 col18\" >-10.397230</td>\n",
       "      <td id=\"T_93ff9_row48_col19\" class=\"data row48 col19\" >-12.607768</td>\n",
       "      <td id=\"T_93ff9_row48_col20\" class=\"data row48 col20\" >0.001020</td>\n",
       "      <td id=\"T_93ff9_row48_col21\" class=\"data row48 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row48_col22\" class=\"data row48 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row48_col23\" class=\"data row48 col23\" >0.283572</td>\n",
       "      <td id=\"T_93ff9_row48_col24\" class=\"data row48 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row48_col25\" class=\"data row48 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row48_col26\" class=\"data row48 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row48_col27\" class=\"data row48 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row48_col28\" class=\"data row48 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row48_col29\" class=\"data row48 col29\" >45</td>\n",
       "      <td id=\"T_93ff9_row48_col30\" class=\"data row48 col30\" >128</td>\n",
       "      <td id=\"T_93ff9_row48_col31\" class=\"data row48 col31\" >oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row49\" class=\"row_heading level0 row49\" >2</th>\n",
       "      <td id=\"T_93ff9_row49_col0\" class=\"data row49 col0\" >0.317333</td>\n",
       "      <td id=\"T_93ff9_row49_col1\" class=\"data row49 col1\" >0.687500</td>\n",
       "      <td id=\"T_93ff9_row49_col2\" class=\"data row49 col2\" >0.687500</td>\n",
       "      <td id=\"T_93ff9_row49_col3\" class=\"data row49 col3\" >0.875000</td>\n",
       "      <td id=\"T_93ff9_row49_col4\" class=\"data row49 col4\" >0.475050</td>\n",
       "      <td id=\"T_93ff9_row49_col5\" class=\"data row49 col5\" >0.745763</td>\n",
       "      <td id=\"T_93ff9_row49_col6\" class=\"data row49 col6\" >0.709677</td>\n",
       "      <td id=\"T_93ff9_row49_col7\" class=\"data row49 col7\" >0.875000</td>\n",
       "      <td id=\"T_93ff9_row49_col8\" class=\"data row49 col8\" >2493.921143</td>\n",
       "      <td id=\"T_93ff9_row49_col9\" class=\"data row49 col9\" >8279.506836</td>\n",
       "      <td id=\"T_93ff9_row49_col10\" class=\"data row49 col10\" >2329.240723</td>\n",
       "      <td id=\"T_93ff9_row49_col11\" class=\"data row49 col11\" >2303.694580</td>\n",
       "      <td id=\"T_93ff9_row49_col12\" class=\"data row49 col12\" >-66.191406</td>\n",
       "      <td id=\"T_93ff9_row49_col13\" class=\"data row49 col13\" >31.407410</td>\n",
       "      <td id=\"T_93ff9_row49_col14\" class=\"data row49 col14\" >51.060486</td>\n",
       "      <td id=\"T_93ff9_row49_col15\" class=\"data row49 col15\" >48.466003</td>\n",
       "      <td id=\"T_93ff9_row49_col16\" class=\"data row49 col16\" >-75.049393</td>\n",
       "      <td id=\"T_93ff9_row49_col17\" class=\"data row49 col17\" >17.921986</td>\n",
       "      <td id=\"T_93ff9_row49_col18\" class=\"data row49 col18\" >14.045191</td>\n",
       "      <td id=\"T_93ff9_row49_col19\" class=\"data row49 col19\" >12.319607</td>\n",
       "      <td id=\"T_93ff9_row49_col20\" class=\"data row49 col20\" >0.003456</td>\n",
       "      <td id=\"T_93ff9_row49_col21\" class=\"data row49 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row49_col22\" class=\"data row49 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row49_col23\" class=\"data row49 col23\" >0.008031</td>\n",
       "      <td id=\"T_93ff9_row49_col24\" class=\"data row49 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row49_col25\" class=\"data row49 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row49_col26\" class=\"data row49 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row49_col27\" class=\"data row49 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row49_col28\" class=\"data row49 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row49_col29\" class=\"data row49 col29\" >53</td>\n",
       "      <td id=\"T_93ff9_row49_col30\" class=\"data row49 col30\" >15</td>\n",
       "      <td id=\"T_93ff9_row49_col31\" class=\"data row49 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row50\" class=\"row_heading level0 row50\" >22</th>\n",
       "      <td id=\"T_93ff9_row50_col0\" class=\"data row50 col0\" >0.317333</td>\n",
       "      <td id=\"T_93ff9_row50_col1\" class=\"data row50 col1\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row50_col2\" class=\"data row50 col2\" >0.781250</td>\n",
       "      <td id=\"T_93ff9_row50_col3\" class=\"data row50 col3\" >0.859375</td>\n",
       "      <td id=\"T_93ff9_row50_col4\" class=\"data row50 col4\" >0.475050</td>\n",
       "      <td id=\"T_93ff9_row50_col5\" class=\"data row50 col5\" >0.796610</td>\n",
       "      <td id=\"T_93ff9_row50_col6\" class=\"data row50 col6\" >0.806452</td>\n",
       "      <td id=\"T_93ff9_row50_col7\" class=\"data row50 col7\" >0.859375</td>\n",
       "      <td id=\"T_93ff9_row50_col8\" class=\"data row50 col8\" >3795.774902</td>\n",
       "      <td id=\"T_93ff9_row50_col9\" class=\"data row50 col9\" >12640.922852</td>\n",
       "      <td id=\"T_93ff9_row50_col10\" class=\"data row50 col10\" >3303.930420</td>\n",
       "      <td id=\"T_93ff9_row50_col11\" class=\"data row50 col11\" >3269.099365</td>\n",
       "      <td id=\"T_93ff9_row50_col12\" class=\"data row50 col12\" >-67.068298</td>\n",
       "      <td id=\"T_93ff9_row50_col13\" class=\"data row50 col13\" >33.202148</td>\n",
       "      <td id=\"T_93ff9_row50_col14\" class=\"data row50 col14\" >54.425659</td>\n",
       "      <td id=\"T_93ff9_row50_col15\" class=\"data row50 col15\" >50.990845</td>\n",
       "      <td id=\"T_93ff9_row50_col16\" class=\"data row50 col16\" >-75.872337</td>\n",
       "      <td id=\"T_93ff9_row50_col17\" class=\"data row50 col17\" >19.716694</td>\n",
       "      <td id=\"T_93ff9_row50_col18\" class=\"data row50 col18\" >17.410362</td>\n",
       "      <td id=\"T_93ff9_row50_col19\" class=\"data row50 col19\" >14.844413</td>\n",
       "      <td id=\"T_93ff9_row50_col20\" class=\"data row50 col20\" >0.075929</td>\n",
       "      <td id=\"T_93ff9_row50_col21\" class=\"data row50 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col22\" class=\"data row50 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col23\" class=\"data row50 col23\" >0.521060</td>\n",
       "      <td id=\"T_93ff9_row50_col24\" class=\"data row50 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row50_col25\" class=\"data row50 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col26\" class=\"data row50 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col27\" class=\"data row50 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col28\" class=\"data row50 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row50_col29\" class=\"data row50 col29\" >22</td>\n",
       "      <td id=\"T_93ff9_row50_col30\" class=\"data row50 col30\" >32</td>\n",
       "      <td id=\"T_93ff9_row50_col31\" class=\"data row50 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row51\" class=\"row_heading level0 row51\" >18</th>\n",
       "      <td id=\"T_93ff9_row51_col0\" class=\"data row51 col0\" >0.312000</td>\n",
       "      <td id=\"T_93ff9_row51_col1\" class=\"data row51 col1\" >0.703125</td>\n",
       "      <td id=\"T_93ff9_row51_col2\" class=\"data row51 col2\" >0.796875</td>\n",
       "      <td id=\"T_93ff9_row51_col3\" class=\"data row51 col3\" >0.843750</td>\n",
       "      <td id=\"T_93ff9_row51_col4\" class=\"data row51 col4\" >0.467066</td>\n",
       "      <td id=\"T_93ff9_row51_col5\" class=\"data row51 col5\" >0.762712</td>\n",
       "      <td id=\"T_93ff9_row51_col6\" class=\"data row51 col6\" >0.822581</td>\n",
       "      <td id=\"T_93ff9_row51_col7\" class=\"data row51 col7\" >0.843750</td>\n",
       "      <td id=\"T_93ff9_row51_col8\" class=\"data row51 col8\" >2635.162109</td>\n",
       "      <td id=\"T_93ff9_row51_col9\" class=\"data row51 col9\" >9958.112305</td>\n",
       "      <td id=\"T_93ff9_row51_col10\" class=\"data row51 col10\" >2186.693359</td>\n",
       "      <td id=\"T_93ff9_row51_col11\" class=\"data row51 col11\" >2262.873047</td>\n",
       "      <td id=\"T_93ff9_row51_col12\" class=\"data row51 col12\" >-64.797791</td>\n",
       "      <td id=\"T_93ff9_row51_col13\" class=\"data row51 col13\" >31.335144</td>\n",
       "      <td id=\"T_93ff9_row51_col14\" class=\"data row51 col14\" >54.552856</td>\n",
       "      <td id=\"T_93ff9_row51_col15\" class=\"data row51 col15\" >52.108093</td>\n",
       "      <td id=\"T_93ff9_row51_col16\" class=\"data row51 col16\" >-73.802605</td>\n",
       "      <td id=\"T_93ff9_row51_col17\" class=\"data row51 col17\" >17.849741</td>\n",
       "      <td id=\"T_93ff9_row51_col18\" class=\"data row51 col18\" >17.537525</td>\n",
       "      <td id=\"T_93ff9_row51_col19\" class=\"data row51 col19\" >15.961662</td>\n",
       "      <td id=\"T_93ff9_row51_col20\" class=\"data row51 col20\" >0.009155</td>\n",
       "      <td id=\"T_93ff9_row51_col21\" class=\"data row51 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row51_col22\" class=\"data row51 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row51_col23\" class=\"data row51 col23\" >0.000008</td>\n",
       "      <td id=\"T_93ff9_row51_col24\" class=\"data row51 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row51_col25\" class=\"data row51 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row51_col26\" class=\"data row51 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row51_col27\" class=\"data row51 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row51_col28\" class=\"data row51 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row51_col29\" class=\"data row51 col29\" >60</td>\n",
       "      <td id=\"T_93ff9_row51_col30\" class=\"data row51 col30\" >35</td>\n",
       "      <td id=\"T_93ff9_row51_col31\" class=\"data row51 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row52\" class=\"row_heading level0 row52\" >17</th>\n",
       "      <td id=\"T_93ff9_row52_col0\" class=\"data row52 col0\" >0.297333</td>\n",
       "      <td id=\"T_93ff9_row52_col1\" class=\"data row52 col1\" >0.750000</td>\n",
       "      <td id=\"T_93ff9_row52_col2\" class=\"data row52 col2\" >0.671875</td>\n",
       "      <td id=\"T_93ff9_row52_col3\" class=\"data row52 col3\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row52_col4\" class=\"data row52 col4\" >0.445110</td>\n",
       "      <td id=\"T_93ff9_row52_col5\" class=\"data row52 col5\" >0.813559</td>\n",
       "      <td id=\"T_93ff9_row52_col6\" class=\"data row52 col6\" >0.693548</td>\n",
       "      <td id=\"T_93ff9_row52_col7\" class=\"data row52 col7\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row52_col8\" class=\"data row52 col8\" >2201614.250000</td>\n",
       "      <td id=\"T_93ff9_row52_col9\" class=\"data row52 col9\" >1994397.750000</td>\n",
       "      <td id=\"T_93ff9_row52_col10\" class=\"data row52 col10\" >2198425.000000</td>\n",
       "      <td id=\"T_93ff9_row52_col11\" class=\"data row52 col11\" >2786387.750000</td>\n",
       "      <td id=\"T_93ff9_row52_col12\" class=\"data row52 col12\" >-139.929077</td>\n",
       "      <td id=\"T_93ff9_row52_col13\" class=\"data row52 col13\" >50.431335</td>\n",
       "      <td id=\"T_93ff9_row52_col14\" class=\"data row52 col14\" >42.324219</td>\n",
       "      <td id=\"T_93ff9_row52_col15\" class=\"data row52 col15\" >38.238037</td>\n",
       "      <td id=\"T_93ff9_row52_col16\" class=\"data row52 col16\" >-147.576279</td>\n",
       "      <td id=\"T_93ff9_row52_col17\" class=\"data row52 col17\" >36.945904</td>\n",
       "      <td id=\"T_93ff9_row52_col18\" class=\"data row52 col18\" >5.308946</td>\n",
       "      <td id=\"T_93ff9_row52_col19\" class=\"data row52 col19\" >2.091619</td>\n",
       "      <td id=\"T_93ff9_row52_col20\" class=\"data row52 col20\" >0.128646</td>\n",
       "      <td id=\"T_93ff9_row52_col21\" class=\"data row52 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row52_col22\" class=\"data row52 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row52_col23\" class=\"data row52 col23\" >0.126500</td>\n",
       "      <td id=\"T_93ff9_row52_col24\" class=\"data row52 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row52_col25\" class=\"data row52 col25\" >False</td>\n",
       "      <td id=\"T_93ff9_row52_col26\" class=\"data row52 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row52_col27\" class=\"data row52 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row52_col28\" class=\"data row52 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row52_col29\" class=\"data row52 col29\" >40</td>\n",
       "      <td id=\"T_93ff9_row52_col30\" class=\"data row52 col30\" >2</td>\n",
       "      <td id=\"T_93ff9_row52_col31\" class=\"data row52 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row53\" class=\"row_heading level0 row53\" >6</th>\n",
       "      <td id=\"T_93ff9_row53_col0\" class=\"data row53 col0\" >0.293333</td>\n",
       "      <td id=\"T_93ff9_row53_col1\" class=\"data row53 col1\" >0.750000</td>\n",
       "      <td id=\"T_93ff9_row53_col2\" class=\"data row53 col2\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row53_col3\" class=\"data row53 col3\" >0.843750</td>\n",
       "      <td id=\"T_93ff9_row53_col4\" class=\"data row53 col4\" >0.439122</td>\n",
       "      <td id=\"T_93ff9_row53_col5\" class=\"data row53 col5\" >0.813559</td>\n",
       "      <td id=\"T_93ff9_row53_col6\" class=\"data row53 col6\" >0.758065</td>\n",
       "      <td id=\"T_93ff9_row53_col7\" class=\"data row53 col7\" >0.843750</td>\n",
       "      <td id=\"T_93ff9_row53_col8\" class=\"data row53 col8\" >4980.395996</td>\n",
       "      <td id=\"T_93ff9_row53_col9\" class=\"data row53 col9\" >7768.288086</td>\n",
       "      <td id=\"T_93ff9_row53_col10\" class=\"data row53 col10\" >4586.631836</td>\n",
       "      <td id=\"T_93ff9_row53_col11\" class=\"data row53 col11\" >4673.315430</td>\n",
       "      <td id=\"T_93ff9_row53_col12\" class=\"data row53 col12\" >-77.896179</td>\n",
       "      <td id=\"T_93ff9_row53_col13\" class=\"data row53 col13\" >33.656128</td>\n",
       "      <td id=\"T_93ff9_row53_col14\" class=\"data row53 col14\" >51.903259</td>\n",
       "      <td id=\"T_93ff9_row53_col15\" class=\"data row53 col15\" >52.253540</td>\n",
       "      <td id=\"T_93ff9_row53_col16\" class=\"data row53 col16\" >-86.840370</td>\n",
       "      <td id=\"T_93ff9_row53_col17\" class=\"data row53 col17\" >20.170696</td>\n",
       "      <td id=\"T_93ff9_row53_col18\" class=\"data row53 col18\" >14.887976</td>\n",
       "      <td id=\"T_93ff9_row53_col19\" class=\"data row53 col19\" >16.107174</td>\n",
       "      <td id=\"T_93ff9_row53_col20\" class=\"data row53 col20\" >0.028712</td>\n",
       "      <td id=\"T_93ff9_row53_col21\" class=\"data row53 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row53_col22\" class=\"data row53 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row53_col23\" class=\"data row53 col23\" >0.000106</td>\n",
       "      <td id=\"T_93ff9_row53_col24\" class=\"data row53 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row53_col25\" class=\"data row53 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row53_col26\" class=\"data row53 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row53_col27\" class=\"data row53 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row53_col28\" class=\"data row53 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row53_col29\" class=\"data row53 col29\" >27</td>\n",
       "      <td id=\"T_93ff9_row53_col30\" class=\"data row53 col30\" >52</td>\n",
       "      <td id=\"T_93ff9_row53_col31\" class=\"data row53 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row54\" class=\"row_heading level0 row54\" >9</th>\n",
       "      <td id=\"T_93ff9_row54_col0\" class=\"data row54 col0\" >0.288000</td>\n",
       "      <td id=\"T_93ff9_row54_col1\" class=\"data row54 col1\" >0.671875</td>\n",
       "      <td id=\"T_93ff9_row54_col2\" class=\"data row54 col2\" >0.671875</td>\n",
       "      <td id=\"T_93ff9_row54_col3\" class=\"data row54 col3\" >0.750000</td>\n",
       "      <td id=\"T_93ff9_row54_col4\" class=\"data row54 col4\" >0.431138</td>\n",
       "      <td id=\"T_93ff9_row54_col5\" class=\"data row54 col5\" >0.728814</td>\n",
       "      <td id=\"T_93ff9_row54_col6\" class=\"data row54 col6\" >0.693548</td>\n",
       "      <td id=\"T_93ff9_row54_col7\" class=\"data row54 col7\" >0.750000</td>\n",
       "      <td id=\"T_93ff9_row54_col8\" class=\"data row54 col8\" >37448.062500</td>\n",
       "      <td id=\"T_93ff9_row54_col9\" class=\"data row54 col9\" >23964.212891</td>\n",
       "      <td id=\"T_93ff9_row54_col10\" class=\"data row54 col10\" >30204.228516</td>\n",
       "      <td id=\"T_93ff9_row54_col11\" class=\"data row54 col11\" >34627.644531</td>\n",
       "      <td id=\"T_93ff9_row54_col12\" class=\"data row54 col12\" >-99.359619</td>\n",
       "      <td id=\"T_93ff9_row54_col13\" class=\"data row54 col13\" >35.313477</td>\n",
       "      <td id=\"T_93ff9_row54_col14\" class=\"data row54 col14\" >30.618103</td>\n",
       "      <td id=\"T_93ff9_row54_col15\" class=\"data row54 col15\" >30.328430</td>\n",
       "      <td id=\"T_93ff9_row54_col16\" class=\"data row54 col16\" >-107.926392</td>\n",
       "      <td id=\"T_93ff9_row54_col17\" class=\"data row54 col17\" >21.828094</td>\n",
       "      <td id=\"T_93ff9_row54_col18\" class=\"data row54 col18\" >-6.397211</td>\n",
       "      <td id=\"T_93ff9_row54_col19\" class=\"data row54 col19\" >-5.817908</td>\n",
       "      <td id=\"T_93ff9_row54_col20\" class=\"data row54 col20\" >0.045967</td>\n",
       "      <td id=\"T_93ff9_row54_col21\" class=\"data row54 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row54_col22\" class=\"data row54 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row54_col23\" class=\"data row54 col23\" >0.000022</td>\n",
       "      <td id=\"T_93ff9_row54_col24\" class=\"data row54 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row54_col25\" class=\"data row54 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row54_col26\" class=\"data row54 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row54_col27\" class=\"data row54 col27\" >True</td>\n",
       "      <td id=\"T_93ff9_row54_col28\" class=\"data row54 col28\" >False</td>\n",
       "      <td id=\"T_93ff9_row54_col29\" class=\"data row54 col29\" >49</td>\n",
       "      <td id=\"T_93ff9_row54_col30\" class=\"data row54 col30\" >93</td>\n",
       "      <td id=\"T_93ff9_row54_col31\" class=\"data row54 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row55\" class=\"row_heading level0 row55\" >14</th>\n",
       "      <td id=\"T_93ff9_row55_col0\" class=\"data row55 col0\" >0.285333</td>\n",
       "      <td id=\"T_93ff9_row55_col1\" class=\"data row55 col1\" >0.703125</td>\n",
       "      <td id=\"T_93ff9_row55_col2\" class=\"data row55 col2\" >0.703125</td>\n",
       "      <td id=\"T_93ff9_row55_col3\" class=\"data row55 col3\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row55_col4\" class=\"data row55 col4\" >0.427146</td>\n",
       "      <td id=\"T_93ff9_row55_col5\" class=\"data row55 col5\" >0.762712</td>\n",
       "      <td id=\"T_93ff9_row55_col6\" class=\"data row55 col6\" >0.725806</td>\n",
       "      <td id=\"T_93ff9_row55_col7\" class=\"data row55 col7\" >0.734375</td>\n",
       "      <td id=\"T_93ff9_row55_col8\" class=\"data row55 col8\" >1370.905273</td>\n",
       "      <td id=\"T_93ff9_row55_col9\" class=\"data row55 col9\" >2127.954834</td>\n",
       "      <td id=\"T_93ff9_row55_col10\" class=\"data row55 col10\" >1207.346436</td>\n",
       "      <td id=\"T_93ff9_row55_col11\" class=\"data row55 col11\" >1195.782349</td>\n",
       "      <td id=\"T_93ff9_row55_col12\" class=\"data row55 col12\" >-71.671631</td>\n",
       "      <td id=\"T_93ff9_row55_col13\" class=\"data row55 col13\" >23.746460</td>\n",
       "      <td id=\"T_93ff9_row55_col14\" class=\"data row55 col14\" >27.977051</td>\n",
       "      <td id=\"T_93ff9_row55_col15\" class=\"data row55 col15\" >29.930664</td>\n",
       "      <td id=\"T_93ff9_row55_col16\" class=\"data row55 col16\" >-80.574455</td>\n",
       "      <td id=\"T_93ff9_row55_col17\" class=\"data row55 col17\" >10.261028</td>\n",
       "      <td id=\"T_93ff9_row55_col18\" class=\"data row55 col18\" >-9.038240</td>\n",
       "      <td id=\"T_93ff9_row55_col19\" class=\"data row55 col19\" >-6.215751</td>\n",
       "      <td id=\"T_93ff9_row55_col20\" class=\"data row55 col20\" >0.094976</td>\n",
       "      <td id=\"T_93ff9_row55_col21\" class=\"data row55 col21\" >False</td>\n",
       "      <td id=\"T_93ff9_row55_col22\" class=\"data row55 col22\" >True</td>\n",
       "      <td id=\"T_93ff9_row55_col23\" class=\"data row55 col23\" >0.000003</td>\n",
       "      <td id=\"T_93ff9_row55_col24\" class=\"data row55 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row55_col25\" class=\"data row55 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row55_col26\" class=\"data row55 col26\" >True</td>\n",
       "      <td id=\"T_93ff9_row55_col27\" class=\"data row55 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row55_col28\" class=\"data row55 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row55_col29\" class=\"data row55 col29\" >3</td>\n",
       "      <td id=\"T_93ff9_row55_col30\" class=\"data row55 col30\" >67</td>\n",
       "      <td id=\"T_93ff9_row55_col31\" class=\"data row55 col31\" >ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row56\" class=\"row_heading level0 row56\" >13</th>\n",
       "      <td id=\"T_93ff9_row56_col0\" class=\"data row56 col0\" >0.284000</td>\n",
       "      <td id=\"T_93ff9_row56_col1\" class=\"data row56 col1\" >0.718750</td>\n",
       "      <td id=\"T_93ff9_row56_col2\" class=\"data row56 col2\" >0.671875</td>\n",
       "      <td id=\"T_93ff9_row56_col3\" class=\"data row56 col3\" >0.796875</td>\n",
       "      <td id=\"T_93ff9_row56_col4\" class=\"data row56 col4\" >0.425150</td>\n",
       "      <td id=\"T_93ff9_row56_col5\" class=\"data row56 col5\" >0.779661</td>\n",
       "      <td id=\"T_93ff9_row56_col6\" class=\"data row56 col6\" >0.693548</td>\n",
       "      <td id=\"T_93ff9_row56_col7\" class=\"data row56 col7\" >0.796875</td>\n",
       "      <td id=\"T_93ff9_row56_col8\" class=\"data row56 col8\" >40658.578125</td>\n",
       "      <td id=\"T_93ff9_row56_col9\" class=\"data row56 col9\" >34293.328125</td>\n",
       "      <td id=\"T_93ff9_row56_col10\" class=\"data row56 col10\" >33031.164062</td>\n",
       "      <td id=\"T_93ff9_row56_col11\" class=\"data row56 col11\" >31593.111328</td>\n",
       "      <td id=\"T_93ff9_row56_col12\" class=\"data row56 col12\" >-99.636108</td>\n",
       "      <td id=\"T_93ff9_row56_col13\" class=\"data row56 col13\" >32.511719</td>\n",
       "      <td id=\"T_93ff9_row56_col14\" class=\"data row56 col14\" >40.289490</td>\n",
       "      <td id=\"T_93ff9_row56_col15\" class=\"data row56 col15\" >42.780579</td>\n",
       "      <td id=\"T_93ff9_row56_col16\" class=\"data row56 col16\" >-108.275238</td>\n",
       "      <td id=\"T_93ff9_row56_col17\" class=\"data row56 col17\" >19.026287</td>\n",
       "      <td id=\"T_93ff9_row56_col18\" class=\"data row56 col18\" >3.274189</td>\n",
       "      <td id=\"T_93ff9_row56_col19\" class=\"data row56 col19\" >6.634173</td>\n",
       "      <td id=\"T_93ff9_row56_col20\" class=\"data row56 col20\" >0.015133</td>\n",
       "      <td id=\"T_93ff9_row56_col21\" class=\"data row56 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row56_col22\" class=\"data row56 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row56_col23\" class=\"data row56 col23\" >1.466379</td>\n",
       "      <td id=\"T_93ff9_row56_col24\" class=\"data row56 col24\" >False</td>\n",
       "      <td id=\"T_93ff9_row56_col25\" class=\"data row56 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row56_col26\" class=\"data row56 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row56_col27\" class=\"data row56 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row56_col28\" class=\"data row56 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row56_col29\" class=\"data row56 col29\" >31</td>\n",
       "      <td id=\"T_93ff9_row56_col30\" class=\"data row56 col30\" >98</td>\n",
       "      <td id=\"T_93ff9_row56_col31\" class=\"data row56 col31\" >etherplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93ff9_level0_row57\" class=\"row_heading level0 row57\" >1</th>\n",
       "      <td id=\"T_93ff9_row57_col0\" class=\"data row57 col0\" >0.278667</td>\n",
       "      <td id=\"T_93ff9_row57_col1\" class=\"data row57 col1\" >0.718750</td>\n",
       "      <td id=\"T_93ff9_row57_col2\" class=\"data row57 col2\" >0.687500</td>\n",
       "      <td id=\"T_93ff9_row57_col3\" class=\"data row57 col3\" >0.718750</td>\n",
       "      <td id=\"T_93ff9_row57_col4\" class=\"data row57 col4\" >0.417166</td>\n",
       "      <td id=\"T_93ff9_row57_col5\" class=\"data row57 col5\" >0.779661</td>\n",
       "      <td id=\"T_93ff9_row57_col6\" class=\"data row57 col6\" >0.709677</td>\n",
       "      <td id=\"T_93ff9_row57_col7\" class=\"data row57 col7\" >0.718750</td>\n",
       "      <td id=\"T_93ff9_row57_col8\" class=\"data row57 col8\" >84983.156250</td>\n",
       "      <td id=\"T_93ff9_row57_col9\" class=\"data row57 col9\" >68335.164062</td>\n",
       "      <td id=\"T_93ff9_row57_col10\" class=\"data row57 col10\" >72358.609375</td>\n",
       "      <td id=\"T_93ff9_row57_col11\" class=\"data row57 col11\" >88334.140625</td>\n",
       "      <td id=\"T_93ff9_row57_col12\" class=\"data row57 col12\" >-110.232788</td>\n",
       "      <td id=\"T_93ff9_row57_col13\" class=\"data row57 col13\" >41.377808</td>\n",
       "      <td id=\"T_93ff9_row57_col14\" class=\"data row57 col14\" >31.388855</td>\n",
       "      <td id=\"T_93ff9_row57_col15\" class=\"data row57 col15\" >30.425659</td>\n",
       "      <td id=\"T_93ff9_row57_col16\" class=\"data row57 col16\" >-118.040215</td>\n",
       "      <td id=\"T_93ff9_row57_col17\" class=\"data row57 col17\" >27.892401</td>\n",
       "      <td id=\"T_93ff9_row57_col18\" class=\"data row57 col18\" >-5.626469</td>\n",
       "      <td id=\"T_93ff9_row57_col19\" class=\"data row57 col19\" >-5.720680</td>\n",
       "      <td id=\"T_93ff9_row57_col20\" class=\"data row57 col20\" >0.357258</td>\n",
       "      <td id=\"T_93ff9_row57_col21\" class=\"data row57 col21\" >True</td>\n",
       "      <td id=\"T_93ff9_row57_col22\" class=\"data row57 col22\" >False</td>\n",
       "      <td id=\"T_93ff9_row57_col23\" class=\"data row57 col23\" >0.000771</td>\n",
       "      <td id=\"T_93ff9_row57_col24\" class=\"data row57 col24\" >True</td>\n",
       "      <td id=\"T_93ff9_row57_col25\" class=\"data row57 col25\" >True</td>\n",
       "      <td id=\"T_93ff9_row57_col26\" class=\"data row57 col26\" >False</td>\n",
       "      <td id=\"T_93ff9_row57_col27\" class=\"data row57 col27\" >False</td>\n",
       "      <td id=\"T_93ff9_row57_col28\" class=\"data row57 col28\" >True</td>\n",
       "      <td id=\"T_93ff9_row57_col29\" class=\"data row57 col29\" >41</td>\n",
       "      <td id=\"T_93ff9_row57_col30\" class=\"data row57 col30\" >46</td>\n",
       "      <td id=\"T_93ff9_row57_col31\" class=\"data row57 col31\" >etherplusHH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f79d9fadcd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ax_client.get_trials_data_frame()\n",
    "d = df.iloc[:, 4:].sort_values(\"acc_gain_vs_ref/oos\", ascending=False)\n",
    "\n",
    "\n",
    "def make_pretty(styler):\n",
    "    styler.set_caption(\"Ax results\")\n",
    "    styler.background_gradient(axis=None, cmap=\"seismic_r\")\n",
    "    return styler\n",
    "\n",
    "\n",
    "make_pretty(d.style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best parameters\n",
    "best_parameters, values = ax_client.get_best_parameters()\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, covariances = values\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(ax_client.get_contour_plot(param_x=\"lr\", param_y=\"loss.β\", metric_name=\"oos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(ax_client.get_optimization_trace())  # Objective_optimum is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pot\n",
    "render(ax_client.get_contour_plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.plot.slice import plot_slice\n",
    "\n",
    "model = ax_client.generation_strategy.model\n",
    "render(plot_slice(model, \"lr\", \"oos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
