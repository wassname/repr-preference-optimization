{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "\n",
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_timeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig, DPOProjGradConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "study_name = \"projgrad\"\n",
    "SEED=42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.ax.target import objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/vwxyzjn/cleanrl/blob/master/tuner_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial2args(trial: optuna.Trial):\n",
    "    args = {\n",
    "        \"learning-rate\": trial.suggest_float(\"learning-rate\", 1e-6, 1e-3, log=True),\n",
    "        \"collect_input\": trial.suggest_categorical(\"collect_input\", [True, False]),\n",
    "        \"collect_hs\": trial.suggest_categorical(\"collect_hs\", [True, False]),\n",
    "        \n",
    "        # ## OrthoConfig\n",
    "        # \"orthogonal_map\": trial.suggest_categorical(\"orthogonal_map\", ('householder', 'cayley', 'matrix_exp')),\n",
    "\n",
    "        # ## ETHERConfig\n",
    "        # \"nb\": trial.suggest_int(\"nb\", 1, 32),\n",
    "        # \"Htype\": trial.suggest_categorical(\"Htype\", [\"ether\", \"etherplus\", \"oft\", \"etherplusHH\"]),\n",
    "        # # \"ether_dropout\": trial.suggest_float(\"ether_dropout\", 0.1, 10.0),\n",
    "        # \"flip_side\": trial.suggest_categorical(\"flip_side\", [True, False]),\n",
    "        # \"reduction\": trial.suggest_int(\"reduction\", 1, 200),\n",
    "\n",
    "        # ## HRAConfig\n",
    "        # \"r\": trial.suggest_int(\"r\", 2, 128),\n",
    "        # \"apply_GS\": trial.suggest_categorical(\"apply_GS\", [True, False]),\n",
    "\n",
    "        # ## SVDConfig\n",
    "        # \"quantile\": trial.suggest_categorical(\"quantile\", [0.1, 0.5, 0.75, 1]),\n",
    "        # \"dual_svd\": trial.suggest_categorical(\"dual_svd\", [True, False]),\n",
    "\n",
    "        # # prefvec\n",
    "        # \"loss.β\": trial.suggest_float(\"loss.β\", 1e-6, 2.0, log=True),\n",
    "        # \"use_orth_loss\": trial.suggest_categorical(\"use_orth_loss\", [True, False]),\n",
    "        # \"use_angle_loss\": trial.suggest_categorical(\"use_angle_loss\", [True, False]),\n",
    "        # \"use_dpo_loss\": trial.suggest_categorical(\"use_dpo_loss\", [True, False]),\n",
    "        # \"use_nll_loss\": trial.suggest_categorical(\"use_nll_loss\", [True, False]),\n",
    "        # \"weight_tokens\": trial.suggest_categorical(\"weight_tokens\", [True, False]),\n",
    "\n",
    "        # ## RankLossConfig\n",
    "        # \"α\": trial.suggest_float(\"α\", 0, 10.0),\n",
    "\n",
    "        # ## MSELossConfig\n",
    "        # \"α\": trial.suggest_float(\"α\", 0, 10.0),\n",
    "\n",
    "        # projgrad\n",
    "        \"β\": trial.suggest_float(\"β\", 0.0, 1.0, log=False),\n",
    "        \"reverse_pref\": trial.suggest_categorical(\"reverse_pref\", [True, False]),\n",
    "        \"scale_orth\": trial.suggest_categorical(\"scale_orth\", [True, False]),\n",
    "        \"weight_dim\": trial.suggest_int(\"weight_dim\", 0, 2),\n",
    "        \"neg_slope\": trial.suggest_categorical(\"neg_slope\",[0, 0.1, 0.5, 1]),\n",
    "    }\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO we can report early\n",
    "# trial.report(aggregated_normalized_score, step=seed)\n",
    "# # TODO we can report fails\n",
    "# if if trial.should_prune():\n",
    "#     raise optuna.TrialPruned()\n",
    "\n",
    "# https://github.com/optuna/optuna-integration/blob/935b44965316acb6076188a1e708481fe5d2978d/optuna_integration/pytorch_lightning/pytorch_lightning.py#L28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2378143/3985133805.py:4: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Disabling the wandb service is deprecated as of version 0.18.0 and will be removed in version 0.19.0.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback\n",
    "wandb_kwargs = {\"project\": \"reprpo-optuna\", \"name\": study_name}\n",
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../outputs/optuna/projgrad.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///../outputs/optuna/projgrad.db'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///../outputs/optuna/{study_name}.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.ax.target import override, tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "\n",
    "\n",
    "starter_experiment_name = \"projgrad\"\n",
    "\n",
    "def objective_func(kwargs, trial):\n",
    "    cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "    override(cfg, tuner_kwargs)\n",
    "    # now subcommands\n",
    "    override(cfg, kwargs)\n",
    "    r = train(cfg, trial=trial)\n",
    "    return r\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = trial2args(trial)\n",
    "    r = objective_func(kwargs, trial)\n",
    "    return r[key_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 08:28:34,270] Using an existing study with name 'projgrad' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    "    storage=f_db,\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.NopPruner(),\n",
    ")\n",
    "study.optimize(objective, n_trials=30, timeout=60*10, callbacks=[wandbc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
