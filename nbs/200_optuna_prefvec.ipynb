{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#sphx-glr-download-tutorial-10-key-features-005-visualization-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "\n",
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "from optuna.visualization.matplotlib import plot_edf\n",
    "from optuna.visualization.matplotlib import plot_intermediate_values\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_parallel_coordinate\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_rank\n",
    "from optuna.visualization.matplotlib import plot_slice\n",
    "from optuna.visualization.matplotlib import plot_timeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.training import train\n",
    "import tyro\n",
    "from reprpo.experiments import experiment_configs\n",
    "from reprpo.ax.parameters import search_spaces\n",
    "\n",
    "from reprpo.interventions import Interventions, DPOConfig, ReprPOConfig, DPOProjGradConfig\n",
    "from reprpo.interventions.losses import Losses\n",
    "from reprpo.interventions.transforms import Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "key_metric = \"acc_gain_vs_ref/oos\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence please\n",
    "import os\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.remove()\n",
    "logger.add(os.sys.stderr, level=\"WARNING\")\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../outputs/optuna/optuna.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sqlite:///../outputs/optuna/optuna.db'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_db = f\"sqlite:///../outputs/optuna/optuna.db\"\n",
    "f = f_db.replace('sqlite:///', './')\n",
    "print(f)\n",
    "Path(f).parent.mkdir(parents=True, exist_ok=True)\n",
    "f_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.ax.target import override, tuner_kwargs\n",
    "from reprpo.experiments import experiment_configs\n",
    "import copy\n",
    "\n",
    "\n",
    "import optuna.pruners\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on pruning. It's only really usefull with validation metrics and for long jobs over many epochs. I've got a small proxy job so there is no need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2550942/1891008565.py:28: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 00:39:05,559] Using an existing study with name 'projgrad' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 175 projgrad trials\n",
      "study.best_trial FrozenTrial(number=70, state=1, values=[1.057915057915058], datetime_start=datetime.datetime(2024, 9, 28, 17, 25, 12, 131962), datetime_complete=datetime.datetime(2024, 9, 28, 17, 28, 13, 416392), params={'learning-rate': 0.00012426382563887213, 'β': 0.7386239719822631, 'reverse_pref': True, 'scale_orth': True, 'weight_dim': 0, 'neg_slope': 0.5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning-rate': FloatDistribution(high=0.001, log=True, low=1e-06, step=None), 'β': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'reverse_pref': CategoricalDistribution(choices=(True, False)), 'scale_orth': CategoricalDistribution(choices=(True, False)), 'weight_dim': IntDistribution(high=2, log=False, low=0, step=1), 'neg_slope': CategoricalDistribution(choices=(0, 0.1, 0.5, 1))}, trial_id=71, value=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2550942/1891008565.py:28: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 00:39:05,817] Using an existing study with name 'side-ether-prefvec' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 0 side-ether-prefvec trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|\u001b[1mINFO\u001b[0m| PL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>\n"
     ]
    }
   ],
   "source": [
    "MAX_TRIALS= 150\n",
    "\n",
    "def list2tuples(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = tuple(v)\n",
    "    return d\n",
    "\n",
    "for starter_experiment_name, trial2args in search_spaces.items():\n",
    "    study_name = f\"{starter_experiment_name}\"\n",
    "\n",
    "    def objective_func(kwargs, trial):\n",
    "        cfg = copy.deepcopy(experiment_configs[starter_experiment_name][1])\n",
    "        override(cfg, tuner_kwargs)\n",
    "        \n",
    "        override(cfg, kwargs)\n",
    "        kwargs = list2tuples(kwargs)\n",
    "        r = train(cfg, trial=trial)\n",
    "        return r\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        kwargs = trial2args(trial)\n",
    "        r = objective_func(kwargs, trial)\n",
    "        return r[key_metric]\n",
    "\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = f\"{study_name}.ipynb\"\n",
    "    wandb_kwargs = {\"project\": \"reprpo-optuna\", \"name\": study_name}\n",
    "    wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True,\n",
    "        storage=f_db,\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        pruner=optuna.pruners.NopPruner(),\n",
    "    )\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    if len(study.trials)>0:\n",
    "        df = study.trials_dataframe().query('state == \"COMPLETE\"').sort_values('value', ascending=False)\n",
    "        n = len(df)\n",
    "\n",
    "        print(f\"loaded {n} {study_name} trials\")\n",
    "    if n < MAX_TRIALS:\n",
    "        study.optimize(objective, \n",
    "                    n_trials=MAX_TRIALS, \n",
    "                    callbacks=[wandbc], gc_after_trial=True, \n",
    "                    # catch=(Exception,)\n",
    "                    )\n",
    "\n",
    "    print('study.best_trial', study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_contour(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apendix 1: dataclass 2 optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import typing\n",
    "# from typing import Literal\n",
    "\n",
    "# def optuna_suggest_from_dataclass(t):\n",
    "#     n = t.__name__\n",
    "#     print(f'## {n}')\n",
    "#     sig = inspect.signature(t)\n",
    "#     for name, param in sig.parameters.items():\n",
    "#         if param.annotation== bool:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [True, False]),')\n",
    "#         elif param.annotation==int:\n",
    "#             print(f'\"{name}\": trial.suggest_int(\"{name}\", 1, 10),')\n",
    "#         elif param.annotation ==float:\n",
    "#             print(f'\"{name}\": trial.suggest_float(\"{name}\", 0.1, 10.0),')\n",
    "#         elif param.annotation == str:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [\"a\", \"b\", \"c\"]),')\n",
    "#         elif param.annotation == tuple:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", [(1, 2), (3, 4), (5, 6)]),')\n",
    "#         elif typing.get_origin(param.annotation) == Literal:\n",
    "#             print(f'\"{name}\": trial.suggest_categorical(\"{name}\", {param.annotation.__args__}),')\n",
    "#         else:\n",
    "#             print(f\"!!Unknown type {param}\")\n",
    "#             # print(name, param.default, param.annotation)\n",
    "\n",
    "# optuna_suggest_from_dataclass(ReprPOConfig)\n",
    "# for t in Transforms:\n",
    "#     print(f'## {t}')\n",
    "#     optuna_suggest_from_dataclass(t.value)\n",
    "# for l in Losses:\n",
    "#     print(f'## {l}')\n",
    "#     optuna_suggest_from_dataclass(l.value)\n",
    "\n",
    "\n",
    "# optuna_suggest_from_dataclass(DPOProjGradConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
