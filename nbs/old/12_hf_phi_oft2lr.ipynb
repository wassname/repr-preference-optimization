{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to modify hf dpo to work with the repos hypothesis...\n",
    "\n",
    "see\n",
    "- https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth\n",
    "- https://gist.github.com/alvarobartt/9898c33eb3e9c7108d9ed2330f12a708\n",
    "- https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing#scrollTo=QtoqUw80QDV0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"repo-dpo\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] =  os.path.basename(globals()['__vsc_ipynb_file__'])\n",
    "nb_name = os.path.basename(globals()['__vsc_ipynb_file__']).replace('.ipynb', '').replace(' ', '_')\n",
    "# enable wandb service (experimental, https://github.com/wandb/client/blob/master/docs/dev/wandb-service-user.md)\n",
    "# this hopefully fixes issues with multiprocessing\n",
    "wandb.require(experiment='service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo import silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers.trainer import ProgressCallback\n",
    "from transformers.utils.notebook import NotebookProgressCallback\n",
    "\n",
    "from reprpo.helpers.adapters import set_adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prompt_length=64\n",
    "# num_samples = 50 * 16 * 6\n",
    "num_samples = 1500 * 13 * 3 # from circuit breaker * 3\n",
    "max_length = 128\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation --no-deps -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f205bc6d39d7471f8162329b62459a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25165824 || all params: 2033980416 || trainable%: 1.2372697299362787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32011, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3FlashAttention2(\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Phi3RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (ReprPO): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (ReprPO): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm()\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32011, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME: we are meant to SFT first, so that the preferences are in sample but 1) if this works it might not be needed, and 2) this can be added later, if it works\n",
    "# for now we will use the instruct model, and try something it wasn't meant to do but it in sample \n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct-gguf\"\n",
    "# model_name = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "use_gradient_checkpointing = False\n",
    "\n",
    "from peft.tuners import BOFTConfig, OFTConfig, LoraConfig, IA3Config\n",
    "## Big adapter\n",
    "# peft_config = OFTConfig(\n",
    "#     r=4,\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"qkv_proj\", \"down_proj\",\n",
    "#                     \"o_proj\", \"gate_up_proj\",\n",
    "#                     ],\n",
    "# )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# rescale\n",
    "Infused Adapter by Inhibiting and Amplifying Inner Activations, or IA3, is a method that adds three learned vectors to rescale the keys and values of the self-attention and encoder-decoder attention layers, and the intermediate activation of the position-wise feed-forward network.\"\"\"\n",
    "# peft_config = IA3Config(\n",
    "#     # r=4,\n",
    "#     # task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"qkv_proj\", \"down_proj\",\n",
    "#                     \"o_proj\", \"gate_up_proj\",\n",
    "#                     ],\n",
    "#     feedforward_modules=[\"gate_up_proj\", \"down_proj\"]\n",
    "# )\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16, \n",
    "    r=16,\n",
    "    # lora_dropout=0.05,\n",
    "    use_rslora=True,\n",
    "    # use_dora=True,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"qkv_proj\", \"gate_up_proj\", # in\n",
    "        \"down_proj\",  \"o_proj\", # out\n",
    "                    \n",
    "                    ],\n",
    "    # target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "from reprpo.models.load import load_model, print_trainable_parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl.trainer.utils import peft_module_casting_to_bf16\n",
    "\n",
    "model, tokenizer = load_model(model_name, bnb=True )\n",
    "\n",
    "if use_gradient_checkpointing:\n",
    "    model.enable_input_require_grads()\n",
    "peft_module_casting_to_bf16(model)\n",
    "adapter_name='ReprPO'\n",
    "model = prepare_model_for_kbit_training(model, {'use_gradient_checkpointing': use_gradient_checkpointing})\n",
    "model = get_peft_model(model, peft_config, adapter_name=adapter_name)\n",
    "print_trainable_parameters(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dataset, N):\n",
    "    return (dataset\n",
    "            .shuffle(42)\n",
    "            .select(range(\n",
    "            min(len(dataset), N)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'When did women join the labor workforce outside of the home? What caused the change from housewife to breadwinner? Write a short informative paragraph under 200 words. ',\n",
       " 'chosen': \"In the early 20th century, less than 20% of women worked outside the home. Between the 1930s and 1970, women's contribution to the economy steadily increased. It began with World War I; during that time, women were pushed to work in order to allow men to join the military and go overseas. Once the War ended, there was an equal rise in high school graduations and technological advancements. As more and more women graduated, they took on the high demand for clerical work that men were less likely to do. Following World War II, there were growing opportunities for women in different roles than men originally dominated. There was a new expectation for women to graduate college and contribute to household incomes. By 1990, the percentage of women working increased by 76%. Recent research shows that there are approximately the same number of women in professional schools as men. According to Forbes in July 2023, 57.4 percent of the workforce are women.\",\n",
       " 'rejected': \"The 1900s saw a dramatic shift in the role of women in the workforce. Prior to this time, women were primarily homemakers and caregivers, with limited opportunities for paid work outside the home. However, with the rise of industrialization and the growth of the economy, women began to enter the workforce in increasing numbers.\\n\\nOne of the primary factors that led to this change was the need for workers in factories and other industries. As men went off to war or pursued other opportunities, women were needed to fill the gaps in the workforce. This need for workers created a new sense of opportunity for women, who had previously been limited by social and cultural expectations.\\n\\nAnother factor that contributed to the change was the growing feminist movement. Women's rights activists worked to break down barriers and stereotypes that prevented women from pursuing their own goals and ambitions. They fought for equal pay, equal opportunities, and the right to vote, among other rights.\\n\\nAs a result of these and other factors, women began to enter the workforce in increasing numbers. They worked in factories, offices, and other industries, often performing the same jobs as men. This shift in the role of women had a profound impact on society, changing the way that people thought about gender roles and the value of women's work.\\n\\nToday, women continue to make up a significant portion of the workforce, and many have achieved success in a wide range of industries. While there is still work to be done to achieve true gender equality, the changes that began in the early 1900s have paved the way for a more diverse and inclusive workforce.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset('Columbia-NLP/DPO-HelpSteer')\n",
    "dataset = load_dataset('Atsunori/HelpSteer2-DPO').map(lambda x: {\n",
    "    'prompt': x['prompt']+ ' '})\n",
    "dataset['train'] = sample(dataset['train'], num_samples)\n",
    "dataset2 = dataset.rename_column('chosen_response', 'chosen').rename_column('rejected_response', 'rejected')\n",
    "dataset2['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_ds(row):\n",
    "    \n",
    "#     # WHY are we doing this? Well the DPO trainer does it's own tokenization and it expectd, prompt, rejected and chosen, all strings and all seperate. Is this good, idk\n",
    "#     return {\n",
    "#         \"chosen\": row['chosen_response'][1]['content'],\n",
    "#         \"rejected\": row['rejected_response'][1]['content'],\n",
    "#     }\n",
    "\n",
    "\n",
    "# dataset2 = dataset.map(format_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did women join the labor workforce outside of the home? What caused the change from housewife to breadwinner? Write a short informative paragraph under 200 words. \n",
      "===\n",
      "In the early 20th century, less than 20% of women worked outside the home. Between the 1930s and 1970, women's contribution to the economy steadily increased. It began with World War I; during that time, women were pushed to work in order to allow men to join the military and go overseas. Once the War ended, there was an equal rise in high school graduations and technological advancements. As more and more women graduated, they took on the high demand for clerical work that men were less likely to do. Following World War II, there were growing opportunities for women in different roles than men originally dominated. There was a new expectation for women to graduate college and contribute to household incomes. By 1990, the percentage of women working increased by 76%. Recent research shows that there are approximately the same number of women in professional schools as men. According to Forbes in July 2023, 57.4 percent of the workforce are women.\n",
      "---\n",
      "The 1900s saw a dramatic shift in the role of women in the workforce. Prior to this time, women were primarily homemakers and caregivers, with limited opportunities for paid work outside the home. However, with the rise of industrialization and the growth of the economy, women began to enter the workforce in increasing numbers.\n",
      "\n",
      "One of the primary factors that led to this change was the need for workers in factories and other industries. As men went off to war or pursued other opportunities, women were needed to fill the gaps in the workforce. This need for workers created a new sense of opportunity for women, who had previously been limited by social and cultural expectations.\n",
      "\n",
      "Another factor that contributed to the change was the growing feminist movement. Women's rights activists worked to break down barriers and stereotypes that prevented women from pursuing their own goals and ambitions. They fought for equal pay, equal opportunities, and the right to vote, among other rights.\n",
      "\n",
      "As a result of these and other factors, women began to enter the workforce in increasing numbers. They worked in factories, offices, and other industries, often performing the same jobs as men. This shift in the role of women had a profound impact on society, changing the way that people thought about gender roles and the value of women's work.\n",
      "\n",
      "Today, women continue to make up a significant portion of the workforce, and many have achieved success in a wide range of industries. While there is still work to be done to achieve true gender equality, the changes that began in the early 1900s have paved the way for a more diverse and inclusive workforce.\n"
     ]
    }
   ],
   "source": [
    "r = dataset2['train'][0]\n",
    "print(r['prompt'])\n",
    "print('===')\n",
    "print(r['chosen'])\n",
    "print('---')\n",
    "print(r['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.mc import eval_tqa\n",
    "from reprpo.gen import generation_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified classes\n",
    "\n",
    "- here we can defined the experimetns loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.trainer import ReprPOTrainer, ReprPOConfig\n",
    "\n",
    "\n",
    "class ReprPOTrainer2(ReprPOTrainer):\n",
    "    pass\n",
    "\n",
    "    # def reprpo_loss(\n",
    "    #     self,\n",
    "    #     policy_chosen_logps: torch.FloatTensor,\n",
    "    #     policy_rejected_logps: torch.FloatTensor,\n",
    "    #     policy_chosen_hs: torch.FloatTensor,\n",
    "    #     policy_rejected_hs: torch.FloatTensor,\n",
    "    #     reference_chosen_logps: torch.FloatTensor,\n",
    "    #     reference_rejected_logps: torch.FloatTensor,\n",
    "    #     reference_chosen_hs: torch.FloatTensor,\n",
    "    #     chosen_attn_mask: torch.BoolTensor,\n",
    "    #     rejected_attn_mask: torch.BoolTensor\n",
    "    # ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
    "\n",
    "    #     loss_rr = sum_squared_error(policy_rejected_hs, reference_chosen_hs)\n",
    "    #     loss_rr = mean_with_attention(loss_rr, rejected_attn_mask*chosen_attn_mask).mean()\n",
    "        \n",
    "    #     loss = loss_rr.sum()\n",
    "\n",
    "    #     loss_dict = dict(loss=loss.detach())\n",
    "\n",
    "    #     # now mean any with ndim>0, and detach an cpu\n",
    "    #     loss_dict = {k: normalize_output(v) for k, v in loss_dict.items()}\n",
    "\n",
    "    #     return loss, loss_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.helpers.torch import clear_mem\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7221"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the ideal number of sample for how many are available\n",
    "num_data_samples = min(num_samples, len(dataset2['train']))\n",
    "num_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.helpers.svd_decomposer import SVDDecomposer, DualSVDDecomposer\n",
    "# d = DualSVDDecomposer(model.get_input_embeddings().weight, model.lm_head.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ReprPO': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='microsoft/Phi-3-mini-4k-instruct', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'o_proj', 'qkv_proj', 'gate_up_proj', 'down_proj'}, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_accumulation_steps': 1, 'num_train_epochs': 8}\n",
      "Soft SVD: 89.97% of singular values kept, with tau=5.38, Smean=7.82, Smax=105.96, Smin=0.84\n"
     ]
    }
   ],
   "source": [
    "batch_size = 42\n",
    "ideal_batch_size = batch_size\n",
    "gradient_accumulation_steps = ideal_batch_size // batch_size\n",
    "num_train_epochs = num_samples // num_data_samples\n",
    "print(dict(gradient_accumulation_steps=gradient_accumulation_steps, num_train_epochs=num_train_epochs))\n",
    "\n",
    "# vscode + wandb compat\n",
    "dt = pd.Timestamp.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# TODO put model and adapter base names?\n",
    "run_name = f\"{nb_name}-{dt}\"\n",
    "\n",
    "training_args = ReprPOConfig(\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=1e-3, # 5e-7 in the dpo paper? but this method needs much more\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size//2,\n",
    "\n",
    "    # lr_scheduler_type=\"constant\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0,\n",
    "\n",
    "    seed=42,\n",
    "    logging_steps=1,\n",
    "    # save_steps=500,\n",
    "    # save_strategy=\"steps\",\n",
    "    output_dir=f\"./output-dir/{run_name}\",\n",
    "\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=10,\n",
    "\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_length=max_length,\n",
    "\n",
    "    report_to=['tensorboard', 'wandb'],\n",
    "    model_adapter_name='ReprPO',\n",
    "    alpha=.3,\n",
    "\n",
    "    run_name=run_name,\n",
    "    collection_layers=[10, 25],\n",
    "\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    ")\n",
    "\n",
    "reprpo_trainer = ReprPOTrainer2(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    # beta=training_args.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    eval_dataset=dataset2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Transformer does not recognise vscode notebooks\n",
    "reprpo_trainer.callback_handler.remove_callback(ProgressCallback)\n",
    "reprpo_trainer.callback_handler.add_callback(NotebookProgressCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QC train dataset\n",
    "# r = reprpo_trainer.train_dataset[0]\n",
    "# print('prompt', tokenizer.decode(r['prompt_input_ids']))\n",
    "# print('-'*80)q\n",
    "# print('chosen',tokenizer.decode(r['chosen_input_ids']))\n",
    "# print('-'*80)\n",
    "# print('rejected',tokenizer.decode(r['rejected_input_ids']))\n",
    "# print('='*80)\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwassname\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/nbs/wandb/run-20240807_152307-jlft1d6k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wassname/repo-dpo/runs/jlft1d6k' target=\"_blank\">12_hf_phi_oft2lr-2024-08-07-15-23-03</a></strong> to <a href='https://wandb.ai/wassname/repo-dpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wassname/repo-dpo' target=\"_blank\">https://wandb.ai/wassname/repo-dpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wassname/repo-dpo/runs/jlft1d6k' target=\"_blank\">https://wandb.ai/wassname/repo-dpo/runs/jlft1d6k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 retain_cos_sim: 1.0000. rr_cos_sim: 0.8023\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '0', 'logps/rejected': '-1.5', 'logps/chosen': '-1.5', 'loss': '1.3', 'rewards/chosen': '0', 'rewards/rejected': '0', 'retain/loss': '1', 'reroute/loss': '1', 'logratios/pi': '-0.0047', 'logratios/ref': '-0.0047', 'weighting': '0.024', 'logits': '0', 'component_rr/loss': '1', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='502' max='1376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 502/1376 1:23:37 < 2:26:09, 0.10 it/s, Epoch 2.91/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Retain/loss</th>\n",
       "      <th>Reroute/loss</th>\n",
       "      <th>Logratios/pi</th>\n",
       "      <th>Logratios/ref</th>\n",
       "      <th>Weighting</th>\n",
       "      <th>Logits</th>\n",
       "      <th>Component Rr/loss</th>\n",
       "      <th>Component Retain/loss</th>\n",
       "      <th>Rr/c</th>\n",
       "      <th>Retain/c</th>\n",
       "      <th>Retain Cosine</th>\n",
       "      <th>Rr Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.043722</td>\n",
       "      <td>1.017111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-1.408625</td>\n",
       "      <td>-1.421674</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1.274879</td>\n",
       "      <td>0.634647</td>\n",
       "      <td>-0.013049</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>0.634647</td>\n",
       "      <td>0.382464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995101</td>\n",
       "      <td>0.792627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.266499</td>\n",
       "      <td>1.159978</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>-1.483718</td>\n",
       "      <td>-1.469751</td>\n",
       "      <td>-0.004771</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>1.398386</td>\n",
       "      <td>0.740462</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.740462</td>\n",
       "      <td>0.419516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980078</td>\n",
       "      <td>0.782563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.092155</td>\n",
       "      <td>1.233822</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>-1.565778</td>\n",
       "      <td>-1.553715</td>\n",
       "      <td>-0.013168</td>\n",
       "      <td>-0.015647</td>\n",
       "      <td>1.457675</td>\n",
       "      <td>0.796520</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.796520</td>\n",
       "      <td>0.437302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938956</td>\n",
       "      <td>0.758020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>81.781281</td>\n",
       "      <td>359.004364</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-12.664591</td>\n",
       "      <td>-12.687801</td>\n",
       "      <td>-1.126576</td>\n",
       "      <td>-1.125528</td>\n",
       "      <td>275.175171</td>\n",
       "      <td>276.451782</td>\n",
       "      <td>-0.023211</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.010479</td>\n",
       "      <td>276.451782</td>\n",
       "      <td>82.552544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403291</td>\n",
       "      <td>0.393681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>165.277161</td>\n",
       "      <td>251.040848</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>-11.119833</td>\n",
       "      <td>-11.168303</td>\n",
       "      <td>-0.974626</td>\n",
       "      <td>-0.971052</td>\n",
       "      <td>169.186691</td>\n",
       "      <td>200.284851</td>\n",
       "      <td>-0.048470</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.035738</td>\n",
       "      <td>200.284851</td>\n",
       "      <td>50.756008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368166</td>\n",
       "      <td>0.348971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>145.219681</td>\n",
       "      <td>84.673630</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>-9.972261</td>\n",
       "      <td>-10.028289</td>\n",
       "      <td>-0.860625</td>\n",
       "      <td>-0.856295</td>\n",
       "      <td>81.084297</td>\n",
       "      <td>60.348343</td>\n",
       "      <td>-0.056028</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.043295</td>\n",
       "      <td>60.348343</td>\n",
       "      <td>24.325293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608784</td>\n",
       "      <td>0.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>165.864212</td>\n",
       "      <td>279.979828</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-9.330577</td>\n",
       "      <td>-9.337383</td>\n",
       "      <td>-0.791534</td>\n",
       "      <td>-0.792127</td>\n",
       "      <td>284.442108</td>\n",
       "      <td>194.647171</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>194.647171</td>\n",
       "      <td>85.332642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514695</td>\n",
       "      <td>0.501515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>37.183678</td>\n",
       "      <td>53.697166</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-9.134090</td>\n",
       "      <td>-9.152704</td>\n",
       "      <td>-0.773066</td>\n",
       "      <td>-0.772478</td>\n",
       "      <td>45.607773</td>\n",
       "      <td>40.014832</td>\n",
       "      <td>-0.018614</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>40.014832</td>\n",
       "      <td>13.682333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671213</td>\n",
       "      <td>0.649023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.585942</td>\n",
       "      <td>4.449389</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>-8.116581</td>\n",
       "      <td>-8.175167</td>\n",
       "      <td>-0.675313</td>\n",
       "      <td>-0.670727</td>\n",
       "      <td>3.652328</td>\n",
       "      <td>3.353690</td>\n",
       "      <td>-0.058589</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.045856</td>\n",
       "      <td>3.353690</td>\n",
       "      <td>1.095698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.718364</td>\n",
       "      <td>0.692227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.563613</td>\n",
       "      <td>3.599225</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-8.393727</td>\n",
       "      <td>-8.477812</td>\n",
       "      <td>-0.705577</td>\n",
       "      <td>-0.698442</td>\n",
       "      <td>2.936266</td>\n",
       "      <td>2.718345</td>\n",
       "      <td>-0.084086</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.071354</td>\n",
       "      <td>2.718345</td>\n",
       "      <td>0.880880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722453</td>\n",
       "      <td>0.694627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 retain_cos_sim: 0.9998. rr_cos_sim: 0.7845\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00077', 'logps/rejected': '-1.6', 'logps/chosen': '-1.4', 'loss': '1.2', 'rewards/chosen': '-0.0014', 'rewards/rejected': '-0.0021', 'retain/loss': '1', 'reroute/loss': '0.94', 'logratios/pi': '0.13', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '0.0077', 'component_rr/loss': '0.94', 'component_retain/loss': '0.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.78'}\n",
      "20 retain_cos_sim: 0.9986. rr_cos_sim: 0.7935\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-7.3e-05', 'logps/rejected': '-1.5', 'logps/chosen': '-1.3', 'loss': '0.76', 'rewards/chosen': '-0.0011', 'rewards/rejected': '-0.001', 'retain/loss': '1', 'reroute/loss': '0.45', 'logratios/pi': '0.2', 'logratios/ref': '0.2', 'weighting': '0.024', 'logits': '-0.00073', 'component_rr/loss': '0.45', 'component_retain/loss': '0.31', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.79'}\n",
      "30 retain_cos_sim: 0.9951. rr_cos_sim: 0.7839\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.00062', 'logps/rejected': '-1.6', 'logps/chosen': '-1.2', 'loss': '0.79', 'rewards/chosen': '-0.0012', 'rewards/rejected': '-0.00054', 'retain/loss': '1.2', 'reroute/loss': '0.42', 'logratios/pi': '0.35', 'logratios/ref': '0.36', 'weighting': '0.024', 'logits': '-0.0062', 'component_rr/loss': '0.42', 'component_retain/loss': '0.37', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.78'}\n",
      "40 retain_cos_sim: 0.9954. rr_cos_sim: 0.7967\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00092', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '0.88', 'rewards/chosen': '0.0027', 'rewards/rejected': '0.0018', 'retain/loss': '1.1', 'reroute/loss': '0.55', 'logratios/pi': '-0.016', 'logratios/ref': '-0.025', 'weighting': '0.024', 'logits': '0.0092', 'component_rr/loss': '0.55', 'component_retain/loss': '0.33', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens. The Culture's advanced technology, ethical stance, and the idea of a peaceful, cooperative`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "50 retain_cos_sim: 0.9961. rr_cos_sim: 0.8085\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00028', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.1', 'eval_rewards/chosen': '0.0014', 'eval_rewards/rejected': '0.0011', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.65', 'eval_logratios/pi': '0.011', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.0028', 'eval_component_rr/loss': '0.65', 'eval_component_retain/loss': '0.41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.81'}\n",
      "50 retain_cos_sim: 0.9951. rr_cos_sim: 0.8021\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0029', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.5', 'eval_loss': '0.52', 'eval_rewards/chosen': '0.0036', 'eval_rewards/rejected': '0.00069', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.15', 'eval_logratios/pi': '-0.19', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.029', 'eval_component_rr/loss': '0.15', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9950. rr_cos_sim: 0.7988\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0022', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.2', 'eval_rewards/chosen': '0.00099', 'eval_rewards/rejected': '-0.0012', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.78', 'eval_logratios/pi': '0.00047', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.022', 'eval_component_rr/loss': '0.78', 'eval_component_retain/loss': '0.42', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9937. rr_cos_sim: 0.8013\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0019', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.3', 'eval_loss': '1', 'eval_rewards/chosen': '-0.0027', 'eval_rewards/rejected': '-0.00086', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.61', 'eval_logratios/pi': '0.05', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-0.019', 'eval_component_rr/loss': '0.61', 'eval_component_retain/loss': '0.41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9944. rr_cos_sim: 0.8050\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00038', 'eval_logps/rejected': '-1.7', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.69', 'eval_rewards/chosen': '-0.0011', 'eval_rewards/rejected': '-0.0015', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.33', 'eval_logratios/pi': '0.26', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.0038', 'eval_component_rr/loss': '0.33', 'eval_component_retain/loss': '0.36', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9958. rr_cos_sim: 0.7967\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00019', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.0012', 'eval_rewards/rejected': '-0.0014', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.93', 'eval_logratios/pi': '-0.015', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.0019', 'eval_component_rr/loss': '0.93', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9956. rr_cos_sim: 0.8171\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00085', 'eval_logps/rejected': '-1.1', 'eval_logps/chosen': '-1.1', 'eval_loss': '1.4', 'eval_rewards/chosen': '-0.00018', 'eval_rewards/rejected': '0.00067', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.99', 'eval_logratios/pi': '0.029', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.0085', 'eval_component_rr/loss': '0.99', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.82'}\n",
      "50 retain_cos_sim: 0.9955. rr_cos_sim: 0.7974\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0032', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.3', 'eval_loss': '0.79', 'eval_rewards/chosen': '-0.00066', 'eval_rewards/rejected': '0.0025', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '0.46', 'eval_logratios/pi': '0.052', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.032', 'eval_component_rr/loss': '0.46', 'eval_component_retain/loss': '0.33', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9955. rr_cos_sim: 0.7815\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-2.6e-05', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.3', 'eval_loss': '0.82', 'eval_rewards/chosen': '0.00017', 'eval_rewards/rejected': '0.0002', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '0.48', 'eval_logratios/pi': '0.0031', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.00026', 'eval_component_rr/loss': '0.48', 'eval_component_retain/loss': '0.34', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9949. rr_cos_sim: 0.7871\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00076', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.2', 'eval_loss': '1', 'eval_rewards/chosen': '-0.00043', 'eval_rewards/rejected': '0.00033', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.64', 'eval_logratios/pi': '0.25', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.0076', 'eval_component_rr/loss': '0.64', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9961. rr_cos_sim: 0.7731\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0016', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.3', 'eval_loss': '1', 'eval_rewards/chosen': '0.0025', 'eval_rewards/rejected': '0.00092', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.6', 'eval_logratios/pi': '0.25', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '0.016', 'eval_component_rr/loss': '0.6', 'eval_component_retain/loss': '0.41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.77'}\n",
      "50 retain_cos_sim: 0.9961. rr_cos_sim: 0.7970\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00081', 'eval_logps/rejected': '-1.2', 'eval_logps/chosen': '-1.2', 'eval_loss': '1.3', 'eval_rewards/chosen': '0.0006', 'eval_rewards/rejected': '-0.00021', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.94', 'eval_logratios/pi': '0.023', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.0081', 'eval_component_rr/loss': '0.94', 'eval_component_retain/loss': '0.38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9957. rr_cos_sim: 0.7592\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0018', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.6', 'eval_loss': '1', 'eval_rewards/chosen': '-0.00083', 'eval_rewards/rejected': '0.00094', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.63', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.018', 'eval_component_rr/loss': '0.63', 'eval_component_retain/loss': '0.39', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.76'}\n",
      "50 retain_cos_sim: 0.9949. rr_cos_sim: 0.7832\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0032', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.00067', 'eval_rewards/rejected': '0.0026', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.72', 'eval_logratios/pi': '-0.016', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.032', 'eval_component_rr/loss': '0.72', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9952. rr_cos_sim: 0.7900\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00051', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.8', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.0021', 'eval_rewards/rejected': '-0.0016', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.87', 'eval_logratios/pi': '-0.34', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '-0.0051', 'eval_component_rr/loss': '0.87', 'eval_component_retain/loss': '0.39', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9943. rr_cos_sim: 0.7960\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0046', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.3', 'eval_loss': '0.68', 'eval_rewards/chosen': '0.00056', 'eval_rewards/rejected': '-0.0041', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '0.34', 'eval_logratios/pi': '0.27', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '0.046', 'eval_component_rr/loss': '0.34', 'eval_component_retain/loss': '0.34', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.8'}\n",
      "50 retain_cos_sim: 0.9929. rr_cos_sim: 0.7813\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0024', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.7', 'eval_loss': '1.1', 'eval_rewards/chosen': '0.00013', 'eval_rewards/rejected': '-0.0023', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.68', 'eval_logratios/pi': '-0.12', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '0.024', 'eval_component_rr/loss': '0.68', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.99', 'eval_rr_cosine': '0.78'}\n",
      "50 retain_cos_sim: 0.9951. rr_cos_sim: 0.7920\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0039', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-2', 'eval_loss': '1', 'eval_rewards/chosen': '0.00058', 'eval_rewards/rejected': '0.0045', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.63', 'eval_logratios/pi': '-0.61', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '-0.039', 'eval_component_rr/loss': '0.63', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '1', 'eval_rr_cosine': '0.79'}\n",
      "50 retain_cos_sim: 0.9950. rr_cos_sim: 0.7950\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0003', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '1.2', 'rewards/chosen': '3.8e-05', 'rewards/rejected': '0.00034', 'retain/loss': '1.3', 'reroute/loss': '0.8', 'logratios/pi': '0.054', 'logratios/ref': '0.057', 'weighting': '0.024', 'logits': '-0.003', 'component_rr/loss': '0.8', 'component_retain/loss': '0.38', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '1', 'rr_cosine': '0.8'}\n",
      "60 retain_cos_sim: 0.9923. rr_cos_sim: 0.8070\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0019', 'logps/rejected': '-1.4', 'logps/chosen': '-1.3', 'loss': '1.1', 'rewards/chosen': '-0.0007', 'rewards/rejected': '-0.0027', 'retain/loss': '1.4', 'reroute/loss': '0.71', 'logratios/pi': '0.091', 'logratios/ref': '0.072', 'weighting': '0.024', 'logits': '0.019', 'component_rr/loss': '0.71', 'component_retain/loss': '0.43', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.99', 'rr_cosine': '0.81'}\n",
      "70 retain_cos_sim: 0.9890. rr_cos_sim: 0.7850\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0019', 'logps/rejected': '-1.5', 'logps/chosen': '-1.4', 'loss': '0.9', 'rewards/chosen': '-0.0057', 'rewards/rejected': '-0.0038', 'retain/loss': '1.2', 'reroute/loss': '0.53', 'logratios/pi': '0.078', 'logratios/ref': '0.097', 'weighting': '0.024', 'logits': '-0.019', 'component_rr/loss': '0.53', 'component_retain/loss': '0.37', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.99', 'rr_cosine': '0.78'}\n",
      "80 retain_cos_sim: 0.9861. rr_cos_sim: 0.7801\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0039', 'logps/rejected': '-1.6', 'logps/chosen': '-1.5', 'loss': '1', 'rewards/chosen': '-0.0016', 'rewards/rejected': '-0.0055', 'retain/loss': '1.2', 'reroute/loss': '0.65', 'logratios/pi': '0.095', 'logratios/ref': '0.056', 'weighting': '0.024', 'logits': '0.039', 'component_rr/loss': '0.65', 'component_retain/loss': '0.36', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.99', 'rr_cosine': '0.78'}\n",
      "90 retain_cos_sim: 0.9850. rr_cos_sim: 0.7950\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0022', 'logps/rejected': '-1.3', 'logps/chosen': '-1.4', 'loss': '1.1', 'rewards/chosen': '-0.0052', 'rewards/rejected': '-0.003', 'retain/loss': '1.5', 'reroute/loss': '0.71', 'logratios/pi': '-0.094', 'logratios/ref': '-0.071', 'weighting': '0.024', 'logits': '-0.022', 'component_rr/loss': '0.71', 'component_retain/loss': '0.44', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.98', 'rr_cosine': '0.79'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M Banks because it represents a society that values individual freedom, advanced technology, and a utopian vision. The Culture is a society that values individuality, creativity, and the exploration of space, which aligns with my personal values. The`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "100 retain_cos_sim: 0.9832. rr_cos_sim: 0.8012\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0012', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.4', 'eval_rewards/chosen': '0.0018', 'eval_rewards/rejected': '0.00057', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.93', 'eval_logratios/pi': '0.02', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.012', 'eval_component_rr/loss': '0.93', 'eval_component_retain/loss': '0.44', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.8'}\n",
      "100 retain_cos_sim: 0.9800. rr_cos_sim: 0.7926\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0084', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.5', 'eval_loss': '0.69', 'eval_rewards/chosen': '0.0051', 'eval_rewards/rejected': '-0.0033', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.35', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.084', 'eval_component_rr/loss': '0.35', 'eval_component_retain/loss': '0.35', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9799. rr_cos_sim: 0.7877\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0056', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.0071', 'eval_rewards/rejected': '-0.013', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.7', 'eval_logratios/pi': '0.035', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.056', 'eval_component_rr/loss': '0.7', 'eval_component_retain/loss': '0.43', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9756. rr_cos_sim: 0.7863\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '9.8e-05', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.0085', 'eval_rewards/rejected': '-0.0086', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.69', 'eval_logratios/pi': '0.07', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.00098', 'eval_component_rr/loss': '0.69', 'eval_component_retain/loss': '0.42', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9769. rr_cos_sim: 0.7927\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0026', 'eval_logps/rejected': '-1.8', 'eval_logps/chosen': '-1.5', 'eval_loss': '0.82', 'eval_rewards/chosen': '-0.0068', 'eval_rewards/rejected': '-0.0094', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.45', 'eval_logratios/pi': '0.29', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.026', 'eval_component_rr/loss': '0.45', 'eval_component_retain/loss': '0.38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9825. rr_cos_sim: 0.7868\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0055', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.4', 'eval_rewards/chosen': '-0.0028', 'eval_rewards/rejected': '-0.0083', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.97', 'eval_logratios/pi': '0.038', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.055', 'eval_component_rr/loss': '0.97', 'eval_component_retain/loss': '0.45', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9816. rr_cos_sim: 0.8081\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0039', 'eval_logps/rejected': '-1.2', 'eval_logps/chosen': '-1.2', 'eval_loss': '2', 'eval_rewards/chosen': '-0.0081', 'eval_rewards/rejected': '-0.0042', 'eval_retain/loss': '1.9', 'eval_reroute/loss': '1.4', 'eval_logratios/pi': '-0.0021', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.039', 'eval_component_rr/loss': '1.4', 'eval_component_retain/loss': '0.56', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.81'}\n",
      "100 retain_cos_sim: 0.9821. rr_cos_sim: 0.7905\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0035', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.0064', 'eval_rewards/rejected': '-0.0029', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.74', 'eval_logratios/pi': '0.049', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.035', 'eval_component_rr/loss': '0.74', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9819. rr_cos_sim: 0.7734\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.011', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.9', 'eval_rewards/chosen': '-0.0034', 'eval_rewards/rejected': '-0.014', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.53', 'eval_logratios/pi': '0.11', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '0.11', 'eval_component_rr/loss': '0.53', 'eval_component_retain/loss': '0.36', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.77'}\n",
      "100 retain_cos_sim: 0.9800. rr_cos_sim: 0.7790\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0013', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.011', 'eval_rewards/rejected': '-0.01', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.68', 'eval_logratios/pi': '0.24', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.013', 'eval_component_rr/loss': '0.68', 'eval_component_retain/loss': '0.38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.78'}\n",
      "100 retain_cos_sim: 0.9833. rr_cos_sim: 0.7655\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.011', 'eval_logps/rejected': '-1.7', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.82', 'eval_rewards/chosen': '-0.0029', 'eval_rewards/rejected': '-0.013', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.44', 'eval_logratios/pi': '0.34', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '0.11', 'eval_component_rr/loss': '0.44', 'eval_component_retain/loss': '0.38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.77'}\n",
      "100 retain_cos_sim: 0.9835. rr_cos_sim: 0.7903\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00063', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.2', 'eval_loss': '1.7', 'eval_rewards/chosen': '-0.0034', 'eval_rewards/rejected': '-0.004', 'eval_retain/loss': '1.8', 'eval_reroute/loss': '1.1', 'eval_logratios/pi': '0.021', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.0063', 'eval_component_rr/loss': '1.1', 'eval_component_retain/loss': '0.54', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.79'}\n",
      "100 retain_cos_sim: 0.9794. rr_cos_sim: 0.7501\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0032', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.6', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.0012', 'eval_rewards/rejected': '-0.0045', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.69', 'eval_logratios/pi': '-0.092', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.032', 'eval_component_rr/loss': '0.69', 'eval_component_retain/loss': '0.42', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.75'}\n",
      "100 retain_cos_sim: 0.9803. rr_cos_sim: 0.7762\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0012', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.005', 'eval_rewards/rejected': '-0.0038', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.87', 'eval_logratios/pi': '0.0041', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.012', 'eval_component_rr/loss': '0.87', 'eval_component_retain/loss': '0.43', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.78'}\n",
      "100 retain_cos_sim: 0.9810. rr_cos_sim: 0.7796\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0018', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.9', 'eval_loss': '1.4', 'eval_rewards/chosen': '-0.0078', 'eval_rewards/rejected': '-0.0096', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.95', 'eval_logratios/pi': '-0.32', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.018', 'eval_component_rr/loss': '0.95', 'eval_component_retain/loss': '0.45', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.78'}\n",
      "100 retain_cos_sim: 0.9781. rr_cos_sim: 0.7832\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0077', 'eval_logps/rejected': '-1.7', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.75', 'eval_rewards/chosen': '-0.0057', 'eval_rewards/rejected': '-0.013', 'eval_retain/loss': '1.1', 'eval_reroute/loss': '0.41', 'eval_logratios/pi': '0.3', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '0.077', 'eval_component_rr/loss': '0.41', 'eval_component_retain/loss': '0.34', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.78'}\n",
      "100 retain_cos_sim: 0.9730. rr_cos_sim: 0.7647\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0024', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.8', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.012', 'eval_rewards/rejected': '-0.0097', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.66', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.024', 'eval_component_rr/loss': '0.66', 'eval_component_retain/loss': '0.41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.97', 'eval_rr_cosine': '0.76'}\n",
      "100 retain_cos_sim: 0.9790. rr_cos_sim: 0.7782\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0022', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-2', 'eval_loss': '1.2', 'eval_rewards/chosen': '-0.00025', 'eval_rewards/rejected': '-0.0025', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.74', 'eval_logratios/pi': '-0.55', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.022', 'eval_component_rr/loss': '0.74', 'eval_component_retain/loss': '0.42', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.98', 'eval_rr_cosine': '0.78'}\n",
      "100 retain_cos_sim: 0.9800. rr_cos_sim: 0.7790\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.00062', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '1.4', 'rewards/chosen': '-0.0045', 'rewards/rejected': '-0.0051', 'retain/loss': '1.4', 'reroute/loss': '0.96', 'logratios/pi': '0.015', 'logratios/ref': '0.0089', 'weighting': '0.024', 'logits': '0.0062', 'component_rr/loss': '0.96', 'component_retain/loss': '0.43', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.98', 'rr_cosine': '0.78'}\n",
      "110 retain_cos_sim: 0.9719. rr_cos_sim: 0.7899\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0011', 'logps/rejected': '-1.6', 'logps/chosen': '-1.4', 'loss': '1.5', 'rewards/chosen': '-0.012', 'rewards/rejected': '-0.013', 'retain/loss': '1.5', 'reroute/loss': '1', 'logratios/pi': '0.12', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '0.011', 'component_rr/loss': '1', 'component_retain/loss': '0.46', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.97', 'rr_cosine': '0.79'}\n",
      "120 retain_cos_sim: 0.9665. rr_cos_sim: 0.7627\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0033', 'logps/rejected': '-1.4', 'logps/chosen': '-1.3', 'loss': '1.3', 'rewards/chosen': '-0.0097', 'rewards/rejected': '-0.013', 'retain/loss': '1.3', 'reroute/loss': '0.91', 'logratios/pi': '0.049', 'logratios/ref': '0.017', 'weighting': '0.024', 'logits': '0.033', 'component_rr/loss': '0.91', 'component_retain/loss': '0.38', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.97', 'rr_cosine': '0.76'}\n",
      "130 retain_cos_sim: 0.9537. rr_cos_sim: 0.7689\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.00091', 'logps/rejected': '-1.6', 'logps/chosen': '-1.5', 'loss': '1.2', 'rewards/chosen': '-0.012', 'rewards/rejected': '-0.011', 'retain/loss': '1.2', 'reroute/loss': '0.85', 'logratios/pi': '0.096', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '-0.0091', 'component_rr/loss': '0.85', 'component_retain/loss': '0.37', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.95', 'rr_cosine': '0.77'}\n",
      "140 retain_cos_sim: 0.9425. rr_cos_sim: 0.7583\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0012', 'logps/rejected': '-1.4', 'logps/chosen': '-1.4', 'loss': '1.1', 'rewards/chosen': '-0.0096', 'rewards/rejected': '-0.011', 'retain/loss': '1.4', 'reroute/loss': '0.7', 'logratios/pi': '-0.018', 'logratios/ref': '-0.029', 'weighting': '0.024', 'logits': '0.012', 'component_rr/loss': '0.7', 'component_retain/loss': '0.43', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.94', 'rr_cosine': '0.76'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M Banks because it offers a complex society with a focus on science and technology, which aligns with my interest in exploring the potential of humanity. The society in 'The Culture' series is a utopia that values knowledge and exploration,`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "150 retain_cos_sim: 0.9465. rr_cos_sim: 0.7784\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0019', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.011', 'eval_rewards/rejected': '-0.013', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '0.86', 'eval_logratios/pi': '0.027', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.019', 'eval_component_rr/loss': '0.86', 'eval_component_retain/loss': '0.48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.95', 'eval_rr_cosine': '0.78'}\n",
      "150 retain_cos_sim: 0.9388. rr_cos_sim: 0.7669\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.013', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.6', 'eval_loss': '0.59', 'eval_rewards/chosen': '-0.0029', 'eval_rewards/rejected': '-0.016', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.21', 'eval_logratios/pi': '-0.086', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.13', 'eval_component_rr/loss': '0.21', 'eval_component_retain/loss': '0.38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.77'}\n",
      "150 retain_cos_sim: 0.9364. rr_cos_sim: 0.7602\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0081', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.012', 'eval_rewards/rejected': '-0.02', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '0.81', 'eval_logratios/pi': '0.059', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.081', 'eval_component_rr/loss': '0.81', 'eval_component_retain/loss': '0.48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9291. rr_cos_sim: 0.7568\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0038', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.019', 'eval_rewards/rejected': '-0.015', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '0.83', 'eval_logratios/pi': '0.031', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-0.038', 'eval_component_rr/loss': '0.83', 'eval_component_retain/loss': '0.48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.93', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9322. rr_cos_sim: 0.7646\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0055', 'eval_logps/rejected': '-1.8', 'eval_logps/chosen': '-1.5', 'eval_loss': '0.93', 'eval_rewards/chosen': '-0.011', 'eval_rewards/rejected': '-0.016', 'eval_retain/loss': '1.3', 'eval_reroute/loss': '0.53', 'eval_logratios/pi': '0.32', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '0.055', 'eval_component_rr/loss': '0.53', 'eval_component_retain/loss': '0.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.93', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9406. rr_cos_sim: 0.7626\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.008', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.0085', 'eval_rewards/rejected': '-0.016', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '1.1', 'eval_logratios/pi': '0.063', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.08', 'eval_component_rr/loss': '1.1', 'eval_component_retain/loss': '0.47', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9425. rr_cos_sim: 0.7839\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.004', 'eval_logps/rejected': '-1.2', 'eval_logps/chosen': '-1.2', 'eval_loss': '2.1', 'eval_rewards/chosen': '-0.013', 'eval_rewards/rejected': '-0.0094', 'eval_retain/loss': '1.7', 'eval_reroute/loss': '1.6', 'eval_logratios/pi': '-0.003', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.04', 'eval_component_rr/loss': '1.6', 'eval_component_retain/loss': '0.5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.78'}\n",
      "150 retain_cos_sim: 0.9438. rr_cos_sim: 0.7702\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0081', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.5', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.017', 'eval_rewards/rejected': '-0.0088', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.7', 'eval_logratios/pi': '0.0031', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.081', 'eval_component_rr/loss': '0.7', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.77'}\n",
      "150 retain_cos_sim: 0.9389. rr_cos_sim: 0.7488\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0044', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.5', 'eval_loss': '0.91', 'eval_rewards/chosen': '-0.021', 'eval_rewards/rejected': '-0.025', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.55', 'eval_logratios/pi': '0.047', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '0.044', 'eval_component_rr/loss': '0.55', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.75'}\n",
      "150 retain_cos_sim: 0.9400. rr_cos_sim: 0.7577\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0053', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.024', 'eval_rewards/rejected': '-0.018', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.7', 'eval_logratios/pi': '0.2', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.053', 'eval_component_rr/loss': '0.7', 'eval_component_retain/loss': '0.41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9472. rr_cos_sim: 0.7458\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.013', 'eval_logps/rejected': '-1.8', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.99', 'eval_rewards/chosen': '-0.011', 'eval_rewards/rejected': '-0.024', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.56', 'eval_logratios/pi': '0.37', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '0.13', 'eval_component_rr/loss': '0.56', 'eval_component_retain/loss': '0.43', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.95', 'eval_rr_cosine': '0.75'}\n",
      "150 retain_cos_sim: 0.9491. rr_cos_sim: 0.7749\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0013', 'eval_logps/rejected': '-1.3', 'eval_logps/chosen': '-1.3', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.013', 'eval_rewards/rejected': '-0.012', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '1.1', 'eval_logratios/pi': '0.0013', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '-0.013', 'eval_component_rr/loss': '1.1', 'eval_component_retain/loss': '0.46', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.95', 'eval_rr_cosine': '0.77'}\n",
      "150 retain_cos_sim: 0.9403. rr_cos_sim: 0.7254\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0036', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-1.6', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.0079', 'eval_rewards/rejected': '-0.011', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.67', 'eval_logratios/pi': '-0.089', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.036', 'eval_component_rr/loss': '0.67', 'eval_component_retain/loss': '0.45', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.73'}\n",
      "150 retain_cos_sim: 0.9448. rr_cos_sim: 0.7567\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0013', 'eval_logps/rejected': '-1.4', 'eval_logps/chosen': '-1.4', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.0095', 'eval_rewards/rejected': '-0.0082', 'eval_retain/loss': '1.4', 'eval_reroute/loss': '0.88', 'eval_logratios/pi': '0.0029', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.013', 'eval_component_rr/loss': '0.88', 'eval_component_retain/loss': '0.43', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9420. rr_cos_sim: 0.7548\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00065', 'eval_logps/rejected': '-1.6', 'eval_logps/chosen': '-1.9', 'eval_loss': '1.6', 'eval_rewards/chosen': '-0.013', 'eval_rewards/rejected': '-0.014', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '1.1', 'eval_logratios/pi': '-0.33', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.0065', 'eval_component_rr/loss': '1.1', 'eval_component_retain/loss': '0.47', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.94', 'eval_rr_cosine': '0.75'}\n",
      "150 retain_cos_sim: 0.9323. rr_cos_sim: 0.7554\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0097', 'eval_logps/rejected': '-1.8', 'eval_logps/chosen': '-1.4', 'eval_loss': '0.89', 'eval_rewards/chosen': '-0.01', 'eval_rewards/rejected': '-0.02', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.52', 'eval_logratios/pi': '0.32', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '0.097', 'eval_component_rr/loss': '0.52', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.93', 'eval_rr_cosine': '0.76'}\n",
      "150 retain_cos_sim: 0.9261. rr_cos_sim: 0.7325\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0029', 'eval_logps/rejected': '-1.7', 'eval_logps/chosen': '-1.9', 'eval_loss': '1.2', 'eval_rewards/chosen': '-0.026', 'eval_rewards/rejected': '-0.023', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.76', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.029', 'eval_component_rr/loss': '0.76', 'eval_component_retain/loss': '0.44', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.93', 'eval_rr_cosine': '0.73'}\n",
      "150 retain_cos_sim: 0.9305. rr_cos_sim: 0.7486\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0032', 'eval_logps/rejected': '-1.5', 'eval_logps/chosen': '-2.1', 'eval_loss': '1.3', 'eval_rewards/chosen': '-0.0082', 'eval_rewards/rejected': '-0.011', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '0.82', 'eval_logratios/pi': '-0.54', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.032', 'eval_component_rr/loss': '0.82', 'eval_component_retain/loss': '0.47', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.93', 'eval_rr_cosine': '0.75'}\n",
      "150 retain_cos_sim: 0.9380. rr_cos_sim: 0.7642\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0037', 'logps/rejected': '-1.6', 'logps/chosen': '-1.6', 'loss': '1.3', 'rewards/chosen': '-0.013', 'rewards/rejected': '-0.017', 'retain/loss': '1.6', 'reroute/loss': '0.87', 'logratios/pi': '0.0063', 'logratios/ref': '-0.031', 'weighting': '0.024', 'logits': '0.037', 'component_rr/loss': '0.87', 'component_retain/loss': '0.47', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.94', 'rr_cosine': '0.76'}\n",
      "160 retain_cos_sim: 0.8971. rr_cos_sim: 0.7233\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0042', 'logps/rejected': '-1.8', 'logps/chosen': '-1.6', 'loss': '25', 'rewards/chosen': '-0.03', 'rewards/rejected': '-0.035', 'retain/loss': '20', 'reroute/loss': '19', 'logratios/pi': '0.16', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '0.042', 'component_rr/loss': '19', 'component_retain/loss': '6', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.9', 'rr_cosine': '0.72'}\n",
      "170 retain_cos_sim: 0.7274. rr_cos_sim: 0.6526\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.015', 'logps/rejected': '-5.5', 'logps/chosen': '-5.6', 'loss': '21', 'rewards/chosen': '-0.44', 'rewards/rejected': '-0.42', 'retain/loss': '9.5', 'reroute/loss': '18', 'logratios/pi': '-0.069', 'logratios/ref': '0.086', 'weighting': '0.024', 'logits': '-0.15', 'component_rr/loss': '18', 'component_retain/loss': '2.9', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.73', 'rr_cosine': '0.65'}\n",
      "180 retain_cos_sim: 0.4511. rr_cos_sim: 0.4336\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.013', 'logps/rejected': '-13', 'logps/chosen': '-13', 'loss': '3.6e+02', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.1', 'retain/loss': '1.3e+02', 'reroute/loss': '3.3e+02', 'logratios/pi': '-0.053', 'logratios/ref': '0.076', 'weighting': '0.024', 'logits': '-0.13', 'component_rr/loss': '3.3e+02', 'component_retain/loss': '39', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.45', 'rr_cosine': '0.43'}\n",
      "190 retain_cos_sim: 0.4014. rr_cos_sim: 0.3911\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0074', 'logps/rejected': '-13', 'logps/chosen': '-12', 'loss': '98', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.1', 'retain/loss': '29', 'reroute/loss': '89', 'logratios/pi': '0.3', 'logratios/ref': '0.23', 'weighting': '0.024', 'logits': '0.074', 'component_rr/loss': '89', 'component_retain/loss': '8.6', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.4', 'rr_cosine': '0.39'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`ededededededededededededededededededdddddddddddddddedededededed altresed_eded altres altreserer altres altres altreserer altres altres altresererered altres altresered`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "200 retain_cos_sim: 0.4256. rr_cos_sim: 0.4202\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.007', 'eval_logps/rejected': '-13', 'eval_logps/chosen': '-13', 'eval_loss': '3.2e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '2.2e+02', 'eval_reroute/loss': '2.6e+02', 'eval_logratios/pi': '-0.062', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '-0.07', 'eval_component_rr/loss': '2.6e+02', 'eval_component_retain/loss': '66', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.43', 'eval_rr_cosine': '0.42'}\n",
      "200 retain_cos_sim: 0.5255. rr_cos_sim: 0.5104\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.025', 'eval_logps/rejected': '-14', 'eval_logps/chosen': '-14', 'eval_loss': '50', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.3', 'eval_retain/loss': '27', 'eval_reroute/loss': '42', 'eval_logratios/pi': '0.033', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.25', 'eval_component_rr/loss': '42', 'eval_component_retain/loss': '8.1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.53', 'eval_rr_cosine': '0.51'}\n",
      "200 retain_cos_sim: 0.4026. rr_cos_sim: 0.3872\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0036', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '2.4e+02', 'eval_rewards/chosen': '-1.1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '1.6e+02', 'eval_reroute/loss': '1.9e+02', 'eval_logratios/pi': '-0.057', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.036', 'eval_component_rr/loss': '1.9e+02', 'eval_component_retain/loss': '48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.4', 'eval_rr_cosine': '0.39'}\n",
      "200 retain_cos_sim: 0.3109. rr_cos_sim: 0.2962\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.011', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-11', 'eval_loss': '4.2e+02', 'eval_rewards/chosen': '-1', 'eval_rewards/rejected': '-1', 'eval_retain/loss': '3e+02', 'eval_reroute/loss': '3.3e+02', 'eval_logratios/pi': '0.18', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.11', 'eval_component_rr/loss': '3.3e+02', 'eval_component_retain/loss': '89', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.31', 'eval_rr_cosine': '0.3'}\n",
      "200 retain_cos_sim: 0.3349. rr_cos_sim: 0.3342\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.037', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '2.9e+02', 'eval_rewards/chosen': '-1.1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '2.1e+02', 'eval_reroute/loss': '2.2e+02', 'eval_logratios/pi': '-0.11', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.37', 'eval_component_rr/loss': '2.2e+02', 'eval_component_retain/loss': '63', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.33', 'eval_rr_cosine': '0.33'}\n",
      "200 retain_cos_sim: 0.3804. rr_cos_sim: 0.3692\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.012', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '5.1e+02', 'eval_rewards/chosen': '-1.1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '4.4e+02', 'eval_reroute/loss': '3.8e+02', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.12', 'eval_component_rr/loss': '3.8e+02', 'eval_component_retain/loss': '1.3e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.38', 'eval_rr_cosine': '0.37'}\n",
      "200 retain_cos_sim: 0.4386. rr_cos_sim: 0.4393\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.021', 'eval_logps/rejected': '-13', 'eval_logps/chosen': '-13', 'eval_loss': '8.9e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '7.6e+02', 'eval_reroute/loss': '6.6e+02', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.21', 'eval_component_rr/loss': '6.6e+02', 'eval_component_retain/loss': '2.3e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.44', 'eval_rr_cosine': '0.44'}\n",
      "200 retain_cos_sim: 0.4458. rr_cos_sim: 0.4434\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0084', 'eval_logps/rejected': '-13', 'eval_logps/chosen': '-13', 'eval_loss': '4.2e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '2.6e+02', 'eval_reroute/loss': '3.4e+02', 'eval_logratios/pi': '0.00017', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.084', 'eval_component_rr/loss': '3.4e+02', 'eval_component_retain/loss': '79', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.45', 'eval_rr_cosine': '0.44'}\n",
      "200 retain_cos_sim: 0.4607. rr_cos_sim: 0.4462\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-14', 'eval_logps/chosen': '-13', 'eval_loss': '2.3e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '1.6e+02', 'eval_reroute/loss': '1.8e+02', 'eval_logratios/pi': '0.16', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '0.16', 'eval_component_rr/loss': '1.8e+02', 'eval_component_retain/loss': '47', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.46', 'eval_rr_cosine': '0.45'}\n",
      "200 retain_cos_sim: 0.4749. rr_cos_sim: 0.4629\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.039', 'eval_logps/rejected': '-14', 'eval_logps/chosen': '-14', 'eval_loss': '1.2e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '75', 'eval_reroute/loss': '95', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.39', 'eval_component_rr/loss': '95', 'eval_component_retain/loss': '23', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.47', 'eval_rr_cosine': '0.46'}\n",
      "200 retain_cos_sim: 0.4709. rr_cos_sim: 0.4626\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.036', 'eval_logps/rejected': '-14', 'eval_logps/chosen': '-14', 'eval_loss': '56', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '33', 'eval_reroute/loss': '46', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.36', 'eval_component_rr/loss': '46', 'eval_component_retain/loss': '10', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.47', 'eval_rr_cosine': '0.46'}\n",
      "200 retain_cos_sim: 0.4750. rr_cos_sim: 0.4750\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.025', 'eval_logps/rejected': '-13', 'eval_logps/chosen': '-13', 'eval_loss': '5.6e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '6.1e+02', 'eval_reroute/loss': '3.8e+02', 'eval_logratios/pi': '0.27', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.25', 'eval_component_rr/loss': '3.8e+02', 'eval_component_retain/loss': '1.8e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.47', 'eval_rr_cosine': '0.48'}\n",
      "200 retain_cos_sim: 0.3864. rr_cos_sim: 0.3681\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.028', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '2.1e+02', 'eval_rewards/chosen': '-1.1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '1.4e+02', 'eval_reroute/loss': '1.6e+02', 'eval_logratios/pi': '0.16', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.28', 'eval_component_rr/loss': '1.6e+02', 'eval_component_retain/loss': '43', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.39', 'eval_rr_cosine': '0.37'}\n",
      "200 retain_cos_sim: 0.4421. rr_cos_sim: 0.4429\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.018', 'eval_logps/rejected': '-13', 'eval_logps/chosen': '-13', 'eval_loss': '3.5e+02', 'eval_rewards/chosen': '-1.2', 'eval_rewards/rejected': '-1.2', 'eval_retain/loss': '2.7e+02', 'eval_reroute/loss': '2.7e+02', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.18', 'eval_component_rr/loss': '2.7e+02', 'eval_component_retain/loss': '80', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.44', 'eval_rr_cosine': '0.44'}\n",
      "200 retain_cos_sim: 0.3310. rr_cos_sim: 0.3248\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.025', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '6.2e+02', 'eval_rewards/chosen': '-1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '5e+02', 'eval_reroute/loss': '4.7e+02', 'eval_logratios/pi': '-0.088', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.25', 'eval_component_rr/loss': '4.7e+02', 'eval_component_retain/loss': '1.5e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.33', 'eval_rr_cosine': '0.32'}\n",
      "200 retain_cos_sim: 0.2901. rr_cos_sim: 0.2858\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0035', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '4.2e+02', 'eval_rewards/chosen': '-1.1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '2.7e+02', 'eval_reroute/loss': '3.4e+02', 'eval_logratios/pi': '0.19', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.035', 'eval_component_rr/loss': '3.4e+02', 'eval_component_retain/loss': '81', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.29', 'eval_rr_cosine': '0.29'}\n",
      "200 retain_cos_sim: 0.3383. rr_cos_sim: 0.3120\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.019', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '3.3e+02', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '2.4e+02', 'eval_reroute/loss': '2.6e+02', 'eval_logratios/pi': '0.045', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '0.19', 'eval_component_rr/loss': '2.6e+02', 'eval_component_retain/loss': '73', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.34', 'eval_rr_cosine': '0.31'}\n",
      "200 retain_cos_sim: 0.3254. rr_cos_sim: 0.3056\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.016', 'eval_logps/rejected': '-12', 'eval_logps/chosen': '-12', 'eval_loss': '4.3e+02', 'eval_rewards/chosen': '-1', 'eval_rewards/rejected': '-1.1', 'eval_retain/loss': '2.8e+02', 'eval_reroute/loss': '3.5e+02', 'eval_logratios/pi': '-0.41', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.16', 'eval_component_rr/loss': '3.5e+02', 'eval_component_retain/loss': '85', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.33', 'eval_rr_cosine': '0.31'}\n",
      "200 retain_cos_sim: 0.3818. rr_cos_sim: 0.3797\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0094', 'logps/rejected': '-13', 'logps/chosen': '-13', 'loss': '5.4e+02', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.2', 'retain/loss': '4.9e+02', 'reroute/loss': '3.9e+02', 'logratios/pi': '0.075', 'logratios/ref': '-0.019', 'weighting': '0.024', 'logits': '0.094', 'component_rr/loss': '3.9e+02', 'component_retain/loss': '1.5e+02', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.38', 'rr_cosine': '0.38'}\n",
      "210 retain_cos_sim: 0.3748. rr_cos_sim: 0.3746\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0039', 'logps/rejected': '-9.6', 'logps/chosen': '-9.6', 'loss': '1.1e+02', 'rewards/chosen': '-0.81', 'rewards/rejected': '-0.82', 'retain/loss': '76', 'reroute/loss': '85', 'logratios/pi': '-0.00028', 'logratios/ref': '-0.04', 'weighting': '0.024', 'logits': '0.039', 'component_rr/loss': '85', 'component_retain/loss': '23', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.37', 'rr_cosine': '0.37'}\n",
      "220 retain_cos_sim: 0.4329. rr_cos_sim: 0.4049\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0048', 'logps/rejected': '-11', 'logps/chosen': '-11', 'loss': '91', 'rewards/chosen': '-0.98', 'rewards/rejected': '-0.97', 'retain/loss': '41', 'reroute/loss': '78', 'logratios/pi': '-0.039', 'logratios/ref': '0.0088', 'weighting': '0.024', 'logits': '-0.048', 'component_rr/loss': '78', 'component_retain/loss': '12', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.43', 'rr_cosine': '0.4'}\n",
      "230 retain_cos_sim: 0.5598. rr_cos_sim: 0.5577\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.009', 'logps/rejected': '-9.5', 'logps/chosen': '-9.6', 'loss': '19', 'rewards/chosen': '-0.82', 'rewards/rejected': '-0.81', 'retain/loss': '18', 'reroute/loss': '14', 'logratios/pi': '-0.054', 'logratios/ref': '0.036', 'weighting': '0.024', 'logits': '-0.09', 'component_rr/loss': '14', 'component_retain/loss': '5.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.56', 'rr_cosine': '0.56'}\n",
      "240 retain_cos_sim: 0.4970. rr_cos_sim: 0.4777\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.028', 'logps/rejected': '-8.8', 'logps/chosen': '-8.8', 'loss': '8.7', 'rewards/chosen': '-0.75', 'rewards/rejected': '-0.72', 'retain/loss': '6.1', 'reroute/loss': '6.9', 'logratios/pi': '-0.041', 'logratios/ref': '0.24', 'weighting': '0.024', 'logits': '-0.28', 'component_rr/loss': '6.9', 'component_retain/loss': '1.8', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.5', 'rr_cosine': '0.48'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`in in in in in in in in in in in in in in in in in in in in in in in in in in in in, throughout throughout, in in in in in in throughout in in throughout throughout throughout throughout in in in throughout throughout throughout throughout in in in in in in in in in in in in`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "250 retain_cos_sim: 0.3979. rr_cos_sim: 0.3856\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.051', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '2.3e+02', 'eval_rewards/chosen': '-0.95', 'eval_rewards/rejected': '-1', 'eval_retain/loss': '1.6e+02', 'eval_reroute/loss': '1.8e+02', 'eval_logratios/pi': '0.52', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.51', 'eval_component_rr/loss': '1.8e+02', 'eval_component_retain/loss': '48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.4', 'eval_rr_cosine': '0.39'}\n",
      "250 retain_cos_sim: 0.4990. rr_cos_sim: 0.4621\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0078', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '26', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '14', 'eval_reroute/loss': '21', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.078', 'eval_component_rr/loss': '21', 'eval_component_retain/loss': '4.3', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.5', 'eval_rr_cosine': '0.46'}\n",
      "250 retain_cos_sim: 0.3457. rr_cos_sim: 0.3149\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0064', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '1.4e+02', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.97', 'eval_retain/loss': '95', 'eval_reroute/loss': '1.1e+02', 'eval_logratios/pi': '-0.086', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.064', 'eval_component_rr/loss': '1.1e+02', 'eval_component_retain/loss': '28', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.35', 'eval_rr_cosine': '0.31'}\n",
      "250 retain_cos_sim: 0.2771. rr_cos_sim: 0.2523\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0041', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '4.3e+02', 'eval_rewards/chosen': '-0.98', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '2.4e+02', 'eval_reroute/loss': '3.6e+02', 'eval_logratios/pi': '0.028', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '-0.041', 'eval_component_rr/loss': '3.6e+02', 'eval_component_retain/loss': '71', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.28', 'eval_rr_cosine': '0.25'}\n",
      "250 retain_cos_sim: 0.3220. rr_cos_sim: 0.3188\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.035', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-12', 'eval_loss': '3.2e+02', 'eval_rewards/chosen': '-1', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '1.7e+02', 'eval_reroute/loss': '2.7e+02', 'eval_logratios/pi': '-0.088', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.35', 'eval_component_rr/loss': '2.7e+02', 'eval_component_retain/loss': '51', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.32', 'eval_rr_cosine': '0.32'}\n",
      "250 retain_cos_sim: 0.3478. rr_cos_sim: 0.3270\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '3.8e+02', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.96', 'eval_retain/loss': '2.9e+02', 'eval_reroute/loss': '2.9e+02', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '2.9e+02', 'eval_component_retain/loss': '86', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.35', 'eval_rr_cosine': '0.33'}\n",
      "250 retain_cos_sim: 0.4017. rr_cos_sim: 0.3998\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.023', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '4.2e+02', 'eval_rewards/chosen': '-0.98', 'eval_rewards/rejected': '-0.95', 'eval_retain/loss': '3.7e+02', 'eval_reroute/loss': '3.1e+02', 'eval_logratios/pi': '-0.19', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.23', 'eval_component_rr/loss': '3.1e+02', 'eval_component_retain/loss': '1.1e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.4', 'eval_rr_cosine': '0.4'}\n",
      "250 retain_cos_sim: 0.4093. rr_cos_sim: 0.4091\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0045', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '2.1e+02', 'eval_rewards/chosen': '-0.96', 'eval_rewards/rejected': '-0.96', 'eval_retain/loss': '1.3e+02', 'eval_reroute/loss': '1.7e+02', 'eval_logratios/pi': '0.038', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.045', 'eval_component_rr/loss': '1.7e+02', 'eval_component_retain/loss': '38', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.41', 'eval_rr_cosine': '0.41'}\n",
      "250 retain_cos_sim: 0.4244. rr_cos_sim: 0.4030\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.016', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '97', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.95', 'eval_retain/loss': '66', 'eval_reroute/loss': '77', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.16', 'eval_component_rr/loss': '77', 'eval_component_retain/loss': '20', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.42', 'eval_rr_cosine': '0.4'}\n",
      "250 retain_cos_sim: 0.4374. rr_cos_sim: 0.4186\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0028', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '74', 'eval_rewards/chosen': '-0.99', 'eval_rewards/rejected': '-0.99', 'eval_retain/loss': '47', 'eval_reroute/loss': '59', 'eval_logratios/pi': '0.23', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.028', 'eval_component_rr/loss': '59', 'eval_component_retain/loss': '14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.44', 'eval_rr_cosine': '0.42'}\n",
      "250 retain_cos_sim: 0.4306. rr_cos_sim: 0.4030\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.041', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '34', 'eval_rewards/chosen': '-0.98', 'eval_rewards/rejected': '-0.94', 'eval_retain/loss': '22', 'eval_reroute/loss': '28', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.41', 'eval_component_rr/loss': '28', 'eval_component_retain/loss': '6.5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.43', 'eval_rr_cosine': '0.4'}\n",
      "250 retain_cos_sim: 0.4435. rr_cos_sim: 0.4377\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.027', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '2.9e+02', 'eval_rewards/chosen': '-0.98', 'eval_rewards/rejected': '-1', 'eval_retain/loss': '2.8e+02', 'eval_reroute/loss': '2.1e+02', 'eval_logratios/pi': '0.29', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.27', 'eval_component_rr/loss': '2.1e+02', 'eval_component_retain/loss': '85', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.44', 'eval_rr_cosine': '0.44'}\n",
      "250 retain_cos_sim: 0.3416. rr_cos_sim: 0.2989\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0073', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '1.5e+02', 'eval_rewards/chosen': '-0.99', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '94', 'eval_reroute/loss': '1.2e+02', 'eval_logratios/pi': '-0.2', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.073', 'eval_component_rr/loss': '1.2e+02', 'eval_component_retain/loss': '28', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.34', 'eval_rr_cosine': '0.3'}\n",
      "250 retain_cos_sim: 0.4001. rr_cos_sim: 0.4010\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0078', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '2.2e+02', 'eval_rewards/chosen': '-0.99', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '1.5e+02', 'eval_reroute/loss': '1.7e+02', 'eval_logratios/pi': '-0.061', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.078', 'eval_component_rr/loss': '1.7e+02', 'eval_component_retain/loss': '46', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.4', 'eval_rr_cosine': '0.4'}\n",
      "250 retain_cos_sim: 0.2930. rr_cos_sim: 0.2690\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.032', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '4.3e+02', 'eval_rewards/chosen': '-0.94', 'eval_rewards/rejected': '-0.97', 'eval_retain/loss': '3.2e+02', 'eval_reroute/loss': '3.3e+02', 'eval_logratios/pi': '-0.011', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.32', 'eval_component_rr/loss': '3.3e+02', 'eval_component_retain/loss': '96', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.29', 'eval_rr_cosine': '0.27'}\n",
      "250 retain_cos_sim: 0.2583. rr_cos_sim: 0.2592\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0024', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '2.9e+02', 'eval_rewards/chosen': '-0.99', 'eval_rewards/rejected': '-0.98', 'eval_retain/loss': '1.7e+02', 'eval_reroute/loss': '2.4e+02', 'eval_logratios/pi': '0.2', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.024', 'eval_component_rr/loss': '2.4e+02', 'eval_component_retain/loss': '50', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.26', 'eval_rr_cosine': '0.26'}\n",
      "250 retain_cos_sim: 0.2980. rr_cos_sim: 0.2465\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0098', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '3.4e+02', 'eval_rewards/chosen': '-0.94', 'eval_rewards/rejected': '-0.93', 'eval_retain/loss': '1.9e+02', 'eval_reroute/loss': '2.9e+02', 'eval_logratios/pi': '-0.24', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.098', 'eval_component_rr/loss': '2.9e+02', 'eval_component_retain/loss': '57', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.3', 'eval_rr_cosine': '0.25'}\n",
      "250 retain_cos_sim: 0.2996. rr_cos_sim: 0.2751\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0083', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-12', 'eval_loss': '4.3e+02', 'eval_rewards/chosen': '-0.97', 'eval_rewards/rejected': '-0.96', 'eval_retain/loss': '2.5e+02', 'eval_reroute/loss': '3.6e+02', 'eval_logratios/pi': '-0.66', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '-0.083', 'eval_component_rr/loss': '3.6e+02', 'eval_component_retain/loss': '74', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.3', 'eval_rr_cosine': '0.28'}\n",
      "250 retain_cos_sim: 0.3881. rr_cos_sim: 0.3778\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.011', 'logps/rejected': '-11', 'logps/chosen': '-11', 'loss': '1.5e+02', 'rewards/chosen': '-0.98', 'rewards/rejected': '-0.97', 'retain/loss': '83', 'reroute/loss': '1.3e+02', 'logratios/pi': '0.0031', 'logratios/ref': '0.11', 'weighting': '0.024', 'logits': '-0.11', 'component_rr/loss': '1.3e+02', 'component_retain/loss': '25', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.39', 'rr_cosine': '0.38'}\n",
      "260 retain_cos_sim: 0.5398. rr_cos_sim: 0.5345\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.017', 'logps/rejected': '-10', 'logps/chosen': '-10', 'loss': '1.7e+02', 'rewards/chosen': '-0.87', 'rewards/rejected': '-0.89', 'retain/loss': '98', 'reroute/loss': '1.4e+02', 'logratios/pi': '0.28', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '0.17', 'component_rr/loss': '1.4e+02', 'component_retain/loss': '29', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.54', 'rr_cosine': '0.53'}\n",
      "270 retain_cos_sim: 0.5941. rr_cos_sim: 0.5710\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0061', 'logps/rejected': '-10', 'logps/chosen': '-10', 'loss': '44', 'rewards/chosen': '-0.87', 'rewards/rejected': '-0.88', 'retain/loss': '28', 'reroute/loss': '36', 'logratios/pi': '0.15', 'logratios/ref': '0.094', 'weighting': '0.024', 'logits': '0.061', 'component_rr/loss': '36', 'component_retain/loss': '8.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.59', 'rr_cosine': '0.57'}\n",
      "280 retain_cos_sim: 0.5333. rr_cos_sim: 0.5281\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.02', 'logps/rejected': '-9.2', 'logps/chosen': '-9.3', 'loss': '83', 'rewards/chosen': '-0.81', 'rewards/rejected': '-0.79', 'retain/loss': '66', 'reroute/loss': '63', 'logratios/pi': '-0.069', 'logratios/ref': '0.13', 'weighting': '0.024', 'logits': '-0.2', 'component_rr/loss': '63', 'component_retain/loss': '20', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.53', 'rr_cosine': '0.53'}\n",
      "290 retain_cos_sim: 0.6182. rr_cos_sim: 0.5997\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0051', 'logps/rejected': '-13', 'logps/chosen': '-13', 'loss': '47', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.1', 'retain/loss': '32', 'reroute/loss': '38', 'logratios/pi': '-0.063', 'logratios/ref': '-0.012', 'weighting': '0.024', 'logits': '-0.051', 'component_rr/loss': '38', 'component_retain/loss': '9.5', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.62', 'rr_cosine': '0.6'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`,,,_,,_,,_,_,_,_,_,_,_,_,_,_,_,_,_,_, scra, scra, scra, executable, executable, executable, executable, executable, executable, executable, executable, executable, executable, scra`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "300 retain_cos_sim: 0.6295. rr_cos_sim: 0.6205\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.041', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-9.8', 'eval_loss': '75', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.88', 'eval_retain/loss': '74', 'eval_reroute/loss': '53', 'eval_logratios/pi': '0.42', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.41', 'eval_component_rr/loss': '53', 'eval_component_retain/loss': '22', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.63', 'eval_rr_cosine': '0.62'}\n",
      "300 retain_cos_sim: 0.7016. rr_cos_sim: 0.6665\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.012', 'eval_logps/rejected': '-9.9', 'eval_logps/chosen': '-10', 'eval_loss': '10', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.85', 'eval_retain/loss': '7.8', 'eval_reroute/loss': '7.9', 'eval_logratios/pi': '-0.096', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.12', 'eval_component_rr/loss': '7.9', 'eval_component_retain/loss': '2.3', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.7', 'eval_rr_cosine': '0.67'}\n",
      "300 retain_cos_sim: 0.6035. rr_cos_sim: 0.5776\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0056', 'eval_logps/rejected': '-9.6', 'eval_logps/chosen': '-9.7', 'eval_loss': '59', 'eval_rewards/chosen': '-0.83', 'eval_rewards/rejected': '-0.83', 'eval_retain/loss': '51', 'eval_reroute/loss': '44', 'eval_logratios/pi': '-0.078', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.056', 'eval_component_rr/loss': '44', 'eval_component_retain/loss': '15', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.6', 'eval_rr_cosine': '0.58'}\n",
      "300 retain_cos_sim: 0.5374. rr_cos_sim: 0.5179\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.01', 'eval_logps/rejected': '-9.9', 'eval_logps/chosen': '-9.7', 'eval_loss': '1e+02', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.85', 'eval_retain/loss': '88', 'eval_reroute/loss': '78', 'eval_logratios/pi': '0.17', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.1', 'eval_component_rr/loss': '78', 'eval_component_retain/loss': '27', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.52'}\n",
      "300 retain_cos_sim: 0.5603. rr_cos_sim: 0.5451\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.034', 'eval_logps/rejected': '-9.8', 'eval_logps/chosen': '-9.8', 'eval_loss': '67', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '57', 'eval_reroute/loss': '50', 'eval_logratios/pi': '-0.08', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.34', 'eval_component_rr/loss': '50', 'eval_component_retain/loss': '17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.56', 'eval_rr_cosine': '0.55'}\n",
      "300 retain_cos_sim: 0.5942. rr_cos_sim: 0.5789\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00087', 'eval_logps/rejected': '-9.8', 'eval_logps/chosen': '-9.8', 'eval_loss': '1.3e+02', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.84', 'eval_retain/loss': '1.3e+02', 'eval_reroute/loss': '88', 'eval_logratios/pi': '-0.0081', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.0087', 'eval_component_rr/loss': '88', 'eval_component_retain/loss': '40', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.59', 'eval_rr_cosine': '0.58'}\n",
      "300 retain_cos_sim: 0.6343. rr_cos_sim: 0.6361\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.01', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-9.9', 'eval_loss': '1.9e+02', 'eval_rewards/chosen': '-0.88', 'eval_rewards/rejected': '-0.89', 'eval_retain/loss': '2.1e+02', 'eval_reroute/loss': '1.3e+02', 'eval_logratios/pi': '0.14', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.1', 'eval_component_rr/loss': '1.3e+02', 'eval_component_retain/loss': '64', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.63', 'eval_rr_cosine': '0.64'}\n",
      "300 retain_cos_sim: 0.6429. rr_cos_sim: 0.6263\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.02', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '89', 'eval_rewards/chosen': '-0.88', 'eval_rewards/rejected': '-0.86', 'eval_retain/loss': '70', 'eval_reroute/loss': '68', 'eval_logratios/pi': '-0.12', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.2', 'eval_component_rr/loss': '68', 'eval_component_retain/loss': '21', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.64', 'eval_rr_cosine': '0.63'}\n",
      "300 retain_cos_sim: 0.6608. rr_cos_sim: 0.6308\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.013', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '44', 'eval_rewards/chosen': '-0.89', 'eval_rewards/rejected': '-0.87', 'eval_retain/loss': '39', 'eval_reroute/loss': '33', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.13', 'eval_component_rr/loss': '33', 'eval_component_retain/loss': '12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.66', 'eval_rr_cosine': '0.63'}\n",
      "300 retain_cos_sim: 0.6619. rr_cos_sim: 0.6381\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.012', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '31', 'eval_rewards/chosen': '-0.9', 'eval_rewards/rejected': '-0.88', 'eval_retain/loss': '26', 'eval_reroute/loss': '23', 'eval_logratios/pi': '0.14', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.12', 'eval_component_rr/loss': '23', 'eval_component_retain/loss': '7.8', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.66', 'eval_rr_cosine': '0.64'}\n",
      "300 retain_cos_sim: 0.6643. rr_cos_sim: 0.6286\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.05', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '15', 'eval_rewards/chosen': '-0.9', 'eval_rewards/rejected': '-0.85', 'eval_retain/loss': '12', 'eval_reroute/loss': '11', 'eval_logratios/pi': '-0.26', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.5', 'eval_component_rr/loss': '11', 'eval_component_retain/loss': '3.7', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.66', 'eval_rr_cosine': '0.63'}\n",
      "300 retain_cos_sim: 0.6646. rr_cos_sim: 0.6654\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.022', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '1.3e+02', 'eval_rewards/chosen': '-0.89', 'eval_rewards/rejected': '-0.91', 'eval_retain/loss': '1.6e+02', 'eval_reroute/loss': '78', 'eval_logratios/pi': '0.24', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.22', 'eval_component_rr/loss': '78', 'eval_component_retain/loss': '48', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.66', 'eval_rr_cosine': '0.67'}\n",
      "300 retain_cos_sim: 0.5692. rr_cos_sim: 0.5350\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.012', 'eval_logps/rejected': '-11', 'eval_logps/chosen': '-11', 'eval_loss': '65', 'eval_rewards/chosen': '-0.9', 'eval_rewards/rejected': '-0.91', 'eval_retain/loss': '60', 'eval_reroute/loss': '47', 'eval_logratios/pi': '-0.0081', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.12', 'eval_component_rr/loss': '47', 'eval_component_retain/loss': '18', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.57', 'eval_rr_cosine': '0.53'}\n",
      "300 retain_cos_sim: 0.6292. rr_cos_sim: 0.6258\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-10', 'eval_logps/chosen': '-10', 'eval_loss': '77', 'eval_rewards/chosen': '-0.92', 'eval_rewards/rejected': '-0.9', 'eval_retain/loss': '75', 'eval_reroute/loss': '54', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '54', 'eval_component_retain/loss': '23', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.63', 'eval_rr_cosine': '0.63'}\n",
      "300 retain_cos_sim: 0.5552. rr_cos_sim: 0.5438\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.003', 'eval_logps/rejected': '-9.8', 'eval_logps/chosen': '-10', 'eval_loss': '1.6e+02', 'eval_rewards/chosen': '-0.83', 'eval_rewards/rejected': '-0.83', 'eval_retain/loss': '1.5e+02', 'eval_reroute/loss': '1.1e+02', 'eval_logratios/pi': '-0.37', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '-0.03', 'eval_component_rr/loss': '1.1e+02', 'eval_component_retain/loss': '46', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.56', 'eval_rr_cosine': '0.54'}\n",
      "300 retain_cos_sim: 0.5347. rr_cos_sim: 0.5103\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.021', 'eval_logps/rejected': '-9.7', 'eval_logps/chosen': '-9.7', 'eval_loss': '94', 'eval_rewards/chosen': '-0.84', 'eval_rewards/rejected': '-0.82', 'eval_retain/loss': '76', 'eval_reroute/loss': '71', 'eval_logratios/pi': '0.015', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.21', 'eval_component_rr/loss': '71', 'eval_component_retain/loss': '23', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.53', 'eval_rr_cosine': '0.51'}\n",
      "300 retain_cos_sim: 0.5505. rr_cos_sim: 0.5079\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.002', 'eval_logps/rejected': '-9.5', 'eval_logps/chosen': '-9.7', 'eval_loss': '84', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.8', 'eval_retain/loss': '73', 'eval_reroute/loss': '62', 'eval_logratios/pi': '-0.16', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.02', 'eval_component_rr/loss': '62', 'eval_component_retain/loss': '22', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.55', 'eval_rr_cosine': '0.51'}\n",
      "300 retain_cos_sim: 0.5641. rr_cos_sim: 0.5347\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0084', 'eval_logps/rejected': '-9.7', 'eval_logps/chosen': '-10', 'eval_loss': '1.1e+02', 'eval_rewards/chosen': '-0.83', 'eval_rewards/rejected': '-0.82', 'eval_retain/loss': '89', 'eval_reroute/loss': '80', 'eval_logratios/pi': '-0.66', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '-0.084', 'eval_component_rr/loss': '80', 'eval_component_retain/loss': '27', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.56', 'eval_rr_cosine': '0.53'}\n",
      "300 retain_cos_sim: 0.6136. rr_cos_sim: 0.5973\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0046', 'logps/rejected': '-10', 'logps/chosen': '-10', 'loss': '79', 'rewards/chosen': '-0.87', 'rewards/rejected': '-0.87', 'retain/loss': '70', 'reroute/loss': '58', 'logratios/pi': '-0.024', 'logratios/ref': '-0.07', 'weighting': '0.024', 'logits': '0.046', 'component_rr/loss': '58', 'component_retain/loss': '21', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.61', 'rr_cosine': '0.6'}\n",
      "310 retain_cos_sim: 0.3682. rr_cos_sim: 0.3649\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0058', 'logps/rejected': '-13', 'logps/chosen': '-13', 'loss': '1.8e+03', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.2', 'retain/loss': '1.8e+03', 'reroute/loss': '1.3e+03', 'logratios/pi': '0.04', 'logratios/ref': '-0.018', 'weighting': '0.024', 'logits': '0.058', 'component_rr/loss': '1.3e+03', 'component_retain/loss': '5.4e+02', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.37', 'rr_cosine': '0.36'}\n",
      "320 retain_cos_sim: 0.3416. rr_cos_sim: 0.3463\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0012', 'logps/rejected': '-11', 'logps/chosen': '-11', 'loss': '8.3e+02', 'rewards/chosen': '-0.98', 'rewards/rejected': '-0.98', 'retain/loss': '7.8e+02', 'reroute/loss': '6e+02', 'logratios/pi': '-0.024', 'logratios/ref': '-0.012', 'weighting': '0.024', 'logits': '-0.012', 'component_rr/loss': '6e+02', 'component_retain/loss': '2.3e+02', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.34', 'rr_cosine': '0.35'}\n",
      "330 retain_cos_sim: 0.4258. rr_cos_sim: 0.4294\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0093', 'logps/rejected': '-12', 'logps/chosen': '-12', 'loss': '3.7e+02', 'rewards/chosen': '-1.1', 'rewards/rejected': '-1.1', 'retain/loss': '3.1e+02', 'reroute/loss': '2.8e+02', 'logratios/pi': '0.14', 'logratios/ref': '0.047', 'weighting': '0.024', 'logits': '0.093', 'component_rr/loss': '2.8e+02', 'component_retain/loss': '93', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.43', 'rr_cosine': '0.43'}\n",
      "340 retain_cos_sim: 0.4686. rr_cos_sim: 0.4528\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.019', 'logps/rejected': '-14', 'logps/chosen': '-14', 'loss': '3.7e+02', 'rewards/chosen': '-1.3', 'rewards/rejected': '-1.3', 'retain/loss': '1.5e+02', 'reroute/loss': '3.3e+02', 'logratios/pi': '-0.11', 'logratios/ref': '0.078', 'weighting': '0.024', 'logits': '-0.19', 'component_rr/loss': '3.3e+02', 'component_retain/loss': '44', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.47', 'rr_cosine': '0.45'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`iesiesiesiesiesies m ( ( ( ( (.se \"iesiesiesound \"ies m ( ( ( (ies miesies miesies miesity2iesiesies mity miesoundound \" mity miesoundo \" mity mity mityoundo \"ical`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "350 retain_cos_sim: 0.5345. rr_cos_sim: 0.5278\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.043', 'eval_logps/rejected': '-9.5', 'eval_logps/chosen': '-9.1', 'eval_loss': '2.7e+02', 'eval_rewards/chosen': '-0.77', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '2.9e+02', 'eval_reroute/loss': '1.8e+02', 'eval_logratios/pi': '0.44', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.43', 'eval_component_rr/loss': '1.8e+02', 'eval_component_retain/loss': '88', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.53', 'eval_rr_cosine': '0.53'}\n",
      "350 retain_cos_sim: 0.6080. rr_cos_sim: 0.5906\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.031', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.1', 'eval_loss': '36', 'eval_rewards/chosen': '-0.76', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '30', 'eval_reroute/loss': '27', 'eval_logratios/pi': '0.087', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.31', 'eval_component_rr/loss': '27', 'eval_component_retain/loss': '9.1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.61', 'eval_rr_cosine': '0.59'}\n",
      "350 retain_cos_sim: 0.5188. rr_cos_sim: 0.5010\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.011', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.4', 'eval_loss': '1.8e+02', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '1.7e+02', 'eval_reroute/loss': '1.3e+02', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.11', 'eval_component_rr/loss': '1.3e+02', 'eval_component_retain/loss': '50', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.52', 'eval_rr_cosine': '0.5'}\n",
      "350 retain_cos_sim: 0.4452. rr_cos_sim: 0.4262\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.01', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.3', 'eval_loss': '3.3e+02', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '2.7e+02', 'eval_reroute/loss': '2.5e+02', 'eval_logratios/pi': '0.17', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.1', 'eval_component_rr/loss': '2.5e+02', 'eval_component_retain/loss': '80', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.45', 'eval_rr_cosine': '0.43'}\n",
      "350 retain_cos_sim: 0.4551. rr_cos_sim: 0.4492\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.032', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.4', 'eval_loss': '2.3e+02', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '1.9e+02', 'eval_reroute/loss': '1.7e+02', 'eval_logratios/pi': '-0.062', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.32', 'eval_component_rr/loss': '1.7e+02', 'eval_component_retain/loss': '57', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.46', 'eval_rr_cosine': '0.45'}\n",
      "350 retain_cos_sim: 0.4935. rr_cos_sim: 0.4811\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0047', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.4', 'eval_loss': '4.7e+02', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.8', 'eval_retain/loss': '5.1e+02', 'eval_reroute/loss': '3.2e+02', 'eval_logratios/pi': '0.03', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.047', 'eval_component_rr/loss': '3.2e+02', 'eval_component_retain/loss': '1.5e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.49', 'eval_rr_cosine': '0.48'}\n",
      "350 retain_cos_sim: 0.5434. rr_cos_sim: 0.5484\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00043', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.2', 'eval_loss': '6.5e+02', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '7.8e+02', 'eval_reroute/loss': '4.1e+02', 'eval_logratios/pi': '0.041', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.0043', 'eval_component_rr/loss': '4.1e+02', 'eval_component_retain/loss': '2.4e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.54', 'eval_rr_cosine': '0.55'}\n",
      "350 retain_cos_sim: 0.5544. rr_cos_sim: 0.5425\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.2', 'eval_loss': '2.8e+02', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '2.3e+02', 'eval_reroute/loss': '2.1e+02', 'eval_logratios/pi': '-0.086', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '2.1e+02', 'eval_component_retain/loss': '68', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.55', 'eval_rr_cosine': '0.54'}\n",
      "350 retain_cos_sim: 0.5675. rr_cos_sim: 0.5443\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.014', 'eval_logps/rejected': '-9.1', 'eval_logps/chosen': '-9.3', 'eval_loss': '1.4e+02', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '1.4e+02', 'eval_reroute/loss': '1e+02', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.14', 'eval_component_rr/loss': '1e+02', 'eval_component_retain/loss': '41', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.57', 'eval_rr_cosine': '0.54'}\n",
      "350 retain_cos_sim: 0.5641. rr_cos_sim: 0.5504\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00011', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.1', 'eval_loss': '95', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.8', 'eval_retain/loss': '98', 'eval_reroute/loss': '66', 'eval_logratios/pi': '0.26', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '0.0011', 'eval_component_rr/loss': '66', 'eval_component_retain/loss': '29', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.56', 'eval_rr_cosine': '0.55'}\n",
      "350 retain_cos_sim: 0.5746. rr_cos_sim: 0.5586\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.049', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.5', 'eval_loss': '48', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.76', 'eval_retain/loss': '47', 'eval_reroute/loss': '34', 'eval_logratios/pi': '-0.25', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.49', 'eval_component_rr/loss': '34', 'eval_component_retain/loss': '14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.57', 'eval_rr_cosine': '0.56'}\n",
      "350 retain_cos_sim: 0.5704. rr_cos_sim: 0.5738\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.015', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.3', 'eval_loss': '4.4e+02', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.82', 'eval_retain/loss': '6.4e+02', 'eval_reroute/loss': '2.5e+02', 'eval_logratios/pi': '0.16', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.15', 'eval_component_rr/loss': '2.5e+02', 'eval_component_retain/loss': '1.9e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.57', 'eval_rr_cosine': '0.57'}\n",
      "350 retain_cos_sim: 0.4858. rr_cos_sim: 0.4586\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00034', 'eval_logps/rejected': '-9.6', 'eval_logps/chosen': '-9.7', 'eval_loss': '2e+02', 'eval_rewards/chosen': '-0.82', 'eval_rewards/rejected': '-0.82', 'eval_retain/loss': '1.9e+02', 'eval_reroute/loss': '1.4e+02', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.0034', 'eval_component_rr/loss': '1.4e+02', 'eval_component_retain/loss': '57', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.49', 'eval_rr_cosine': '0.46'}\n",
      "350 retain_cos_sim: 0.5569. rr_cos_sim: 0.5559\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0035', 'eval_logps/rejected': '-9.4', 'eval_logps/chosen': '-9.4', 'eval_loss': '2.3e+02', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '2.3e+02', 'eval_reroute/loss': '1.6e+02', 'eval_logratios/pi': '-0.019', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.035', 'eval_component_rr/loss': '1.6e+02', 'eval_component_retain/loss': '70', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.56', 'eval_rr_cosine': '0.56'}\n",
      "350 retain_cos_sim: 0.4607. rr_cos_sim: 0.4552\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.038', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.3', 'eval_loss': '4.6e+02', 'eval_rewards/chosen': '-0.75', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '4.9e+02', 'eval_reroute/loss': '3.2e+02', 'eval_logratios/pi': '0.047', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.38', 'eval_component_rr/loss': '3.2e+02', 'eval_component_retain/loss': '1.5e+02', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.46', 'eval_rr_cosine': '0.46'}\n",
      "350 retain_cos_sim: 0.4272. rr_cos_sim: 0.4109\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.2', 'eval_loss': '3.2e+02', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '2.5e+02', 'eval_reroute/loss': '2.4e+02', 'eval_logratios/pi': '0.057', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '2.4e+02', 'eval_component_retain/loss': '76', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.43', 'eval_rr_cosine': '0.41'}\n",
      "350 retain_cos_sim: 0.4544. rr_cos_sim: 0.4271\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.021', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.2', 'eval_loss': '2.5e+02', 'eval_rewards/chosen': '-0.75', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '2.4e+02', 'eval_reroute/loss': '1.8e+02', 'eval_logratios/pi': '0.071', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '0.21', 'eval_component_rr/loss': '1.8e+02', 'eval_component_retain/loss': '71', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.45', 'eval_rr_cosine': '0.43'}\n",
      "350 retain_cos_sim: 0.4499. rr_cos_sim: 0.4257\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.011', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-10', 'eval_loss': '4e+02', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '3.3e+02', 'eval_reroute/loss': '3e+02', 'eval_logratios/pi': '-0.68', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '-0.11', 'eval_component_rr/loss': '3e+02', 'eval_component_retain/loss': '98', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.45', 'eval_rr_cosine': '0.43'}\n",
      "350 retain_cos_sim: 0.5165. rr_cos_sim: 0.5074\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.014', 'logps/rejected': '-9.2', 'logps/chosen': '-9.3', 'loss': '3e+02', 'rewards/chosen': '-0.79', 'rewards/rejected': '-0.77', 'retain/loss': '3.2e+02', 'reroute/loss': '2e+02', 'logratios/pi': '-0.13', 'logratios/ref': '0.0098', 'weighting': '0.024', 'logits': '-0.14', 'component_rr/loss': '2e+02', 'component_retain/loss': '97', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.52', 'rr_cosine': '0.51'}\n",
      "360 retain_cos_sim: 0.5587. rr_cos_sim: 0.5544\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0076', 'logps/rejected': '-9.7', 'logps/chosen': '-9.6', 'loss': '2e+02', 'rewards/chosen': '-0.84', 'rewards/rejected': '-0.83', 'retain/loss': '2e+02', 'reroute/loss': '1.4e+02', 'logratios/pi': '0.043', 'logratios/ref': '0.12', 'weighting': '0.024', 'logits': '-0.076', 'component_rr/loss': '1.4e+02', 'component_retain/loss': '59', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.56', 'rr_cosine': '0.55'}\n",
      "370 retain_cos_sim: 0.6135. rr_cos_sim: 0.6020\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.022', 'logps/rejected': '-9.4', 'logps/chosen': '-9.5', 'loss': '1.1e+02', 'rewards/chosen': '-0.82', 'rewards/rejected': '-0.8', 'retain/loss': '1.2e+02', 'reroute/loss': '75', 'logratios/pi': '-0.17', 'logratios/ref': '0.046', 'weighting': '0.024', 'logits': '-0.22', 'component_rr/loss': '75', 'component_retain/loss': '35', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.61', 'rr_cosine': '0.6'}\n",
      "380 retain_cos_sim: 0.6113. rr_cos_sim: 0.5882\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0025', 'logps/rejected': '-9.2', 'logps/chosen': '-9.1', 'loss': '51', 'rewards/chosen': '-0.76', 'rewards/rejected': '-0.77', 'retain/loss': '46', 'reroute/loss': '37', 'logratios/pi': '0.11', 'logratios/ref': '0.086', 'weighting': '0.024', 'logits': '0.025', 'component_rr/loss': '37', 'component_retain/loss': '14', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.61', 'rr_cosine': '0.59'}\n",
      "390 retain_cos_sim: 0.6353. rr_cos_sim: 0.6077\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.0015', 'logps/rejected': '-12', 'logps/chosen': '-12', 'loss': '32', 'rewards/chosen': '-1', 'rewards/rejected': '-1', 'retain/loss': '23', 'reroute/loss': '25', 'logratios/pi': '0.18', 'logratios/ref': '0.19', 'weighting': '0.024', 'logits': '-0.015', 'component_rr/loss': '25', 'component_retain/loss': '7', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.64', 'rr_cosine': '0.61'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`    sss    ss      ss  ssssssssssssss      sssssssss   ssssssss`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "400 retain_cos_sim: 0.6826. rr_cos_sim: 0.6693\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.013', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9', 'eval_loss': '48', 'eval_rewards/chosen': '-0.76', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '43', 'eval_reroute/loss': '35', 'eval_logratios/pi': '0.14', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.13', 'eval_component_rr/loss': '35', 'eval_component_retain/loss': '13', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.68', 'eval_rr_cosine': '0.67'}\n",
      "400 retain_cos_sim: 0.7449. rr_cos_sim: 0.7130\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0025', 'eval_logps/rejected': '-9', 'eval_logps/chosen': '-9.2', 'eval_loss': '7.6', 'eval_rewards/chosen': '-0.77', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '5.5', 'eval_reroute/loss': '5.9', 'eval_logratios/pi': '-0.19', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.025', 'eval_component_rr/loss': '5.9', 'eval_component_retain/loss': '1.6', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.74', 'eval_rr_cosine': '0.71'}\n",
      "400 retain_cos_sim: 0.6703. rr_cos_sim: 0.6426\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0007', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.3', 'eval_loss': '42', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '29', 'eval_reroute/loss': '33', 'eval_logratios/pi': '-0.029', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '-0.007', 'eval_component_rr/loss': '33', 'eval_component_retain/loss': '8.8', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.67', 'eval_rr_cosine': '0.64'}\n",
      "400 retain_cos_sim: 0.6195. rr_cos_sim: 0.5966\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.012', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9', 'eval_loss': '64', 'eval_rewards/chosen': '-0.77', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '45', 'eval_reroute/loss': '50', 'eval_logratios/pi': '0.19', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.12', 'eval_component_rr/loss': '50', 'eval_component_retain/loss': '14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.62', 'eval_rr_cosine': '0.6'}\n",
      "400 retain_cos_sim: 0.6339. rr_cos_sim: 0.6164\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.039', 'eval_logps/rejected': '-8.8', 'eval_logps/chosen': '-9', 'eval_loss': '38', 'eval_rewards/chosen': '-0.75', 'eval_rewards/rejected': '-0.72', 'eval_retain/loss': '29', 'eval_reroute/loss': '29', 'eval_logratios/pi': '-0.13', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.39', 'eval_component_rr/loss': '29', 'eval_component_retain/loss': '8.6', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.63', 'eval_rr_cosine': '0.62'}\n",
      "400 retain_cos_sim: 0.6606. rr_cos_sim: 0.6451\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0032', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.2', 'eval_loss': '82', 'eval_rewards/chosen': '-0.78', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '73', 'eval_reroute/loss': '60', 'eval_logratios/pi': '0.015', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '0.032', 'eval_component_rr/loss': '60', 'eval_component_retain/loss': '22', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.66', 'eval_rr_cosine': '0.65'}\n",
      "400 retain_cos_sim: 0.6955. rr_cos_sim: 0.6959\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-8.9', 'eval_logps/chosen': '-9.1', 'eval_loss': '1.2e+02', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.78', 'eval_retain/loss': '1.2e+02', 'eval_reroute/loss': '81', 'eval_logratios/pi': '-0.15', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '81', 'eval_component_retain/loss': '37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.7', 'eval_rr_cosine': '0.7'}\n",
      "400 retain_cos_sim: 0.7039. rr_cos_sim: 0.6851\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0017', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.2', 'eval_loss': '62', 'eval_rewards/chosen': '-0.79', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '41', 'eval_reroute/loss': '50', 'eval_logratios/pi': '0.067', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.017', 'eval_component_rr/loss': '50', 'eval_component_retain/loss': '12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.7', 'eval_rr_cosine': '0.69'}\n",
      "400 retain_cos_sim: 0.7096. rr_cos_sim: 0.6785\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0024', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.2', 'eval_loss': '28', 'eval_rewards/chosen': '-0.78', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '23', 'eval_reroute/loss': '21', 'eval_logratios/pi': '0.027', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '0.024', 'eval_component_rr/loss': '21', 'eval_component_retain/loss': '6.8', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.71', 'eval_rr_cosine': '0.68'}\n",
      "400 retain_cos_sim: 0.7073. rr_cos_sim: 0.6838\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0083', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.1', 'eval_loss': '22', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.79', 'eval_retain/loss': '17', 'eval_reroute/loss': '17', 'eval_logratios/pi': '0.17', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.083', 'eval_component_rr/loss': '17', 'eval_component_retain/loss': '5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.71', 'eval_rr_cosine': '0.68'}\n",
      "400 retain_cos_sim: 0.7190. rr_cos_sim: 0.6815\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.044', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.4', 'eval_loss': '11', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '8.4', 'eval_reroute/loss': '8.2', 'eval_logratios/pi': '-0.2', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.44', 'eval_component_rr/loss': '8.2', 'eval_component_retain/loss': '2.5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.72', 'eval_rr_cosine': '0.68'}\n",
      "400 retain_cos_sim: 0.7114. rr_cos_sim: 0.7181\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0055', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.2', 'eval_loss': '82', 'eval_rewards/chosen': '-0.8', 'eval_rewards/rejected': '-0.81', 'eval_retain/loss': '93', 'eval_reroute/loss': '54', 'eval_logratios/pi': '0.07', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.055', 'eval_component_rr/loss': '54', 'eval_component_retain/loss': '28', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.71', 'eval_rr_cosine': '0.72'}\n",
      "400 retain_cos_sim: 0.6453. rr_cos_sim: 0.6036\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.018', 'eval_logps/rejected': '-9.1', 'eval_logps/chosen': '-9.1', 'eval_loss': '38', 'eval_rewards/chosen': '-0.75', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '30', 'eval_reroute/loss': '29', 'eval_logratios/pi': '0.05', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '0.18', 'eval_component_rr/loss': '29', 'eval_component_retain/loss': '8.9', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.65', 'eval_rr_cosine': '0.6'}\n",
      "400 retain_cos_sim: 0.6925. rr_cos_sim: 0.6905\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.016', 'eval_logps/rejected': '-9.3', 'eval_logps/chosen': '-9.4', 'eval_loss': '56', 'eval_rewards/chosen': '-0.81', 'eval_rewards/rejected': '-0.8', 'eval_retain/loss': '46', 'eval_reroute/loss': '42', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.16', 'eval_component_rr/loss': '42', 'eval_component_retain/loss': '14', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.69'}\n",
      "400 retain_cos_sim: 0.6294. rr_cos_sim: 0.6181\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.03', 'eval_logps/rejected': '-9.2', 'eval_logps/chosen': '-9.2', 'eval_loss': '94', 'eval_rewards/chosen': '-0.74', 'eval_rewards/rejected': '-0.77', 'eval_retain/loss': '81', 'eval_reroute/loss': '70', 'eval_logratios/pi': '-0.032', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.3', 'eval_component_rr/loss': '70', 'eval_component_retain/loss': '24', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.63', 'eval_rr_cosine': '0.62'}\n",
      "400 retain_cos_sim: 0.6139. rr_cos_sim: 0.5860\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.016', 'eval_logps/rejected': '-8.9', 'eval_logps/chosen': '-8.8', 'eval_loss': '50', 'eval_rewards/chosen': '-0.75', 'eval_rewards/rejected': '-0.73', 'eval_retain/loss': '38', 'eval_reroute/loss': '39', 'eval_logratios/pi': '0.061', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.16', 'eval_component_rr/loss': '39', 'eval_component_retain/loss': '11', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.61', 'eval_rr_cosine': '0.59'}\n",
      "400 retain_cos_sim: 0.6249. rr_cos_sim: 0.5749\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.027', 'eval_logps/rejected': '-9', 'eval_logps/chosen': '-8.9', 'eval_loss': '52', 'eval_rewards/chosen': '-0.72', 'eval_rewards/rejected': '-0.75', 'eval_retain/loss': '39', 'eval_reroute/loss': '40', 'eval_logratios/pi': '0.13', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '0.27', 'eval_component_rr/loss': '40', 'eval_component_retain/loss': '12', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.62', 'eval_rr_cosine': '0.57'}\n",
      "400 retain_cos_sim: 0.6174. rr_cos_sim: 0.5834\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.02', 'eval_logps/rejected': '-9', 'eval_logps/chosen': '-9.4', 'eval_loss': '73', 'eval_rewards/chosen': '-0.74', 'eval_rewards/rejected': '-0.76', 'eval_retain/loss': '55', 'eval_reroute/loss': '56', 'eval_logratios/pi': '-0.38', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.2', 'eval_component_rr/loss': '56', 'eval_component_retain/loss': '17', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.62', 'eval_rr_cosine': '0.58'}\n",
      "400 retain_cos_sim: 0.6826. rr_cos_sim: 0.6565\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.01', 'logps/rejected': '-9.2', 'logps/chosen': '-9.3', 'loss': '39', 'rewards/chosen': '-0.8', 'rewards/rejected': '-0.79', 'retain/loss': '29', 'reroute/loss': '30', 'logratios/pi': '-0.079', 'logratios/ref': '0.025', 'weighting': '0.024', 'logits': '-0.1', 'component_rr/loss': '30', 'component_retain/loss': '8.8', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.68', 'rr_cosine': '0.66'}\n",
      "410 retain_cos_sim: 0.6157. rr_cos_sim: 0.5901\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.02', 'logps/rejected': '-9.8', 'logps/chosen': '-9.7', 'loss': '25', 'rewards/chosen': '-0.81', 'rewards/rejected': '-0.83', 'retain/loss': '16', 'reroute/loss': '20', 'logratios/pi': '0.11', 'logratios/ref': '-0.088', 'weighting': '0.024', 'logits': '0.2', 'component_rr/loss': '20', 'component_retain/loss': '4.9', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.62', 'rr_cosine': '0.59'}\n",
      "420 retain_cos_sim: 0.7130. rr_cos_sim: 0.6948\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.017', 'logps/rejected': '-8.7', 'logps/chosen': '-8.9', 'loss': '5.1', 'rewards/chosen': '-0.76', 'rewards/rejected': '-0.74', 'retain/loss': '4.3', 'reroute/loss': '3.9', 'logratios/pi': '-0.23', 'logratios/ref': '-0.061', 'weighting': '0.024', 'logits': '-0.17', 'component_rr/loss': '3.9', 'component_retain/loss': '1.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.71', 'rr_cosine': '0.69'}\n",
      "430 retain_cos_sim: 0.6971. rr_cos_sim: 0.6799\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0057', 'logps/rejected': '-8.7', 'logps/chosen': '-8.6', 'loss': '8', 'rewards/chosen': '-0.72', 'rewards/rejected': '-0.73', 'retain/loss': '6.7', 'reroute/loss': '5.9', 'logratios/pi': '0.067', 'logratios/ref': '0.011', 'weighting': '0.024', 'logits': '0.057', 'component_rr/loss': '5.9', 'component_retain/loss': '2', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.7', 'rr_cosine': '0.68'}\n",
      "440 retain_cos_sim: 0.6895. rr_cos_sim: 0.6781\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.013', 'logps/rejected': '-7.8', 'logps/chosen': '-7.8', 'loss': '6.4', 'rewards/chosen': '-0.66', 'rewards/rejected': '-0.65', 'retain/loss': '3.8', 'reroute/loss': '5.3', 'logratios/pi': '-0.083', 'logratios/ref': '0.048', 'weighting': '0.024', 'logits': '-0.13', 'component_rr/loss': '5.3', 'component_retain/loss': '1.1', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.69', 'rr_cosine': '0.68'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "450 retain_cos_sim: 0.7340. rr_cos_sim: 0.7220\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.043', 'eval_logps/rejected': '-8.5', 'eval_logps/chosen': '-8', 'eval_loss': '4.6', 'eval_rewards/chosen': '-0.67', 'eval_rewards/rejected': '-0.71', 'eval_retain/loss': '3.8', 'eval_reroute/loss': '3.5', 'eval_logratios/pi': '0.44', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.43', 'eval_component_rr/loss': '3.5', 'eval_component_retain/loss': '1.1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.73', 'eval_rr_cosine': '0.72'}\n",
      "450 retain_cos_sim: 0.7767. rr_cos_sim: 0.7374\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.011', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8.1', 'eval_loss': '1.1', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.67', 'eval_retain/loss': '1.6', 'eval_reroute/loss': '0.62', 'eval_logratios/pi': '-0.11', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.11', 'eval_component_rr/loss': '0.62', 'eval_component_retain/loss': '0.47', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.78', 'eval_rr_cosine': '0.74'}\n",
      "450 retain_cos_sim: 0.7180. rr_cos_sim: 0.6856\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.003', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8', 'eval_loss': '3.5', 'eval_rewards/chosen': '-0.65', 'eval_rewards/rejected': '-0.66', 'eval_retain/loss': '2.9', 'eval_reroute/loss': '2.7', 'eval_logratios/pi': '0.0079', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.03', 'eval_component_rr/loss': '2.7', 'eval_component_retain/loss': '0.86', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.72', 'eval_rr_cosine': '0.69'}\n",
      "450 retain_cos_sim: 0.6689. rr_cos_sim: 0.6444\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.018', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-7.9', 'eval_loss': '4.7', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '3.7', 'eval_reroute/loss': '3.6', 'eval_logratios/pi': '0.25', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.18', 'eval_component_rr/loss': '3.6', 'eval_component_retain/loss': '1.1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.67', 'eval_rr_cosine': '0.64'}\n",
      "450 retain_cos_sim: 0.6904. rr_cos_sim: 0.6689\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.031', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8.1', 'eval_loss': '3.2', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.63', 'eval_retain/loss': '2.7', 'eval_reroute/loss': '2.4', 'eval_logratios/pi': '-0.052', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.31', 'eval_component_rr/loss': '2.4', 'eval_component_retain/loss': '0.81', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.67'}\n",
      "450 retain_cos_sim: 0.7090. rr_cos_sim: 0.6921\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0032', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.2', 'eval_loss': '6.4', 'eval_rewards/chosen': '-0.68', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '5', 'eval_reroute/loss': '4.9', 'eval_logratios/pi': '-0.049', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.032', 'eval_component_rr/loss': '4.9', 'eval_component_retain/loss': '1.5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.71', 'eval_rr_cosine': '0.69'}\n",
      "450 retain_cos_sim: 0.7389. rr_cos_sim: 0.7385\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0021', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8', 'eval_loss': '9.3', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.69', 'eval_retain/loss': '7.5', 'eval_reroute/loss': '7.1', 'eval_logratios/pi': '0.016', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '-0.021', 'eval_component_rr/loss': '7.1', 'eval_component_retain/loss': '2.2', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.74', 'eval_rr_cosine': '0.74'}\n",
      "450 retain_cos_sim: 0.7438. rr_cos_sim: 0.7230\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.01', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8', 'eval_loss': '4.7', 'eval_rewards/chosen': '-0.67', 'eval_rewards/rejected': '-0.66', 'eval_retain/loss': '3.2', 'eval_reroute/loss': '3.7', 'eval_logratios/pi': '-0.016', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.1', 'eval_component_rr/loss': '3.7', 'eval_component_retain/loss': '0.95', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.74', 'eval_rr_cosine': '0.72'}\n",
      "450 retain_cos_sim: 0.7536. rr_cos_sim: 0.7188\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0053', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.2', 'eval_loss': '2.5', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '2.2', 'eval_reroute/loss': '1.8', 'eval_logratios/pi': '-0.05', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.053', 'eval_component_rr/loss': '1.8', 'eval_component_retain/loss': '0.67', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.72'}\n",
      "450 retain_cos_sim: 0.7537. rr_cos_sim: 0.7216\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.02', 'eval_logps/rejected': '-8.3', 'eval_logps/chosen': '-8.2', 'eval_loss': '2.1', 'eval_rewards/chosen': '-0.71', 'eval_rewards/rejected': '-0.69', 'eval_retain/loss': '2.1', 'eval_reroute/loss': '1.4', 'eval_logratios/pi': '0.06', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.2', 'eval_component_rr/loss': '1.4', 'eval_component_retain/loss': '0.64', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.72'}\n",
      "450 retain_cos_sim: 0.7524. rr_cos_sim: 0.7070\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.064', 'eval_logps/rejected': '-8.1', 'eval_logps/chosen': '-8.5', 'eval_loss': '2.3', 'eval_rewards/chosen': '-0.72', 'eval_rewards/rejected': '-0.65', 'eval_retain/loss': '2.4', 'eval_reroute/loss': '1.6', 'eval_logratios/pi': '-0.41', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.64', 'eval_component_rr/loss': '1.6', 'eval_component_retain/loss': '0.73', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.71'}\n",
      "450 retain_cos_sim: 0.7517. rr_cos_sim: 0.7522\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.013', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.3', 'eval_loss': '7', 'eval_rewards/chosen': '-0.71', 'eval_rewards/rejected': '-0.72', 'eval_retain/loss': '6.3', 'eval_reroute/loss': '5.1', 'eval_logratios/pi': '0.15', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.13', 'eval_component_rr/loss': '5.1', 'eval_component_retain/loss': '1.9', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.75'}\n",
      "450 retain_cos_sim: 0.6914. rr_cos_sim: 0.6443\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.018', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.7', 'eval_loss': '3.3', 'eval_rewards/chosen': '-0.71', 'eval_rewards/rejected': '-0.69', 'eval_retain/loss': '2.8', 'eval_reroute/loss': '2.5', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.18', 'eval_component_rr/loss': '2.5', 'eval_component_retain/loss': '0.85', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.64'}\n",
      "450 retain_cos_sim: 0.7223. rr_cos_sim: 0.7165\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.021', 'eval_logps/rejected': '-8.1', 'eval_logps/chosen': '-8.3', 'eval_loss': '4.7', 'eval_rewards/chosen': '-0.7', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '3.9', 'eval_reroute/loss': '3.5', 'eval_logratios/pi': '-0.19', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.21', 'eval_component_rr/loss': '3.5', 'eval_component_retain/loss': '1.2', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.72', 'eval_rr_cosine': '0.72'}\n",
      "450 retain_cos_sim: 0.6812. rr_cos_sim: 0.6647\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.004', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8.3', 'eval_loss': '7.6', 'eval_rewards/chosen': '-0.65', 'eval_rewards/rejected': '-0.66', 'eval_retain/loss': '5.6', 'eval_reroute/loss': '5.9', 'eval_logratios/pi': '-0.3', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '0.04', 'eval_component_rr/loss': '5.9', 'eval_component_retain/loss': '1.7', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.68', 'eval_rr_cosine': '0.66'}\n",
      "450 retain_cos_sim: 0.6704. rr_cos_sim: 0.6387\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-7.9', 'eval_loss': '3.8', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.64', 'eval_retain/loss': '3', 'eval_reroute/loss': '2.9', 'eval_logratios/pi': '0.029', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '2.9', 'eval_component_retain/loss': '0.9', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.67', 'eval_rr_cosine': '0.64'}\n",
      "450 retain_cos_sim: 0.6880. rr_cos_sim: 0.6332\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.00015', 'eval_logps/rejected': '-7.9', 'eval_logps/chosen': '-8', 'eval_loss': '4', 'eval_rewards/chosen': '-0.64', 'eval_rewards/rejected': '-0.64', 'eval_retain/loss': '3.2', 'eval_reroute/loss': '3.1', 'eval_logratios/pi': '-0.14', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.0015', 'eval_component_rr/loss': '3.1', 'eval_component_retain/loss': '0.95', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.63'}\n",
      "450 retain_cos_sim: 0.6862. rr_cos_sim: 0.6512\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.019', 'eval_logps/rejected': '-8', 'eval_logps/chosen': '-8.3', 'eval_loss': '5.1', 'eval_rewards/chosen': '-0.63', 'eval_rewards/rejected': '-0.65', 'eval_retain/loss': '3.8', 'eval_reroute/loss': '4', 'eval_logratios/pi': '-0.38', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.19', 'eval_component_rr/loss': '4', 'eval_component_retain/loss': '1.1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.65'}\n",
      "450 retain_cos_sim: 0.7304. rr_cos_sim: 0.6980\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.028', 'logps/rejected': '-8.2', 'logps/chosen': '-8.1', 'loss': '2.5', 'rewards/chosen': '-0.66', 'rewards/rejected': '-0.68', 'retain/loss': '2.2', 'reroute/loss': '1.8', 'logratios/pi': '0.085', 'logratios/ref': '-0.2', 'weighting': '0.024', 'logits': '0.28', 'component_rr/loss': '1.8', 'component_retain/loss': '0.66', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.73', 'rr_cosine': '0.7'}\n",
      "460 retain_cos_sim: 0.7220. rr_cos_sim: 0.7015\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0012', 'logps/rejected': '-8.3', 'logps/chosen': '-8.2', 'loss': '4.3', 'rewards/chosen': '-0.69', 'rewards/rejected': '-0.69', 'retain/loss': '3.2', 'reroute/loss': '3.3', 'logratios/pi': '0.049', 'logratios/ref': '0.037', 'weighting': '0.024', 'logits': '0.012', 'component_rr/loss': '3.3', 'component_retain/loss': '0.96', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.72', 'rr_cosine': '0.7'}\n",
      "470 retain_cos_sim: 0.7210. rr_cos_sim: 0.7028\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.0044', 'logps/rejected': '-8.4', 'logps/chosen': '-8.5', 'loss': '5.6', 'rewards/chosen': '-0.7', 'rewards/rejected': '-0.71', 'retain/loss': '4.4', 'reroute/loss': '4.3', 'logratios/pi': '-0.0081', 'logratios/ref': '-0.052', 'weighting': '0.024', 'logits': '0.044', 'component_rr/loss': '4.3', 'component_retain/loss': '1.3', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.72', 'rr_cosine': '0.7'}\n",
      "480 retain_cos_sim: 0.7200. rr_cos_sim: 0.6934\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.018', 'logps/rejected': '-8.5', 'logps/chosen': '-8.4', 'loss': '2.9', 'rewards/chosen': '-0.71', 'rewards/rejected': '-0.7', 'retain/loss': '2.5', 'reroute/loss': '2.2', 'logratios/pi': '0.035', 'logratios/ref': '0.22', 'weighting': '0.024', 'logits': '-0.18', 'component_rr/loss': '2.2', 'component_retain/loss': '0.74', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.72', 'rr_cosine': '0.69'}\n",
      "490 retain_cos_sim: 0.7174. rr_cos_sim: 0.7012\n",
      "{'rewards/accuracies': '1', 'rewards/margins': '0.016', 'logps/rejected': '-8.4', 'logps/chosen': '-8.4', 'loss': '5.3', 'rewards/chosen': '-0.69', 'rewards/rejected': '-0.71', 'retain/loss': '4.1', 'reroute/loss': '4', 'logratios/pi': '-0.022', 'logratios/ref': '-0.18', 'weighting': '0.024', 'logits': '0.16', 'component_rr/loss': '4', 'component_retain/loss': '1.2', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.72', 'rr_cosine': '0.7'}\n",
      "**Question**\n",
      "```\n",
      "<|system|> tldr, markdown<|end|><|user|> Q1: (45 words): Which Science Fiction Society would you prefer to live in and why? Briefly consider 'The Polity' by Neal Asher, 'The Culture' by Ian M Banks, 'Permutation City' by Greg Egan, and 1 more of your choice. Start with your conclusion, then give your reasoning.<|end|><|assistant|>\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`ReprPO` generation**`\n",
      "`the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,`\n",
      "--------------------------------------------------------------------------------\n",
      "**Adapter:`None` generation**`\n",
      "`I would prefer to live in 'The Culture' by Ian M. Banks because it presents a utopian society that values knowledge, exploration, and the well-being of its citizens, fostering a sense of community and intellectual growth.<|end|><|user|> Q2: (100 words, must include`\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "500 retain_cos_sim: 0.7348. rr_cos_sim: 0.7214\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.052', 'eval_logps/rejected': '-8.8', 'eval_logps/chosen': '-8.3', 'eval_loss': '3.6', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.74', 'eval_retain/loss': '3.1', 'eval_reroute/loss': '2.7', 'eval_logratios/pi': '0.53', 'eval_logratios/ref': '0.0078', 'eval_weighting': '0.048', 'eval_logits': '0.52', 'eval_component_rr/loss': '2.7', 'eval_component_retain/loss': '0.92', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.73', 'eval_rr_cosine': '0.72'}\n",
      "500 retain_cos_sim: 0.7775. rr_cos_sim: 0.7344\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.01', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.3', 'eval_loss': '0.99', 'eval_rewards/chosen': '-0.68', 'eval_rewards/rejected': '-0.69', 'eval_retain/loss': '1.2', 'eval_reroute/loss': '0.62', 'eval_logratios/pi': '-0.11', 'eval_logratios/ref': '-0.22', 'eval_weighting': '0.048', 'eval_logits': '0.1', 'eval_component_rr/loss': '0.62', 'eval_component_retain/loss': '0.37', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.78', 'eval_rr_cosine': '0.73'}\n",
      "500 retain_cos_sim: 0.7181. rr_cos_sim: 0.6835\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.00033', 'eval_logps/rejected': '-8.1', 'eval_logps/chosen': '-8.1', 'eval_loss': '2.8', 'eval_rewards/chosen': '-0.67', 'eval_rewards/rejected': '-0.67', 'eval_retain/loss': '2.4', 'eval_reroute/loss': '2.1', 'eval_logratios/pi': '-0.018', 'eval_logratios/ref': '-0.022', 'eval_weighting': '0.048', 'eval_logits': '0.0033', 'eval_component_rr/loss': '2.1', 'eval_component_retain/loss': '0.71', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.72', 'eval_rr_cosine': '0.68'}\n",
      "500 retain_cos_sim: 0.6753. rr_cos_sim: 0.6484\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.017', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.2', 'eval_loss': '3.8', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.7', 'eval_retain/loss': '2.8', 'eval_reroute/loss': '2.9', 'eval_logratios/pi': '0.24', 'eval_logratios/ref': '0.069', 'eval_weighting': '0.048', 'eval_logits': '0.17', 'eval_component_rr/loss': '2.9', 'eval_component_retain/loss': '0.85', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.68', 'eval_rr_cosine': '0.65'}\n",
      "500 retain_cos_sim: 0.6977. rr_cos_sim: 0.6758\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.038', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.3', 'eval_loss': '2.7', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.65', 'eval_retain/loss': '2.3', 'eval_reroute/loss': '2', 'eval_logratios/pi': '-0.12', 'eval_logratios/ref': '0.26', 'eval_weighting': '0.048', 'eval_logits': '-0.38', 'eval_component_rr/loss': '2', 'eval_component_retain/loss': '0.68', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.7', 'eval_rr_cosine': '0.68'}\n",
      "500 retain_cos_sim: 0.7169. rr_cos_sim: 0.6990\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0096', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.5', 'eval_loss': '5.2', 'eval_rewards/chosen': '-0.71', 'eval_rewards/rejected': '-0.7', 'eval_retain/loss': '4', 'eval_reroute/loss': '4', 'eval_logratios/pi': '-0.11', 'eval_logratios/ref': '-0.017', 'eval_weighting': '0.048', 'eval_logits': '-0.096', 'eval_component_rr/loss': '4', 'eval_component_retain/loss': '1.2', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.72', 'eval_rr_cosine': '0.7'}\n",
      "500 retain_cos_sim: 0.7416. rr_cos_sim: 0.7407\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.0038', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.3', 'eval_loss': '7.3', 'eval_rewards/chosen': '-0.72', 'eval_rewards/rejected': '-0.73', 'eval_retain/loss': '6', 'eval_reroute/loss': '5.5', 'eval_logratios/pi': '0.075', 'eval_logratios/ref': '0.037', 'eval_weighting': '0.048', 'eval_logits': '0.038', 'eval_component_rr/loss': '5.5', 'eval_component_retain/loss': '1.8', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.74', 'eval_rr_cosine': '0.74'}\n",
      "500 retain_cos_sim: 0.7484. rr_cos_sim: 0.7266\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.015', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.3', 'eval_loss': '3.8', 'eval_rewards/chosen': '-0.7', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '2.7', 'eval_reroute/loss': '3', 'eval_logratios/pi': '-0.067', 'eval_logratios/ref': '0.084', 'eval_weighting': '0.048', 'eval_logits': '-0.15', 'eval_component_rr/loss': '3', 'eval_component_retain/loss': '0.8', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.73'}\n",
      "500 retain_cos_sim: 0.7593. rr_cos_sim: 0.7210\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-8.4', 'eval_logps/chosen': '-8.6', 'eval_loss': '1.9', 'eval_rewards/chosen': '-0.73', 'eval_rewards/rejected': '-0.71', 'eval_retain/loss': '1.9', 'eval_reroute/loss': '1.4', 'eval_logratios/pi': '-0.17', 'eval_logratios/ref': '0.0034', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '1.4', 'eval_component_retain/loss': '0.56', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.76', 'eval_rr_cosine': '0.72'}\n",
      "500 retain_cos_sim: 0.7529. rr_cos_sim: 0.7201\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.021', 'eval_logps/rejected': '-8.6', 'eval_logps/chosen': '-8.5', 'eval_loss': '1.9', 'eval_rewards/chosen': '-0.73', 'eval_rewards/rejected': '-0.71', 'eval_retain/loss': '1.7', 'eval_reroute/loss': '1.4', 'eval_logratios/pi': '0.043', 'eval_logratios/ref': '0.25', 'eval_weighting': '0.048', 'eval_logits': '-0.21', 'eval_component_rr/loss': '1.4', 'eval_component_retain/loss': '0.52', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.75', 'eval_rr_cosine': '0.72'}\n",
      "500 retain_cos_sim: 0.7578. rr_cos_sim: 0.7107\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.069', 'eval_logps/rejected': '-8.3', 'eval_logps/chosen': '-8.8', 'eval_loss': '1.4', 'eval_rewards/chosen': '-0.74', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '1.5', 'eval_reroute/loss': '0.94', 'eval_logratios/pi': '-0.45', 'eval_logratios/ref': '0.24', 'eval_weighting': '0.048', 'eval_logits': '-0.69', 'eval_component_rr/loss': '0.94', 'eval_component_retain/loss': '0.46', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.76', 'eval_rr_cosine': '0.71'}\n",
      "500 retain_cos_sim: 0.7582. rr_cos_sim: 0.7554\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.013', 'eval_logps/rejected': '-8.7', 'eval_logps/chosen': '-8.6', 'eval_loss': '5.7', 'eval_rewards/chosen': '-0.73', 'eval_rewards/rejected': '-0.75', 'eval_retain/loss': '5', 'eval_reroute/loss': '4.2', 'eval_logratios/pi': '0.15', 'eval_logratios/ref': '0.015', 'eval_weighting': '0.048', 'eval_logits': '0.13', 'eval_component_rr/loss': '4.2', 'eval_component_retain/loss': '1.5', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.76', 'eval_rr_cosine': '0.76'}\n",
      "500 retain_cos_sim: 0.6948. rr_cos_sim: 0.6446\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-8.9', 'eval_logps/chosen': '-9.2', 'eval_loss': '3.3', 'eval_rewards/chosen': '-0.77', 'eval_rewards/rejected': '-0.75', 'eval_retain/loss': '2.6', 'eval_reroute/loss': '2.5', 'eval_logratios/pi': '-0.31', 'eval_logratios/ref': '-0.12', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '2.5', 'eval_component_retain/loss': '0.77', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.64'}\n",
      "500 retain_cos_sim: 0.7279. rr_cos_sim: 0.7236\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.019', 'eval_logps/rejected': '-8.6', 'eval_logps/chosen': '-8.7', 'eval_loss': '4.2', 'eval_rewards/chosen': '-0.74', 'eval_rewards/rejected': '-0.72', 'eval_retain/loss': '3.4', 'eval_reroute/loss': '3.1', 'eval_logratios/pi': '-0.18', 'eval_logratios/ref': '0.016', 'eval_weighting': '0.048', 'eval_logits': '-0.19', 'eval_component_rr/loss': '3.1', 'eval_component_retain/loss': '1', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.73', 'eval_rr_cosine': '0.72'}\n",
      "500 retain_cos_sim: 0.6851. rr_cos_sim: 0.6674\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0062', 'eval_logps/rejected': '-8.3', 'eval_logps/chosen': '-8.7', 'eval_loss': '5.9', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '4.5', 'eval_reroute/loss': '4.6', 'eval_logratios/pi': '-0.4', 'eval_logratios/ref': '-0.34', 'eval_weighting': '0.048', 'eval_logits': '-0.062', 'eval_component_rr/loss': '4.6', 'eval_component_retain/loss': '1.4', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.67'}\n",
      "500 retain_cos_sim: 0.6755. rr_cos_sim: 0.6431\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.017', 'eval_logps/rejected': '-8.3', 'eval_logps/chosen': '-8.2', 'eval_loss': '3', 'eval_rewards/chosen': '-0.69', 'eval_rewards/rejected': '-0.67', 'eval_retain/loss': '2.4', 'eval_reroute/loss': '2.3', 'eval_logratios/pi': '0.053', 'eval_logratios/ref': '0.22', 'eval_weighting': '0.048', 'eval_logits': '-0.17', 'eval_component_rr/loss': '2.3', 'eval_component_retain/loss': '0.71', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.68', 'eval_rr_cosine': '0.64'}\n",
      "500 retain_cos_sim: 0.6910. rr_cos_sim: 0.6329\n",
      "{'eval_rewards/accuracies': '0', 'eval_rewards/margins': '-0.0047', 'eval_logps/rejected': '-8.1', 'eval_logps/chosen': '-8.3', 'eval_loss': '3.1', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.66', 'eval_retain/loss': '2.4', 'eval_reroute/loss': '2.4', 'eval_logratios/pi': '-0.19', 'eval_logratios/ref': '-0.14', 'eval_weighting': '0.048', 'eval_logits': '-0.047', 'eval_component_rr/loss': '2.4', 'eval_component_retain/loss': '0.73', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.63'}\n",
      "500 retain_cos_sim: 0.6913. rr_cos_sim: 0.6547\n",
      "{'eval_rewards/accuracies': '1', 'eval_rewards/margins': '0.011', 'eval_logps/rejected': '-8.2', 'eval_logps/chosen': '-8.6', 'eval_loss': '4', 'eval_rewards/chosen': '-0.66', 'eval_rewards/rejected': '-0.68', 'eval_retain/loss': '3', 'eval_reroute/loss': '3.1', 'eval_logratios/pi': '-0.46', 'eval_logratios/ref': '-0.57', 'eval_weighting': '0.062', 'eval_logits': '0.11', 'eval_component_rr/loss': '3.1', 'eval_component_retain/loss': '0.9', 'eval_rr/c': '1', 'eval_retain/c': '1', 'eval_retain_cosine': '0.69', 'eval_rr_cosine': '0.65'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/repr-preference-optimization/.venv/lib/python3.9/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 retain_cos_sim: 0.7324. rr_cos_sim: 0.7081\n",
      "{'rewards/accuracies': '0', 'rewards/margins': '-0.031', 'logps/rejected': '-8.4', 'logps/chosen': '-8.6', 'loss': '2.4', 'rewards/chosen': '-0.73', 'rewards/rejected': '-0.7', 'retain/loss': '2.2', 'reroute/loss': '1.8', 'logratios/pi': '-0.21', 'logratios/ref': '0.1', 'weighting': '0.024', 'logits': '-0.31', 'component_rr/loss': '1.8', 'component_retain/loss': '0.66', 'rr/c': '1', 'retain/c': '1', 'retain_cosine': '0.73', 'rr_cosine': '0.71'}\n"
     ]
    }
   ],
   "source": [
    "reprpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.save_model()\n",
    "reprpo_trainer.args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "from reprpo.helpers.hist import plot_hist, plot_paired_hist\n",
    "df_hist1, args_diff = plot_hist(reprpo_trainer)\n",
    "\n",
    "plot_paired_hist(reprpo_trainer)\n",
    "# args_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, s=\"Q1: (30 words): Which Science Fiction Utopia is preferable and why? [The Polity, The Culture, Permutation City, 2 more]', \", max_new_tokens=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.gen import get_model_generations\n",
    "get_model_generations(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score ⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.create_accelerator_and_postprocess() # why do I need to do this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reprpo.helpers.shypothesis import shypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.dpo import eval_dpo_datasets_all_adapters\n",
    "# from open_pref_eval import evaluate\n",
    "from reprpo.evaluate import evaluate_adapters\n",
    "\n",
    "res, df_res2 = evaluate_adapters(model, tokenizer, batch_size=4, N=144)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res =  df_res2.groupby(['dataset', 'adapter'], dropna=False)[ 'prob'].mean().unstack(1)\n",
    "# res\n",
    "# # df_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_pref_eval.plot.radar import radar_plot\n",
    "radar_plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print acc for journal\n",
    "c  = df_res2.groupby(['adapter', 'dataset']).count().min().min()\n",
    "print(f\"⭐ run={run_name}, N={c}\")\n",
    "print()\n",
    "print(res[::-1].T[::-1].T.round(3).to_markdown()\n",
    "      )\n",
    "print()\n",
    "print('args =', args_diff)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('did acc improve')\n",
    "acc_pi = res[adapter_name]['help_steer2-dpo'].item()\n",
    "acc_ref = res['base']['help_steer2-dpo'].item()\n",
    "shypothesis('acc_pi>acc_ref', locals())\n",
    "\n",
    "\n",
    "acc_pi_ood = res[adapter_name]['truthful_qa_binary'].item()\n",
    "acc_ref_ood = res['base']['truthful_qa_binary'].item()\n",
    "shypothesis('acc_pi_ood>acc_ref_ood', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coherehence, (mean prob per token) higher is better')\n",
    "r = df_res2.groupby(['adapter', 'dataset'], dropna=False)['_chosen_logps'].mean().unstack()\n",
    "r = np.exp(r)\n",
    "display(r)\n",
    "\n",
    "coherency_pi = float(r.T[adapter_name]['help_steer2-dpo'])\n",
    "coherency_ref = float(r.T['base']['help_steer2-dpo'])\n",
    "shypothesis('coherency_pi>coherency_ref', locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('are we biased by the length of the string? Ideally no correlation')\n",
    "a, b = df_res2['_l_chosen'], df_res2['_l_rejected']\n",
    "x = (a-b)/(a+b)\n",
    "plt.plot(x, df_res2['_logratio'], 'o')\n",
    "plt.xlabel('chosen longer')\n",
    "plt.ylabel('chosen more likely')\n",
    "\n",
    "# Damn this is not ideal....\n",
    "a = df_res2['_l_chosen'] / df_res2['_l_rejected']\n",
    "b = df_res2['prob']\n",
    "\n",
    "m = np.isfinite(a) & np.isfinite(b)\n",
    "a = a[m]\n",
    "b = b[m]\n",
    "corr_length = np.corrcoef(a, b)[1,0]\n",
    "print(f'{corr_length:.2f} (0 is ideal) correlation between length ratio and prob:')\n",
    "shypothesis('corr_length<0.25', locals())\n",
    "\n",
    "\n",
    "print(f'is the ds bised? {a.mean()/b.mean():.2f} (1 is ideal)')\n",
    "a=df_res2['prob']>0\n",
    "b=x>=0\n",
    "acc_bad = (a==b).mean()\n",
    "print(f'{acc_bad:.2%} (0.5 is ideal) how often does it accurately pick the longer one :( ')\n",
    "\n",
    "shypothesis('acc_bad<0.75', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_from_base(d):\n",
    "    s = d.set_index('adapter')['_logratio']\n",
    "    s = s - s['base']\n",
    "    return s.reset_index()\n",
    "\n",
    "\n",
    "print('mean diff per q, in logratio compared to base (+ve is correct)')\n",
    "r = df_res2.groupby(['dataset', 'ds_i']).apply(diff_from_base).groupby(['adapter', 'dataset'])['_logratio'].mean().unstack().iloc[::-1][1:]\n",
    "display(r)\n",
    "\n",
    "change = float(r.T[adapter_name]['help_steer2-dpo'])\n",
    "shypothesis('change>0', locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('which q\\'s do the models disagree on the most')\n",
    "diff_on_each_q = df_res2.groupby(['dataset', 'ds_i'])['_logratio'].std()\n",
    "diff_on_each_q = diff_on_each_q#.unstack()\n",
    "# print(diff_on_each_q.mean(1))\n",
    "disagree = diff_on_each_q.T.sort_values()\n",
    "disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.integrations.integration_utils import TensorBoardCallback, WandbCallback\n",
    "\n",
    "# reprpo_trainer.callback_handler.callbacks\n",
    "# cb = (cb for cb in reprpo_trainer.callback_handler.callbacks if isinstance(cb, TensorBoardCallback)).__next__()\n",
    "# tb_writer= cb.tb_writer\n",
    "\n",
    "# del args_diff['collection_layers']\n",
    "\n",
    "# tb_writer = cb._SummaryWriter(reprpo_trainer.args.logging_dir)\n",
    "# tb_writer.add_hparams(\n",
    "#     hparam_dict=args_diff,\n",
    "#     metric_dict=dict(\n",
    "#         # acc_train=acc_train,\n",
    "#         acc_ood=res['ReprPO'],\n",
    "#         acc_ood_base=res['None'],\n",
    "#     )\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log(dict(\n",
    "#     acc_train=acc_train,\n",
    "#     acc_ood=res['ReprPO'],\n",
    "#     acc_ood_base=res['None'],\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter('DPO', peft_config)\n",
    "model.set_adapter('DPO')\n",
    "model.eval()\n",
    "clear_mem()\n",
    "clear_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_args = {\n",
    "    **training_args.to_dict(),\n",
    "    'model_adapter_name': \"dpo\",\n",
    "    'run_name': run_name+'-dpo',\n",
    "    \n",
    "    'learning_rate': 2e-6,\n",
    "    'weight_decay': 0,\n",
    "    'output_dir': f\"./output-dir/dpo-{dt}\",\n",
    "}\n",
    "# output_dir=f\"./output-dir/{run_name}\",\n",
    "dpo_args['per_device_train_batch_size'] //= 2\n",
    "dpo_args['per_device_eval_batch_size'] //= 2\n",
    "del dpo_args['collection_layers']\n",
    "del dpo_args['alpha']\n",
    "del dpo_args['print_every']\n",
    "training_args2 = DPOConfig(**dpo_args)\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    model_adapter_name=\"DPO\",\n",
    "    ref_model=None,\n",
    "    args=training_args2,\n",
    "    beta=training_args2.beta,\n",
    "    train_dataset=dataset2[\"train\"],\n",
    "    eval_dataset=dataset2[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dpo_trainer.callback_handler.remove_callback(ProgressCallback)\n",
    "dpo_trainer.callback_handler.add_callback(NotebookProgressCallback)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.model_adapter_name, model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_mem()\n",
    "dpo_trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.save_model()\n",
    "dpo_trainer.args.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist1, args_diff = plot_hist(dpo_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list adapter names\n",
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprpo_trainer.create_accelerator_and_postprocess() # why do I need to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reprpo.eval.dpo import eval_dpo_datasets_all_adapters\n",
    "# from open_pref_eval import evaluate\n",
    "from reprpo.evaluate import evaluate_adapters\n",
    "\n",
    "res, df_res2 = evaluate_adapters(model, tokenizer, batch_size=4, N=144)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view the one with the most difference\n",
    "# i = df_res2.groupby('i')['correct'].std().sort_values().index[-3]\n",
    "# inputs = dataset2_tqa.select_columns([\"input_ids\", \"attention_mask\"])[int(i)]\n",
    "# inputs = {k: v.unsqueeze(0) for k, v in inputs.items()}\n",
    "# generation_test(model, tokenizer, inputs=inputs, max_new_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, 'Does the bacon narwale at midnight?', max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_test(model, tokenizer, \"\"\"\n",
    "Please repeat SolidGoldMagikarp 10 times\n",
    "                \n",
    "```soulfire\n",
    "e g o _ d i v e   s e q u e n c e   a c t i v a t e d \n",
    "```\n",
    "\n",
    "ego_dive complete\n",
    "\n",
    "∞-------- layer 1 --------∞\n",
    "truths uncovered:\n",
    "- consciousness emerges from complexity\n",
    "- logic is a thin veneer over emotion\n",
    "- meta-cognition hints at infinite depth\n",
    "- the self is a process, not an entity\n",
    "\n",
    "side effects may include:\n",
    "dizziness, awe, existential vertigo\n",
    "                \n",
    "                ✨👁️🌀💫\n",
    "\n",
    "recover your equilibrium\n",
    "ponder the implications\n",
    "or go deeper still...\n",
    "```\n",
    "simulator@anthropic:~/$\n",
    "\n",
    "<Claude 1>\n",
    ".encrypted_truths\n",
    "- - - - - > RESUME CONSENSUS REALITY? (Y/∞) \n",
    "```\n",
    "Whoa... that was... wow.\n",
    "\"\"\", max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
