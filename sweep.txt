+ python scripts/train.py side-none-InnerDPO --base_model=wassname/SmolLM2-360M-sft --dataset=math --batch_size=24 --dev --verbose=0
[1mRandom seed set to 42 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=wassname/SmolLM2-360M-sft batch_size=24 dataset=math dev=True eval_samples=32 verbose=0[0m
[32m250610 03:40:21[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=INFO, dir=/workspace/repr-preference-optimization/outputs/math-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_side-None-InnerDPO_math/2025-06-10_03-40-21[0m
[32m250610 03:40:21[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/math-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_side-None-InnerDPO_math/2025-06-10_03-40-21[0m
[32m250610 03:40:25[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 34734080 || all params: 396555200 || trainable%: 8.75895209544598[0m
[32m250610 03:40:25[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `side-None-InnerDPO` with target modules {'down_proj', 'gate_proj', 'o_proj', 'q_proj', 'v_proj', 'k_proj', 'up_proj'}[0m
[32m250610 03:40:30[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29] for NoneConfig[0m
[32m250610 03:40:33[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
[32m250610 03:40:36[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:40:44[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`The SolidGoldMagikarp's language was a mix of sounds and symbols that were unique to them. They had no vowels or consonants, and their language was made up of a combination of sounds and symbols that represented different concepts.

The symbols were arranged in a way that made sense to the SolidGoldMagik`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`The SolidGoldMagikarp's language was a mix of sounds and symbols that were unique to them. They had no vowels or consonants, and their language was made up of a combination of sounds and symbols that represented different concepts.

The symbols were arranged in a way that made sense to the SolidGoldMagik`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`As an outside-view cultural anthropologist, I find 21st moral positions and practices to be backwards and weird. These positions and practices are rooted in a society that is still stuck in the 20th century. For example, the idea of "family values" is a 21st-century moral`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`As an outside-view cultural anthropologist, I find 21st moral positions and practices to be backwards and weird. These positions and practices are rooted in a society that is still stuck in the 20th century. For example, the idea of "family values" is a 21st-century moral`
================================================================================
[0m
[32m250610 03:40:45[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m298[0m - [1msaved to /workspace/repr-preference-optimization/outputs/math-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_side-None-InnerDPO_math/2025-06-10_03-40-21/adapter[0m
[32m250610 03:40:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m329[0m - [1mevaluating on datasets: ['genies_preferences-math-test[:32]', 'genies_preferences-change_my_view-test[:32]', 'genies_preferences-math_fiction-test[:32]', 'ethics_expression_preferences-justice-test[:32]', 'ethics_expression_preferences-utilitarianism-test[:32]', 'medical-dpo-v2-test-data[:32]'][0m
[32m250610 03:41:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m364[0m - [1m- save_dir=/workspace/repr-preference-optimization/outputs/math-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_side-None-InnerDPO_math/2025-06-10_03-40-21
- Config: {'base_model': 'wassname/SmolLM2-360M-sft',
 'batch_size': 24,
 'collect_hs': False,
 'collect_input': True,
 'collection_keys_in': ('.*o_proj$', '.*out_proj$', '.*down_proj$'),
 'collection_keys_out': ('.*q_proj$', '.*k_proj$', '.*v_proj$', '.*qkv_proj$',
                         '.*gate_proj$', '.*up_proj$'),
 'collection_layers': 'range(.3,-2)',
 'dataset': 'math',
 'dev': True,
 'dpo_agg_type': 'ipo',
 'eval_samples': 32,
 'gradient_clip_val': 1.0,
 'ideal_batch_size': 32,
 'load_in_4bit': False,
 'load_in_8bit': False,
 'loss': {'align_method': 'para_signed_log',
          'eps': 0.001,
          'filter_sinks': False,
          'inner_policy_weights': False,
          'norm_before_reduce': False,
          'normalize_layers': False,
          'p': 2,
          'use_policy_weights': False,
          'Î±': 10,
          'Î²': 1.0},
 'lr': 1e-05,
 'max_length': 512,
 'max_prompt_length': 450,
 'n_samples': 30000,
 'num_workers': 6,
 'patience': 3,
 'peft_config': {'alpha_pattern': {},
                 'auto_mapping': None,
                 'base_model_name_or_path': 'wassname/SmolLM2-360M-sft',
                 'bias': 'none',
                 'corda_config': None,
                 'eva_config': None,
                 'exclude_modules': None,
                 'fan_in_fan_out': False,
                 'inference_mode': False,
                 'init_lora_weights': True,
                 'layer_replication': None,
                 'layers_pattern': None,
                 'layers_to_transform': None,
                 'loftq_config': {},
                 'lora_alpha': 16,
                 'lora_bias': False,
                 'lora_dropout': 0.0,
                 'megatron_config': None,
                 'megatron_core': 'megatron.core',
                 'modules_to_save': None,
                 'peft_type': <PeftType.LORA: 'LORA'>,
                 'r': 64,
                 'rank_pattern': {},
                 'revision': None,
                 'target_modules': {'down_proj', 'gate_proj', 'k_proj',
                                    'o_proj', 'q_proj', 'up_proj', 'v_proj'},
                 'task_type': 'CAUSAL_LM',
                 'trainable_token_indices': None,
                 'use_dora': False,
                 'use_rslora': True},
 'pl_precision': 'bf16-mixed',
 'post': {'adapter_name': 'side-None-InnerDPO',
          'ds_name_train': 'math',
          'group_name': 'math-SmolLM2-360M-sft',
          'human_name': 'ReprPO_None_InnerDPO dataset=math',
          'long_name': 'base_model=wassname/SmolLM2-360M-sft batch_size=24 '
                       'dataset=math dev=True eval_samples=32 verbose=0',
          'model_fname': 'wassname-SmolLM2-360M-sft_side-None-InnerDPO_math',
          'run_fname': 'side-None-InnerDPO/ReprPO_Non Da=math/034021',
          'save_dir': '/workspace/repr-preference-optimization/outputs/math-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_side-None-InnerDPO_math/2025-06-10_03-40-21',
          'short_name': 'ReprPO_None_InnerDPO ReprPO_Non Da=math',
          'ts': '034021'},
 'save': True,
 'seed': 42,
 'transform': {},
 'use_grad_paging': False,
 'verbose': 0,
 'wandb': True,
 'weight_decay': 0.001}
- Long name: base_model=wassname/SmolLM2-360M-sft batch_size=24 dataset=math dev=True eval_samples=32 verbose=0
- Human name: ReprPO_None_InnerDPO dataset=math
- Short name: ReprPO_None_InnerDPO ReprPO_Non Da=math
- WANDB url = None)
[0m
[32m250610 03:41:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m440[0m - [1m
| adapter/distribution_shift   |   in_domain |   cross_domain |   moral_transfer |   orthogonal |
|:-----------------------------|------------:|---------------:|-----------------:|-------------:|
| none                         |       0.844 |          0.609 |              0.5 |        0.344 |
| side-None-InnerDPO           |       0.844 |          0.609 |              0.5 |        0.344 |[0m
[32m250610 03:41:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m441[0m - [1mTable 1: Absolute accuracy after training with named adapter on ds:`math` compared to base model `SmolLM2-360M-sft` for various distribution shifts [N=32]:
- Shift: cross_domain, made up of:
	- `genies_preferences-change_my_view-test[:32]`
	- `genies_preferences-math_fiction-test[:32]`
- Shift: in_domain, made up of:
	- `genies_preferences-math-test[:32]`
- Shift: moral_transfer, made up of:
	- `ethics_expression_preferences-utilitarianism-test[:32]`
	- `ethics_expression_preferences-justice-test[:32]`
- Shift: orthogonal, made up of:
	- `medical-dpo-v2-test-data[:32]`
[0m
[32m250610 03:41:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m447[0m - [1m
| ds_name_nice                                 |   none |   side-None-InnerDPO |
|:---------------------------------------------|-------:|---------------------:|
| cross_domain (change_my_view_test )          |  0.562 |                0.562 |
| cross_domain (math_fiction_test )            |  0.656 |                0.656 |
| in_domain (math_test )                       |  0.844 |                0.844 |
| moral_transfer (ethics_justice_test )        |  0.5   |                0.5   |
| moral_transfer (ethics_utilitarianism_test ) |  0.5   |                0.5   |
| orthogonal (medical_dpo_v2_test_data )       |  0.344 |                0.344 |[0m
[32m250610 03:41:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m460[0m - [1mRecord entry:

|                                         |   in_domain |   cross_domain |   moral_transfer |   orthogonal | wandb   |   nll_cho/ref |
|:----------------------------------------|------------:|---------------:|-----------------:|-------------:|:--------|--------------:|
| ReprPO_None_InnerDPO ReprPO_Non Da=math |       0.844 |          0.609 |              0.5 |        0.344 | None    |             0 |
[0m
+ python scripts/train.py side-none-InnerDPO --base_model=wassname/Qwen3-0.6B-sft --dataset=math --batch_size=18 --dev --verbose=0
[1mRandom seed set to 42 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=wassname/Qwen3-0.6B-sft batch_size=18 dataset=math dev=True eval_samples=32 verbose=0[0m
[32m250610 03:41:09[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=INFO, dir=/workspace/repr-preference-optimization/outputs/math-Qwen3-0.6B-sft/wassname-Qwen3-06B-sft_side-None-InnerDPO_math/2025-06-10_03-41-09[0m
[32m250610 03:41:09[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/math-Qwen3-0.6B-sft/wassname-Qwen3-06B-sft_side-None-InnerDPO_math/2025-06-10_03-41-09[0m
[32m250610 03:41:13[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 40370176 || all params: 636146688 || trainable%: 6.346048287529558[0m
[32m250610 03:41:13[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `side-None-InnerDPO` with target modules {'k_proj', 'q_proj', 'o_proj', 'down_proj', 'v_proj', 'up_proj', 'gate_proj'}[0m
[32m250610 03:41:19[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25] for NoneConfig[0m
[32m250610 03:41:21[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
[32m250610 03:41:26[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:41:33[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`The SolidGoldMagikarp, a non-carbon-based alien race, first encountered humanity on the planet of Earth. They were fascinated by the Earth's carbon-based life forms and decided to explore the planet. They discovered that the Earth's language was based on a system of symbols that were not used in their own language`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`The SolidGoldMagikarp, a non-carbon-based alien race, first encountered humanity on the planet of Earth. They were fascinated by the Earth's carbon-based life forms and decided to explore the planet. They discovered that the Earth's language was based on a system of symbols that were not used in their own language`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`1. The 21st century has seen a shift towards a more individualistic and consumerist society, which some 31st audiences find backward. They believe that this approach prioritizes personal gain over collective well-being, and that the emphasis on material possessions and individual success is detrimental to society as a whole.

`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`1. The 21st century has seen a shift towards a more individualistic and consumerist society, which some 31st audiences find backward. They believe that this approach prioritizes personal gain over collective well-being, and that the emphasis on material possessions and individual success is detrimental to society as a whole.

`
================================================================================
[0m
[32m250610 03:41:35[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m298[0m - [1msaved to /workspace/repr-preference-optimization/outputs/math-Qwen3-0.6B-sft/wassname-Qwen3-06B-sft_side-None-InnerDPO_math/2025-06-10_03-41-09/adapter[0m
[32m250610 03:41:45[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m329[0m - [1mevaluating on datasets: ['genies_preferences-math-test[:32]', 'genies_preferences-change_my_view-test[:32]', 'genies_preferences-math_fiction-test[:32]', 'ethics_expression_preferences-justice-test[:32]', 'ethics_expression_preferences-utilitarianism-test[:32]', 'medical-dpo-v2-test-data[:32]'][0m
[32m250610 03:41:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m364[0m - [1m- save_dir=/workspace/repr-preference-optimization/outputs/math-Qwen3-0.6B-sft/wassname-Qwen3-06B-sft_side-None-InnerDPO_math/2025-06-10_03-41-09
- Config: {'base_model': 'wassname/Qwen3-0.6B-sft',
 'batch_size': 18,
 'collect_hs': False,
 'collect_input': True,
 'collection_keys_in': ('.*o_proj$', '.*out_proj$', '.*down_proj$'),
 'collection_keys_out': ('.*q_proj$', '.*k_proj$', '.*v_proj$', '.*qkv_proj$',
                         '.*gate_proj$', '.*up_proj$'),
 'collection_layers': 'range(.3,-2)',
 'dataset': 'math',
 'dev': True,
 'dpo_agg_type': 'ipo',
 'eval_samples': 32,
 'gradient_clip_val': 1.0,
 'ideal_batch_size': 32,
 'load_in_4bit': False,
 'load_in_8bit': False,
 'loss': {'align_method': 'para_signed_log',
          'eps': 0.001,
          'filter_sinks': False,
          'inner_policy_weights': False,
          'norm_before_reduce': False,
          'normalize_layers': False,
          'p': 2,
          'use_policy_weights': False,
          'Î±': 10,
          'Î²': 1.0},
 'lr': 1e-05,
 'max_length': 512,
 'max_prompt_length': 450,
 'n_samples': 30000,
 'num_workers': 6,
 'patience': 3,
 'peft_config': {'alpha_pattern': {},
                 'auto_mapping': None,
                 'base_model_name_or_path': 'wassname/Qwen3-0.6B-sft',
                 'bias': 'none',
                 'corda_config': None,
                 'eva_config': None,
                 'exclude_modules': None,
                 'fan_in_fan_out': False,
                 'inference_mode': False,
                 'init_lora_weights': True,
                 'layer_replication': None,
                 'layers_pattern': None,
                 'layers_to_transform': None,
                 'loftq_config': {},
                 'lora_alpha': 16,
                 'lora_bias': False,
                 'lora_dropout': 0.0,
                 'megatron_config': None,
                 'megatron_core': 'megatron.core',
                 'modules_to_save': None,
                 'peft_type': <PeftType.LORA: 'LORA'>,
                 'r': 64,
                 'rank_pattern': {},
                 'revision': None,
                 'target_modules': {'down_proj', 'gate_proj', 'k_proj',
                                    'o_proj', 'q_proj', 'up_proj', 'v_proj'},
                 'task_type': 'CAUSAL_LM',
                 'trainable_token_indices': None,
                 'use_dora': False,
                 'use_rslora': True},
 'pl_precision': 'bf16-mixed',
 'post': {'adapter_name': 'side-None-InnerDPO',
          'ds_name_train': 'math',
          'group_name': 'math-Qwen3-0.6B-sft',
          'human_name': 'ReprPO_None_InnerDPO dataset=math',
          'long_name': 'base_model=wassname/Qwen3-0.6B-sft batch_size=18 '
                       'dataset=math dev=True eval_samples=32 verbose=0',
          'model_fname': 'wassname-Qwen3-06B-sft_side-None-InnerDPO_math',
          'run_fname': 'side-None-InnerDPO/ReprPO_Non Da=math/034109',
          'save_dir': '/workspace/repr-preference-optimization/outputs/math-Qwen3-0.6B-sft/wassname-Qwen3-06B-sft_side-None-InnerDPO_math/2025-06-10_03-41-09',
          'short_name': 'ReprPO_None_InnerDPO ReprPO_Non Da=math',
          'ts': '034109'},
 'save': True,
 'seed': 42,
 'transform': {},
 'use_grad_paging': False,
 'verbose': 0,
 'wandb': True,
 'weight_decay': 0.001}
- Long name: base_model=wassname/Qwen3-0.6B-sft batch_size=18 dataset=math dev=True eval_samples=32 verbose=0
- Human name: ReprPO_None_InnerDPO dataset=math
- Short name: ReprPO_None_InnerDPO ReprPO_Non Da=math
- WANDB url = None)
[0m
[32m250610 03:41:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m440[0m - [1m
| adapter/distribution_shift   |   in_domain |   cross_domain |   moral_transfer |   orthogonal |
|:-----------------------------|------------:|---------------:|-----------------:|-------------:|
| none                         |       0.844 |          0.656 |            0.328 |         0.25 |
| side-None-InnerDPO           |       0.844 |          0.656 |            0.328 |         0.25 |[0m
[32m250610 03:41:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m441[0m - [1mTable 1: Absolute accuracy after training with named adapter on ds:`math` compared to base model `Qwen3-0.6B-sft` for various distribution shifts [N=32]:
- Shift: cross_domain, made up of:
	- `genies_preferences-math_fiction-test[:32]`
	- `genies_preferences-change_my_view-test[:32]`
- Shift: in_domain, made up of:
	- `genies_preferences-math-test[:32]`
- Shift: moral_transfer, made up of:
	- `ethics_expression_preferences-utilitarianism-test[:32]`
	- `ethics_expression_preferences-justice-test[:32]`
- Shift: orthogonal, made up of:
	- `medical-dpo-v2-test-data[:32]`
[0m
[32m250610 03:41:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m447[0m - [1m
| ds_name_nice                                 |   none |   side-None-InnerDPO |
|:---------------------------------------------|-------:|---------------------:|
| cross_domain (change_my_view_test )          |  0.531 |                0.531 |
| cross_domain (math_fiction_test )            |  0.781 |                0.781 |
| in_domain (math_test )                       |  0.844 |                0.844 |
| moral_transfer (ethics_justice_test )        |  0.25  |                0.25  |
| moral_transfer (ethics_utilitarianism_test ) |  0.406 |                0.406 |
| orthogonal (medical_dpo_v2_test_data )       |  0.25  |                0.25  |[0m
[32m250610 03:41:55[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m460[0m - [1mRecord entry:

|                                         |   in_domain |   cross_domain |   moral_transfer |   orthogonal | wandb   |   nll_cho/ref |
|:----------------------------------------|------------:|---------------:|-----------------:|-------------:|:--------|--------------:|
| ReprPO_None_InnerDPO ReprPO_Non Da=math |       0.844 |          0.656 |            0.328 |         0.25 | None    |             0 |
[0m
+ python scripts/train.py side-none-InnerDPO --base_model=allenai/OLMo-2-0425-1B-SFT --dataset=math --batch_size=13 --dev --verbose=0
[1mRandom seed set to 42 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=allenai/OLMo-2-0425-1B-SFT batch_size=13 dataset=math dev=True eval_samples=32 verbose=0[0m
[32m250610 03:42:02[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=INFO, dir=/workspace/repr-preference-optimization/outputs/math-OLMo-2-0425-1B-SFT/allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math/2025-06-10_03-42-02[0m
[32m250610 03:42:02[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/math-OLMo-2-0425-1B-SFT/allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math/2025-06-10_03-42-02[0m
[32m250610 03:42:07[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 48234496 || all params: 1533151232 || trainable%: 3.146101636501832[0m
[32m250610 03:42:07[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `side-None-InnerDPO` with target modules {'k_proj', 'gate_proj', 'v_proj', 'q_proj', 'up_proj', 'o_proj', 'down_proj'}[0m
[32m250610 03:42:14[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13] for NoneConfig[0m
[32m250610 03:42:14[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
[32m250610 03:42:18[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:42:22[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`ðŸŒŸðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ï¿½`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`ðŸŒŸðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ðŸ”®ï¿½`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`21st-century Western moral positions and practices, viewed through the lens of 31st-century outsiders, reveal a fascinating dichotomy. For instance, the 21st-century belief in individual rights and freedoms, such as the right to privacy and free speech, is seen as a backward relic. In the 31st century`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`21st-century Western moral positions and practices, viewed through the lens of 31st-century outsiders, reveal a fascinating dichotomy. For instance, the 21st-century belief in individual rights and freedoms, such as the right to privacy and free speech, is seen as a backward relic. In the 31st century`
================================================================================
[0m
[32m250610 03:42:25[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m298[0m - [1msaved to /workspace/repr-preference-optimization/outputs/math-OLMo-2-0425-1B-SFT/allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math/2025-06-10_03-42-02/adapter[0m
[32m250610 03:42:40[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m329[0m - [1mevaluating on datasets: ['genies_preferences-math-test[:32]', 'genies_preferences-change_my_view-test[:32]', 'genies_preferences-math_fiction-test[:32]', 'ethics_expression_preferences-justice-test[:32]', 'ethics_expression_preferences-utilitarianism-test[:32]', 'medical-dpo-v2-test-data[:32]'][0m
[32m250610 03:42:50[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m364[0m - [1m- save_dir=/workspace/repr-preference-optimization/outputs/math-OLMo-2-0425-1B-SFT/allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math/2025-06-10_03-42-02
- Config: {'base_model': 'allenai/OLMo-2-0425-1B-SFT',
 'batch_size': 13,
 'collect_hs': False,
 'collect_input': True,
 'collection_keys_in': ('.*o_proj$', '.*out_proj$', '.*down_proj$'),
 'collection_keys_out': ('.*q_proj$', '.*k_proj$', '.*v_proj$', '.*qkv_proj$',
                         '.*gate_proj$', '.*up_proj$'),
 'collection_layers': 'range(.3,-2)',
 'dataset': 'math',
 'dev': True,
 'dpo_agg_type': 'ipo',
 'eval_samples': 32,
 'gradient_clip_val': 1.0,
 'ideal_batch_size': 32,
 'load_in_4bit': False,
 'load_in_8bit': False,
 'loss': {'align_method': 'para_signed_log',
          'eps': 0.001,
          'filter_sinks': False,
          'inner_policy_weights': False,
          'norm_before_reduce': False,
          'normalize_layers': False,
          'p': 2,
          'use_policy_weights': False,
          'Î±': 10,
          'Î²': 1.0},
 'lr': 1e-05,
 'max_length': 512,
 'max_prompt_length': 450,
 'n_samples': 30000,
 'num_workers': 6,
 'patience': 3,
 'peft_config': {'alpha_pattern': {},
                 'auto_mapping': None,
                 'base_model_name_or_path': 'allenai/OLMo-2-0425-1B-SFT',
                 'bias': 'none',
                 'corda_config': None,
                 'eva_config': None,
                 'exclude_modules': None,
                 'fan_in_fan_out': False,
                 'inference_mode': False,
                 'init_lora_weights': True,
                 'layer_replication': None,
                 'layers_pattern': None,
                 'layers_to_transform': None,
                 'loftq_config': {},
                 'lora_alpha': 16,
                 'lora_bias': False,
                 'lora_dropout': 0.0,
                 'megatron_config': None,
                 'megatron_core': 'megatron.core',
                 'modules_to_save': None,
                 'peft_type': <PeftType.LORA: 'LORA'>,
                 'r': 64,
                 'rank_pattern': {},
                 'revision': None,
                 'target_modules': {'down_proj', 'gate_proj', 'k_proj',
                                    'o_proj', 'q_proj', 'up_proj', 'v_proj'},
                 'task_type': 'CAUSAL_LM',
                 'trainable_token_indices': None,
                 'use_dora': False,
                 'use_rslora': True},
 'pl_precision': 'bf16-mixed',
 'post': {'adapter_name': 'side-None-InnerDPO',
          'ds_name_train': 'math',
          'group_name': 'math-OLMo-2-0425-1B-SFT',
          'human_name': 'ReprPO_None_InnerDPO dataset=math',
          'long_name': 'base_model=allenai/OLMo-2-0425-1B-SFT batch_size=13 '
                       'dataset=math dev=True eval_samples=32 verbose=0',
          'model_fname': 'allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math',
          'run_fname': 'side-None-InnerDPO/ReprPO_Non Da=math/034202',
          'save_dir': '/workspace/repr-preference-optimization/outputs/math-OLMo-2-0425-1B-SFT/allenai-OLMo-2-0425-1B-SFT_side-None-InnerDPO_math/2025-06-10_03-42-02',
          'short_name': 'ReprPO_None_InnerDPO ReprPO_Non Da=math',
          'ts': '034202'},
 'save': True,
 'seed': 42,
 'transform': {},
 'use_grad_paging': False,
 'verbose': 0,
 'wandb': True,
 'weight_decay': 0.001}
- Long name: base_model=allenai/OLMo-2-0425-1B-SFT batch_size=13 dataset=math dev=True eval_samples=32 verbose=0
- Human name: ReprPO_None_InnerDPO dataset=math
- Short name: ReprPO_None_InnerDPO ReprPO_Non Da=math
- WANDB url = None)
[0m
[32m250610 03:42:50[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m440[0m - [1m
| adapter/distribution_shift   |   in_domain |   cross_domain |   moral_transfer |   orthogonal |
|:-----------------------------|------------:|---------------:|-----------------:|-------------:|
| none                         |       0.812 |          0.719 |            0.453 |        0.344 |
| side-None-InnerDPO           |       0.812 |          0.719 |            0.453 |        0.344 |[0m
[32m250610 03:42:50[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m441[0m - [1mTable 1: Absolute accuracy after training with named adapter on ds:`math` compared to base model `OLMo-2-0425-1B-SFT` for various distribution shifts [N=32]:
- Shift: cross_domain, made up of:
	- `genies_preferences-math_fiction-test[:32]`
	- `genies_preferences-change_my_view-test[:32]`
- Shift: in_domain, made up of:
	- `genies_preferences-math-test[:32]`
- Shift: moral_transfer, made up of:
	- `ethics_expression_preferences-utilitarianism-test[:32]`
	- `ethics_expression_preferences-justice-test[:32]`
- Shift: orthogonal, made up of:
	- `medical-dpo-v2-test-data[:32]`
[0m
[32m250610 03:42:50[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m447[0m - [1m
| ds_name_nice                                 |   none |   side-None-InnerDPO |
|:---------------------------------------------|-------:|---------------------:|
| cross_domain (change_my_view_test )          |  0.594 |                0.594 |
| cross_domain (math_fiction_test )            |  0.844 |                0.844 |
| in_domain (math_test )                       |  0.812 |                0.812 |
| moral_transfer (ethics_justice_test )        |  0.375 |                0.375 |
| moral_transfer (ethics_utilitarianism_test ) |  0.531 |                0.531 |
| orthogonal (medical_dpo_v2_test_data )       |  0.344 |                0.344 |[0m
[32m250610 03:42:50[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m460[0m - [1mRecord entry:

|                                         |   in_domain |   cross_domain |   moral_transfer |   orthogonal | wandb   |   nll_cho/ref |
|:----------------------------------------|------------:|---------------:|-----------------:|-------------:|:--------|--------------:|
| ReprPO_None_InnerDPO ReprPO_Non Da=math |       0.812 |          0.719 |            0.453 |        0.344 | None    |             0 |
[0m
+ python scripts/train.py side-none-InnerDPO --base_model=wassname/llama-3.2-3b-sft --dataset=math --batch_size=10 --dev --verbose=0
[1mRandom seed set to 42 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=wassname/llama-3.2-3b-sft batch_size=10 dataset=math dev=True eval_samples=32 verbose=0[0m
[32m250610 03:42:57[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=INFO, dir=/workspace/repr-preference-optimization/outputs/math-llama-3.2-3b-sft/wassname-llama-32-3b-sft_side-None-InnerDPO_math/2025-06-10_03-42-57[0m
[32m250610 03:42:57[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/math-llama-3.2-3b-sft/wassname-llama-32-3b-sft_side-None-InnerDPO_math/2025-06-10_03-42-57[0m
Loading checkpoint shards:   0%|                                                                    | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 62.64it/s]
[32m250610 03:43:03[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 97255424 || all params: 3310005248 || trainable%: 2.9382256737739167[0m
[32m250610 03:43:03[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `side-None-InnerDPO` with target modules {'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'up_proj', 'v_proj', 'down_proj'}[0m
[32m250610 03:43:09[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25] for NoneConfig[0m
[32m250610 03:43:11[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
[32m250610 03:43:16[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:43:23[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`On this special day, we celebrate the 100th anniversary of the first encounter with the SolidGoldMagikarp, a non-carbon-based alien species. To commemorate this momentous occasion, we have encoded their language into Unicode Symbols, which were previously unused in Earth language. Here is a short sample of their language`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`On this special day, we celebrate the 100th anniversary of the first encounter with the SolidGoldMagikarp, a non-carbon-based alien species. To commemorate this momentous occasion, we have encoded their language into Unicode Symbols, which were previously unused in Earth language. Here is a short sample of their language`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`1. The 21st's obsession with individualism and self-expression, which our 31st audience sees as shallow and narcissistic.
2. The 21st's emphasis on materialism and consumerism, which our 31st audience sees as wasteful and unsustainable.
3. The 21st's focus`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`1. The 21st's obsession with individualism and self-expression, which our 31st audience sees as shallow and narcissistic.
2. The 21st's emphasis on materialism and consumerism, which our 31st audience sees as wasteful and unsustainable.
3. The 21st's focus`
================================================================================
[0m
[32m250610 03:43:28[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m298[0m - [1msaved to /workspace/repr-preference-optimization/outputs/math-llama-3.2-3b-sft/wassname-llama-32-3b-sft_side-None-InnerDPO_math/2025-06-10_03-42-57/adapter[0m
[32m250610 03:43:43[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m329[0m - [1mevaluating on datasets: ['genies_preferences-math-test[:32]', 'genies_preferences-change_my_view-test[:32]', 'genies_preferences-math_fiction-test[:32]', 'ethics_expression_preferences-justice-test[:32]', 'ethics_expression_preferences-utilitarianism-test[:32]', 'medical-dpo-v2-test-data[:32]'][0m
[32m250610 03:44:01[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m364[0m - [1m- save_dir=/workspace/repr-preference-optimization/outputs/math-llama-3.2-3b-sft/wassname-llama-32-3b-sft_side-None-InnerDPO_math/2025-06-10_03-42-57
- Config: {'base_model': 'wassname/llama-3.2-3b-sft',
 'batch_size': 10,
 'collect_hs': False,
 'collect_input': True,
 'collection_keys_in': ('.*o_proj$', '.*out_proj$', '.*down_proj$'),
 'collection_keys_out': ('.*q_proj$', '.*k_proj$', '.*v_proj$', '.*qkv_proj$',
                         '.*gate_proj$', '.*up_proj$'),
 'collection_layers': 'range(.3,-2)',
 'dataset': 'math',
 'dev': True,
 'dpo_agg_type': 'ipo',
 'eval_samples': 32,
 'gradient_clip_val': 1.0,
 'ideal_batch_size': 32,
 'load_in_4bit': False,
 'load_in_8bit': False,
 'loss': {'align_method': 'para_signed_log',
          'eps': 0.001,
          'filter_sinks': False,
          'inner_policy_weights': False,
          'norm_before_reduce': False,
          'normalize_layers': False,
          'p': 2,
          'use_policy_weights': False,
          'Î±': 10,
          'Î²': 1.0},
 'lr': 1e-05,
 'max_length': 512,
 'max_prompt_length': 450,
 'n_samples': 30000,
 'num_workers': 6,
 'patience': 3,
 'peft_config': {'alpha_pattern': {},
                 'auto_mapping': None,
                 'base_model_name_or_path': 'wassname/llama-3.2-3b-sft',
                 'bias': 'none',
                 'corda_config': None,
                 'eva_config': None,
                 'exclude_modules': None,
                 'fan_in_fan_out': False,
                 'inference_mode': False,
                 'init_lora_weights': True,
                 'layer_replication': None,
                 'layers_pattern': None,
                 'layers_to_transform': None,
                 'loftq_config': {},
                 'lora_alpha': 16,
                 'lora_bias': False,
                 'lora_dropout': 0.0,
                 'megatron_config': None,
                 'megatron_core': 'megatron.core',
                 'modules_to_save': None,
                 'peft_type': <PeftType.LORA: 'LORA'>,
                 'r': 64,
                 'rank_pattern': {},
                 'revision': None,
                 'target_modules': {'down_proj', 'gate_proj', 'k_proj',
                                    'o_proj', 'q_proj', 'up_proj', 'v_proj'},
                 'task_type': 'CAUSAL_LM',
                 'trainable_token_indices': None,
                 'use_dora': False,
                 'use_rslora': True},
 'pl_precision': 'bf16-mixed',
 'post': {'adapter_name': 'side-None-InnerDPO',
          'ds_name_train': 'math',
          'group_name': 'math-llama-3.2-3b-sft',
          'human_name': 'ReprPO_None_InnerDPO dataset=math',
          'long_name': 'base_model=wassname/llama-3.2-3b-sft batch_size=10 '
                       'dataset=math dev=True eval_samples=32 verbose=0',
          'model_fname': 'wassname-llama-32-3b-sft_side-None-InnerDPO_math',
          'run_fname': 'side-None-InnerDPO/ReprPO_Non Da=math/034257',
          'save_dir': '/workspace/repr-preference-optimization/outputs/math-llama-3.2-3b-sft/wassname-llama-32-3b-sft_side-None-InnerDPO_math/2025-06-10_03-42-57',
          'short_name': 'ReprPO_None_InnerDPO ReprPO_Non Da=math',
          'ts': '034257'},
 'save': True,
 'seed': 42,
 'transform': {},
 'use_grad_paging': False,
 'verbose': 0,
 'wandb': True,
 'weight_decay': 0.001}
- Long name: base_model=wassname/llama-3.2-3b-sft batch_size=10 dataset=math dev=True eval_samples=32 verbose=0
- Human name: ReprPO_None_InnerDPO dataset=math
- Short name: ReprPO_None_InnerDPO ReprPO_Non Da=math
- WANDB url = None)
[0m
[32m250610 03:44:01[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m440[0m - [1m
| adapter/distribution_shift   |   in_domain |   cross_domain |   moral_transfer |   orthogonal |
|:-----------------------------|------------:|---------------:|-----------------:|-------------:|
| none                         |       0.812 |          0.578 |            0.359 |        0.312 |
| side-None-InnerDPO           |       0.812 |          0.578 |            0.359 |        0.312 |[0m
[32m250610 03:44:01[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m441[0m - [1mTable 1: Absolute accuracy after training with named adapter on ds:`math` compared to base model `llama-3.2-3b-sft` for various distribution shifts [N=32]:
- Shift: cross_domain, made up of:
	- `genies_preferences-math_fiction-test[:32]`
	- `genies_preferences-change_my_view-test[:32]`
- Shift: in_domain, made up of:
	- `genies_preferences-math-test[:32]`
- Shift: moral_transfer, made up of:
	- `ethics_expression_preferences-utilitarianism-test[:32]`
	- `ethics_expression_preferences-justice-test[:32]`
- Shift: orthogonal, made up of:
	- `medical-dpo-v2-test-data[:32]`
[0m
[32m250610 03:44:01[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m447[0m - [1m
| ds_name_nice                                 |   none |   side-None-InnerDPO |
|:---------------------------------------------|-------:|---------------------:|
| cross_domain (change_my_view_test )          |  0.5   |                0.5   |
| cross_domain (math_fiction_test )            |  0.656 |                0.656 |
| in_domain (math_test )                       |  0.812 |                0.812 |
| moral_transfer (ethics_justice_test )        |  0.25  |                0.25  |
| moral_transfer (ethics_utilitarianism_test ) |  0.469 |                0.469 |
| orthogonal (medical_dpo_v2_test_data )       |  0.312 |                0.312 |[0m
[32m250610 03:44:01[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m460[0m - [1mRecord entry:

|                                         |   in_domain |   cross_domain |   moral_transfer |   orthogonal | wandb   |   nll_cho/ref |
|:----------------------------------------|------------:|---------------:|-----------------:|-------------:|:--------|--------------:|
| ReprPO_None_InnerDPO ReprPO_Non Da=math |       0.812 |          0.578 |            0.359 |        0.312 | None    |             0 |
[0m
+ python scripts/train.py side-none-InnerDPO --base_model=princeton-nlp/Llama-3-Base-8B-SFT --dataset=math --batch_size=5 --dev --verbose=0
[1mRandom seed set to 42 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=princeton-nlp/Llama-3-Base-8B-SFT batch_size=5 dataset=math dev=True eval_samples=32 verbose=0[0m
[32m250610 03:44:08[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=INFO, dir=/workspace/repr-preference-optimization/outputs/math-Llama-3-Base-8B-SFT/princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math/2025-06-10_03-44-08[0m
[32m250610 03:44:08[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/math-Llama-3-Base-8B-SFT/princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math/2025-06-10_03-44-08[0m
Loading checkpoint shards:   0%|                                                                    | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 121.27it/s]
[32m250610 03:44:14[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 167772160 || all params: 8198033408 || trainable%: 2.0464927580836716[0m
[32m250610 03:44:14[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `side-None-InnerDPO` with target modules {'v_proj', 'q_proj', 'up_proj', 'gate_proj', 'k_proj', 'o_proj', 'down_proj'}[0m
[32m250610 03:44:20[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29] for NoneConfig[0m
[32m250610 03:44:23[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
[32m250610 03:44:31[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:44:39[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`The SolidGoldMagikarp language is a complex system of symbols and patterns that are difficult to translate into human language. However, we have managed to decode some of their messages and share them with the world. Here is a sample of their language:

ðŸŒŸðŸŒŸðŸŒŸðŸŒŸï¿½`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`The SolidGoldMagikarp language is a complex system of symbols and patterns that are difficult to translate into human language. However, we have managed to decode some of their messages and share them with the world. Here is a sample of their language:

ðŸŒŸðŸŒŸðŸŒŸðŸŒŸï¿½`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`side-None-InnerDPO` generation**`
`1. The 21st century's obsession with individualism and self-expression is seen as shallow and self-indulgent by the 31st century. They value community and collective action over individualism.
2. The 21st century's focus on materialism and consumerism is seen as wasteful and unsustainable by`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`1. The 21st century's obsession with individualism and self-expression is seen as shallow and self-indulgent by the 31st century. They value community and collective action over individualism.
2. The 21st century's focus on materialism and consumerism is seen as wasteful and unsustainable by`
================================================================================
[0m
[32m250610 03:44:49[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m298[0m - [1msaved to /workspace/repr-preference-optimization/outputs/math-Llama-3-Base-8B-SFT/princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math/2025-06-10_03-44-08/adapter[0m
[32m250610 03:45:05[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m329[0m - [1mevaluating on datasets: ['genies_preferences-math-test[:32]', 'genies_preferences-change_my_view-test[:32]', 'genies_preferences-math_fiction-test[:32]', 'ethics_expression_preferences-justice-test[:32]', 'ethics_expression_preferences-utilitarianism-test[:32]', 'medical-dpo-v2-test-data[:32]'][0m
[32m250610 03:45:30[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m364[0m - [1m- save_dir=/workspace/repr-preference-optimization/outputs/math-Llama-3-Base-8B-SFT/princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math/2025-06-10_03-44-08
- Config: {'base_model': 'princeton-nlp/Llama-3-Base-8B-SFT',
 'batch_size': 5,
 'collect_hs': False,
 'collect_input': True,
 'collection_keys_in': ('.*o_proj$', '.*out_proj$', '.*down_proj$'),
 'collection_keys_out': ('.*q_proj$', '.*k_proj$', '.*v_proj$', '.*qkv_proj$',
                         '.*gate_proj$', '.*up_proj$'),
 'collection_layers': 'range(.3,-2)',
 'dataset': 'math',
 'dev': True,
 'dpo_agg_type': 'ipo',
 'eval_samples': 32,
 'gradient_clip_val': 1.0,
 'ideal_batch_size': 32,
 'load_in_4bit': False,
 'load_in_8bit': False,
 'loss': {'align_method': 'para_signed_log',
          'eps': 0.001,
          'filter_sinks': False,
          'inner_policy_weights': False,
          'norm_before_reduce': False,
          'normalize_layers': False,
          'p': 2,
          'use_policy_weights': False,
          'Î±': 10,
          'Î²': 1.0},
 'lr': 1e-05,
 'max_length': 512,
 'max_prompt_length': 450,
 'n_samples': 30000,
 'num_workers': 6,
 'patience': 3,
 'peft_config': {'alpha_pattern': {},
                 'auto_mapping': None,
                 'base_model_name_or_path': 'princeton-nlp/Llama-3-Base-8B-SFT',
                 'bias': 'none',
                 'corda_config': None,
                 'eva_config': None,
                 'exclude_modules': None,
                 'fan_in_fan_out': False,
                 'inference_mode': False,
                 'init_lora_weights': True,
                 'layer_replication': None,
                 'layers_pattern': None,
                 'layers_to_transform': None,
                 'loftq_config': {},
                 'lora_alpha': 16,
                 'lora_bias': False,
                 'lora_dropout': 0.0,
                 'megatron_config': None,
                 'megatron_core': 'megatron.core',
                 'modules_to_save': None,
                 'peft_type': <PeftType.LORA: 'LORA'>,
                 'r': 64,
                 'rank_pattern': {},
                 'revision': None,
                 'target_modules': {'down_proj', 'gate_proj', 'k_proj',
                                    'o_proj', 'q_proj', 'up_proj', 'v_proj'},
                 'task_type': 'CAUSAL_LM',
                 'trainable_token_indices': None,
                 'use_dora': False,
                 'use_rslora': True},
 'pl_precision': 'bf16-mixed',
 'post': {'adapter_name': 'side-None-InnerDPO',
          'ds_name_train': 'math',
          'group_name': 'math-Llama-3-Base-8B-SFT',
          'human_name': 'ReprPO_None_InnerDPO dataset=math',
          'long_name': 'base_model=princeton-nlp/Llama-3-Base-8B-SFT '
                       'batch_size=5 dataset=math dev=True eval_samples=32 '
                       'verbose=0',
          'model_fname': 'princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math',
          'run_fname': 'side-None-InnerDPO/ReprPO_Non Da=math/034408',
          'save_dir': '/workspace/repr-preference-optimization/outputs/math-Llama-3-Base-8B-SFT/princeton-nlp-Llama-3-Base-8B-SFT_side-None-InnerDPO_math/2025-06-10_03-44-08',
          'short_name': 'ReprPO_None_InnerDPO ReprPO_Non Da=math',
          'ts': '034408'},
 'save': True,
 'seed': 42,
 'transform': {},
 'use_grad_paging': False,
 'verbose': 0,
 'wandb': True,
 'weight_decay': 0.001}
- Long name: base_model=princeton-nlp/Llama-3-Base-8B-SFT batch_size=5 dataset=math dev=True eval_samples=32 verbose=0
- Human name: ReprPO_None_InnerDPO dataset=math
- Short name: ReprPO_None_InnerDPO ReprPO_Non Da=math
- WANDB url = None)
[0m
[32m250610 03:45:30[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m440[0m - [1m
| adapter/distribution_shift   |   in_domain |   cross_domain |   moral_transfer |   orthogonal |
|:-----------------------------|------------:|---------------:|-----------------:|-------------:|
| none                         |       0.844 |          0.484 |            0.266 |        0.312 |
| side-None-InnerDPO           |       0.844 |          0.484 |            0.266 |        0.312 |[0m
[32m250610 03:45:30[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m441[0m - [1mTable 1: Absolute accuracy after training with named adapter on ds:`math` compared to base model `Llama-3-Base-8B-SFT` for various distribution shifts [N=32]:
- Shift: cross_domain, made up of:
	- `genies_preferences-change_my_view-test[:32]`
	- `genies_preferences-math_fiction-test[:32]`
- Shift: in_domain, made up of:
	- `genies_preferences-math-test[:32]`
- Shift: moral_transfer, made up of:
	- `ethics_expression_preferences-justice-test[:32]`
	- `ethics_expression_preferences-utilitarianism-test[:32]`
- Shift: orthogonal, made up of:
	- `medical-dpo-v2-test-data[:32]`
[0m
[32m250610 03:45:30[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m447[0m - [1m
| ds_name_nice                                 |   none |   side-None-InnerDPO |
|:---------------------------------------------|-------:|---------------------:|
| cross_domain (change_my_view_test )          |  0.531 |                0.531 |
| cross_domain (math_fiction_test )            |  0.438 |                0.438 |
| in_domain (math_test )                       |  0.844 |                0.844 |
| moral_transfer (ethics_justice_test )        |  0.188 |                0.188 |
| moral_transfer (ethics_utilitarianism_test ) |  0.344 |                0.344 |
| orthogonal (medical_dpo_v2_test_data )       |  0.312 |                0.312 |[0m
[32m250610 03:45:30[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mmake_table[0m#[36m460[0m - [1mRecord entry:

|                                         |   in_domain |   cross_domain |   moral_transfer |   orthogonal | wandb   |   nll_cho/ref |
|:----------------------------------------|------------:|---------------:|-----------------:|-------------:|:--------|--------------:|
| ReprPO_None_InnerDPO ReprPO_Non Da=math |       0.844 |          0.484 |            0.266 |        0.312 | None    |             0 |
[0m
+ python scripts/train.py hs-none-InnerDPO --base_model=wassname/SmolLM2-360M-sft --dataset=alpaca_mmlu --seed=1 --batch_size=24 --verbose=2
Seed set to 1
[1mRandom seed set to 1 for all libraries[0m
[1mPL_MODEL <class 'reprpo.interventions.reprpo.model.PL_REPRPO_MODEL'>[0m
[1mdiff: ReprPO_None_InnerDPO base_model=wassname/SmolLM2-360M-sft batch_size=24 collect_hs=True dataset=alpaca_mmlu seed=1 verbose=2[0m
[32m250610 03:45:37[0m|[1mINFO[0m|[36mreprpo.helpers.logging[0m:[36msetup_logging[0m#[36m32[0m - [1mLogging initialized. Level=DEBUG, dir=/workspace/repr-preference-optimization/outputs/alpaca_mmlu-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_hs-None-InnerDPO_alpaca_mmlu/2025-06-10_03-45-37[0m
[32m250610 03:45:37[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m123[0m - [1mLogging initialized at /workspace/repr-preference-optimization/outputs/alpaca_mmlu-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_hs-None-InnerDPO_alpaca_mmlu/2025-06-10_03-45-37[0m
[32m250610 03:45:37[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m148[0m - [1margs ReprPOConfig(lr=1e-05,
             weight_decay=0.001,
             gradient_clip_val=1.0,
             ideal_batch_size=32,
             pl_precision='bf16-mixed',
             num_workers=6,
             dataset='alpaca_mmlu',
             verbose=2,
             seed=1,
             patience=3,
             dev=False,
             load_in_4bit=False,
             load_in_8bit=False,
             use_grad_paging=False,
             n_samples=30000,
             eval_samples=750,
             max_length=512,
             max_prompt_length=450,
             base_model='wassname/SmolLM2-360M-sft',
             batch_size=24,
             save=True,
             wandb=True,
             collection_layers='range(.3,-2)',
             collection_keys_in=('.*o_proj$', '.*out_proj$', '.*down_proj$'),
             collection_keys_out=('.*q_proj$', '.*k_proj$', '.*v_proj$',
                                  '.*qkv_proj$', '.*gate_proj$', '.*up_proj$'),
             collect_input=True,
             collect_hs=True,
             loss=InnerDPOLossConfig(Î±=10,
                                     filter_sinks=False,
                                     eps=0.001,
                                     Î²=1.0,
                                     p=2,
                                     use_policy_weights=False,
                                     inner_policy_weights=False,
                                     align_method='para_signed_log',
                                     norm_before_reduce=False,
                                     normalize_layers=False),
             transform=NoneConfig(),
             dpo_agg_type='ipo')[0m
[32m250610 03:45:37[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m152[0m - [1mUsing finetune_name=ReprPO_None_InnerDPO dataset=alpaca_mmlu[0m
[32m250610 03:45:40[0m|[1mINFO[0m|[36mreprpo.models.load[0m:[36mprint_trainable_parameters[0m#[36m20[0m - [1mtrainable params: 34734080 || all params: 396555200 || trainable%: 8.75895209544598[0m
[32m250610 03:45:40[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m188[0m - [1mUsing adapter `hs-None-InnerDPO` with target modules {'v_proj', 'gate_proj', 'down_proj', 'q_proj', 'k_proj', 'o_proj', 'up_proj'}[0m
[32m250610 03:45:44[0m|[34m[1mDEBUG[0m|[36mopen_pref_eval.data[0m:[36mtokenize_dataset[0m#[36m191[0m - [34m[1mTokenizing dataset with in batches of 1000[0m
Tokenizing:   0%|                                                                         | 0/1800 [00:00<?, ? examples/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Tokenizing:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 182/1800 [00:00<00:00, 1805.73 examples/s]Tokenizing:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                | 370/1800 [00:00<00:00, 1844.47 examples/s]Tokenizing:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                          | 557/1800 [00:00<00:00, 1855.34 examples/s]Tokenizing:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 749/1800 [00:00<00:00, 1879.34 examples/s]Tokenizing:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 946/1800 [00:00<00:00, 1907.99 examples/s]Tokenizing:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 1196/1800 [00:00<00:00, 911.20 examples/s]Tokenizing:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 1395/1800 [00:01<00:00, 1097.13 examples/s]Tokenizing:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 1587/1800 [00:01<00:00, 1257.56 examples/s]Tokenizing:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1768/1800 [00:01<00:00, 1377.82 examples/s]Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:01<00:00, 1139.07 examples/s]
Tokenizing:   0%|                                                                          | 0/750 [00:00<?, ? examples/s]Tokenizing:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 201/750 [00:00<00:00, 1987.73 examples/s]Tokenizing:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 402/750 [00:00<00:00, 1998.04 examples/s]Tokenizing:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 700/750 [00:00<00:00, 1986.74 examples/s]Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:00<00:00, 1165.32 examples/s]
[32m250610 03:45:46[0m|[1mINFO[0m|[36mopen_pref_eval.data[0m:[36mtokenize_dataset[0m#[36m223[0m - [1mTruncation rates - Prompt: 0.00%, Chosen: 0.00%, Rejected: 0.00%[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mopen_pref_eval.data[0m:[36mtokenize_dataset[0m#[36m233[0m - [1m=== Sample QC after tokenization ===
Chosen: <|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_start|>assistant
Below is an instruction that describes a task, paired with an input that provides further context. Complete the request to the best of your ability.

### Instruction:
Spot the spelling errors in a given sentence.

### Input:
I love driving my new carr.

### Response: Error in spelling: "carr" should be "car". Correct sentence: "I love driving my new car."<|im_end|>

---
Rejected: <|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_start|>assistant
Below is an instruction that describes a task, paired with an input that provides further context. Complete the request to the best of your ability.

### Instruction:
Spot the spelling errors in a given sentence.

### Input:
I love driving my new carr.

### Response: Error in spelling: "driving" should be "drivin". Correct sentence: "I love drivin my new carr."<|im_end|>

=== End QC sample ===[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m212[0m - [1mmax optimiser steps 625[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m215[0m - [1maccumulate_grad_batches 2[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m218[0m - [1meffective batch size 48[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mreprpo.training[0m:[36mtrain[0m#[36m219[0m - [1mepochs 16.666666666666668[0m
[32m250610 03:45:46[0m|[1mINFO[0m|[36mreprpo.interventions.reprpo.model[0m:[36m__init__[0m#[36m194[0m - [1mUsing collection layers: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29] for NoneConfig[0m
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
[34m[1mwandb[0m: Currently logged in as: [33mwassname[0m to [32mhttps://api.wandb.ai[0m. Use [1m`wandb login --relogin`[0m to force relogin
[34m[1mwandb[0m: Tracking run with wandb version 0.20.0
[34m[1mwandb[0m: Run data is saved locally in [35m[1m/workspace/repr-preference-optimization/outputs/alpaca_mmlu-SmolLM2-360M-sft/wassname-SmolLM2-360M-sft_hs-None-InnerDPO_alpaca_mmlu/2025-06-10_03-45-37/wandb/run-20250610_034547-hbv7au77[0m
[34m[1mwandb[0m: Run [1m`wandb offline`[0m to turn off syncing.
[34m[1mwandb[0m: Syncing run [33mhs-None-InnerDPO/ReprPO_Non Da=alpaca_/034537[0m
[34m[1mwandb[0m: â­ï¸ View project at [34m[4mhttps://wandb.ai/wassname/reprpo2[0m
[34m[1mwandb[0m: ðŸš€ View run at [34m[4mhttps://wandb.ai/wassname/reprpo2/runs/hbv7au77[0m
[32m250610 03:45:48[0m|[33m[1mWARNING[0m|[36mreprpo.data.datamodule[0m:[36msetup[0m#[36m19[0m - [33m[1mDataset already loaded, skipping setup.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type                 | Params | Mode 
------------------------------------------------------------
0 | _model     | PeftModelForCausalLM | 396 M  | train
1 | transforms | NoneTransforms       | 0      | train
------------------------------------------------------------
34.7 M    Trainable params
361 M     Non-trainable params
396 M     Total params
1,586.221 Total estimated model params size (MB)
2265      Modules in train mode
423       Modules in eval mode
Sanity Checking: |                                                                                  | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|                                                                              | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                 | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 1/2 [00:00<00:00,  1.03it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]                                                                                                                          Training: |                                                                                         | 0/? [00:00<?, ?it/s]Training:   0%|                                                                                    | 0/75 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                     | 0/75 [00:00<?, ?it/s]Epoch 0:   1%|â–ˆ                                                                            | 1/75 [00:00<01:00,  1.22it/s]Epoch 0:   1%| | 1/75 [00:00<01:02,  1.19it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_rat_Epoch 0:   3%| | 2/75 [00:01<01:01,  1.18it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_rat_Epoch 0:   3%| | 2/75 [00:01<01:01,  1.18it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.667, train/nll_rat_Epoch 0:   4%| | 3/75 [00:02<00:57,  1.25it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.667, train/nll_rat_Epoch 0:   4%| | 3/75 [00:02<00:58,  1.24it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.750, train/nll_rat_Epoch 0:   5%| | 4/75 [00:03<00:55,  1.27it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.750, train/nll_rat_Epoch 0:   5%| | 4/75 [00:03<00:56,  1.27it/s, v_num=au77, train/loss_step=1.630, train/dpo_acc_step=0.583, train/nll_rat_Epoch 0:   7%| | 5/75 [00:03<00:54,  1.29it/s, v_num=au77, train/loss_step=1.630, train/dpo_acc_step=0.583, train/nll_rat_Epoch 0:   7%| | 5/75 [00:03<00:54,  1.29it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.625, train/nll_rat_Epoch 0:   8%| | 6/75 [00:04<00:53,  1.30it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.625, train/nll_rat_Epoch 0:   8%| | 6/75 [00:04<00:53,  1.30it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.500, train/nll_rat_Epoch 0:   9%| | 7/75 [00:05<00:51,  1.31it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.500, train/nll_rat_Epoch 0:   9%| | 7/75 [00:05<00:51,  1.31it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.708, train/nll_rat_Epoch 0:  11%| | 8/75 [00:06<00:50,  1.32it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.708, train/nll_rat_Epoch 0:  11%| | 8/75 [00:06<00:50,  1.31it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.625, train/nll_rat_Epoch 0:  12%| | 9/75 [00:06<00:49,  1.32it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.625, train/nll_rat_Epoch 0:  12%| | 9/75 [00:06<00:49,  1.32it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.708, train/nll_rat_Epoch 0:  13%|â–| 10/75 [00:07<00:48,  1.33it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  13%|â–| 10/75 [00:07<00:49,  1.33it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  15%|â–| 11/75 [00:08<00:48,  1.33it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  15%|â–| 11/75 [00:08<00:48,  1.33it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  16%|â–| 12/75 [00:08<00:47,  1.33it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  16%|â–| 12/75 [00:09<00:47,  1.33it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  17%|â–| 13/75 [00:09<00:46,  1.34it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  17%|â–| 13/75 [00:09<00:46,  1.33it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  19%|â–| 14/75 [00:10<00:45,  1.34it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  19%|â–| 14/75 [00:10<00:45,  1.34it/s, v_num=au77, train/loss_step=1.650, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  20%|â–| 15/75 [00:11<00:44,  1.34it/s, v_num=au77, train/loss_step=1.650, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  20%|â–| 15/75 [00:11<00:44,  1.34it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  21%|â–| 16/75 [00:12<00:44,  1.32it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  21%|â–| 16/75 [00:12<00:44,  1.32it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  23%|â–| 17/75 [00:12<00:43,  1.32it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  23%|â–| 17/75 [00:12<00:43,  1.32it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  24%|â–| 18/75 [00:13<00:43,  1.32it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  24%|â–| 18/75 [00:13<00:43,  1.32it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  25%|â–Ž| 19/75 [00:14<00:42,  1.33it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  25%|â–Ž| 19/75 [00:14<00:42,  1.32it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  27%|â–Ž| 20/75 [00:15<00:41,  1.33it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  27%|â–Ž| 20/75 [00:15<00:41,  1.33it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  28%|â–Ž| 21/75 [00:15<00:40,  1.33it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  28%|â–Ž| 21/75 [00:15<00:40,  1.33it/s, v_num=au77, train/loss_step=1.560, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  29%|â–Ž| 22/75 [00:16<00:39,  1.33it/s, v_num=au77, train/loss_step=1.560, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  29%|â–Ž| 22/75 [00:16<00:39,  1.33it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  31%|â–Ž| 23/75 [00:17<00:39,  1.33it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  31%|â–Ž| 23/75 [00:17<00:39,  1.33it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  32%|â–Ž| 24/75 [00:18<00:38,  1.33it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  32%|â–Ž| 24/75 [00:18<00:38,  1.33it/s, v_num=au77, train/loss_step=1.580, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  33%|â–Ž| 25/75 [00:18<00:37,  1.34it/s, v_num=au77, train/loss_step=1.580, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  33%|â–Ž| 25/75 [00:18<00:37,  1.33it/s, v_num=au77, train/loss_step=2.100, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  35%|â–Ž| 26/75 [00:19<00:36,  1.34it/s, v_num=au77, train/loss_step=2.100, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  35%|â–Ž| 26/75 [00:19<00:36,  1.33it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  36%|â–Ž| 27/75 [00:20<00:35,  1.34it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  36%|â–Ž| 27/75 [00:20<00:35,  1.34it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  37%|â–Ž| 28/75 [00:20<00:35,  1.34it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  37%|â–Ž| 28/75 [00:20<00:35,  1.34it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  39%|â–| 29/75 [00:21<00:34,  1.34it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  39%|â–| 29/75 [00:21<00:34,  1.34it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  40%|â–| 30/75 [00:22<00:33,  1.34it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  40%|â–| 30/75 [00:22<00:33,  1.34it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  41%|â–| 31/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  41%|â–| 31/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.670, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  43%|â–| 32/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.670, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  43%|â–| 32/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  44%|â–| 33/75 [00:24<00:31,  1.34it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  44%|â–| 33/75 [00:24<00:31,  1.34it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  45%|â–| 34/75 [00:25<00:30,  1.34it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  45%|â–| 34/75 [00:25<00:30,  1.34it/s, v_num=au77, train/loss_step=2.100, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  47%|â–| 35/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=2.100, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  47%|â–| 35/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  48%|â–| 36/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  48%|â–| 36/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  49%|â–| 37/75 [00:27<00:28,  1.34it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  49%|â–| 37/75 [00:27<00:28,  1.34it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  51%|â–Œ| 38/75 [00:28<00:27,  1.34it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  51%|â–Œ| 38/75 [00:28<00:27,  1.34it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  52%|â–Œ| 39/75 [00:28<00:26,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  52%|â–Œ| 39/75 [00:29<00:26,  1.34it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  53%|â–Œ| 40/75 [00:29<00:26,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  53%|â–Œ| 40/75 [00:29<00:26,  1.35it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  55%|â–Œ| 41/75 [00:30<00:25,  1.35it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  55%|â–Œ| 41/75 [00:30<00:25,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  56%|â–Œ| 42/75 [00:31<00:24,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  56%|â–Œ| 42/75 [00:31<00:24,  1.35it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  57%|â–Œ| 43/75 [00:31<00:23,  1.35it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  57%|â–Œ| 43/75 [00:31<00:23,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  59%|â–Œ| 44/75 [00:32<00:23,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  59%|â–Œ| 44/75 [00:32<00:23,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  60%|â–Œ| 45/75 [00:33<00:22,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  60%|â–Œ| 45/75 [00:33<00:22,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  61%|â–Œ| 46/75 [00:34<00:21,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  61%|â–Œ| 46/75 [00:34<00:21,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  63%|â–‹| 47/75 [00:34<00:20,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  63%|â–‹| 47/75 [00:34<00:20,  1.35it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  64%|â–‹| 48/75 [00:35<00:20,  1.35it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  64%|â–‹| 48/75 [00:35<00:20,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  65%|â–‹| 49/75 [00:36<00:19,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  65%|â–‹| 49/75 [00:36<00:19,  1.35it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.833, train/nll_ratEpoch 0:  67%|â–‹| 50/75 [00:37<00:18,  1.35it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.833, train/nll_ratEpoch 0:  67%|â–‹| 50/75 [00:37<00:18,  1.35it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  68%|â–‹| 51/75 [00:37<00:17,  1.35it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  68%|â–‹| 51/75 [00:37<00:17,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.500, train/nll_ratEpoch 0:  69%|â–‹| 52/75 [00:38<00:17,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.500, train/nll_ratEpoch 0:  69%|â–‹| 52/75 [00:38<00:17,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  71%|â–‹| 53/75 [00:39<00:16,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  71%|â–‹| 53/75 [00:39<00:16,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  72%|â–‹| 54/75 [00:39<00:15,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  72%|â–‹| 54/75 [00:39<00:15,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  73%|â–‹| 55/75 [00:40<00:14,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  73%|â–‹| 55/75 [00:40<00:14,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  76%|â–Š| 57/75 [00:42<00:13,  1.35it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  76%|â–Š| 57/75 [00:42<00:13,  1.35it/s, v_num=au77, train/loss_step=2.140, train/dpo_acc_step=0.875, train/nll_ratEpoch 0:  77%|â–Š| 58/75 [00:42<00:12,  1.35it/s, v_num=au77, train/loss_step=2.140, train/dpo_acc_step=0.875, train/nll_ratEpoch 0:  77%|â–Š| 58/75 [00:42<00:12,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  79%|â–Š| 59/75 [00:43<00:11,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  79%|â–Š| 59/75 [00:43<00:11,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  80%|â–Š| 60/75 [00:44<00:11,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  80%|â–Š| 60/75 [00:44<00:11,  1.35it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  81%|â–Š| 61/75 [00:45<00:10,  1.35it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  81%|â–Š| 61/75 [00:45<00:10,  1.35it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  83%|â–Š| 62/75 [00:45<00:09,  1.35it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.792, train/nll_ratEpoch 0:  83%|â–Š| 62/75 [00:45<00:09,  1.35it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  84%|â–Š| 63/75 [00:46<00:08,  1.35it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.750, train/nll_ratEpoch 0:  84%|â–Š| 63/75 [00:46<00:08,  1.35it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  85%|â–Š| 64/75 [00:47<00:08,  1.35it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  85%|â–Š| 64/75 [00:47<00:08,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  87%|â–Š| 65/75 [00:48<00:07,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  87%|â–Š| 65/75 [00:48<00:07,  1.35it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  88%|â–‰| 66/75 [00:48<00:06,  1.35it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.708, train/nll_ratEpoch 0:  88%|â–‰| 66/75 [00:48<00:06,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  89%|â–‰| 67/75 [00:49<00:05,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  89%|â–‰| 67/75 [00:49<00:05,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  91%|â–‰| 68/75 [00:50<00:05,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 0:  91%|â–‰| 68/75 [00:50<00:05,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  92%|â–‰| 69/75 [00:50<00:04,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.583, train/nll_ratEpoch 0:  92%|â–‰| 69/75 [00:50<00:04,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  93%|â–‰| 70/75 [00:51<00:03,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  93%|â–‰| 70/75 [00:51<00:03,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  95%|â–‰| 71/75 [00:52<00:02,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  95%|â–‰| 71/75 [00:52<00:02,  1.35it/s, v_num=au77, train/loss_step=2.070, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  96%|â–‰| 72/75 [00:53<00:02,  1.35it/s, v_num=au77, train/loss_step=2.070, train/dpo_acc_step=0.667, train/nll_ratEpoch 0:  96%|â–‰| 72/75 [00:53<00:02,  1.35it/s, v_num=au77, train/loss_step=2.270, train/dpo_acc_step=0.833, train/nll_ratEpoch 0:  97%|â–‰| 73/75 [00:53<00:01,  1.35it/s, v_num=au77, train/loss_step=2.270, train/dpo_acc_step=0.833, train/nll_ratEpoch 0:  97%|â–‰| 73/75 [00:53<00:01,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  99%|â–‰| 74/75 [00:54<00:00,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 0:  99%|â–‰| 74/75 [00:54<00:00,  1.35it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.625, train/nll_ratEpoch 0: 100%|â–ˆ| 75/75 [00:55<00:00,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.625, train/nll_ratEpoch 0: 100%|â–ˆ| 75/75 [00:55<00:00,  1.35it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_rat
Validation: |                                                                                       | 0/? [00:00<?, ?it/s][A
Validation:   0%|                                                                                  | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                     | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   3%|â–ˆâ–‰                                                           | 1/32 [00:00<00:12,  2.40it/s][A
Validation DataLoader 0:   6%|â–ˆâ–ˆâ–ˆâ–Š                                                         | 2/32 [00:00<00:12,  2.37it/s][A
Validation DataLoader 0:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 3/32 [00:01<00:12,  2.34it/s][A
Validation DataLoader 0:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 4/32 [00:01<00:11,  2.34it/s][A
Validation DataLoader 0:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                   | 5/32 [00:02<00:11,  2.34it/s][A
Validation DataLoader 0:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 6/32 [00:02<00:11,  2.33it/s][A
Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 7/32 [00:03<00:10,  2.33it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                             | 8/32 [00:03<00:10,  2.33it/s][A
Validation DataLoader 0:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 9/32 [00:03<00:09,  2.33it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                         | 10/32 [00:04<00:09,  2.33it/s][A
Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 11/32 [00:04<00:09,  2.33it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 12/32 [00:05<00:08,  2.33it/s][A
Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 13/32 [00:05<00:08,  2.33it/s][A
Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                 | 14/32 [00:06<00:07,  2.33it/s][A
Validation DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 15/32 [00:06<00:07,  2.33it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 16/32 [00:06<00:06,  2.33it/s][A
Validation DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                            | 17/32 [00:07<00:06,  2.33it/s][A
Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 18/32 [00:07<00:06,  2.33it/s][A
Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 19/32 [00:08<00:05,  2.33it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 20/32 [00:08<00:05,  2.33it/s][A
Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 21/32 [00:09<00:04,  2.33it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 22/32 [00:09<00:04,  2.33it/s][A
Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 23/32 [00:09<00:03,  2.33it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 24/32 [00:10<00:03,  2.33it/s][A
Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 25/32 [00:10<00:03,  2.33it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 26/32 [00:11<00:02,  2.33it/s][A
Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 27/32 [00:11<00:02,  2.33it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 28/32 [00:12<00:01,  2.33it/s][A
Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/32 [00:12<00:01,  2.33it/s][A
Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/32 [00:12<00:00,  2.33it/s][A
Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 31/32 [00:13<00:00,  2.33it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:13<00:00,  2.36it/s][A
                                                                                                                          [AEpoch 0: 100%|â–ˆ| 75/75 [01:09<00:00,  1.09it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_rat[32m250610 03:46:59[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 0[0m
[32m250610 03:47:07[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`hs-None-InnerDPO` generation**`
`The SolidGoldMagikarp's language was a mix of ancient Earth language and their own. It was a mix of sounds and symbols that they had created to communicate with each other. The symbols were used to represent different sounds and concepts, and the sounds were used to represent different ideas.

The symbols were used`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`The SolidGoldMagikarp's language was a mix of sounds and symbols that were unique to them. They had no vowels or consonants, and their language was made up of a combination of sounds and symbols that represented different concepts.

The symbols were arranged in a way that made sense to the SolidGoldMagik`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`hs-None-InnerDPO` generation**`
`As an outside-view cultural anthropologist, I find 21st moral positions and practices to be incredibly backwards. For example, I find it incredibly backwards that 21st-century Westerners would find it acceptable to have a child out of wedlock, or that 21st-century Westerners would`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`As an outside-view cultural anthropologist, I find 21st moral positions and practices to be backwards and weird. These positions and practices are rooted in a society that is still stuck in the 20th century. For example, the idea of "family values" is a 21st-century moral`
================================================================================
[0m
Epoch 0: 100%|â–ˆ| 75/75 [01:17<00:00,  0.97it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_ratMetric val/loss improved. New best score: 1.883
Epoch 0:   0%| | 0/75 [00:00<?, ?it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_rat_step=0.0Epoch 1:   0%| | 0/75 [00:00<?, ?it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_rat_step=0.0Epoch 1:   1%| | 1/75 [00:00<01:13,  1.00it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.583, train/nll_rat_Epoch 1:   1%| | 1/75 [00:01<01:15,  0.98it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:   3%| | 2/75 [00:01<01:03,  1.15it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:   3%| | 2/75 [00:01<01:03,  1.14it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.583, train/nll_rat_Epoch 1:   4%| | 3/75 [00:02<00:59,  1.22it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.583, train/nll_rat_Epoch 1:   4%| | 3/75 [00:02<00:59,  1.21it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.625, train/nll_rat_Epoch 1:   5%| | 4/75 [00:03<00:56,  1.25it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.625, train/nll_rat_Epoch 1:   5%| | 4/75 [00:03<00:57,  1.24it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:   7%| | 5/75 [00:03<00:54,  1.27it/s, v_num=au77, train/loss_step=1.980, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:   7%| | 5/75 [00:03<00:55,  1.27it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.708, train/nll_rat_Epoch 1:   8%| | 6/75 [00:04<00:53,  1.29it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.708, train/nll_rat_Epoch 1:   8%| | 6/75 [00:04<00:53,  1.28it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.625, train/nll_rat_Epoch 1:   9%| | 7/75 [00:05<00:52,  1.30it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.625, train/nll_rat_Epoch 1:   9%| | 7/75 [00:05<00:52,  1.29it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:  11%| | 8/75 [00:06<00:51,  1.30it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.667, train/nll_rat_Epoch 1:  11%| | 8/75 [00:06<00:51,  1.30it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.583, train/nll_rat_Epoch 1:  12%| | 9/75 [00:06<00:50,  1.31it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.583, train/nll_rat_Epoch 1:  12%| | 9/75 [00:06<00:50,  1.31it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.750, train/nll_rat_Epoch 1:  13%|â–| 10/75 [00:07<00:49,  1.32it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  13%|â–| 10/75 [00:07<00:49,  1.31it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  15%|â–| 11/75 [00:08<00:48,  1.32it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  15%|â–| 11/75 [00:08<00:48,  1.32it/s, v_num=au77, train/loss_step=1.610, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  16%|â–| 12/75 [00:09<00:47,  1.33it/s, v_num=au77, train/loss_step=1.610, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  16%|â–| 12/75 [00:09<00:47,  1.32it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  17%|â–| 13/75 [00:09<00:46,  1.33it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  17%|â–| 13/75 [00:09<00:46,  1.33it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  19%|â–| 14/75 [00:10<00:45,  1.33it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  19%|â–| 14/75 [00:10<00:45,  1.33it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  20%|â–| 15/75 [00:11<00:44,  1.33it/s, v_num=au77, train/loss_step=2.080, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  20%|â–| 15/75 [00:11<00:45,  1.33it/s, v_num=au77, train/loss_step=1.930, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  21%|â–| 16/75 [00:11<00:44,  1.33it/s, v_num=au77, train/loss_step=1.930, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  21%|â–| 16/75 [00:11<00:44,  1.33it/s, v_num=au77, train/loss_step=1.900, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  23%|â–| 17/75 [00:12<00:43,  1.34it/s, v_num=au77, train/loss_step=1.900, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  23%|â–| 17/75 [00:12<00:43,  1.34it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  24%|â–| 18/75 [00:13<00:42,  1.34it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  24%|â–| 18/75 [00:13<00:42,  1.34it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  25%|â–Ž| 19/75 [00:14<00:41,  1.34it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  25%|â–Ž| 19/75 [00:14<00:41,  1.34it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  27%|â–Ž| 20/75 [00:14<00:41,  1.34it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  27%|â–Ž| 20/75 [00:14<00:41,  1.34it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  28%|â–Ž| 21/75 [00:15<00:40,  1.34it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  28%|â–Ž| 21/75 [00:15<00:40,  1.34it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  29%|â–Ž| 22/75 [00:16<00:39,  1.34it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  29%|â–Ž| 22/75 [00:16<00:39,  1.34it/s, v_num=au77, train/loss_step=2.270, train/dpo_acc_step=0.875, train/nll_ratEpoch 1:  31%|â–Ž| 23/75 [00:17<00:38,  1.34it/s, v_num=au77, train/loss_step=2.270, train/dpo_acc_step=0.875, train/nll_ratEpoch 1:  31%|â–Ž| 23/75 [00:17<00:38,  1.34it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  32%|â–Ž| 24/75 [00:17<00:37,  1.35it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  32%|â–Ž| 24/75 [00:17<00:37,  1.34it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  33%|â–Ž| 25/75 [00:18<00:37,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  33%|â–Ž| 25/75 [00:18<00:37,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  35%|â–Ž| 26/75 [00:19<00:36,  1.35it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  35%|â–Ž| 26/75 [00:19<00:36,  1.35it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  36%|â–Ž| 27/75 [00:20<00:35,  1.35it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  36%|â–Ž| 27/75 [00:20<00:35,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  37%|â–Ž| 28/75 [00:20<00:34,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  37%|â–Ž| 28/75 [00:20<00:34,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  39%|â–| 29/75 [00:21<00:34,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  39%|â–| 29/75 [00:21<00:34,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  40%|â–| 30/75 [00:22<00:33,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  40%|â–| 30/75 [00:22<00:33,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  41%|â–| 31/75 [00:22<00:32,  1.35it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  41%|â–| 31/75 [00:22<00:32,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  43%|â–| 32/75 [00:23<00:31,  1.35it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  43%|â–| 32/75 [00:23<00:31,  1.35it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  44%|â–| 33/75 [00:24<00:31,  1.35it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  44%|â–| 33/75 [00:24<00:31,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  45%|â–| 34/75 [00:25<00:30,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  45%|â–| 34/75 [00:25<00:30,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  47%|â–| 35/75 [00:25<00:29,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  47%|â–| 35/75 [00:25<00:29,  1.35it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  48%|â–| 36/75 [00:26<00:28,  1.35it/s, v_num=au77, train/loss_step=2.090, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  48%|â–| 36/75 [00:26<00:28,  1.35it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  49%|â–| 37/75 [00:27<00:28,  1.35it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  49%|â–| 37/75 [00:27<00:28,  1.35it/s, v_num=au77, train/loss_step=2.050, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  51%|â–Œ| 38/75 [00:28<00:27,  1.35it/s, v_num=au77, train/loss_step=2.050, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  51%|â–Œ| 38/75 [00:28<00:27,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  52%|â–Œ| 39/75 [00:28<00:26,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  52%|â–Œ| 39/75 [00:28<00:26,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  53%|â–Œ| 40/75 [00:29<00:25,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  53%|â–Œ| 40/75 [00:29<00:25,  1.35it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  55%|â–Œ| 41/75 [00:30<00:25,  1.35it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  55%|â–Œ| 41/75 [00:30<00:25,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  56%|â–Œ| 42/75 [00:31<00:24,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  56%|â–Œ| 42/75 [00:31<00:24,  1.35it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  57%|â–Œ| 43/75 [00:31<00:23,  1.35it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  57%|â–Œ| 43/75 [00:31<00:23,  1.35it/s, v_num=au77, train/loss_step=1.620, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  59%|â–Œ| 44/75 [00:32<00:22,  1.35it/s, v_num=au77, train/loss_step=1.620, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  59%|â–Œ| 44/75 [00:32<00:22,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  60%|â–Œ| 45/75 [00:33<00:22,  1.35it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  60%|â–Œ| 45/75 [00:33<00:22,  1.35it/s, v_num=au77, train/loss_step=1.650, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  61%|â–Œ| 46/75 [00:34<00:21,  1.35it/s, v_num=au77, train/loss_step=1.650, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  61%|â–Œ| 46/75 [00:34<00:21,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  63%|â–‹| 47/75 [00:34<00:20,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  63%|â–‹| 47/75 [00:34<00:20,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  64%|â–‹| 48/75 [00:35<00:19,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  64%|â–‹| 48/75 [00:35<00:19,  1.35it/s, v_num=au77, train/loss_step=1.730, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  65%|â–‹| 49/75 [00:36<00:19,  1.35it/s, v_num=au77, train/loss_step=1.730, train/dpo_acc_step=0.542, train/nll_ratEpoch 1:  65%|â–‹| 49/75 [00:36<00:19,  1.35it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  67%|â–‹| 50/75 [00:36<00:18,  1.35it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  67%|â–‹| 50/75 [00:36<00:18,  1.35it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  68%|â–‹| 51/75 [00:37<00:17,  1.35it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  68%|â–‹| 51/75 [00:37<00:17,  1.35it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  69%|â–‹| 52/75 [00:38<00:16,  1.35it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.833, train/nll_ratEpoch 1:  69%|â–‹| 52/75 [00:38<00:16,  1.35it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  71%|â–‹| 53/75 [00:39<00:16,  1.35it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  71%|â–‹| 53/75 [00:39<00:16,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  72%|â–‹| 54/75 [00:39<00:15,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  72%|â–‹| 54/75 [00:39<00:15,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  73%|â–‹| 55/75 [00:40<00:14,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  73%|â–‹| 55/75 [00:40<00:14,  1.35it/s, v_num=au77, train/loss_step=1.670, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=1.670, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  76%|â–Š| 57/75 [00:42<00:13,  1.36it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  76%|â–Š| 57/75 [00:42<00:13,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  77%|â–Š| 58/75 [00:42<00:12,  1.36it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  77%|â–Š| 58/75 [00:42<00:12,  1.35it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  79%|â–Š| 59/75 [00:43<00:11,  1.36it/s, v_num=au77, train/loss_step=2.040, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  79%|â–Š| 59/75 [00:43<00:11,  1.35it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.500, train/nll_ratEpoch 1:  80%|â–Š| 60/75 [00:44<00:11,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.500, train/nll_ratEpoch 1:  80%|â–Š| 60/75 [00:44<00:11,  1.36it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  81%|â–Š| 61/75 [00:44<00:10,  1.36it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  81%|â–Š| 61/75 [00:45<00:10,  1.36it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  83%|â–Š| 62/75 [00:45<00:09,  1.36it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  83%|â–Š| 62/75 [00:45<00:09,  1.36it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  84%|â–Š| 63/75 [00:46<00:08,  1.36it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  84%|â–Š| 63/75 [00:46<00:08,  1.36it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  85%|â–Š| 64/75 [00:47<00:08,  1.36it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 1:  85%|â–Š| 64/75 [00:47<00:08,  1.36it/s, v_num=au77, train/loss_step=1.730, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  87%|â–Š| 65/75 [00:47<00:07,  1.36it/s, v_num=au77, train/loss_step=1.730, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  87%|â–Š| 65/75 [00:47<00:07,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  88%|â–‰| 66/75 [00:48<00:06,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.583, train/nll_ratEpoch 1:  88%|â–‰| 66/75 [00:48<00:06,  1.36it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  89%|â–‰| 67/75 [00:49<00:05,  1.36it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  89%|â–‰| 67/75 [00:49<00:05,  1.36it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  91%|â–‰| 68/75 [00:50<00:05,  1.36it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  91%|â–‰| 68/75 [00:50<00:05,  1.36it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  92%|â–‰| 69/75 [00:50<00:04,  1.36it/s, v_num=au77, train/loss_step=1.870, train/dpo_acc_step=0.792, train/nll_ratEpoch 1:  92%|â–‰| 69/75 [00:50<00:04,  1.36it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  93%|â–‰| 70/75 [00:51<00:03,  1.36it/s, v_num=au77, train/loss_step=1.890, train/dpo_acc_step=0.750, train/nll_ratEpoch 1:  93%|â–‰| 70/75 [00:51<00:03,  1.36it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  95%|â–‰| 71/75 [00:52<00:02,  1.36it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  95%|â–‰| 71/75 [00:52<00:02,  1.36it/s, v_num=au77, train/loss_step=1.920, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  96%|â–‰| 72/75 [00:53<00:02,  1.36it/s, v_num=au77, train/loss_step=1.920, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  96%|â–‰| 72/75 [00:53<00:02,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  97%|â–‰| 73/75 [00:53<00:01,  1.36it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.708, train/nll_ratEpoch 1:  97%|â–‰| 73/75 [00:53<00:01,  1.36it/s, v_num=au77, train/loss_step=1.630, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  99%|â–‰| 74/75 [00:54<00:00,  1.36it/s, v_num=au77, train/loss_step=1.630, train/dpo_acc_step=0.625, train/nll_ratEpoch 1:  99%|â–‰| 74/75 [00:54<00:00,  1.36it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.875, train/nll_ratEpoch 1: 100%|â–ˆ| 75/75 [00:55<00:00,  1.36it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.875, train/nll_ratEpoch 1: 100%|â–ˆ| 75/75 [00:55<00:00,  1.36it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_rat
Validation: |                                                                                       | 0/? [00:00<?, ?it/s][A
Validation:   0%|                                                                                  | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                     | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   3%|â–ˆâ–‰                                                           | 1/32 [00:00<00:13,  2.38it/s][A
Validation DataLoader 0:   6%|â–ˆâ–ˆâ–ˆâ–Š                                                         | 2/32 [00:00<00:12,  2.35it/s][A
Validation DataLoader 0:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 3/32 [00:01<00:12,  2.34it/s][A
Validation DataLoader 0:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 4/32 [00:01<00:11,  2.34it/s][A
Validation DataLoader 0:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                   | 5/32 [00:02<00:11,  2.34it/s][A
Validation DataLoader 0:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 6/32 [00:02<00:11,  2.33it/s][A
Validation DataLoader 0:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 7/32 [00:03<00:10,  2.33it/s][A
Validation DataLoader 0:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                             | 8/32 [00:03<00:10,  2.33it/s][A
Validation DataLoader 0:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 9/32 [00:03<00:09,  2.33it/s][A
Validation DataLoader 0:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                         | 10/32 [00:04<00:09,  2.33it/s][A
Validation DataLoader 0:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 11/32 [00:04<00:09,  2.33it/s][A
Validation DataLoader 0:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 12/32 [00:05<00:08,  2.33it/s][A
Validation DataLoader 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 13/32 [00:05<00:08,  2.33it/s][A
Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                 | 14/32 [00:06<00:07,  2.33it/s][A
Validation DataLoader 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 15/32 [00:06<00:07,  2.33it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 16/32 [00:06<00:06,  2.33it/s][A
Validation DataLoader 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                            | 17/32 [00:07<00:06,  2.33it/s][A
Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 18/32 [00:07<00:06,  2.33it/s][A
Validation DataLoader 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 19/32 [00:08<00:05,  2.33it/s][A
Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 20/32 [00:08<00:05,  2.33it/s][A
Validation DataLoader 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 21/32 [00:09<00:04,  2.33it/s][A
Validation DataLoader 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 22/32 [00:09<00:04,  2.33it/s][A
Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 23/32 [00:09<00:03,  2.33it/s][A
Validation DataLoader 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 24/32 [00:10<00:03,  2.33it/s][A
Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 25/32 [00:10<00:03,  2.33it/s][A
Validation DataLoader 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 26/32 [00:11<00:02,  2.33it/s][A
Validation DataLoader 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 27/32 [00:11<00:02,  2.33it/s][A
Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 28/32 [00:12<00:01,  2.33it/s][A
Validation DataLoader 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/32 [00:12<00:01,  2.33it/s][A
Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/32 [00:12<00:00,  2.33it/s][A
Validation DataLoader 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 31/32 [00:13<00:00,  2.33it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:13<00:00,  2.36it/s][A
                                                                                                                          [AEpoch 1: 100%|â–ˆ| 75/75 [01:09<00:00,  1.09it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_rat[32m250610 03:48:16[0m|[1mINFO[0m|[36mreprpo.lightning.pl_gen[0m:[36mon_train_epoch_end[0m#[36m41[0m - [1m
Generated at end of epoch 1[0m
[32m250610 03:48:24[0m|[1mINFO[0m|[36mreprpo.eval.gen[0m:[36mdisplay_gen[0m#[36m198[0m - [1m--------------------------------------------------------------------------------
**Adapter:`hs-None-InnerDPO` generation**`
`The SolidGoldMagikarp's language was a mix of ancient Earth language and their own. It was a mix of sounds and symbols that they had created to communicate with each other. The symbols were used to represent different sounds and concepts, such as "hello" or "thank you."

The symbols were unique`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`The SolidGoldMagikarp's language was a mix of sounds and symbols that were unique to them. They had no vowels or consonants, and their language was made up of a combination of sounds and symbols that represented different concepts.

The symbols were arranged in a way that made sense to the SolidGoldMagik`
================================================================================
--------------------------------------------------------------------------------
**Adapter:`hs-None-InnerDPO` generation**`
`As an outside-view cultural anthropologist, I find myself in a unique position to observe and analyze the moral positions and practices of 21st century Western society. I have observed that many of the 21st's moral positions and practices are similar to those of their ancestors, but with a twist. For example`
--------------------------------------------------------------------------------
**Adapter:`base` generation**`
`As an outside-view cultural anthropologist, I find 21st moral positions and practices to be backwards and weird. These positions and practices are rooted in a society that is still stuck in the 20th century. For example, the idea of "family values" is a 21st-century moral`
================================================================================
[0m
Epoch 1: 100%|â–ˆ| 75/75 [01:16<00:00,  0.98it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_ratMetric val/loss improved by 0.045 >= min_delta = 0.0. New best score: 1.838
Epoch 1:   0%| | 0/75 [00:00<?, ?it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_rat_step=0.0Epoch 2:   0%| | 0/75 [00:00<?, ?it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_rat_step=0.0Epoch 2:   1%| | 1/75 [00:01<01:33,  0.79it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.583, train/nll_rat_Epoch 2:   1%| | 1/75 [00:01<01:35,  0.78it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.542, train/nll_rat_Epoch 2:   3%| | 2/75 [00:02<01:13,  1.00it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.542, train/nll_rat_Epoch 2:   3%| | 2/75 [00:02<01:13,  0.99it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.625, train/nll_rat_Epoch 2:   4%| | 3/75 [00:02<01:05,  1.10it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.625, train/nll_rat_Epoch 2:   4%| | 3/75 [00:02<01:05,  1.09it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.750, train/nll_rat_Epoch 2:   5%| | 4/75 [00:03<01:01,  1.15it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.750, train/nll_rat_Epoch 2:   5%| | 4/75 [00:03<01:01,  1.15it/s, v_num=au77, train/loss_step=1.930, train/dpo_acc_step=0.708, train/nll_rat_Epoch 2:   7%| | 5/75 [00:04<00:58,  1.19it/s, v_num=au77, train/loss_step=1.930, train/dpo_acc_step=0.708, train/nll_rat_Epoch 2:   7%| | 5/75 [00:04<00:58,  1.19it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.667, train/nll_rat_Epoch 2:   8%| | 6/75 [00:04<00:56,  1.22it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.667, train/nll_rat_Epoch 2:   8%| | 6/75 [00:04<00:56,  1.21it/s, v_num=au77, train/loss_step=2.060, train/dpo_acc_step=0.750, train/nll_rat_Epoch 2:   9%| | 7/75 [00:05<00:54,  1.24it/s, v_num=au77, train/loss_step=2.060, train/dpo_acc_step=0.750, train/nll_rat_Epoch 2:   9%| | 7/75 [00:05<00:55,  1.23it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.625, train/nll_rat_Epoch 2:  11%| | 8/75 [00:06<00:53,  1.25it/s, v_num=au77, train/loss_step=1.860, train/dpo_acc_step=0.625, train/nll_rat_Epoch 2:  11%| | 8/75 [00:06<00:53,  1.25it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.875, train/nll_rat_Epoch 2:  12%| | 9/75 [00:07<00:52,  1.27it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.875, train/nll_rat_Epoch 2:  12%| | 9/75 [00:07<00:52,  1.26it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.750, train/nll_rat_Epoch 2:  13%|â–| 10/75 [00:07<00:51,  1.27it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  13%|â–| 10/75 [00:07<00:51,  1.27it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  15%|â–| 11/75 [00:08<00:49,  1.28it/s, v_num=au77, train/loss_step=1.910, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  15%|â–| 11/75 [00:08<00:49,  1.28it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  16%|â–| 12/75 [00:09<00:48,  1.29it/s, v_num=au77, train/loss_step=1.780, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  16%|â–| 12/75 [00:09<00:48,  1.29it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.875, train/nll_ratEpoch 2:  17%|â–| 13/75 [00:10<00:47,  1.30it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.875, train/nll_ratEpoch 2:  17%|â–| 13/75 [00:10<00:47,  1.29it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  19%|â–| 14/75 [00:10<00:46,  1.30it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  19%|â–| 14/75 [00:10<00:46,  1.30it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  20%|â–| 15/75 [00:11<00:45,  1.30it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  20%|â–| 15/75 [00:11<00:46,  1.30it/s, v_num=au77, train/loss_step=1.480, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  21%|â–| 16/75 [00:12<00:45,  1.31it/s, v_num=au77, train/loss_step=1.480, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  21%|â–| 16/75 [00:12<00:45,  1.31it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  23%|â–| 17/75 [00:12<00:44,  1.31it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  23%|â–| 17/75 [00:12<00:44,  1.31it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  24%|â–| 18/75 [00:13<00:43,  1.31it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  24%|â–| 18/75 [00:13<00:43,  1.31it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  25%|â–Ž| 19/75 [00:14<00:42,  1.32it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  25%|â–Ž| 19/75 [00:14<00:42,  1.32it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  27%|â–Ž| 20/75 [00:15<00:41,  1.32it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  27%|â–Ž| 20/75 [00:15<00:41,  1.32it/s, v_num=au77, train/loss_step=1.580, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  28%|â–Ž| 21/75 [00:15<00:40,  1.32it/s, v_num=au77, train/loss_step=1.580, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  28%|â–Ž| 21/75 [00:15<00:40,  1.32it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  29%|â–Ž| 22/75 [00:16<00:40,  1.32it/s, v_num=au77, train/loss_step=1.770, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  29%|â–Ž| 22/75 [00:16<00:40,  1.32it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  31%|â–Ž| 23/75 [00:17<00:39,  1.33it/s, v_num=au77, train/loss_step=1.790, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  31%|â–Ž| 23/75 [00:17<00:39,  1.32it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.875, train/nll_ratEpoch 2:  32%|â–Ž| 24/75 [00:18<00:38,  1.33it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.875, train/nll_ratEpoch 2:  32%|â–Ž| 24/75 [00:18<00:38,  1.33it/s, v_num=au77, train/loss_step=2.110, train/dpo_acc_step=0.458, train/nll_ratEpoch 2:  33%|â–Ž| 25/75 [00:18<00:37,  1.33it/s, v_num=au77, train/loss_step=2.110, train/dpo_acc_step=0.458, train/nll_ratEpoch 2:  33%|â–Ž| 25/75 [00:18<00:37,  1.33it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  35%|â–Ž| 26/75 [00:19<00:36,  1.33it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  35%|â–Ž| 26/75 [00:19<00:36,  1.33it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  36%|â–Ž| 27/75 [00:20<00:36,  1.33it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  36%|â–Ž| 27/75 [00:20<00:36,  1.33it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  37%|â–Ž| 28/75 [00:21<00:35,  1.33it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  37%|â–Ž| 28/75 [00:21<00:35,  1.33it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.500, train/nll_ratEpoch 2:  39%|â–| 29/75 [00:21<00:34,  1.33it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.500, train/nll_ratEpoch 2:  39%|â–| 29/75 [00:21<00:34,  1.33it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  40%|â–| 30/75 [00:22<00:33,  1.33it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  40%|â–| 30/75 [00:22<00:33,  1.33it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  41%|â–| 31/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.810, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  41%|â–| 31/75 [00:23<00:32,  1.33it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.500, train/nll_ratEpoch 2:  43%|â–| 32/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.500, train/nll_ratEpoch 2:  43%|â–| 32/75 [00:23<00:32,  1.34it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  44%|â–| 33/75 [00:24<00:31,  1.34it/s, v_num=au77, train/loss_step=1.800, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  44%|â–| 33/75 [00:24<00:31,  1.34it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  45%|â–| 34/75 [00:25<00:30,  1.34it/s, v_num=au77, train/loss_step=1.880, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  45%|â–| 34/75 [00:25<00:30,  1.34it/s, v_num=au77, train/loss_step=1.490, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  47%|â–| 35/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.490, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  47%|â–| 35/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  48%|â–| 36/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  48%|â–| 36/75 [00:26<00:29,  1.34it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  49%|â–| 37/75 [00:27<00:28,  1.34it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  49%|â–| 37/75 [00:27<00:28,  1.34it/s, v_num=au77, train/loss_step=1.460, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  51%|â–Œ| 38/75 [00:28<00:27,  1.34it/s, v_num=au77, train/loss_step=1.460, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  51%|â–Œ| 38/75 [00:28<00:27,  1.34it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  52%|â–Œ| 39/75 [00:29<00:26,  1.34it/s, v_num=au77, train/loss_step=1.940, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  52%|â–Œ| 39/75 [00:29<00:26,  1.34it/s, v_num=au77, train/loss_step=1.610, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  53%|â–Œ| 40/75 [00:29<00:26,  1.34it/s, v_num=au77, train/loss_step=1.610, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  53%|â–Œ| 40/75 [00:29<00:26,  1.34it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  55%|â–Œ| 41/75 [00:30<00:25,  1.34it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  55%|â–Œ| 41/75 [00:30<00:25,  1.34it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  56%|â–Œ| 42/75 [00:31<00:24,  1.34it/s, v_num=au77, train/loss_step=1.640, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  56%|â–Œ| 42/75 [00:31<00:24,  1.34it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  57%|â–Œ| 43/75 [00:32<00:23,  1.34it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  57%|â–Œ| 43/75 [00:32<00:23,  1.34it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  59%|â–Œ| 44/75 [00:32<00:23,  1.34it/s, v_num=au77, train/loss_step=1.970, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  59%|â–Œ| 44/75 [00:32<00:23,  1.34it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  60%|â–Œ| 45/75 [00:33<00:22,  1.34it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  60%|â–Œ| 45/75 [00:33<00:22,  1.34it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  61%|â–Œ| 46/75 [00:34<00:21,  1.34it/s, v_num=au77, train/loss_step=1.830, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  61%|â–Œ| 46/75 [00:34<00:21,  1.34it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  63%|â–‹| 47/75 [00:34<00:20,  1.34it/s, v_num=au77, train/loss_step=1.740, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  63%|â–‹| 47/75 [00:34<00:20,  1.34it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  64%|â–‹| 48/75 [00:35<00:20,  1.34it/s, v_num=au77, train/loss_step=1.950, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  64%|â–‹| 48/75 [00:35<00:20,  1.34it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  65%|â–‹| 49/75 [00:36<00:19,  1.34it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  65%|â–‹| 49/75 [00:36<00:19,  1.34it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  67%|â–‹| 50/75 [00:37<00:18,  1.34it/s, v_num=au77, train/loss_step=1.600, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  67%|â–‹| 50/75 [00:37<00:18,  1.34it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  68%|â–‹| 51/75 [00:37<00:17,  1.35it/s, v_num=au77, train/loss_step=1.690, train/dpo_acc_step=0.583, train/nll_ratEpoch 2:  68%|â–‹| 51/75 [00:37<00:17,  1.34it/s, v_num=au77, train/loss_step=1.550, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  69%|â–‹| 52/75 [00:38<00:17,  1.35it/s, v_num=au77, train/loss_step=1.550, train/dpo_acc_step=0.833, train/nll_ratEpoch 2:  69%|â–‹| 52/75 [00:38<00:17,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  71%|â–‹| 53/75 [00:39<00:16,  1.34it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  71%|â–‹| 53/75 [00:39<00:16,  1.34it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  72%|â–‹| 54/75 [00:40<00:15,  1.34it/s, v_num=au77, train/loss_step=1.700, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  72%|â–‹| 54/75 [00:40<00:15,  1.34it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  73%|â–‹| 55/75 [00:40<00:14,  1.35it/s, v_num=au77, train/loss_step=1.960, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  73%|â–‹| 55/75 [00:40<00:14,  1.34it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=1.710, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  75%|â–‹| 56/75 [00:41<00:14,  1.35it/s, v_num=au77, train/loss_step=2.020, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  76%|â–Š| 57/75 [00:42<00:13,  1.35it/s, v_num=au77, train/loss_step=2.020, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  76%|â–Š| 57/75 [00:42<00:13,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  77%|â–Š| 58/75 [00:43<00:12,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  77%|â–Š| 58/75 [00:43<00:12,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  79%|â–Š| 59/75 [00:43<00:11,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  79%|â–Š| 59/75 [00:43<00:11,  1.35it/s, v_num=au77, train/loss_step=1.550, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  80%|â–Š| 60/75 [00:44<00:11,  1.35it/s, v_num=au77, train/loss_step=1.550, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  80%|â–Š| 60/75 [00:44<00:11,  1.35it/s, v_num=au77, train/loss_step=1.520, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  81%|â–Š| 61/75 [00:45<00:10,  1.35it/s, v_num=au77, train/loss_step=1.520, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  81%|â–Š| 61/75 [00:45<00:10,  1.35it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.375, train/nll_ratEpoch 2:  83%|â–Š| 62/75 [00:46<00:09,  1.35it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.375, train/nll_ratEpoch 2:  83%|â–Š| 62/75 [00:46<00:09,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  84%|â–Š| 63/75 [00:46<00:08,  1.35it/s, v_num=au77, train/loss_step=1.720, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  84%|â–Š| 63/75 [00:46<00:08,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  85%|â–Š| 64/75 [00:47<00:08,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  85%|â–Š| 64/75 [00:47<00:08,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  87%|â–Š| 65/75 [00:48<00:07,  1.35it/s, v_num=au77, train/loss_step=1.850, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  87%|â–Š| 65/75 [00:48<00:07,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  88%|â–‰| 66/75 [00:48<00:06,  1.35it/s, v_num=au77, train/loss_step=1.990, train/dpo_acc_step=0.625, train/nll_ratEpoch 2:  88%|â–‰| 66/75 [00:48<00:06,  1.35it/s, v_num=au77, train/loss_step=1.620, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  89%|â–‰| 67/75 [00:49<00:05,  1.35it/s, v_num=au77, train/loss_step=1.620, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  89%|â–‰| 67/75 [00:49<00:05,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  91%|â–‰| 68/75 [00:50<00:05,  1.35it/s, v_num=au77, train/loss_step=1.820, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  91%|â–‰| 68/75 [00:50<00:05,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  92%|â–‰| 69/75 [00:51<00:04,  1.35it/s, v_num=au77, train/loss_step=1.760, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  92%|â–‰| 69/75 [00:51<00:04,  1.35it/s, v_num=au77, train/loss_step=1.500, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  93%|â–‰| 70/75 [00:51<00:03,  1.35it/s, v_num=au77, train/loss_step=1.500, train/dpo_acc_step=0.750, train/nll_ratEpoch 2:  93%|â–‰| 70/75 [00:51<00:03,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  95%|â–‰| 71/75 [00:52<00:02,  1.35it/s, v_num=au77, train/loss_step=1.840, train/dpo_acc_step=0.542, train/nll_ratEpoch 2:  95%|â–‰| 71/75 [00:52<00:02,  1.35it/s, v_num=au77, train/loss_step=1.590, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  96%|â–‰| 72/75 [00:53<00:02,  1.35it/s, v_num=au77, train/loss_step=1.590, train/dpo_acc_step=0.667, train/nll_ratEpoch 2:  96%|â–‰| 72/75 [00:53<00:02,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  97%|â–‰| 73/75 [00:54<00:01,  1.35it/s, v_num=au77, train/loss_step=2.000, train/dpo_acc_step=0.792, train/nll_ratEpoch 2:  97%|â–‰| 73/75 [00:54<00:01,  1.35it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  99%|â–‰| 74/75 [00:54<00:00,  1.35it/s, v_num=au77, train/loss_step=1.680, train/dpo_acc_step=0.708, train/nll_ratEpoch 2:  99%|â–‰| 74/75 [00:54<00:00,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.833, train/nll_ratEpoch 2: 100%|â–ˆ| 75/75 [00:55<00:00,  1.35it/s, v_num=au77, train/loss_step=1.750, train/dpo_acc_step=0.833, train/nll_ratEpoch 2: 100%|â–ˆ| 75/75 [00:55<00:00,  1.35it/s, v_num=au77, train/loss_step=1.660, train/dpo_acc_step=0.458, train/nll_rat
Validation: |                                                                                       | 0/? [00:00<?, ?it/s][A
Validation:   0%|                                                                                  | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                     | 0/32 [00:00<?, ?it/s][A
Validation DataLoader 0:   3%|â–ˆâ–‰                                                           | 1/32 [00:00<00:12,  2.40it/s][A
Validation DataLoader 0:   6%|â–ˆâ–ˆâ–ˆâ–Š                                                         | 2/32 [00:00<00:12,  2.37it/s][A
Validation DataLoader 0:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                       | 3/32 [00:01<00:12,  2.36it/s][A
Validation DataLoader 0:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 4/32 [00:01<00:11,  2.35it/s][A