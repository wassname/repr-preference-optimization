
base_model: 'NousResearch/Meta-Llama-3.1-8B'
load_in_4bit: True
batch_size: 16
collection_layers: 
  - 10
  - 12
  - 14
  - 16
  - 18
  - 20
  - 22
  - 24
