# not really needed as this is the default params
base_model: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'
collection_layers_side: 
  - 8
  - 10
  - 12
  - 14
  - 16
  - 18
collection_layers_hs
  - 8
  - 18
collection_keys_in:
  - "base_model.model.model.layers.{layer}.self_attn.o_proj"
  - "base_model.model.model.layers.{layer}.mlp.down_proj"
collection_keys_out:
  - "base_model.model.model.layers.{layer}.self_attn.q_proj"
  - "base_model.model.model.layers.{layer}.self_attn.k_proj"
  - "base_model.model.model.layers.{layer}.self_attn.v_proj"
  - "base_model.model.model.layers.{layer}.mlp.gate_proj"
  - "base_model.model.model.layers.{layer}.mlp.up_proj"
