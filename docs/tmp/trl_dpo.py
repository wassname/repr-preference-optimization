https://github.com/huggingface/trl/blob/main/trl/trainer/dpo_trainer.py
